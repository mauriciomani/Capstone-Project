{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is the implementation of Built-In DeepAR sagemaker model \n",
    "This is a supervised learning algorithm for forecasting scalar time series.\n",
    "For more information please visit: https://docs.aws.amazon.com/sagemaker/latest/dg/deepar.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "import pandas as pd\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import boto3\n",
    "import s3fs\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "sagemaker_session = sagemaker.Session()\n",
    "\n",
    "region = sagemaker_session.boto_region_name\n",
    "role = get_execution_role()\n",
    "\n",
    "s3_bucket = \"sagemaker-us-east-1-563718358426\"\n",
    "prefix = \"tryouts\"\n",
    "\n",
    "s3_output_path = \"s3://{}/{}/model\".format(s3_bucket, prefix)\n",
    "\n",
    "image_name = sagemaker.amazon.amazon_estimator.get_image_uri(region, \"forecasting-deepar\", \"latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add information about kaggle competition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>holiday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weather</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>humidity</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>datetime</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2011-01-01 00:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 01:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 02:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.02</td>\n",
       "      <td>13.635</td>\n",
       "      <td>80.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 03:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011-01-01 04:00:00</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.84</td>\n",
       "      <td>14.395</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     season  holiday  workingday  weather  temp   atemp  \\\n",
       "datetime                                                                  \n",
       "2011-01-01 00:00:00     1.0      0.0         0.0      1.0  9.84  14.395   \n",
       "2011-01-01 01:00:00     1.0      0.0         0.0      1.0  9.02  13.635   \n",
       "2011-01-01 02:00:00     1.0      0.0         0.0      1.0  9.02  13.635   \n",
       "2011-01-01 03:00:00     1.0      0.0         0.0      1.0  9.84  14.395   \n",
       "2011-01-01 04:00:00     1.0      0.0         0.0      1.0  9.84  14.395   \n",
       "\n",
       "                     humidity  windspeed  casual  registered  count  \n",
       "datetime                                                             \n",
       "2011-01-01 00:00:00      81.0        0.0     3.0        13.0   16.0  \n",
       "2011-01-01 01:00:00      80.0        0.0     8.0        32.0   40.0  \n",
       "2011-01-01 02:00:00      80.0        0.0     5.0        27.0   32.0  \n",
       "2011-01-01 03:00:00      75.0        0.0     3.0        10.0   13.0  \n",
       "2011-01-01 04:00:00      75.0        0.0     0.0         1.0    1.0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"train.csv\", parse_dates= True, index_col=0)\n",
    "df = df.resample(\"1h\").mean()\n",
    "df.head(5)\n",
    "#I have no null values and have hourly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,7))\n",
    "plt.plot(df[\"count\"])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#12 days \n",
    "prediction_span = 24\n",
    "context =  24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_lines = []\n",
    "count_lines = 0\n",
    "for record in df.index:\n",
    "    target =[str(i) for i in list(df.iloc[count_lines:count_lines + context*7, 10])]\n",
    "    target =[\"NaN\" if i == \"nan\" else round(float(i)) for i in target]\n",
    "    if len(target) == context*7:\n",
    "        dictionary = {\"start\":str(record), \"target\": target}\n",
    "        json_lines.append(dictionary)\n",
    "        count_lines += 1\n",
    "    else:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dicts_to_file(path, data):\n",
    "    with open(path, 'wb') as fp:\n",
    "        for d in data:\n",
    "            fp.write(json.dumps(d).encode(\"utf-8\"))\n",
    "            fp.write(\"\\n\".encode('utf-8'))\n",
    "\n",
    "write_dicts_to_file(\"train.json\", json_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train.json\", \"rb\") as f:\n",
    "    boto3.Session().resource(\"s3\").Bucket(s3_bucket).Object(prefix + \"/train/train.json\").upload_fileobj(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "estimator = sagemaker.estimator.Estimator(\n",
    "    sagemaker_session=sagemaker_session,\n",
    "    image_name=image_name,\n",
    "    role=role,\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.m5.large',\n",
    "    base_job_name='deepAr-forecast',\n",
    "    output_path=s3_output_path)\n",
    "\n",
    "#time_freq for the frequency of the records, every hour\n",
    "hyperparameters = {\n",
    "    \"time_freq\": \"1H\",\n",
    "    \"epochs\": \"80\",\n",
    "    \"early_stopping_patience\": \"10\",\n",
    "    \"mini_batch_size\": \"64\",\n",
    "    \"learning_rate\": \"5E-4\",\n",
    "    \"context_length\": str(context),\n",
    "    \"prediction_length\": str(prediction_span)}\n",
    "\n",
    "estimator.set_hyperparameters(**hyperparameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-07 01:20:27 Starting - Starting the training job...............\n",
      "2020-09-07 01:22:35 Starting - Launching requested ML instances.........\n",
      "2020-09-07 01:24:09 Starting - Preparing the instances for training......\n",
      "2020-09-07 01:25:07 Downloading - Downloading input data...\n",
      "2020-09-07 01:25:50 Training - Training image download completed. Training in progress.\u001b[34mArguments: train\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:52 INFO 139866244298560] Reading default configuration from /opt/amazon/lib/python2.7/site-packages/algorithm/resources/default-input.json: {u'num_dynamic_feat': u'auto', u'dropout_rate': u'0.10', u'mini_batch_size': u'128', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'_num_gpus': u'auto', u'num_eval_samples': u'100', u'learning_rate': u'0.001', u'num_cells': u'40', u'num_layers': u'2', u'embedding_dimension': u'10', u'_kvstore': u'auto', u'_num_kv_servers': u'auto', u'cardinality': u'auto', u'likelihood': u'student-t', u'early_stopping_patience': u''}\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:52 INFO 139866244298560] Reading provided configuration from /opt/ml/input/config/hyperparameters.json: {u'learning_rate': u'5E-4', u'prediction_length': u'24', u'epochs': u'80', u'time_freq': u'1H', u'context_length': u'24', u'mini_batch_size': u'64', u'early_stopping_patience': u'10'}\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:52 INFO 139866244298560] Final configuration: {u'dropout_rate': u'0.10', u'test_quantiles': u'[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]', u'_tuning_objective_metric': u'', u'num_eval_samples': u'100', u'learning_rate': u'5E-4', u'num_layers': u'2', u'epochs': u'80', u'embedding_dimension': u'10', u'num_cells': u'40', u'_num_kv_servers': u'auto', u'mini_batch_size': u'64', u'likelihood': u'student-t', u'num_dynamic_feat': u'auto', u'cardinality': u'auto', u'_num_gpus': u'auto', u'prediction_length': u'24', u'time_freq': u'1H', u'context_length': u'24', u'_kvstore': u'auto', u'early_stopping_patience': u'10'}\u001b[0m\n",
      "\u001b[34mProcess 1 is a worker.\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:52 INFO 139866244298560] Detected entry point for worker worker\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:52 INFO 139866244298560] Using early stopping with patience 10\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:52 INFO 139866244298560] [cardinality=auto] `cat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:52 INFO 139866244298560] [num_dynamic_feat=auto] `dynamic_feat` field was NOT found in the file `/opt/ml/input/data/train/train.json` and will NOT be used for training.\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:54 INFO 139866244298560] Training set statistics:\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:54 INFO 139866244298560] Integer time series\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:54 INFO 139866244298560] number of time series: 17089\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:54 INFO 139866244298560] number of observations: 2870952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:54 INFO 139866244298560] mean target length: 168\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:54 INFO 139866244298560] min/mean/max target: 0.0/120.75380501/977.0\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:54 INFO 139866244298560] mean abs(target): 120.75380501\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:54 INFO 139866244298560] contains missing values: yes (37.3%)\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:54 INFO 139866244298560] No test channel found not running evaluations\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:54 INFO 139866244298560] nvidia-smi took: 0.0251290798187 secs to identify 0 gpus\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:54 INFO 139866244298560] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:54 INFO 139866244298560] Create Store: local\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 95.4289436340332, \"sum\": 95.4289436340332, \"min\": 95.4289436340332}}, \"EndTime\": 1599441954.851994, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599441954.755658}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:54 INFO 139866244298560] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"initialize.time\": {\"count\": 1, \"max\": 280.6990146636963, \"sum\": 280.6990146636963, \"min\": 280.6990146636963}}, \"EndTime\": 1599441955.036493, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599441954.852084}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:55 INFO 139866244298560] Epoch[0] Batch[0] avg_epoch_loss=3.138515\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=0 train loss <loss>=3.13851451874\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:55 INFO 139866244298560] Epoch[0] Batch[5] avg_epoch_loss=3.005251\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=5 train loss <loss>=3.00525128841\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:55 INFO 139866244298560] Epoch[0] Batch [5]#011Speed: 604.25 samples/sec#011loss=3.005251\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:56 INFO 139866244298560] Epoch[0] Batch[10] avg_epoch_loss=3.003116\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=10 train loss <loss>=3.00055375099\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:56 INFO 139866244298560] Epoch[0] Batch [10]#011Speed: 374.11 samples/sec#011loss=3.000554\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:57 INFO 139866244298560] Epoch[0] Batch[15] avg_epoch_loss=3.299503\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=15 train loss <loss>=3.95155549049\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:57 INFO 139866244298560] Epoch[0] Batch [15]#011Speed: 416.63 samples/sec#011loss=3.951555\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:58 INFO 139866244298560] Epoch[0] Batch[20] avg_epoch_loss=3.447801\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=20 train loss <loss>=3.92235331535\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:58 INFO 139866244298560] Epoch[0] Batch [20]#011Speed: 419.11 samples/sec#011loss=3.922353\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:59 INFO 139866244298560] Epoch[0] Batch[25] avg_epoch_loss=3.499814\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=25 train loss <loss>=3.71826944351\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:59 INFO 139866244298560] Epoch[0] Batch [25]#011Speed: 351.19 samples/sec#011loss=3.718269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:59 INFO 139866244298560] Epoch[0] Batch[30] avg_epoch_loss=3.556221\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=30 train loss <loss>=3.84953866005\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:25:59 INFO 139866244298560] Epoch[0] Batch [30]#011Speed: 462.58 samples/sec#011loss=3.849539\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:00 INFO 139866244298560] Epoch[0] Batch[35] avg_epoch_loss=3.608903\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=35 train loss <loss>=3.93552718163\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:00 INFO 139866244298560] Epoch[0] Batch [35]#011Speed: 570.71 samples/sec#011loss=3.935527\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:01 INFO 139866244298560] Epoch[0] Batch[40] avg_epoch_loss=3.598615\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=40 train loss <loss>=3.52454252243\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:01 INFO 139866244298560] Epoch[0] Batch [40]#011Speed: 459.57 samples/sec#011loss=3.524543\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:01 INFO 139866244298560] Epoch[0] Batch[45] avg_epoch_loss=3.567699\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=45 train loss <loss>=3.31419024467\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:01 INFO 139866244298560] Epoch[0] Batch [45]#011Speed: 515.11 samples/sec#011loss=3.314190\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:02 INFO 139866244298560] Epoch[0] Batch[50] avg_epoch_loss=3.533531\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=50 train loss <loss>=3.21917967796\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:02 INFO 139866244298560] Epoch[0] Batch [50]#011Speed: 438.51 samples/sec#011loss=3.219180\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:03 INFO 139866244298560] Epoch[0] Batch[55] avg_epoch_loss=3.500772\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=55 train loss <loss>=3.16663417816\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:03 INFO 139866244298560] Epoch[0] Batch [55]#011Speed: 593.84 samples/sec#011loss=3.166634\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:03 INFO 139866244298560] Epoch[0] Batch[60] avg_epoch_loss=3.481518\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=60 train loss <loss>=3.26587538719\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:03 INFO 139866244298560] Epoch[0] Batch [60]#011Speed: 444.26 samples/sec#011loss=3.265875\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:04 INFO 139866244298560] Epoch[0] Batch[65] avg_epoch_loss=3.458791\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=65 train loss <loss>=3.18151521683\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:04 INFO 139866244298560] Epoch[0] Batch [65]#011Speed: 585.92 samples/sec#011loss=3.181515\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:05 INFO 139866244298560] Epoch[0] Batch[70] avg_epoch_loss=3.469594\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=70 train loss <loss>=3.61219825745\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:05 INFO 139866244298560] Epoch[0] Batch [70]#011Speed: 446.77 samples/sec#011loss=3.612198\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:05 INFO 139866244298560] Epoch[0] Batch[75] avg_epoch_loss=3.489991\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=75 train loss <loss>=3.77962908745\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:05 INFO 139866244298560] Epoch[0] Batch [75]#011Speed: 601.19 samples/sec#011loss=3.779629\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:06 INFO 139866244298560] Epoch[0] Batch[80] avg_epoch_loss=3.511679\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=80 train loss <loss>=3.84133234024\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:06 INFO 139866244298560] Epoch[0] Batch [80]#011Speed: 443.90 samples/sec#011loss=3.841332\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:06 INFO 139866244298560] Epoch[0] Batch[85] avg_epoch_loss=3.533410\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=85 train loss <loss>=3.88546295166\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:06 INFO 139866244298560] Epoch[0] Batch [85]#011Speed: 537.11 samples/sec#011loss=3.885463\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:07 INFO 139866244298560] Epoch[0] Batch[90] avg_epoch_loss=3.556310\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=90 train loss <loss>=3.95018706322\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:07 INFO 139866244298560] Epoch[0] Batch [90]#011Speed: 428.13 samples/sec#011loss=3.950187\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:08 INFO 139866244298560] Epoch[0] Batch[95] avg_epoch_loss=3.561457\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=95 train loss <loss>=3.65512604713\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:08 INFO 139866244298560] Epoch[0] Batch [95]#011Speed: 598.27 samples/sec#011loss=3.655126\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:08 INFO 139866244298560] Epoch[0] Batch[100] avg_epoch_loss=3.558968\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=100 train loss <loss>=3.51118450165\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:08 INFO 139866244298560] Epoch[0] Batch [100]#011Speed: 433.08 samples/sec#011loss=3.511185\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:09 INFO 139866244298560] Epoch[0] Batch[105] avg_epoch_loss=3.534703\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=105 train loss <loss>=3.04453830719\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:09 INFO 139866244298560] Epoch[0] Batch [105]#011Speed: 525.92 samples/sec#011loss=3.044538\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:10 INFO 139866244298560] Epoch[0] Batch[110] avg_epoch_loss=3.515589\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=110 train loss <loss>=3.1103852272\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:10 INFO 139866244298560] Epoch[0] Batch [110]#011Speed: 428.95 samples/sec#011loss=3.110385\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:10 INFO 139866244298560] Epoch[0] Batch[115] avg_epoch_loss=3.485288\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=115 train loss <loss>=2.81260704994\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:10 INFO 139866244298560] Epoch[0] Batch [115]#011Speed: 601.01 samples/sec#011loss=2.812607\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:11 INFO 139866244298560] Epoch[0] Batch[120] avg_epoch_loss=3.458898\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=120 train loss <loss>=2.84664173126\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:11 INFO 139866244298560] Epoch[0] Batch [120]#011Speed: 446.09 samples/sec#011loss=2.846642\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:12 INFO 139866244298560] Epoch[0] Batch[125] avg_epoch_loss=3.428407\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=125 train loss <loss>=2.69052824974\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:12 INFO 139866244298560] Epoch[0] Batch [125]#011Speed: 555.94 samples/sec#011loss=2.690528\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:12 INFO 139866244298560] Epoch[0] Batch[130] avg_epoch_loss=3.417927\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=130 train loss <loss>=3.15383777618\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:12 INFO 139866244298560] Epoch[0] Batch [130]#011Speed: 443.19 samples/sec#011loss=3.153838\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:13 INFO 139866244298560] Epoch[0] Batch[135] avg_epoch_loss=3.400957\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=135 train loss <loss>=2.95632991791\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:13 INFO 139866244298560] Epoch[0] Batch [135]#011Speed: 599.23 samples/sec#011loss=2.956330\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:14 INFO 139866244298560] Epoch[0] Batch[140] avg_epoch_loss=3.411755\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=140 train loss <loss>=3.70547795296\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:14 INFO 139866244298560] Epoch[0] Batch [140]#011Speed: 430.86 samples/sec#011loss=3.705478\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:14 INFO 139866244298560] Epoch[0] Batch[145] avg_epoch_loss=3.429291\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=145 train loss <loss>=3.92380843163\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:14 INFO 139866244298560] Epoch[0] Batch [145]#011Speed: 598.94 samples/sec#011loss=3.923808\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:15 INFO 139866244298560] Epoch[0] Batch[150] avg_epoch_loss=3.430826\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=150 train loss <loss>=3.475644207\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:15 INFO 139866244298560] Epoch[0] Batch [150]#011Speed: 421.55 samples/sec#011loss=3.475644\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:15 INFO 139866244298560] Epoch[0] Batch[155] avg_epoch_loss=3.425583\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=155 train loss <loss>=3.26723308563\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:15 INFO 139866244298560] Epoch[0] Batch [155]#011Speed: 594.77 samples/sec#011loss=3.267233\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:16 INFO 139866244298560] Epoch[0] Batch[160] avg_epoch_loss=3.419784\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=160 train loss <loss>=3.23886036873\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:16 INFO 139866244298560] Epoch[0] Batch [160]#011Speed: 441.51 samples/sec#011loss=3.238860\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:17 INFO 139866244298560] Epoch[0] Batch[165] avg_epoch_loss=3.408754\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=165 train loss <loss>=3.05357227325\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:17 INFO 139866244298560] Epoch[0] Batch [165]#011Speed: 542.08 samples/sec#011loss=3.053572\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:17 INFO 139866244298560] Epoch[0] Batch[170] avg_epoch_loss=3.390979\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=170 train loss <loss>=2.80086956024\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:17 INFO 139866244298560] Epoch[0] Batch [170]#011Speed: 436.08 samples/sec#011loss=2.800870\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:18 INFO 139866244298560] Epoch[0] Batch[175] avg_epoch_loss=3.371598\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=175 train loss <loss>=2.70875530243\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:18 INFO 139866244298560] Epoch[0] Batch [175]#011Speed: 595.19 samples/sec#011loss=2.708755\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:19 INFO 139866244298560] Epoch[0] Batch[180] avg_epoch_loss=3.365090\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=180 train loss <loss>=3.13600993156\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:19 INFO 139866244298560] Epoch[0] Batch [180]#011Speed: 414.55 samples/sec#011loss=3.136010\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:20 INFO 139866244298560] Epoch[0] Batch[185] avg_epoch_loss=3.360695\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=185 train loss <loss>=3.20160307884\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:20 INFO 139866244298560] Epoch[0] Batch [185]#011Speed: 431.77 samples/sec#011loss=3.201603\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:20 INFO 139866244298560] Epoch[0] Batch[190] avg_epoch_loss=3.359167\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=190 train loss <loss>=3.30230669975\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:20 INFO 139866244298560] Epoch[0] Batch [190]#011Speed: 595.90 samples/sec#011loss=3.302307\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:21 INFO 139866244298560] Epoch[0] Batch[195] avg_epoch_loss=3.360332\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=195 train loss <loss>=3.40483241081\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:21 INFO 139866244298560] Epoch[0] Batch [195]#011Speed: 426.69 samples/sec#011loss=3.404832\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:21 INFO 139866244298560] Epoch[0] Batch[200] avg_epoch_loss=3.372657\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=200 train loss <loss>=3.8558277607\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:21 INFO 139866244298560] Epoch[0] Batch [200]#011Speed: 600.25 samples/sec#011loss=3.855828\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:22 INFO 139866244298560] Epoch[0] Batch[205] avg_epoch_loss=3.388329\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=205 train loss <loss>=4.01831746101\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:22 INFO 139866244298560] Epoch[0] Batch [205]#011Speed: 406.62 samples/sec#011loss=4.018317\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:23 INFO 139866244298560] Epoch[0] Batch[210] avg_epoch_loss=3.402389\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=210 train loss <loss>=3.98167796135\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:23 INFO 139866244298560] Epoch[0] Batch [210]#011Speed: 591.95 samples/sec#011loss=3.981678\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:23 INFO 139866244298560] Epoch[0] Batch[215] avg_epoch_loss=3.396451\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=215 train loss <loss>=3.14586510658\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:24 INFO 139866244298560] Epoch[0] Batch [215]#011Speed: 395.73 samples/sec#011loss=3.145865\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:24 INFO 139866244298560] Epoch[0] Batch[220] avg_epoch_loss=3.382583\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=220 train loss <loss>=2.78347125053\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:24 INFO 139866244298560] Epoch[0] Batch [220]#011Speed: 605.45 samples/sec#011loss=2.783471\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:25 INFO 139866244298560] Epoch[0] Batch[225] avg_epoch_loss=3.371851\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=225 train loss <loss>=2.89751491547\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:25 INFO 139866244298560] Epoch[0] Batch [225]#011Speed: 419.17 samples/sec#011loss=2.897515\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:25 INFO 139866244298560] Epoch[0] Batch[230] avg_epoch_loss=3.362140\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=230 train loss <loss>=2.92318778038\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:25 INFO 139866244298560] Epoch[0] Batch [230]#011Speed: 600.21 samples/sec#011loss=2.923188\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:26 INFO 139866244298560] Epoch[0] Batch[235] avg_epoch_loss=3.357143\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=235 train loss <loss>=3.1262901783\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:26 INFO 139866244298560] Epoch[0] Batch [235]#011Speed: 403.22 samples/sec#011loss=3.126290\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:27 INFO 139866244298560] Epoch[0] Batch[240] avg_epoch_loss=3.356780\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=240 train loss <loss>=3.33966770172\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:27 INFO 139866244298560] Epoch[0] Batch [240]#011Speed: 553.26 samples/sec#011loss=3.339668\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:27 INFO 139866244298560] Epoch[0] Batch[245] avg_epoch_loss=3.349732\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=245 train loss <loss>=3.01001105309\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:27 INFO 139866244298560] Epoch[0] Batch [245]#011Speed: 419.03 samples/sec#011loss=3.010011\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:28 INFO 139866244298560] Epoch[0] Batch[250] avg_epoch_loss=3.356359\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=250 train loss <loss>=3.6823931694\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:28 INFO 139866244298560] Epoch[0] Batch [250]#011Speed: 592.23 samples/sec#011loss=3.682393\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:29 INFO 139866244298560] Epoch[0] Batch[255] avg_epoch_loss=3.371026\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=255 train loss <loss>=4.10728459358\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:29 INFO 139866244298560] Epoch[0] Batch [255]#011Speed: 424.39 samples/sec#011loss=4.107285\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:29 INFO 139866244298560] Epoch[0] Batch[260] avg_epoch_loss=3.380555\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=260 train loss <loss>=3.86844263077\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:29 INFO 139866244298560] Epoch[0] Batch [260]#011Speed: 596.46 samples/sec#011loss=3.868443\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:30 INFO 139866244298560] Epoch[0] Batch[265] avg_epoch_loss=3.375852\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=265 train loss <loss>=3.13036799431\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:30 INFO 139866244298560] Epoch[0] Batch [265]#011Speed: 425.25 samples/sec#011loss=3.130368\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:31 INFO 139866244298560] Epoch[0] Batch[270] avg_epoch_loss=3.372004\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, batch=270 train loss <loss>=3.16731872559\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:31 INFO 139866244298560] Epoch[0] Batch [270]#011Speed: 596.60 samples/sec#011loss=3.167319\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:31 INFO 139866244298560] processed a total of 17409 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"epochs\": {\"count\": 1, \"max\": 80, \"sum\": 80.0, \"min\": 80}, \"update.time\": {\"count\": 1, \"max\": 36268.55206489563, \"sum\": 36268.55206489563, \"min\": 36268.55206489563}}, \"EndTime\": 1599441991.305201, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599441955.036552}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:31 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=480.000344565 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:31 INFO 139866244298560] #progress_metric: host=algo-1, completed 1 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=0, train loss <loss>=3.38186289976\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:31 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:31 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_3b0f2e8c-61e2-4477-8397-0f1d52e71a80-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 20.01786231994629, \"sum\": 20.01786231994629, \"min\": 20.01786231994629}}, \"EndTime\": 1599441991.326108, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599441991.305319}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:31 INFO 139866244298560] Epoch[1] Batch[0] avg_epoch_loss=2.474025\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=0 train loss <loss>=2.47402477264\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:32 INFO 139866244298560] Epoch[1] Batch[5] avg_epoch_loss=2.241341\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=5 train loss <loss>=2.24134075642\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:32 INFO 139866244298560] Epoch[1] Batch [5]#011Speed: 591.59 samples/sec#011loss=2.241341\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:32 INFO 139866244298560] Epoch[1] Batch[10] avg_epoch_loss=2.391332\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=10 train loss <loss>=2.57132225037\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:32 INFO 139866244298560] Epoch[1] Batch [10]#011Speed: 455.93 samples/sec#011loss=2.571322\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:33 INFO 139866244298560] Epoch[1] Batch[15] avg_epoch_loss=2.590876\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=15 train loss <loss>=3.02987132072\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:33 INFO 139866244298560] Epoch[1] Batch [15]#011Speed: 596.16 samples/sec#011loss=3.029871\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:34 INFO 139866244298560] Epoch[1] Batch[20] avg_epoch_loss=2.718811\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=20 train loss <loss>=3.12820167542\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:34 INFO 139866244298560] Epoch[1] Batch [20]#011Speed: 471.27 samples/sec#011loss=3.128202\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:34 INFO 139866244298560] Epoch[1] Batch[25] avg_epoch_loss=2.870923\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=25 train loss <loss>=3.50979719162\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:34 INFO 139866244298560] Epoch[1] Batch [25]#011Speed: 599.59 samples/sec#011loss=3.509797\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:35 INFO 139866244298560] Epoch[1] Batch[30] avg_epoch_loss=2.894468\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=30 train loss <loss>=3.016898489\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:35 INFO 139866244298560] Epoch[1] Batch [30]#011Speed: 476.61 samples/sec#011loss=3.016898\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:35 INFO 139866244298560] Epoch[1] Batch[35] avg_epoch_loss=2.870959\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=35 train loss <loss>=2.72520194054\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:35 INFO 139866244298560] Epoch[1] Batch [35]#011Speed: 593.79 samples/sec#011loss=2.725202\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:36 INFO 139866244298560] Epoch[1] Batch[40] avg_epoch_loss=2.858447\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=40 train loss <loss>=2.76836438179\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:36 INFO 139866244298560] Epoch[1] Batch [40]#011Speed: 476.59 samples/sec#011loss=2.768364\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:36 INFO 139866244298560] Epoch[1] Batch[45] avg_epoch_loss=2.856891\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=45 train loss <loss>=2.84413099289\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:36 INFO 139866244298560] Epoch[1] Batch [45]#011Speed: 601.30 samples/sec#011loss=2.844131\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:37 INFO 139866244298560] Epoch[1] Batch[50] avg_epoch_loss=2.830715\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=50 train loss <loss>=2.58989257813\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:37 INFO 139866244298560] Epoch[1] Batch [50]#011Speed: 452.81 samples/sec#011loss=2.589893\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:38 INFO 139866244298560] Epoch[1] Batch[55] avg_epoch_loss=2.792630\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=55 train loss <loss>=2.40416185856\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:38 INFO 139866244298560] Epoch[1] Batch [55]#011Speed: 594.36 samples/sec#011loss=2.404162\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:38 INFO 139866244298560] Epoch[1] Batch[60] avg_epoch_loss=2.802032\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=60 train loss <loss>=2.90733604431\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:38 INFO 139866244298560] Epoch[1] Batch [60]#011Speed: 471.83 samples/sec#011loss=2.907336\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:39 INFO 139866244298560] Epoch[1] Batch[65] avg_epoch_loss=2.837802\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=65 train loss <loss>=3.27419419289\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:39 INFO 139866244298560] Epoch[1] Batch [65]#011Speed: 450.79 samples/sec#011loss=3.274194\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:40 INFO 139866244298560] Epoch[1] Batch[70] avg_epoch_loss=2.915662\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=70 train loss <loss>=3.94341835976\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:40 INFO 139866244298560] Epoch[1] Batch [70]#011Speed: 593.62 samples/sec#011loss=3.943418\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:40 INFO 139866244298560] Epoch[1] Batch[75] avg_epoch_loss=2.961412\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=75 train loss <loss>=3.61105594635\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:40 INFO 139866244298560] Epoch[1] Batch [75]#011Speed: 487.31 samples/sec#011loss=3.611056\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:41 INFO 139866244298560] Epoch[1] Batch[80] avg_epoch_loss=2.977325\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=80 train loss <loss>=3.21920962334\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:41 INFO 139866244298560] Epoch[1] Batch [80]#011Speed: 599.45 samples/sec#011loss=3.219210\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:42 INFO 139866244298560] Epoch[1] Batch[85] avg_epoch_loss=2.980950\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=85 train loss <loss>=3.03966579437\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:42 INFO 139866244298560] Epoch[1] Batch [85]#011Speed: 471.58 samples/sec#011loss=3.039666\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:42 INFO 139866244298560] Epoch[1] Batch[90] avg_epoch_loss=2.965548\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=90 train loss <loss>=2.70063295364\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:42 INFO 139866244298560] Epoch[1] Batch [90]#011Speed: 561.17 samples/sec#011loss=2.700633\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:43 INFO 139866244298560] Epoch[1] Batch[95] avg_epoch_loss=2.949864\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=95 train loss <loss>=2.66441822052\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:43 INFO 139866244298560] Epoch[1] Batch [95]#011Speed: 469.48 samples/sec#011loss=2.664418\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:43 INFO 139866244298560] Epoch[1] Batch[100] avg_epoch_loss=2.951094\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=100 train loss <loss>=2.97472252846\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:43 INFO 139866244298560] Epoch[1] Batch [100]#011Speed: 580.35 samples/sec#011loss=2.974723\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:44 INFO 139866244298560] Epoch[1] Batch[105] avg_epoch_loss=2.953287\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=105 train loss <loss>=2.99758553505\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:44 INFO 139866244298560] Epoch[1] Batch [105]#011Speed: 461.75 samples/sec#011loss=2.997586\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:45 INFO 139866244298560] Epoch[1] Batch[110] avg_epoch_loss=2.947063\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=110 train loss <loss>=2.81511392593\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:45 INFO 139866244298560] Epoch[1] Batch [110]#011Speed: 590.85 samples/sec#011loss=2.815114\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:45 INFO 139866244298560] Epoch[1] Batch[115] avg_epoch_loss=2.954551\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=115 train loss <loss>=3.12078771591\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:45 INFO 139866244298560] Epoch[1] Batch [115]#011Speed: 472.03 samples/sec#011loss=3.120788\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:46 INFO 139866244298560] Epoch[1] Batch[120] avg_epoch_loss=2.965361\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=120 train loss <loss>=3.21613636017\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:46 INFO 139866244298560] Epoch[1] Batch [120]#011Speed: 599.75 samples/sec#011loss=3.216136\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:46 INFO 139866244298560] Epoch[1] Batch[125] avg_epoch_loss=2.974481\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=125 train loss <loss>=3.19518508911\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:46 INFO 139866244298560] Epoch[1] Batch [125]#011Speed: 486.54 samples/sec#011loss=3.195185\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:47 INFO 139866244298560] Epoch[1] Batch[130] avg_epoch_loss=2.990869\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=130 train loss <loss>=3.40386571884\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:47 INFO 139866244298560] Epoch[1] Batch [130]#011Speed: 557.30 samples/sec#011loss=3.403866\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:48 INFO 139866244298560] Epoch[1] Batch[135] avg_epoch_loss=2.992754\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=135 train loss <loss>=3.04212245941\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:48 INFO 139866244298560] Epoch[1] Batch [135]#011Speed: 355.52 samples/sec#011loss=3.042122\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:48 INFO 139866244298560] Epoch[1] Batch[140] avg_epoch_loss=2.996388\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=140 train loss <loss>=3.09523129463\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:48 INFO 139866244298560] Epoch[1] Batch [140]#011Speed: 556.17 samples/sec#011loss=3.095231\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:49 INFO 139866244298560] Epoch[1] Batch[145] avg_epoch_loss=2.977888\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=145 train loss <loss>=2.45619082451\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:49 INFO 139866244298560] Epoch[1] Batch [145]#011Speed: 471.07 samples/sec#011loss=2.456191\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:50 INFO 139866244298560] Epoch[1] Batch[150] avg_epoch_loss=2.963274\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=150 train loss <loss>=2.53654093742\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:50 INFO 139866244298560] Epoch[1] Batch [150]#011Speed: 592.07 samples/sec#011loss=2.536541\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:50 INFO 139866244298560] Epoch[1] Batch[155] avg_epoch_loss=2.960368\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=155 train loss <loss>=2.87262806892\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:50 INFO 139866244298560] Epoch[1] Batch [155]#011Speed: 478.34 samples/sec#011loss=2.872628\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:51 INFO 139866244298560] Epoch[1] Batch[160] avg_epoch_loss=2.961691\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=160 train loss <loss>=3.0029542923\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:51 INFO 139866244298560] Epoch[1] Batch [160]#011Speed: 598.56 samples/sec#011loss=3.002954\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:52 INFO 139866244298560] Epoch[1] Batch[165] avg_epoch_loss=2.950587\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=165 train loss <loss>=2.59304451942\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:52 INFO 139866244298560] Epoch[1] Batch [165]#011Speed: 466.08 samples/sec#011loss=2.593045\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:52 INFO 139866244298560] Epoch[1] Batch[170] avg_epoch_loss=2.950495\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=170 train loss <loss>=2.94742007256\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:52 INFO 139866244298560] Epoch[1] Batch [170]#011Speed: 597.03 samples/sec#011loss=2.947420\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:53 INFO 139866244298560] Epoch[1] Batch[175] avg_epoch_loss=2.959657\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=175 train loss <loss>=3.2729968071\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:53 INFO 139866244298560] Epoch[1] Batch [175]#011Speed: 441.35 samples/sec#011loss=3.272997\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:54 INFO 139866244298560] Epoch[1] Batch[180] avg_epoch_loss=2.970476\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=180 train loss <loss>=3.35130457878\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:54 INFO 139866244298560] Epoch[1] Batch [180]#011Speed: 475.31 samples/sec#011loss=3.351305\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:54 INFO 139866244298560] Epoch[1] Batch[185] avg_epoch_loss=2.993446\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=185 train loss <loss>=3.82498416901\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:54 INFO 139866244298560] Epoch[1] Batch [185]#011Speed: 586.28 samples/sec#011loss=3.824984\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:55 INFO 139866244298560] Epoch[1] Batch[190] avg_epoch_loss=3.013877\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=190 train loss <loss>=3.77388577461\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:55 INFO 139866244298560] Epoch[1] Batch [190]#011Speed: 486.99 samples/sec#011loss=3.773886\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:55 INFO 139866244298560] Epoch[1] Batch[195] avg_epoch_loss=3.025920\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=195 train loss <loss>=3.48597893715\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:55 INFO 139866244298560] Epoch[1] Batch [195]#011Speed: 595.48 samples/sec#011loss=3.485979\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:56 INFO 139866244298560] Epoch[1] Batch[200] avg_epoch_loss=3.039807\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=200 train loss <loss>=3.58419289589\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:56 INFO 139866244298560] Epoch[1] Batch [200]#011Speed: 485.83 samples/sec#011loss=3.584193\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:56 INFO 139866244298560] Epoch[1] Batch[205] avg_epoch_loss=3.039387\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=205 train loss <loss>=3.02250914574\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:56 INFO 139866244298560] Epoch[1] Batch [205]#011Speed: 599.85 samples/sec#011loss=3.022509\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:57 INFO 139866244298560] Epoch[1] Batch[210] avg_epoch_loss=3.036479\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=210 train loss <loss>=2.91663346291\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:57 INFO 139866244298560] Epoch[1] Batch [210]#011Speed: 485.70 samples/sec#011loss=2.916633\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:58 INFO 139866244298560] Epoch[1] Batch[215] avg_epoch_loss=3.031632\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=215 train loss <loss>=2.82710371017\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:58 INFO 139866244298560] Epoch[1] Batch [215]#011Speed: 589.14 samples/sec#011loss=2.827104\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:58 INFO 139866244298560] Epoch[1] Batch[220] avg_epoch_loss=3.024970\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=220 train loss <loss>=2.73718094826\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:58 INFO 139866244298560] Epoch[1] Batch [220]#011Speed: 448.38 samples/sec#011loss=2.737181\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:59 INFO 139866244298560] Epoch[1] Batch[225] avg_epoch_loss=3.016196\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=225 train loss <loss>=2.62838523388\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:26:59 INFO 139866244298560] Epoch[1] Batch [225]#011Speed: 582.35 samples/sec#011loss=2.628385\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:00 INFO 139866244298560] Epoch[1] Batch[230] avg_epoch_loss=3.019099\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=230 train loss <loss>=3.15029115677\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:00 INFO 139866244298560] Epoch[1] Batch [230]#011Speed: 470.19 samples/sec#011loss=3.150291\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:00 INFO 139866244298560] Epoch[1] Batch[235] avg_epoch_loss=3.027288\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=235 train loss <loss>=3.40561914444\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:00 INFO 139866244298560] Epoch[1] Batch [235]#011Speed: 598.41 samples/sec#011loss=3.405619\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:01 INFO 139866244298560] Epoch[1] Batch[240] avg_epoch_loss=3.047826\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=240 train loss <loss>=4.01722602844\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:01 INFO 139866244298560] Epoch[1] Batch [240]#011Speed: 471.92 samples/sec#011loss=4.017226\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:01 INFO 139866244298560] Epoch[1] Batch[245] avg_epoch_loss=3.064797\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=245 train loss <loss>=3.8828312397\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:01 INFO 139866244298560] Epoch[1] Batch [245]#011Speed: 478.76 samples/sec#011loss=3.882831\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:02 INFO 139866244298560] Epoch[1] Batch[250] avg_epoch_loss=3.064040\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=250 train loss <loss>=3.02679023743\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:02 INFO 139866244298560] Epoch[1] Batch [250]#011Speed: 593.75 samples/sec#011loss=3.026790\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:03 INFO 139866244298560] Epoch[1] Batch[255] avg_epoch_loss=3.064833\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=255 train loss <loss>=3.10463247299\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:03 INFO 139866244298560] Epoch[1] Batch [255]#011Speed: 471.14 samples/sec#011loss=3.104632\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:03 INFO 139866244298560] Epoch[1] Batch[260] avg_epoch_loss=3.060006\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=260 train loss <loss>=2.81286025047\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:03 INFO 139866244298560] Epoch[1] Batch [260]#011Speed: 564.09 samples/sec#011loss=2.812860\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:04 INFO 139866244298560] Epoch[1] Batch[265] avg_epoch_loss=3.062816\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, batch=265 train loss <loss>=3.209471035\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:04 INFO 139866244298560] Epoch[1] Batch [265]#011Speed: 560.09 samples/sec#011loss=3.209471\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:04 INFO 139866244298560] processed a total of 17111 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33229.554891586304, \"sum\": 33229.554891586304, \"min\": 33229.554891586304}}, \"EndTime\": 1599442024.555857, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599441991.326238}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:04 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=514.930844968 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:04 INFO 139866244298560] #progress_metric: host=algo-1, completed 2 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=1, train loss <loss>=3.07395744235\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:04 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:04 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_d31a9a4c-bd78-4380-b2c1-96103154ac32-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.280982971191406, \"sum\": 18.280982971191406, \"min\": 18.280982971191406}}, \"EndTime\": 1599442024.57519, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442024.555969}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:04 INFO 139866244298560] Epoch[2] Batch[0] avg_epoch_loss=2.403867\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=0 train loss <loss>=2.40386652946\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:05 INFO 139866244298560] Epoch[2] Batch[5] avg_epoch_loss=2.389690\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=5 train loss <loss>=2.3896895647\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:05 INFO 139866244298560] Epoch[2] Batch [5]#011Speed: 596.26 samples/sec#011loss=2.389690\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:06 INFO 139866244298560] Epoch[2] Batch[10] avg_epoch_loss=2.521517\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=10 train loss <loss>=2.67970890999\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:06 INFO 139866244298560] Epoch[2] Batch [10]#011Speed: 461.02 samples/sec#011loss=2.679709\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:06 INFO 139866244298560] Epoch[2] Batch[15] avg_epoch_loss=2.637152\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=15 train loss <loss>=2.8915491581\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:06 INFO 139866244298560] Epoch[2] Batch [15]#011Speed: 582.26 samples/sec#011loss=2.891549\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:07 INFO 139866244298560] Epoch[2] Batch[20] avg_epoch_loss=2.714874\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=20 train loss <loss>=2.96358561516\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:07 INFO 139866244298560] Epoch[2] Batch [20]#011Speed: 467.33 samples/sec#011loss=2.963586\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:07 INFO 139866244298560] Epoch[2] Batch[25] avg_epoch_loss=2.780248\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=25 train loss <loss>=3.05481729507\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:07 INFO 139866244298560] Epoch[2] Batch [25]#011Speed: 596.06 samples/sec#011loss=3.054817\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:08 INFO 139866244298560] Epoch[2] Batch[30] avg_epoch_loss=2.814581\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=30 train loss <loss>=2.99311256409\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:08 INFO 139866244298560] Epoch[2] Batch [30]#011Speed: 455.06 samples/sec#011loss=2.993113\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:09 INFO 139866244298560] Epoch[2] Batch[35] avg_epoch_loss=2.811894\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=35 train loss <loss>=2.79523916245\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:09 INFO 139866244298560] Epoch[2] Batch [35]#011Speed: 583.01 samples/sec#011loss=2.795239\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:09 INFO 139866244298560] Epoch[2] Batch[40] avg_epoch_loss=2.811294\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=40 train loss <loss>=2.80697221756\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:09 INFO 139866244298560] Epoch[2] Batch [40]#011Speed: 435.73 samples/sec#011loss=2.806972\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:10 INFO 139866244298560] Epoch[2] Batch[45] avg_epoch_loss=2.819372\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=45 train loss <loss>=2.88561224937\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:10 INFO 139866244298560] Epoch[2] Batch [45]#011Speed: 594.80 samples/sec#011loss=2.885612\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:11 INFO 139866244298560] Epoch[2] Batch[50] avg_epoch_loss=2.789268\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=50 train loss <loss>=2.51230649948\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:11 INFO 139866244298560] Epoch[2] Batch [50]#011Speed: 477.65 samples/sec#011loss=2.512306\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:11 INFO 139866244298560] Epoch[2] Batch[55] avg_epoch_loss=2.752009\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=55 train loss <loss>=2.3719643116\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:11 INFO 139866244298560] Epoch[2] Batch [55]#011Speed: 597.12 samples/sec#011loss=2.371964\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:12 INFO 139866244298560] Epoch[2] Batch[60] avg_epoch_loss=2.752092\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=60 train loss <loss>=2.75302672386\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:12 INFO 139866244298560] Epoch[2] Batch [60]#011Speed: 482.08 samples/sec#011loss=2.753027\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:12 INFO 139866244298560] Epoch[2] Batch[65] avg_epoch_loss=2.749760\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=65 train loss <loss>=2.72130861282\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:12 INFO 139866244298560] Epoch[2] Batch [65]#011Speed: 600.73 samples/sec#011loss=2.721309\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:13 INFO 139866244298560] Epoch[2] Batch[70] avg_epoch_loss=2.784951\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=70 train loss <loss>=3.24947452545\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:13 INFO 139866244298560] Epoch[2] Batch [70]#011Speed: 476.11 samples/sec#011loss=3.249475\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:14 INFO 139866244298560] Epoch[2] Batch[75] avg_epoch_loss=2.813518\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=75 train loss <loss>=3.21916513443\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:14 INFO 139866244298560] Epoch[2] Batch [75]#011Speed: 530.86 samples/sec#011loss=3.219165\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:14 INFO 139866244298560] Epoch[2] Batch[80] avg_epoch_loss=2.848480\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=80 train loss <loss>=3.37990660667\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:14 INFO 139866244298560] Epoch[2] Batch [80]#011Speed: 447.77 samples/sec#011loss=3.379907\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:15 INFO 139866244298560] Epoch[2] Batch[85] avg_epoch_loss=2.880272\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=85 train loss <loss>=3.39530267715\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:15 INFO 139866244298560] Epoch[2] Batch [85]#011Speed: 590.02 samples/sec#011loss=3.395303\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:15 INFO 139866244298560] Epoch[2] Batch[90] avg_epoch_loss=2.898924\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=90 train loss <loss>=3.21974430084\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:15 INFO 139866244298560] Epoch[2] Batch [90]#011Speed: 482.44 samples/sec#011loss=3.219744\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:16 INFO 139866244298560] Epoch[2] Batch[95] avg_epoch_loss=2.917417\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=95 train loss <loss>=3.2539814949\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:16 INFO 139866244298560] Epoch[2] Batch [95]#011Speed: 481.27 samples/sec#011loss=3.253981\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:17 INFO 139866244298560] Epoch[2] Batch[100] avg_epoch_loss=2.896565\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=100 train loss <loss>=2.49620094299\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:17 INFO 139866244298560] Epoch[2] Batch [100]#011Speed: 591.23 samples/sec#011loss=2.496201\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:17 INFO 139866244298560] Epoch[2] Batch[105] avg_epoch_loss=2.894606\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=105 train loss <loss>=2.85503568649\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:17 INFO 139866244298560] Epoch[2] Batch [105]#011Speed: 480.87 samples/sec#011loss=2.855036\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:18 INFO 139866244298560] Epoch[2] Batch[110] avg_epoch_loss=2.874702\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=110 train loss <loss>=2.45275325775\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:18 INFO 139866244298560] Epoch[2] Batch [110]#011Speed: 592.22 samples/sec#011loss=2.452753\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:19 INFO 139866244298560] Epoch[2] Batch[115] avg_epoch_loss=2.857397\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=115 train loss <loss>=2.47320752144\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:19 INFO 139866244298560] Epoch[2] Batch [115]#011Speed: 440.61 samples/sec#011loss=2.473208\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:19 INFO 139866244298560] Epoch[2] Batch[120] avg_epoch_loss=2.853111\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=120 train loss <loss>=2.75368318558\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:19 INFO 139866244298560] Epoch[2] Batch [120]#011Speed: 587.95 samples/sec#011loss=2.753683\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:20 INFO 139866244298560] Epoch[2] Batch[125] avg_epoch_loss=2.858384\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=125 train loss <loss>=2.98600187302\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:20 INFO 139866244298560] Epoch[2] Batch [125]#011Speed: 482.49 samples/sec#011loss=2.986002\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:20 INFO 139866244298560] Epoch[2] Batch[130] avg_epoch_loss=2.876067\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=130 train loss <loss>=3.32166981697\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:20 INFO 139866244298560] Epoch[2] Batch [130]#011Speed: 601.07 samples/sec#011loss=3.321670\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:21 INFO 139866244298560] Epoch[2] Batch[135] avg_epoch_loss=2.895395\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=135 train loss <loss>=3.40177788734\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:21 INFO 139866244298560] Epoch[2] Batch [135]#011Speed: 479.17 samples/sec#011loss=3.401778\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:22 INFO 139866244298560] Epoch[2] Batch[140] avg_epoch_loss=2.905261\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=140 train loss <loss>=3.17362484932\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:22 INFO 139866244298560] Epoch[2] Batch [140]#011Speed: 592.95 samples/sec#011loss=3.173625\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:22 INFO 139866244298560] Epoch[2] Batch[145] avg_epoch_loss=2.903882\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=145 train loss <loss>=2.86498656273\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:22 INFO 139866244298560] Epoch[2] Batch [145]#011Speed: 485.17 samples/sec#011loss=2.864987\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:23 INFO 139866244298560] Epoch[2] Batch[150] avg_epoch_loss=2.896942\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=150 train loss <loss>=2.69431557655\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:23 INFO 139866244298560] Epoch[2] Batch [150]#011Speed: 596.09 samples/sec#011loss=2.694316\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:23 INFO 139866244298560] Epoch[2] Batch[155] avg_epoch_loss=2.887804\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=155 train loss <loss>=2.61180911064\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:23 INFO 139866244298560] Epoch[2] Batch [155]#011Speed: 464.31 samples/sec#011loss=2.611809\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:24 INFO 139866244298560] Epoch[2] Batch[160] avg_epoch_loss=2.885396\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=160 train loss <loss>=2.81028232574\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:24 INFO 139866244298560] Epoch[2] Batch [160]#011Speed: 469.91 samples/sec#011loss=2.810282\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:25 INFO 139866244298560] Epoch[2] Batch[165] avg_epoch_loss=2.875590\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=165 train loss <loss>=2.55982508659\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:25 INFO 139866244298560] Epoch[2] Batch [165]#011Speed: 593.24 samples/sec#011loss=2.559825\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:25 INFO 139866244298560] Epoch[2] Batch[170] avg_epoch_loss=2.878357\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=170 train loss <loss>=2.97022256851\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:25 INFO 139866244298560] Epoch[2] Batch [170]#011Speed: 479.50 samples/sec#011loss=2.970223\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:26 INFO 139866244298560] Epoch[2] Batch[175] avg_epoch_loss=2.890862\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=175 train loss <loss>=3.31855301857\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:26 INFO 139866244298560] Epoch[2] Batch [175]#011Speed: 595.71 samples/sec#011loss=3.318553\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:27 INFO 139866244298560] Epoch[2] Batch[180] avg_epoch_loss=2.910521\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=180 train loss <loss>=3.6024969101\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:27 INFO 139866244298560] Epoch[2] Batch [180]#011Speed: 485.69 samples/sec#011loss=3.602497\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:27 INFO 139866244298560] Epoch[2] Batch[185] avg_epoch_loss=2.937373\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=185 train loss <loss>=3.9094183445\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:27 INFO 139866244298560] Epoch[2] Batch [185]#011Speed: 594.95 samples/sec#011loss=3.909418\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:28 INFO 139866244298560] Epoch[2] Batch[190] avg_epoch_loss=2.944872\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=190 train loss <loss>=3.22382497787\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:28 INFO 139866244298560] Epoch[2] Batch [190]#011Speed: 483.14 samples/sec#011loss=3.223825\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:28 INFO 139866244298560] Epoch[2] Batch[195] avg_epoch_loss=2.946599\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=195 train loss <loss>=3.01257972717\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:28 INFO 139866244298560] Epoch[2] Batch [195]#011Speed: 595.20 samples/sec#011loss=3.012580\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:29 INFO 139866244298560] Epoch[2] Batch[200] avg_epoch_loss=2.943726\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=200 train loss <loss>=2.83111948967\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:29 INFO 139866244298560] Epoch[2] Batch [200]#011Speed: 446.54 samples/sec#011loss=2.831119\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:30 INFO 139866244298560] Epoch[2] Batch[205] avg_epoch_loss=2.953189\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=205 train loss <loss>=3.3335796833\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:30 INFO 139866244298560] Epoch[2] Batch [205]#011Speed: 595.00 samples/sec#011loss=3.333580\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:30 INFO 139866244298560] Epoch[2] Batch[210] avg_epoch_loss=2.949125\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=210 train loss <loss>=2.78168406487\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:30 INFO 139866244298560] Epoch[2] Batch [210]#011Speed: 474.13 samples/sec#011loss=2.781684\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:31 INFO 139866244298560] Epoch[2] Batch[215] avg_epoch_loss=2.943664\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=215 train loss <loss>=2.71320800781\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:31 INFO 139866244298560] Epoch[2] Batch [215]#011Speed: 593.16 samples/sec#011loss=2.713208\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:31 INFO 139866244298560] Epoch[2] Batch[220] avg_epoch_loss=2.941193\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=220 train loss <loss>=2.83444499969\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:31 INFO 139866244298560] Epoch[2] Batch [220]#011Speed: 488.97 samples/sec#011loss=2.834445\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:32 INFO 139866244298560] Epoch[2] Batch[225] avg_epoch_loss=2.936101\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=225 train loss <loss>=2.71105213165\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:32 INFO 139866244298560] Epoch[2] Batch [225]#011Speed: 598.39 samples/sec#011loss=2.711052\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:33 INFO 139866244298560] Epoch[2] Batch[230] avg_epoch_loss=2.952279\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=230 train loss <loss>=3.68350949287\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:33 INFO 139866244298560] Epoch[2] Batch [230]#011Speed: 481.86 samples/sec#011loss=3.683509\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:33 INFO 139866244298560] Epoch[2] Batch[235] avg_epoch_loss=2.961471\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=235 train loss <loss>=3.38616394997\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:33 INFO 139866244298560] Epoch[2] Batch [235]#011Speed: 595.78 samples/sec#011loss=3.386164\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:34 INFO 139866244298560] Epoch[2] Batch[240] avg_epoch_loss=2.974858\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=240 train loss <loss>=3.60671925545\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:34 INFO 139866244298560] Epoch[2] Batch [240]#011Speed: 448.69 samples/sec#011loss=3.606719\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:34 INFO 139866244298560] Epoch[2] Batch[245] avg_epoch_loss=2.986750\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=245 train loss <loss>=3.55996689796\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:34 INFO 139866244298560] Epoch[2] Batch [245]#011Speed: 594.36 samples/sec#011loss=3.559967\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:35 INFO 139866244298560] Epoch[2] Batch[250] avg_epoch_loss=2.987769\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=250 train loss <loss>=3.03788146973\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:35 INFO 139866244298560] Epoch[2] Batch [250]#011Speed: 473.43 samples/sec#011loss=3.037881\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:36 INFO 139866244298560] Epoch[2] Batch[255] avg_epoch_loss=2.990942\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=255 train loss <loss>=3.1502093792\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:36 INFO 139866244298560] Epoch[2] Batch [255]#011Speed: 586.03 samples/sec#011loss=3.150209\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:36 INFO 139866244298560] Epoch[2] Batch[260] avg_epoch_loss=2.987072\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=260 train loss <loss>=2.78896112442\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:36 INFO 139866244298560] Epoch[2] Batch [260]#011Speed: 479.58 samples/sec#011loss=2.788961\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:37 INFO 139866244298560] Epoch[2] Batch[265] avg_epoch_loss=2.978310\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, batch=265 train loss <loss>=2.52093954086\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:37 INFO 139866244298560] Epoch[2] Batch [265]#011Speed: 595.77 samples/sec#011loss=2.520940\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:37 INFO 139866244298560] processed a total of 17122 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32936.22803688049, \"sum\": 32936.22803688049, \"min\": 32936.22803688049}}, \"EndTime\": 1599442057.511558, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442024.575256}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:37 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=519.851342652 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:37 INFO 139866244298560] #progress_metric: host=algo-1, completed 3 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=2, train loss <loss>=2.98865390002\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:37 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:37 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_0590cd02-6903-4dde-bf68-a7d86bba4e2f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.767906188964844, \"sum\": 17.767906188964844, \"min\": 17.767906188964844}}, \"EndTime\": 1599442057.52993, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442057.511623}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:37 INFO 139866244298560] Epoch[3] Batch[0] avg_epoch_loss=2.495353\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=0 train loss <loss>=2.49535250664\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:38 INFO 139866244298560] Epoch[3] Batch[5] avg_epoch_loss=2.136931\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=5 train loss <loss>=2.13693072399\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:38 INFO 139866244298560] Epoch[3] Batch [5]#011Speed: 595.92 samples/sec#011loss=2.136931\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:39 INFO 139866244298560] Epoch[3] Batch[10] avg_epoch_loss=2.222373\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=10 train loss <loss>=2.32490367889\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:39 INFO 139866244298560] Epoch[3] Batch [10]#011Speed: 461.61 samples/sec#011loss=2.324904\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:39 INFO 139866244298560] Epoch[3] Batch[15] avg_epoch_loss=2.452777\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=15 train loss <loss>=2.95966534615\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:39 INFO 139866244298560] Epoch[3] Batch [15]#011Speed: 542.92 samples/sec#011loss=2.959665\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:40 INFO 139866244298560] Epoch[3] Batch[20] avg_epoch_loss=2.609499\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=20 train loss <loss>=3.11100811958\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:40 INFO 139866244298560] Epoch[3] Batch [20]#011Speed: 443.24 samples/sec#011loss=3.111008\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:40 INFO 139866244298560] Epoch[3] Batch[25] avg_epoch_loss=2.744408\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=25 train loss <loss>=3.31102862358\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:40 INFO 139866244298560] Epoch[3] Batch [25]#011Speed: 594.39 samples/sec#011loss=3.311029\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:41 INFO 139866244298560] Epoch[3] Batch[30] avg_epoch_loss=2.796827\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=30 train loss <loss>=3.06940522194\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:41 INFO 139866244298560] Epoch[3] Batch [30]#011Speed: 475.48 samples/sec#011loss=3.069405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:42 INFO 139866244298560] Epoch[3] Batch[35] avg_epoch_loss=2.814376\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=35 train loss <loss>=2.92317852974\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:42 INFO 139866244298560] Epoch[3] Batch [35]#011Speed: 598.15 samples/sec#011loss=2.923179\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:42 INFO 139866244298560] Epoch[3] Batch[40] avg_epoch_loss=2.851347\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=40 train loss <loss>=3.11753959656\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:42 INFO 139866244298560] Epoch[3] Batch [40]#011Speed: 475.89 samples/sec#011loss=3.117540\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:43 INFO 139866244298560] Epoch[3] Batch[45] avg_epoch_loss=2.853158\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=45 train loss <loss>=2.8680106163\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:43 INFO 139866244298560] Epoch[3] Batch [45]#011Speed: 592.18 samples/sec#011loss=2.868011\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:43 INFO 139866244298560] Epoch[3] Batch[50] avg_epoch_loss=2.856180\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=50 train loss <loss>=2.88398361206\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:43 INFO 139866244298560] Epoch[3] Batch [50]#011Speed: 483.48 samples/sec#011loss=2.883984\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:44 INFO 139866244298560] Epoch[3] Batch[55] avg_epoch_loss=2.822897\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=55 train loss <loss>=2.48341135979\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:44 INFO 139866244298560] Epoch[3] Batch [55]#011Speed: 553.39 samples/sec#011loss=2.483411\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:45 INFO 139866244298560] Epoch[3] Batch[60] avg_epoch_loss=2.798975\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=60 train loss <loss>=2.53104233742\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:45 INFO 139866244298560] Epoch[3] Batch [60]#011Speed: 475.15 samples/sec#011loss=2.531042\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:45 INFO 139866244298560] Epoch[3] Batch[65] avg_epoch_loss=2.799873\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=65 train loss <loss>=2.8108309269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:45 INFO 139866244298560] Epoch[3] Batch [65]#011Speed: 594.94 samples/sec#011loss=2.810831\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:46 INFO 139866244298560] Epoch[3] Batch[70] avg_epoch_loss=2.810874\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=70 train loss <loss>=2.95608139038\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:46 INFO 139866244298560] Epoch[3] Batch [70]#011Speed: 476.38 samples/sec#011loss=2.956081\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:46 INFO 139866244298560] Epoch[3] Batch[75] avg_epoch_loss=2.830314\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=75 train loss <loss>=3.10635986328\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:46 INFO 139866244298560] Epoch[3] Batch [75]#011Speed: 597.66 samples/sec#011loss=3.106360\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:47 INFO 139866244298560] Epoch[3] Batch[80] avg_epoch_loss=2.854516\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=80 train loss <loss>=3.22239942551\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:47 INFO 139866244298560] Epoch[3] Batch [80]#011Speed: 480.24 samples/sec#011loss=3.222399\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:48 INFO 139866244298560] Epoch[3] Batch[85] avg_epoch_loss=2.889229\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=85 train loss <loss>=3.45157513618\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:48 INFO 139866244298560] Epoch[3] Batch [85]#011Speed: 588.59 samples/sec#011loss=3.451575\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:48 INFO 139866244298560] Epoch[3] Batch[90] avg_epoch_loss=2.920971\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=90 train loss <loss>=3.46693911552\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:48 INFO 139866244298560] Epoch[3] Batch [90]#011Speed: 482.80 samples/sec#011loss=3.466939\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:49 INFO 139866244298560] Epoch[3] Batch[95] avg_epoch_loss=2.937886\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=95 train loss <loss>=3.24572248459\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:49 INFO 139866244298560] Epoch[3] Batch [95]#011Speed: 445.95 samples/sec#011loss=3.245722\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:50 INFO 139866244298560] Epoch[3] Batch[100] avg_epoch_loss=2.920095\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=100 train loss <loss>=2.5785241127\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:50 INFO 139866244298560] Epoch[3] Batch [100]#011Speed: 594.79 samples/sec#011loss=2.578524\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:50 INFO 139866244298560] Epoch[3] Batch[105] avg_epoch_loss=2.906711\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=105 train loss <loss>=2.63634667397\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:50 INFO 139866244298560] Epoch[3] Batch [105]#011Speed: 477.14 samples/sec#011loss=2.636347\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:51 INFO 139866244298560] Epoch[3] Batch[110] avg_epoch_loss=2.887907\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=110 train loss <loss>=2.4892583847\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:51 INFO 139866244298560] Epoch[3] Batch [110]#011Speed: 587.17 samples/sec#011loss=2.489258\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:51 INFO 139866244298560] Epoch[3] Batch[115] avg_epoch_loss=2.866710\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=115 train loss <loss>=2.39614958763\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:51 INFO 139866244298560] Epoch[3] Batch [115]#011Speed: 484.96 samples/sec#011loss=2.396150\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:52 INFO 139866244298560] Epoch[3] Batch[120] avg_epoch_loss=2.849457\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=120 train loss <loss>=2.44918656349\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:52 INFO 139866244298560] Epoch[3] Batch [120]#011Speed: 587.47 samples/sec#011loss=2.449187\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:53 INFO 139866244298560] Epoch[3] Batch[125] avg_epoch_loss=2.848026\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=125 train loss <loss>=2.81338186264\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:53 INFO 139866244298560] Epoch[3] Batch [125]#011Speed: 481.35 samples/sec#011loss=2.813382\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:53 INFO 139866244298560] Epoch[3] Batch[130] avg_epoch_loss=2.861429\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=130 train loss <loss>=3.19918842316\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:53 INFO 139866244298560] Epoch[3] Batch [130]#011Speed: 596.55 samples/sec#011loss=3.199188\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:54 INFO 139866244298560] Epoch[3] Batch[135] avg_epoch_loss=2.872489\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=135 train loss <loss>=3.16226353645\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:54 INFO 139866244298560] Epoch[3] Batch [135]#011Speed: 447.53 samples/sec#011loss=3.162264\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:54 INFO 139866244298560] Epoch[3] Batch[140] avg_epoch_loss=2.892467\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=140 train loss <loss>=3.43587522507\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:54 INFO 139866244298560] Epoch[3] Batch [140]#011Speed: 596.84 samples/sec#011loss=3.435875\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:55 INFO 139866244298560] Epoch[3] Batch[145] avg_epoch_loss=2.887823\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=145 train loss <loss>=2.75684361458\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:55 INFO 139866244298560] Epoch[3] Batch [145]#011Speed: 475.64 samples/sec#011loss=2.756844\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:56 INFO 139866244298560] Epoch[3] Batch[150] avg_epoch_loss=2.883318\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=150 train loss <loss>=2.75178108215\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:56 INFO 139866244298560] Epoch[3] Batch [150]#011Speed: 586.94 samples/sec#011loss=2.751781\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:56 INFO 139866244298560] Epoch[3] Batch[155] avg_epoch_loss=2.888122\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=155 train loss <loss>=3.03321919441\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:56 INFO 139866244298560] Epoch[3] Batch [155]#011Speed: 479.16 samples/sec#011loss=3.033219\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:57 INFO 139866244298560] Epoch[3] Batch[160] avg_epoch_loss=2.881218\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=160 train loss <loss>=2.66579546928\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:57 INFO 139866244298560] Epoch[3] Batch [160]#011Speed: 477.84 samples/sec#011loss=2.665795\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:58 INFO 139866244298560] Epoch[3] Batch[165] avg_epoch_loss=2.857307\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=165 train loss <loss>=2.08738994598\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:58 INFO 139866244298560] Epoch[3] Batch [165]#011Speed: 598.23 samples/sec#011loss=2.087390\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:58 INFO 139866244298560] Epoch[3] Batch[170] avg_epoch_loss=2.851059\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=170 train loss <loss>=2.64362211227\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:58 INFO 139866244298560] Epoch[3] Batch [170]#011Speed: 478.06 samples/sec#011loss=2.643622\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:59 INFO 139866244298560] Epoch[3] Batch[175] avg_epoch_loss=2.849137\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=175 train loss <loss>=2.78337950706\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:59 INFO 139866244298560] Epoch[3] Batch [175]#011Speed: 598.65 samples/sec#011loss=2.783380\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:59 INFO 139866244298560] Epoch[3] Batch[180] avg_epoch_loss=2.854903\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=180 train loss <loss>=3.05789222717\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:27:59 INFO 139866244298560] Epoch[3] Batch [180]#011Speed: 439.35 samples/sec#011loss=3.057892\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:00 INFO 139866244298560] Epoch[3] Batch[185] avg_epoch_loss=2.876471\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=185 train loss <loss>=3.65721392632\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:00 INFO 139866244298560] Epoch[3] Batch [185]#011Speed: 590.99 samples/sec#011loss=3.657214\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:01 INFO 139866244298560] Epoch[3] Batch[190] avg_epoch_loss=2.896684\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=190 train loss <loss>=3.6486061573\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:01 INFO 139866244298560] Epoch[3] Batch [190]#011Speed: 478.11 samples/sec#011loss=3.648606\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:01 INFO 139866244298560] Epoch[3] Batch[195] avg_epoch_loss=2.916204\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=195 train loss <loss>=3.66187720299\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:01 INFO 139866244298560] Epoch[3] Batch [195]#011Speed: 575.30 samples/sec#011loss=3.661877\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:02 INFO 139866244298560] Epoch[3] Batch[200] avg_epoch_loss=2.926136\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=200 train loss <loss>=3.31546802521\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:02 INFO 139866244298560] Epoch[3] Batch [200]#011Speed: 479.17 samples/sec#011loss=3.315468\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:02 INFO 139866244298560] Epoch[3] Batch[205] avg_epoch_loss=2.930775\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=205 train loss <loss>=3.11725635529\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:02 INFO 139866244298560] Epoch[3] Batch [205]#011Speed: 592.35 samples/sec#011loss=3.117256\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:03 INFO 139866244298560] Epoch[3] Batch[210] avg_epoch_loss=2.931135\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=210 train loss <loss>=2.94597902298\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:03 INFO 139866244298560] Epoch[3] Batch [210]#011Speed: 478.02 samples/sec#011loss=2.945979\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:04 INFO 139866244298560] Epoch[3] Batch[215] avg_epoch_loss=2.923125\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=215 train loss <loss>=2.58509440422\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:04 INFO 139866244298560] Epoch[3] Batch [215]#011Speed: 596.11 samples/sec#011loss=2.585094\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:04 INFO 139866244298560] Epoch[3] Batch[220] avg_epoch_loss=2.918135\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=220 train loss <loss>=2.70258040428\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:04 INFO 139866244298560] Epoch[3] Batch [220]#011Speed: 431.87 samples/sec#011loss=2.702580\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:05 INFO 139866244298560] Epoch[3] Batch[225] avg_epoch_loss=2.907951\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=225 train loss <loss>=2.45779867172\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:05 INFO 139866244298560] Epoch[3] Batch [225]#011Speed: 591.56 samples/sec#011loss=2.457799\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:06 INFO 139866244298560] Epoch[3] Batch[230] avg_epoch_loss=2.916196\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=230 train loss <loss>=3.28887143135\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:06 INFO 139866244298560] Epoch[3] Batch [230]#011Speed: 465.83 samples/sec#011loss=3.288871\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:06 INFO 139866244298560] Epoch[3] Batch[235] avg_epoch_loss=2.925589\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=235 train loss <loss>=3.35955305099\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:06 INFO 139866244298560] Epoch[3] Batch [235]#011Speed: 601.20 samples/sec#011loss=3.359553\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:07 INFO 139866244298560] Epoch[3] Batch[240] avg_epoch_loss=2.938869\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=240 train loss <loss>=3.56570005417\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:07 INFO 139866244298560] Epoch[3] Batch [240]#011Speed: 472.40 samples/sec#011loss=3.565700\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:07 INFO 139866244298560] Epoch[3] Batch[245] avg_epoch_loss=2.955068\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=245 train loss <loss>=3.73584370613\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:07 INFO 139866244298560] Epoch[3] Batch [245]#011Speed: 593.96 samples/sec#011loss=3.735844\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:08 INFO 139866244298560] Epoch[3] Batch[250] avg_epoch_loss=2.958421\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=250 train loss <loss>=3.12338452339\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:08 INFO 139866244298560] Epoch[3] Batch [250]#011Speed: 483.67 samples/sec#011loss=3.123385\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:09 INFO 139866244298560] Epoch[3] Batch[255] avg_epoch_loss=2.961078\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=255 train loss <loss>=3.09444279671\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:09 INFO 139866244298560] Epoch[3] Batch [255]#011Speed: 488.03 samples/sec#011loss=3.094443\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:09 INFO 139866244298560] Epoch[3] Batch[260] avg_epoch_loss=2.956567\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=260 train loss <loss>=2.72564468384\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:09 INFO 139866244298560] Epoch[3] Batch [260]#011Speed: 530.79 samples/sec#011loss=2.725645\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:10 INFO 139866244298560] Epoch[3] Batch[265] avg_epoch_loss=2.962151\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, batch=265 train loss <loss>=3.25359969139\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:10 INFO 139866244298560] Epoch[3] Batch [265]#011Speed: 520.96 samples/sec#011loss=3.253600\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:10 INFO 139866244298560] processed a total of 17042 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32973.642110824585, \"sum\": 32973.642110824585, \"min\": 32973.642110824585}}, \"EndTime\": 1599442090.503718, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442057.529989}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:10 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=516.834358152 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:10 INFO 139866244298560] #progress_metric: host=algo-1, completed 5 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=3, train loss <loss>=2.95448319251\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:10 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:10 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_a5c69e87-ee86-4da1-abd2-629f38169d11-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.882108688354492, \"sum\": 17.882108688354492, \"min\": 17.882108688354492}}, \"EndTime\": 1599442090.522401, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442090.503828}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:10 INFO 139866244298560] Epoch[4] Batch[0] avg_epoch_loss=2.588037\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=0 train loss <loss>=2.58803701401\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:11 INFO 139866244298560] Epoch[4] Batch[5] avg_epoch_loss=2.426521\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=5 train loss <loss>=2.42652090391\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:11 INFO 139866244298560] Epoch[4] Batch [5]#011Speed: 595.09 samples/sec#011loss=2.426521\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:11 INFO 139866244298560] Epoch[4] Batch[10] avg_epoch_loss=2.460339\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=10 train loss <loss>=2.50091962814\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:11 INFO 139866244298560] Epoch[4] Batch [10]#011Speed: 481.37 samples/sec#011loss=2.500920\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:12 INFO 139866244298560] Epoch[4] Batch[15] avg_epoch_loss=2.620229\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=15 train loss <loss>=2.97198858261\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:12 INFO 139866244298560] Epoch[4] Batch [15]#011Speed: 593.67 samples/sec#011loss=2.971989\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:13 INFO 139866244298560] Epoch[4] Batch[20] avg_epoch_loss=2.684181\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=20 train loss <loss>=2.88882784843\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:13 INFO 139866244298560] Epoch[4] Batch [20]#011Speed: 474.85 samples/sec#011loss=2.888828\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:13 INFO 139866244298560] Epoch[4] Batch[25] avg_epoch_loss=2.754749\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=25 train loss <loss>=3.05113120079\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:13 INFO 139866244298560] Epoch[4] Batch [25]#011Speed: 596.98 samples/sec#011loss=3.051131\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:14 INFO 139866244298560] Epoch[4] Batch[30] avg_epoch_loss=2.771157\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=30 train loss <loss>=2.85647859573\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:14 INFO 139866244298560] Epoch[4] Batch [30]#011Speed: 483.85 samples/sec#011loss=2.856479\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:14 INFO 139866244298560] Epoch[4] Batch[35] avg_epoch_loss=2.758010\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=35 train loss <loss>=2.67650370598\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:14 INFO 139866244298560] Epoch[4] Batch [35]#011Speed: 536.21 samples/sec#011loss=2.676504\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:15 INFO 139866244298560] Epoch[4] Batch[40] avg_epoch_loss=2.778200\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=40 train loss <loss>=2.92356729507\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:15 INFO 139866244298560] Epoch[4] Batch [40]#011Speed: 470.33 samples/sec#011loss=2.923567\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:16 INFO 139866244298560] Epoch[4] Batch[45] avg_epoch_loss=2.768102\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=45 train loss <loss>=2.68529419899\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:16 INFO 139866244298560] Epoch[4] Batch [45]#011Speed: 591.49 samples/sec#011loss=2.685294\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:16 INFO 139866244298560] Epoch[4] Batch[50] avg_epoch_loss=2.774121\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=50 train loss <loss>=2.82950077057\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:16 INFO 139866244298560] Epoch[4] Batch [50]#011Speed: 485.90 samples/sec#011loss=2.829501\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:17 INFO 139866244298560] Epoch[4] Batch[55] avg_epoch_loss=2.753982\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=55 train loss <loss>=2.54855661392\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:17 INFO 139866244298560] Epoch[4] Batch [55]#011Speed: 595.11 samples/sec#011loss=2.548557\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:18 INFO 139866244298560] Epoch[4] Batch[60] avg_epoch_loss=2.771068\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=60 train loss <loss>=2.96243796349\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:18 INFO 139866244298560] Epoch[4] Batch [60]#011Speed: 489.42 samples/sec#011loss=2.962438\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:18 INFO 139866244298560] Epoch[4] Batch[65] avg_epoch_loss=2.764295\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=65 train loss <loss>=2.6816628933\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:18 INFO 139866244298560] Epoch[4] Batch [65]#011Speed: 585.89 samples/sec#011loss=2.681663\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:19 INFO 139866244298560] Epoch[4] Batch[70] avg_epoch_loss=2.801394\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=70 train loss <loss>=3.29109458923\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:19 INFO 139866244298560] Epoch[4] Batch [70]#011Speed: 481.34 samples/sec#011loss=3.291095\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:19 INFO 139866244298560] Epoch[4] Batch[75] avg_epoch_loss=2.827223\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=75 train loss <loss>=3.19399747849\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:19 INFO 139866244298560] Epoch[4] Batch [75]#011Speed: 440.13 samples/sec#011loss=3.193997\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:20 INFO 139866244298560] Epoch[4] Batch[80] avg_epoch_loss=2.866095\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=80 train loss <loss>=3.45695419312\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:20 INFO 139866244298560] Epoch[4] Batch [80]#011Speed: 593.29 samples/sec#011loss=3.456954\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:21 INFO 139866244298560] Epoch[4] Batch[85] avg_epoch_loss=2.886405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=85 train loss <loss>=3.21543011665\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:21 INFO 139866244298560] Epoch[4] Batch [85]#011Speed: 471.73 samples/sec#011loss=3.215430\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:21 INFO 139866244298560] Epoch[4] Batch[90] avg_epoch_loss=2.871181\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=90 train loss <loss>=2.6093173027\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:21 INFO 139866244298560] Epoch[4] Batch [90]#011Speed: 601.81 samples/sec#011loss=2.609317\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:22 INFO 139866244298560] Epoch[4] Batch[95] avg_epoch_loss=2.865538\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=95 train loss <loss>=2.76283650398\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:22 INFO 139866244298560] Epoch[4] Batch [95]#011Speed: 473.20 samples/sec#011loss=2.762837\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:22 INFO 139866244298560] Epoch[4] Batch[100] avg_epoch_loss=2.853175\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=100 train loss <loss>=2.61580548286\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:22 INFO 139866244298560] Epoch[4] Batch [100]#011Speed: 601.59 samples/sec#011loss=2.615805\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:23 INFO 139866244298560] Epoch[4] Batch[105] avg_epoch_loss=2.834418\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=105 train loss <loss>=2.45553240776\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:23 INFO 139866244298560] Epoch[4] Batch [105]#011Speed: 484.83 samples/sec#011loss=2.455532\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:24 INFO 139866244298560] Epoch[4] Batch[110] avg_epoch_loss=2.816375\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=110 train loss <loss>=2.43386311531\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:24 INFO 139866244298560] Epoch[4] Batch [110]#011Speed: 590.72 samples/sec#011loss=2.433863\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:24 INFO 139866244298560] Epoch[4] Batch[115] avg_epoch_loss=2.804405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=115 train loss <loss>=2.53867726326\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:24 INFO 139866244298560] Epoch[4] Batch [115]#011Speed: 478.09 samples/sec#011loss=2.538677\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:25 INFO 139866244298560] Epoch[4] Batch[120] avg_epoch_loss=2.803449\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=120 train loss <loss>=2.78125634193\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:25 INFO 139866244298560] Epoch[4] Batch [120]#011Speed: 550.63 samples/sec#011loss=2.781256\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:26 INFO 139866244298560] Epoch[4] Batch[125] avg_epoch_loss=2.807636\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=125 train loss <loss>=2.90895652771\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:26 INFO 139866244298560] Epoch[4] Batch [125]#011Speed: 481.91 samples/sec#011loss=2.908957\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:26 INFO 139866244298560] Epoch[4] Batch[130] avg_epoch_loss=2.820423\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=130 train loss <loss>=3.14267225266\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:26 INFO 139866244298560] Epoch[4] Batch [130]#011Speed: 600.99 samples/sec#011loss=3.142672\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:27 INFO 139866244298560] Epoch[4] Batch[135] avg_epoch_loss=2.833283\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=135 train loss <loss>=3.17022042274\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:27 INFO 139866244298560] Epoch[4] Batch [135]#011Speed: 478.29 samples/sec#011loss=3.170220\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:27 INFO 139866244298560] Epoch[4] Batch[140] avg_epoch_loss=2.847038\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=140 train loss <loss>=3.22115597725\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:27 INFO 139866244298560] Epoch[4] Batch [140]#011Speed: 598.87 samples/sec#011loss=3.221156\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:28 INFO 139866244298560] Epoch[4] Batch[145] avg_epoch_loss=2.835191\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=145 train loss <loss>=2.50112552643\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:28 INFO 139866244298560] Epoch[4] Batch [145]#011Speed: 476.51 samples/sec#011loss=2.501126\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:29 INFO 139866244298560] Epoch[4] Batch[150] avg_epoch_loss=2.824500\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=150 train loss <loss>=2.51231255531\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:29 INFO 139866244298560] Epoch[4] Batch [150]#011Speed: 594.14 samples/sec#011loss=2.512313\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:29 INFO 139866244298560] Epoch[4] Batch[155] avg_epoch_loss=2.821512\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=155 train loss <loss>=2.73128457069\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:29 INFO 139866244298560] Epoch[4] Batch [155]#011Speed: 469.20 samples/sec#011loss=2.731285\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:30 INFO 139866244298560] Epoch[4] Batch[160] avg_epoch_loss=2.823730\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=160 train loss <loss>=2.89290566444\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:30 INFO 139866244298560] Epoch[4] Batch [160]#011Speed: 524.78 samples/sec#011loss=2.892906\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:30 INFO 139866244298560] Epoch[4] Batch[165] avg_epoch_loss=2.822662\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=165 train loss <loss>=2.78827238083\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:30 INFO 139866244298560] Epoch[4] Batch [165]#011Speed: 468.93 samples/sec#011loss=2.788272\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:31 INFO 139866244298560] Epoch[4] Batch[170] avg_epoch_loss=2.814432\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=170 train loss <loss>=2.54120564461\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:31 INFO 139866244298560] Epoch[4] Batch [170]#011Speed: 595.39 samples/sec#011loss=2.541206\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:32 INFO 139866244298560] Epoch[4] Batch[175] avg_epoch_loss=2.815303\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=175 train loss <loss>=2.84509153366\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:32 INFO 139866244298560] Epoch[4] Batch [175]#011Speed: 472.03 samples/sec#011loss=2.845092\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:32 INFO 139866244298560] Epoch[4] Batch[180] avg_epoch_loss=2.814441\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=180 train loss <loss>=2.78408699036\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:32 INFO 139866244298560] Epoch[4] Batch [180]#011Speed: 598.41 samples/sec#011loss=2.784087\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:33 INFO 139866244298560] Epoch[4] Batch[185] avg_epoch_loss=2.831278\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=185 train loss <loss>=3.44080786705\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:33 INFO 139866244298560] Epoch[4] Batch [185]#011Speed: 481.98 samples/sec#011loss=3.440808\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:33 INFO 139866244298560] Epoch[4] Batch[190] avg_epoch_loss=2.848040\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=190 train loss <loss>=3.47157926559\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:33 INFO 139866244298560] Epoch[4] Batch [190]#011Speed: 592.91 samples/sec#011loss=3.471579\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:34 INFO 139866244298560] Epoch[4] Batch[195] avg_epoch_loss=2.866029\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=195 train loss <loss>=3.55320944786\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:34 INFO 139866244298560] Epoch[4] Batch [195]#011Speed: 483.35 samples/sec#011loss=3.553209\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:35 INFO 139866244298560] Epoch[4] Batch[200] avg_epoch_loss=2.881198\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=200 train loss <loss>=3.47580189705\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:35 INFO 139866244298560] Epoch[4] Batch [200]#011Speed: 502.13 samples/sec#011loss=3.475802\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:35 INFO 139866244298560] Epoch[4] Batch[205] avg_epoch_loss=2.887760\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=205 train loss <loss>=3.15157432556\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:35 INFO 139866244298560] Epoch[4] Batch [205]#011Speed: 461.04 samples/sec#011loss=3.151574\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:36 INFO 139866244298560] Epoch[4] Batch[210] avg_epoch_loss=2.893041\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=210 train loss <loss>=3.11059317589\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:36 INFO 139866244298560] Epoch[4] Batch [210]#011Speed: 586.04 samples/sec#011loss=3.110593\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:37 INFO 139866244298560] Epoch[4] Batch[215] avg_epoch_loss=2.892125\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=215 train loss <loss>=2.85347337723\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:37 INFO 139866244298560] Epoch[4] Batch [215]#011Speed: 473.97 samples/sec#011loss=2.853473\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:37 INFO 139866244298560] Epoch[4] Batch[220] avg_epoch_loss=2.884833\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=220 train loss <loss>=2.56980805397\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:37 INFO 139866244298560] Epoch[4] Batch [220]#011Speed: 483.65 samples/sec#011loss=2.569808\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:38 INFO 139866244298560] Epoch[4] Batch[225] avg_epoch_loss=2.880798\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=225 train loss <loss>=2.70246896744\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:38 INFO 139866244298560] Epoch[4] Batch [225]#011Speed: 595.23 samples/sec#011loss=2.702469\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:39 INFO 139866244298560] Epoch[4] Batch[230] avg_epoch_loss=2.877278\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=230 train loss <loss>=2.71816916466\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:39 INFO 139866244298560] Epoch[4] Batch [230]#011Speed: 466.20 samples/sec#011loss=2.718169\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:39 INFO 139866244298560] Epoch[4] Batch[235] avg_epoch_loss=2.878419\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=235 train loss <loss>=2.93115653992\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:39 INFO 139866244298560] Epoch[4] Batch [235]#011Speed: 600.77 samples/sec#011loss=2.931157\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:40 INFO 139866244298560] Epoch[4] Batch[240] avg_epoch_loss=2.879868\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=240 train loss <loss>=2.94825057983\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:40 INFO 139866244298560] Epoch[4] Batch [240]#011Speed: 458.85 samples/sec#011loss=2.948251\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:40 INFO 139866244298560] Epoch[4] Batch[245] avg_epoch_loss=2.885426\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=245 train loss <loss>=3.15332636833\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:40 INFO 139866244298560] Epoch[4] Batch [245]#011Speed: 518.49 samples/sec#011loss=3.153326\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:41 INFO 139866244298560] Epoch[4] Batch[250] avg_epoch_loss=2.894300\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=250 train loss <loss>=3.33087458611\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:41 INFO 139866244298560] Epoch[4] Batch [250]#011Speed: 473.69 samples/sec#011loss=3.330875\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:42 INFO 139866244298560] Epoch[4] Batch[255] avg_epoch_loss=2.909014\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=255 train loss <loss>=3.64766969681\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:42 INFO 139866244298560] Epoch[4] Batch [255]#011Speed: 593.70 samples/sec#011loss=3.647670\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:42 INFO 139866244298560] Epoch[4] Batch[260] avg_epoch_loss=2.918257\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=260 train loss <loss>=3.39149441719\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:42 INFO 139866244298560] Epoch[4] Batch [260]#011Speed: 493.98 samples/sec#011loss=3.391494\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:43 INFO 139866244298560] Epoch[4] Batch[265] avg_epoch_loss=2.923843\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, batch=265 train loss <loss>=3.21543698311\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:43 INFO 139866244298560] Epoch[4] Batch [265]#011Speed: 595.71 samples/sec#011loss=3.215437\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:43 INFO 139866244298560] processed a total of 17164 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33088.73200416565, \"sum\": 33088.73200416565, \"min\": 33088.73200416565}}, \"EndTime\": 1599442123.611305, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442090.522477}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:43 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=518.724458058 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:43 INFO 139866244298560] #progress_metric: host=algo-1, completed 6 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=4, train loss <loss>=2.93278556242\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:43 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:43 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_1728180f-8b5f-4a55-9ab3-f0001b995bc2-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.763853073120117, \"sum\": 17.763853073120117, \"min\": 17.763853073120117}}, \"EndTime\": 1599442123.629964, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442123.611374}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:43 INFO 139866244298560] Epoch[5] Batch[0] avg_epoch_loss=2.629848\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=0 train loss <loss>=2.62984848022\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:44 INFO 139866244298560] Epoch[5] Batch[5] avg_epoch_loss=2.495856\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=5 train loss <loss>=2.49585584799\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:44 INFO 139866244298560] Epoch[5] Batch [5]#011Speed: 593.11 samples/sec#011loss=2.495856\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:45 INFO 139866244298560] Epoch[5] Batch[10] avg_epoch_loss=2.469022\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=10 train loss <loss>=2.43682198524\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:45 INFO 139866244298560] Epoch[5] Batch [10]#011Speed: 472.23 samples/sec#011loss=2.436822\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:45 INFO 139866244298560] Epoch[5] Batch[15] avg_epoch_loss=2.600981\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=15 train loss <loss>=2.89128890038\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:45 INFO 139866244298560] Epoch[5] Batch [15]#011Speed: 546.31 samples/sec#011loss=2.891289\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:46 INFO 139866244298560] Epoch[5] Batch[20] avg_epoch_loss=2.694243\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=20 train loss <loss>=2.99268169403\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:46 INFO 139866244298560] Epoch[5] Batch [20]#011Speed: 474.73 samples/sec#011loss=2.992682\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:46 INFO 139866244298560] Epoch[5] Batch[25] avg_epoch_loss=2.730576\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=25 train loss <loss>=2.88317584991\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:46 INFO 139866244298560] Epoch[5] Batch [25]#011Speed: 595.27 samples/sec#011loss=2.883176\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:47 INFO 139866244298560] Epoch[5] Batch[30] avg_epoch_loss=2.716276\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=30 train loss <loss>=2.64191632271\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:47 INFO 139866244298560] Epoch[5] Batch [30]#011Speed: 477.89 samples/sec#011loss=2.641916\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:48 INFO 139866244298560] Epoch[5] Batch[35] avg_epoch_loss=2.690116\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=35 train loss <loss>=2.52792110443\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:48 INFO 139866244298560] Epoch[5] Batch [35]#011Speed: 594.88 samples/sec#011loss=2.527921\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:48 INFO 139866244298560] Epoch[5] Batch[40] avg_epoch_loss=2.687493\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=40 train loss <loss>=2.66861300468\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:48 INFO 139866244298560] Epoch[5] Batch [40]#011Speed: 480.03 samples/sec#011loss=2.668613\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:49 INFO 139866244298560] Epoch[5] Batch[45] avg_epoch_loss=2.686682\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=45 train loss <loss>=2.68002901077\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:49 INFO 139866244298560] Epoch[5] Batch [45]#011Speed: 595.41 samples/sec#011loss=2.680029\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:49 INFO 139866244298560] Epoch[5] Batch[50] avg_epoch_loss=2.674411\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=50 train loss <loss>=2.56151819229\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:49 INFO 139866244298560] Epoch[5] Batch [50]#011Speed: 475.41 samples/sec#011loss=2.561518\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:50 INFO 139866244298560] Epoch[5] Batch[55] avg_epoch_loss=2.653927\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=55 train loss <loss>=2.44499154091\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:50 INFO 139866244298560] Epoch[5] Batch [55]#011Speed: 595.78 samples/sec#011loss=2.444992\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:51 INFO 139866244298560] Epoch[5] Batch[60] avg_epoch_loss=2.680641\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=60 train loss <loss>=2.97983841896\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:51 INFO 139866244298560] Epoch[5] Batch [60]#011Speed: 451.95 samples/sec#011loss=2.979838\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:51 INFO 139866244298560] Epoch[5] Batch[65] avg_epoch_loss=2.682597\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=65 train loss <loss>=2.70645942688\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:51 INFO 139866244298560] Epoch[5] Batch [65]#011Speed: 595.86 samples/sec#011loss=2.706459\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:52 INFO 139866244298560] Epoch[5] Batch[70] avg_epoch_loss=2.724859\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=70 train loss <loss>=3.28270969391\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:52 INFO 139866244298560] Epoch[5] Batch [70]#011Speed: 478.81 samples/sec#011loss=3.282710\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:53 INFO 139866244298560] Epoch[5] Batch[75] avg_epoch_loss=2.757166\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=75 train loss <loss>=3.21592545509\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:53 INFO 139866244298560] Epoch[5] Batch [75]#011Speed: 472.05 samples/sec#011loss=3.215925\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:53 INFO 139866244298560] Epoch[5] Batch[80] avg_epoch_loss=2.794446\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=80 train loss <loss>=3.361109972\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:53 INFO 139866244298560] Epoch[5] Batch [80]#011Speed: 598.31 samples/sec#011loss=3.361110\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:54 INFO 139866244298560] Epoch[5] Batch[85] avg_epoch_loss=2.816367\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=85 train loss <loss>=3.17148771286\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:54 INFO 139866244298560] Epoch[5] Batch [85]#011Speed: 467.39 samples/sec#011loss=3.171488\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:54 INFO 139866244298560] Epoch[5] Batch[90] avg_epoch_loss=2.804695\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=90 train loss <loss>=2.6039273262\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:54 INFO 139866244298560] Epoch[5] Batch [90]#011Speed: 593.42 samples/sec#011loss=2.603927\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:55 INFO 139866244298560] Epoch[5] Batch[95] avg_epoch_loss=2.785825\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=95 train loss <loss>=2.44239149094\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:55 INFO 139866244298560] Epoch[5] Batch [95]#011Speed: 473.48 samples/sec#011loss=2.442391\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:56 INFO 139866244298560] Epoch[5] Batch[100] avg_epoch_loss=2.775628\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=100 train loss <loss>=2.57984490395\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:56 INFO 139866244298560] Epoch[5] Batch [100]#011Speed: 556.31 samples/sec#011loss=2.579845\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:56 INFO 139866244298560] Epoch[5] Batch[105] avg_epoch_loss=2.760121\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=105 train loss <loss>=2.44688673019\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:56 INFO 139866244298560] Epoch[5] Batch [105]#011Speed: 478.36 samples/sec#011loss=2.446887\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:57 INFO 139866244298560] Epoch[5] Batch[110] avg_epoch_loss=2.754078\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=110 train loss <loss>=2.62595896721\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:57 INFO 139866244298560] Epoch[5] Batch [110]#011Speed: 597.71 samples/sec#011loss=2.625959\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:57 INFO 139866244298560] Epoch[5] Batch[115] avg_epoch_loss=2.751848\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=115 train loss <loss>=2.70235414505\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:57 INFO 139866244298560] Epoch[5] Batch [115]#011Speed: 480.95 samples/sec#011loss=2.702354\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:58 INFO 139866244298560] Epoch[5] Batch[120] avg_epoch_loss=2.738017\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=120 train loss <loss>=2.41714334488\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:58 INFO 139866244298560] Epoch[5] Batch [120]#011Speed: 596.06 samples/sec#011loss=2.417143\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:59 INFO 139866244298560] Epoch[5] Batch[125] avg_epoch_loss=2.742203\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=125 train loss <loss>=2.84350481033\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:59 INFO 139866244298560] Epoch[5] Batch [125]#011Speed: 468.93 samples/sec#011loss=2.843505\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:59 INFO 139866244298560] Epoch[5] Batch[130] avg_epoch_loss=2.745241\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=130 train loss <loss>=2.82179756165\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:28:59 INFO 139866244298560] Epoch[5] Batch [130]#011Speed: 594.75 samples/sec#011loss=2.821798\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:00 INFO 139866244298560] Epoch[5] Batch[135] avg_epoch_loss=2.750921\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=135 train loss <loss>=2.89973578453\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:00 INFO 139866244298560] Epoch[5] Batch [135]#011Speed: 473.14 samples/sec#011loss=2.899736\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:01 INFO 139866244298560] Epoch[5] Batch[140] avg_epoch_loss=2.770094\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=140 train loss <loss>=3.29159212112\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:01 INFO 139866244298560] Epoch[5] Batch [140]#011Speed: 551.94 samples/sec#011loss=3.291592\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:01 INFO 139866244298560] Epoch[5] Batch[145] avg_epoch_loss=2.769716\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=145 train loss <loss>=2.75905060768\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:01 INFO 139866244298560] Epoch[5] Batch [145]#011Speed: 471.66 samples/sec#011loss=2.759051\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:02 INFO 139866244298560] Epoch[5] Batch[150] avg_epoch_loss=2.770628\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=150 train loss <loss>=2.79727535248\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:02 INFO 139866244298560] Epoch[5] Batch [150]#011Speed: 592.03 samples/sec#011loss=2.797275\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:02 INFO 139866244298560] Epoch[5] Batch[155] avg_epoch_loss=2.769790\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=155 train loss <loss>=2.74446144104\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:02 INFO 139866244298560] Epoch[5] Batch [155]#011Speed: 466.19 samples/sec#011loss=2.744461\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:03 INFO 139866244298560] Epoch[5] Batch[160] avg_epoch_loss=2.768635\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=160 train loss <loss>=2.73259792328\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:03 INFO 139866244298560] Epoch[5] Batch [160]#011Speed: 594.27 samples/sec#011loss=2.732598\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:04 INFO 139866244298560] Epoch[5] Batch[165] avg_epoch_loss=2.761037\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=165 train loss <loss>=2.51639611721\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:04 INFO 139866244298560] Epoch[5] Batch [165]#011Speed: 485.18 samples/sec#011loss=2.516396\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:04 INFO 139866244298560] Epoch[5] Batch[170] avg_epoch_loss=2.750717\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=170 train loss <loss>=2.40807414055\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:04 INFO 139866244298560] Epoch[5] Batch [170]#011Speed: 594.41 samples/sec#011loss=2.408074\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:05 INFO 139866244298560] Epoch[5] Batch[175] avg_epoch_loss=2.744768\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=175 train loss <loss>=2.54132561684\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:05 INFO 139866244298560] Epoch[5] Batch [175]#011Speed: 466.71 samples/sec#011loss=2.541326\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:05 INFO 139866244298560] Epoch[5] Batch[180] avg_epoch_loss=2.746481\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=180 train loss <loss>=2.80679626465\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:05 INFO 139866244298560] Epoch[5] Batch [180]#011Speed: 596.47 samples/sec#011loss=2.806796\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:06 INFO 139866244298560] Epoch[5] Batch[185] avg_epoch_loss=2.760454\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=185 train loss <loss>=3.26626992226\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:06 INFO 139866244298560] Epoch[5] Batch [185]#011Speed: 437.09 samples/sec#011loss=3.266270\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:07 INFO 139866244298560] Epoch[5] Batch[190] avg_epoch_loss=2.773926\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=190 train loss <loss>=3.27506527901\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:07 INFO 139866244298560] Epoch[5] Batch [190]#011Speed: 599.22 samples/sec#011loss=3.275065\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:07 INFO 139866244298560] Epoch[5] Batch[195] avg_epoch_loss=2.799602\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=195 train loss <loss>=3.78044390678\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:07 INFO 139866244298560] Epoch[5] Batch [195]#011Speed: 481.14 samples/sec#011loss=3.780444\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:08 INFO 139866244298560] Epoch[5] Batch[200] avg_epoch_loss=2.816932\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=200 train loss <loss>=3.49626235962\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:08 INFO 139866244298560] Epoch[5] Batch [200]#011Speed: 480.30 samples/sec#011loss=3.496262\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:08 INFO 139866244298560] Epoch[5] Batch[205] avg_epoch_loss=2.825441\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=205 train loss <loss>=3.16747746468\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:08 INFO 139866244298560] Epoch[5] Batch [205]#011Speed: 601.78 samples/sec#011loss=3.167477\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:09 INFO 139866244298560] Epoch[5] Batch[210] avg_epoch_loss=2.834292\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=210 train loss <loss>=3.19897751808\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:09 INFO 139866244298560] Epoch[5] Batch [210]#011Speed: 477.50 samples/sec#011loss=3.198978\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:10 INFO 139866244298560] Epoch[5] Batch[215] avg_epoch_loss=2.830148\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=215 train loss <loss>=2.65528712273\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:10 INFO 139866244298560] Epoch[5] Batch [215]#011Speed: 586.23 samples/sec#011loss=2.655287\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:10 INFO 139866244298560] Epoch[5] Batch[220] avg_epoch_loss=2.824427\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=220 train loss <loss>=2.57727584839\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:10 INFO 139866244298560] Epoch[5] Batch [220]#011Speed: 437.58 samples/sec#011loss=2.577276\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:11 INFO 139866244298560] Epoch[5] Batch[225] avg_epoch_loss=2.821893\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=225 train loss <loss>=2.70985441208\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:11 INFO 139866244298560] Epoch[5] Batch [225]#011Speed: 442.61 samples/sec#011loss=2.709854\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:12 INFO 139866244298560] Epoch[5] Batch[230] avg_epoch_loss=2.819562\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=230 train loss <loss>=2.71420559883\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:12 INFO 139866244298560] Epoch[5] Batch [230]#011Speed: 481.39 samples/sec#011loss=2.714206\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:12 INFO 139866244298560] Epoch[5] Batch[235] avg_epoch_loss=2.823556\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=235 train loss <loss>=3.00810747147\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:12 INFO 139866244298560] Epoch[5] Batch [235]#011Speed: 600.59 samples/sec#011loss=3.008107\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:13 INFO 139866244298560] Epoch[5] Batch[240] avg_epoch_loss=2.828462\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=240 train loss <loss>=3.06001639366\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:13 INFO 139866244298560] Epoch[5] Batch [240]#011Speed: 476.72 samples/sec#011loss=3.060016\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:14 INFO 139866244298560] Epoch[5] Batch[245] avg_epoch_loss=2.841330\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=245 train loss <loss>=3.46154499054\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:14 INFO 139866244298560] Epoch[5] Batch [245]#011Speed: 590.22 samples/sec#011loss=3.461545\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:14 INFO 139866244298560] Epoch[5] Batch[250] avg_epoch_loss=2.858352\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=250 train loss <loss>=3.69586486816\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:14 INFO 139866244298560] Epoch[5] Batch [250]#011Speed: 478.01 samples/sec#011loss=3.695865\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:15 INFO 139866244298560] Epoch[5] Batch[255] avg_epoch_loss=2.878289\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=255 train loss <loss>=3.87911553383\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:15 INFO 139866244298560] Epoch[5] Batch [255]#011Speed: 588.56 samples/sec#011loss=3.879116\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:15 INFO 139866244298560] Epoch[5] Batch[260] avg_epoch_loss=2.881323\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=260 train loss <loss>=3.03663778305\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:15 INFO 139866244298560] Epoch[5] Batch [260]#011Speed: 490.15 samples/sec#011loss=3.036638\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:16 INFO 139866244298560] Epoch[5] Batch[265] avg_epoch_loss=2.885544\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, batch=265 train loss <loss>=3.10591187477\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:16 INFO 139866244298560] Epoch[5] Batch [265]#011Speed: 596.35 samples/sec#011loss=3.105912\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:16 INFO 139866244298560] processed a total of 17007 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32851.68194770813, \"sum\": 32851.68194770813, \"min\": 32851.68194770813}}, \"EndTime\": 1599442156.4818, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442123.630044}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:16 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=517.688514007 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:16 INFO 139866244298560] #progress_metric: host=algo-1, completed 7 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=5, train loss <loss>=2.88554414098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:16 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:16 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_c02a6db9-010c-4b84-acc9-8b1cef12b758-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.78697967529297, \"sum\": 17.78697967529297, \"min\": 17.78697967529297}}, \"EndTime\": 1599442156.500305, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442156.481886}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:16 INFO 139866244298560] Epoch[6] Batch[0] avg_epoch_loss=2.171806\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=0 train loss <loss>=2.17180633545\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:17 INFO 139866244298560] Epoch[6] Batch[5] avg_epoch_loss=2.311636\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=5 train loss <loss>=2.31163577239\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:17 INFO 139866244298560] Epoch[6] Batch [5]#011Speed: 593.23 samples/sec#011loss=2.311636\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:18 INFO 139866244298560] Epoch[6] Batch[10] avg_epoch_loss=2.323854\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=10 train loss <loss>=2.3385155201\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:18 INFO 139866244298560] Epoch[6] Batch [10]#011Speed: 462.90 samples/sec#011loss=2.338516\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:18 INFO 139866244298560] Epoch[6] Batch[15] avg_epoch_loss=2.434273\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=15 train loss <loss>=2.67719368935\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:18 INFO 139866244298560] Epoch[6] Batch [15]#011Speed: 598.52 samples/sec#011loss=2.677194\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:19 INFO 139866244298560] Epoch[6] Batch[20] avg_epoch_loss=2.535682\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=20 train loss <loss>=2.86019101143\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:19 INFO 139866244298560] Epoch[6] Batch [20]#011Speed: 474.75 samples/sec#011loss=2.860191\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:19 INFO 139866244298560] Epoch[6] Batch[25] avg_epoch_loss=2.636858\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=25 train loss <loss>=3.06179876328\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:19 INFO 139866244298560] Epoch[6] Batch [25]#011Speed: 593.52 samples/sec#011loss=3.061799\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:20 INFO 139866244298560] Epoch[6] Batch[30] avg_epoch_loss=2.659190\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=30 train loss <loss>=2.77531499863\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:20 INFO 139866244298560] Epoch[6] Batch [30]#011Speed: 466.14 samples/sec#011loss=2.775315\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:21 INFO 139866244298560] Epoch[6] Batch[35] avg_epoch_loss=2.673255\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=35 train loss <loss>=2.76045732498\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:21 INFO 139866244298560] Epoch[6] Batch [35]#011Speed: 598.95 samples/sec#011loss=2.760457\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:21 INFO 139866244298560] Epoch[6] Batch[40] avg_epoch_loss=2.664227\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=40 train loss <loss>=2.59922571182\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:21 INFO 139866244298560] Epoch[6] Batch [40]#011Speed: 487.16 samples/sec#011loss=2.599226\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:22 INFO 139866244298560] Epoch[6] Batch[45] avg_epoch_loss=2.625656\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=45 train loss <loss>=2.30937952995\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:22 INFO 139866244298560] Epoch[6] Batch [45]#011Speed: 541.85 samples/sec#011loss=2.309380\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:22 INFO 139866244298560] Epoch[6] Batch[50] avg_epoch_loss=2.611983\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=50 train loss <loss>=2.48618993759\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:22 INFO 139866244298560] Epoch[6] Batch [50]#011Speed: 468.20 samples/sec#011loss=2.486190\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:23 INFO 139866244298560] Epoch[6] Batch[55] avg_epoch_loss=2.587576\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=55 train loss <loss>=2.33862433434\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:23 INFO 139866244298560] Epoch[6] Batch [55]#011Speed: 593.72 samples/sec#011loss=2.338624\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:24 INFO 139866244298560] Epoch[6] Batch[60] avg_epoch_loss=2.598927\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=60 train loss <loss>=2.72606153488\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:24 INFO 139866244298560] Epoch[6] Batch [60]#011Speed: 478.70 samples/sec#011loss=2.726062\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:24 INFO 139866244298560] Epoch[6] Batch[65] avg_epoch_loss=2.611076\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=65 train loss <loss>=2.75929436684\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:24 INFO 139866244298560] Epoch[6] Batch [65]#011Speed: 596.59 samples/sec#011loss=2.759294\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:25 INFO 139866244298560] Epoch[6] Batch[70] avg_epoch_loss=2.625415\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=70 train loss <loss>=2.81468710899\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:25 INFO 139866244298560] Epoch[6] Batch [70]#011Speed: 464.58 samples/sec#011loss=2.814687\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:25 INFO 139866244298560] Epoch[6] Batch[75] avg_epoch_loss=2.657742\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=75 train loss <loss>=3.11678209305\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:25 INFO 139866244298560] Epoch[6] Batch [75]#011Speed: 599.23 samples/sec#011loss=3.116782\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:26 INFO 139866244298560] Epoch[6] Batch[80] avg_epoch_loss=2.685666\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=80 train loss <loss>=3.11010789871\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:26 INFO 139866244298560] Epoch[6] Batch [80]#011Speed: 478.38 samples/sec#011loss=3.110108\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:27 INFO 139866244298560] Epoch[6] Batch[85] avg_epoch_loss=2.711636\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=85 train loss <loss>=3.13235397339\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:27 INFO 139866244298560] Epoch[6] Batch [85]#011Speed: 529.57 samples/sec#011loss=3.132354\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:27 INFO 139866244298560] Epoch[6] Batch[90] avg_epoch_loss=2.728081\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=90 train loss <loss>=3.01093783379\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:27 INFO 139866244298560] Epoch[6] Batch [90]#011Speed: 476.88 samples/sec#011loss=3.010938\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:28 INFO 139866244298560] Epoch[6] Batch[95] avg_epoch_loss=2.751453\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=95 train loss <loss>=3.17681870461\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:28 INFO 139866244298560] Epoch[6] Batch [95]#011Speed: 595.69 samples/sec#011loss=3.176819\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:29 INFO 139866244298560] Epoch[6] Batch[100] avg_epoch_loss=2.747545\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=100 train loss <loss>=2.67251534462\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:29 INFO 139866244298560] Epoch[6] Batch [100]#011Speed: 474.44 samples/sec#011loss=2.672515\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:29 INFO 139866244298560] Epoch[6] Batch[105] avg_epoch_loss=2.743753\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=105 train loss <loss>=2.66714248657\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:29 INFO 139866244298560] Epoch[6] Batch [105]#011Speed: 594.23 samples/sec#011loss=2.667142\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:30 INFO 139866244298560] Epoch[6] Batch[110] avg_epoch_loss=2.732918\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=110 train loss <loss>=2.50321969986\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:30 INFO 139866244298560] Epoch[6] Batch [110]#011Speed: 479.89 samples/sec#011loss=2.503220\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:30 INFO 139866244298560] Epoch[6] Batch[115] avg_epoch_loss=2.717476\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=115 train loss <loss>=2.37466897964\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:30 INFO 139866244298560] Epoch[6] Batch [115]#011Speed: 485.91 samples/sec#011loss=2.374669\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:31 INFO 139866244298560] Epoch[6] Batch[120] avg_epoch_loss=2.704620\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=120 train loss <loss>=2.4063662529\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:31 INFO 139866244298560] Epoch[6] Batch [120]#011Speed: 598.87 samples/sec#011loss=2.406366\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:32 INFO 139866244298560] Epoch[6] Batch[125] avg_epoch_loss=2.695617\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=125 train loss <loss>=2.47773396969\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:32 INFO 139866244298560] Epoch[6] Batch [125]#011Speed: 454.47 samples/sec#011loss=2.477734\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:32 INFO 139866244298560] Epoch[6] Batch[130] avg_epoch_loss=2.695073\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=130 train loss <loss>=2.6813765049\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:32 INFO 139866244298560] Epoch[6] Batch [130]#011Speed: 597.43 samples/sec#011loss=2.681377\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:33 INFO 139866244298560] Epoch[6] Batch[135] avg_epoch_loss=2.713046\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=135 train loss <loss>=3.1839389801\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:33 INFO 139866244298560] Epoch[6] Batch [135]#011Speed: 481.50 samples/sec#011loss=3.183939\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:33 INFO 139866244298560] Epoch[6] Batch[140] avg_epoch_loss=2.727338\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=140 train loss <loss>=3.11606702805\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:33 INFO 139866244298560] Epoch[6] Batch [140]#011Speed: 598.97 samples/sec#011loss=3.116067\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:34 INFO 139866244298560] Epoch[6] Batch[145] avg_epoch_loss=2.733914\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=145 train loss <loss>=2.91936159134\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:34 INFO 139866244298560] Epoch[6] Batch [145]#011Speed: 473.02 samples/sec#011loss=2.919362\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:35 INFO 139866244298560] Epoch[6] Batch[150] avg_epoch_loss=2.730603\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=150 train loss <loss>=2.63393211365\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:35 INFO 139866244298560] Epoch[6] Batch [150]#011Speed: 589.33 samples/sec#011loss=2.633932\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:35 INFO 139866244298560] Epoch[6] Batch[155] avg_epoch_loss=2.730458\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=155 train loss <loss>=2.72608222961\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:35 INFO 139866244298560] Epoch[6] Batch [155]#011Speed: 473.60 samples/sec#011loss=2.726082\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:36 INFO 139866244298560] Epoch[6] Batch[160] avg_epoch_loss=2.735707\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=160 train loss <loss>=2.89947638512\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:36 INFO 139866244298560] Epoch[6] Batch [160]#011Speed: 588.89 samples/sec#011loss=2.899476\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:37 INFO 139866244298560] Epoch[6] Batch[165] avg_epoch_loss=2.724836\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=165 train loss <loss>=2.37478494644\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:37 INFO 139866244298560] Epoch[6] Batch [165]#011Speed: 463.64 samples/sec#011loss=2.374785\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:37 INFO 139866244298560] Epoch[6] Batch[170] avg_epoch_loss=2.716123\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=170 train loss <loss>=2.42683451176\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:37 INFO 139866244298560] Epoch[6] Batch [170]#011Speed: 581.92 samples/sec#011loss=2.426835\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:38 INFO 139866244298560] Epoch[6] Batch[175] avg_epoch_loss=2.714022\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=175 train loss <loss>=2.64219164848\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:38 INFO 139866244298560] Epoch[6] Batch [175]#011Speed: 479.65 samples/sec#011loss=2.642192\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:38 INFO 139866244298560] Epoch[6] Batch[180] avg_epoch_loss=2.720164\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=180 train loss <loss>=2.93633942604\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:38 INFO 139866244298560] Epoch[6] Batch [180]#011Speed: 486.59 samples/sec#011loss=2.936339\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:39 INFO 139866244298560] Epoch[6] Batch[185] avg_epoch_loss=2.741256\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=185 train loss <loss>=3.50479393005\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:39 INFO 139866244298560] Epoch[6] Batch [185]#011Speed: 589.54 samples/sec#011loss=3.504794\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:40 INFO 139866244298560] Epoch[6] Batch[190] avg_epoch_loss=2.760577\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=190 train loss <loss>=3.47933473587\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:40 INFO 139866244298560] Epoch[6] Batch [190]#011Speed: 484.32 samples/sec#011loss=3.479335\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:40 INFO 139866244298560] Epoch[6] Batch[195] avg_epoch_loss=2.782119\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=195 train loss <loss>=3.60501279831\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:40 INFO 139866244298560] Epoch[6] Batch [195]#011Speed: 581.28 samples/sec#011loss=3.605013\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:41 INFO 139866244298560] Epoch[6] Batch[200] avg_epoch_loss=2.796561\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=200 train loss <loss>=3.36267728806\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:41 INFO 139866244298560] Epoch[6] Batch [200]#011Speed: 445.11 samples/sec#011loss=3.362677\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:41 INFO 139866244298560] Epoch[6] Batch[205] avg_epoch_loss=2.798700\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=205 train loss <loss>=2.88469552994\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:41 INFO 139866244298560] Epoch[6] Batch [205]#011Speed: 599.27 samples/sec#011loss=2.884696\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:42 INFO 139866244298560] Epoch[6] Batch[210] avg_epoch_loss=2.793730\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=210 train loss <loss>=2.58894810677\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:42 INFO 139866244298560] Epoch[6] Batch [210]#011Speed: 457.38 samples/sec#011loss=2.588948\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:43 INFO 139866244298560] Epoch[6] Batch[215] avg_epoch_loss=2.795714\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=215 train loss <loss>=2.87947297096\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:43 INFO 139866244298560] Epoch[6] Batch [215]#011Speed: 593.39 samples/sec#011loss=2.879473\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:43 INFO 139866244298560] Epoch[6] Batch[220] avg_epoch_loss=2.788354\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=220 train loss <loss>=2.47039256096\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:43 INFO 139866244298560] Epoch[6] Batch [220]#011Speed: 475.63 samples/sec#011loss=2.470393\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:44 INFO 139866244298560] Epoch[6] Batch[225] avg_epoch_loss=2.786615\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=225 train loss <loss>=2.70975193977\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:44 INFO 139866244298560] Epoch[6] Batch [225]#011Speed: 592.18 samples/sec#011loss=2.709752\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:45 INFO 139866244298560] Epoch[6] Batch[230] avg_epoch_loss=2.790021\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=230 train loss <loss>=2.94397211075\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:45 INFO 139866244298560] Epoch[6] Batch [230]#011Speed: 464.98 samples/sec#011loss=2.943972\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:45 INFO 139866244298560] Epoch[6] Batch[235] avg_epoch_loss=2.798163\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=235 train loss <loss>=3.17431812286\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:45 INFO 139866244298560] Epoch[6] Batch [235]#011Speed: 584.26 samples/sec#011loss=3.174318\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:46 INFO 139866244298560] Epoch[6] Batch[240] avg_epoch_loss=2.814213\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=240 train loss <loss>=3.57178587914\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:46 INFO 139866244298560] Epoch[6] Batch [240]#011Speed: 473.50 samples/sec#011loss=3.571786\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:46 INFO 139866244298560] Epoch[6] Batch[245] avg_epoch_loss=2.831872\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=245 train loss <loss>=3.68302288055\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:46 INFO 139866244298560] Epoch[6] Batch [245]#011Speed: 588.90 samples/sec#011loss=3.683023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:47 INFO 139866244298560] Epoch[6] Batch[250] avg_epoch_loss=2.849814\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=250 train loss <loss>=3.73255648613\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:47 INFO 139866244298560] Epoch[6] Batch [250]#011Speed: 442.87 samples/sec#011loss=3.732556\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:48 INFO 139866244298560] Epoch[6] Batch[255] avg_epoch_loss=2.857802\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=255 train loss <loss>=3.25880470276\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:48 INFO 139866244298560] Epoch[6] Batch [255]#011Speed: 598.36 samples/sec#011loss=3.258805\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:48 INFO 139866244298560] Epoch[6] Batch[260] avg_epoch_loss=2.861122\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=260 train loss <loss>=3.03111133575\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:48 INFO 139866244298560] Epoch[6] Batch [260]#011Speed: 480.55 samples/sec#011loss=3.031111\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:49 INFO 139866244298560] Epoch[6] Batch[265] avg_epoch_loss=2.862454\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, batch=265 train loss <loss>=2.9319852829\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:49 INFO 139866244298560] Epoch[6] Batch [265]#011Speed: 596.64 samples/sec#011loss=2.931985\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:49 INFO 139866244298560] processed a total of 17120 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33001.87110900879, \"sum\": 33001.87110900879, \"min\": 33001.87110900879}}, \"EndTime\": 1599442189.502308, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442156.500362}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:49 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=518.756280132 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:49 INFO 139866244298560] #progress_metric: host=algo-1, completed 8 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=6, train loss <loss>=2.85670751511\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:49 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:49 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_0b900fbc-5df7-431f-96be-e44abc1105e7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.49587059020996, \"sum\": 17.49587059020996, \"min\": 17.49587059020996}}, \"EndTime\": 1599442189.520593, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442189.502396}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:49 INFO 139866244298560] Epoch[7] Batch[0] avg_epoch_loss=2.351413\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=0 train loss <loss>=2.35141277313\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:50 INFO 139866244298560] Epoch[7] Batch[5] avg_epoch_loss=2.177952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=5 train loss <loss>=2.17795228958\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:50 INFO 139866244298560] Epoch[7] Batch [5]#011Speed: 577.93 samples/sec#011loss=2.177952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:51 INFO 139866244298560] Epoch[7] Batch[10] avg_epoch_loss=2.247669\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=10 train loss <loss>=2.33132843971\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:51 INFO 139866244298560] Epoch[7] Batch [10]#011Speed: 459.08 samples/sec#011loss=2.331328\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:51 INFO 139866244298560] Epoch[7] Batch[15] avg_epoch_loss=2.415282\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=15 train loss <loss>=2.78403124809\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:51 INFO 139866244298560] Epoch[7] Batch [15]#011Speed: 599.42 samples/sec#011loss=2.784031\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:52 INFO 139866244298560] Epoch[7] Batch[20] avg_epoch_loss=2.531356\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=20 train loss <loss>=2.90279173851\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:52 INFO 139866244298560] Epoch[7] Batch [20]#011Speed: 478.73 samples/sec#011loss=2.902792\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:52 INFO 139866244298560] Epoch[7] Batch[25] avg_epoch_loss=2.606383\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=25 train loss <loss>=2.92149605751\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:52 INFO 139866244298560] Epoch[7] Batch [25]#011Speed: 582.69 samples/sec#011loss=2.921496\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:53 INFO 139866244298560] Epoch[7] Batch[30] avg_epoch_loss=2.646798\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=30 train loss <loss>=2.85695648193\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:53 INFO 139866244298560] Epoch[7] Batch [30]#011Speed: 473.43 samples/sec#011loss=2.856956\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:53 INFO 139866244298560] Epoch[7] Batch[35] avg_epoch_loss=2.673039\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=35 train loss <loss>=2.83573246002\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:53 INFO 139866244298560] Epoch[7] Batch [35]#011Speed: 598.63 samples/sec#011loss=2.835732\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:54 INFO 139866244298560] Epoch[7] Batch[40] avg_epoch_loss=2.694741\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=40 train loss <loss>=2.85099635124\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:54 INFO 139866244298560] Epoch[7] Batch [40]#011Speed: 474.36 samples/sec#011loss=2.850996\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:55 INFO 139866244298560] Epoch[7] Batch[45] avg_epoch_loss=2.690633\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=45 train loss <loss>=2.65694923401\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:55 INFO 139866244298560] Epoch[7] Batch [45]#011Speed: 587.33 samples/sec#011loss=2.656949\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:55 INFO 139866244298560] Epoch[7] Batch[50] avg_epoch_loss=2.662042\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=50 train loss <loss>=2.3989991188\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:55 INFO 139866244298560] Epoch[7] Batch [50]#011Speed: 472.66 samples/sec#011loss=2.398999\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:56 INFO 139866244298560] Epoch[7] Batch[55] avg_epoch_loss=2.648007\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=55 train loss <loss>=2.50485668182\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:56 INFO 139866244298560] Epoch[7] Batch [55]#011Speed: 600.10 samples/sec#011loss=2.504857\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:57 INFO 139866244298560] Epoch[7] Batch[60] avg_epoch_loss=2.645547\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=60 train loss <loss>=2.6179930687\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:57 INFO 139866244298560] Epoch[7] Batch [60]#011Speed: 486.23 samples/sec#011loss=2.617993\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:57 INFO 139866244298560] Epoch[7] Batch[65] avg_epoch_loss=2.644044\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=65 train loss <loss>=2.62571187019\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:57 INFO 139866244298560] Epoch[7] Batch [65]#011Speed: 596.27 samples/sec#011loss=2.625712\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:58 INFO 139866244298560] Epoch[7] Batch[70] avg_epoch_loss=2.681685\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=70 train loss <loss>=3.17854447365\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:58 INFO 139866244298560] Epoch[7] Batch [70]#011Speed: 487.55 samples/sec#011loss=3.178544\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:58 INFO 139866244298560] Epoch[7] Batch[75] avg_epoch_loss=2.715904\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=75 train loss <loss>=3.20181317329\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:58 INFO 139866244298560] Epoch[7] Batch [75]#011Speed: 486.35 samples/sec#011loss=3.201813\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:59 INFO 139866244298560] Epoch[7] Batch[80] avg_epoch_loss=2.745310\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=80 train loss <loss>=3.19228539467\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:29:59 INFO 139866244298560] Epoch[7] Batch [80]#011Speed: 594.72 samples/sec#011loss=3.192285\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:00 INFO 139866244298560] Epoch[7] Batch[85] avg_epoch_loss=2.771675\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=85 train loss <loss>=3.19877877235\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:00 INFO 139866244298560] Epoch[7] Batch [85]#011Speed: 480.36 samples/sec#011loss=3.198779\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:00 INFO 139866244298560] Epoch[7] Batch[90] avg_epoch_loss=2.755734\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=90 train loss <loss>=2.48155708313\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:00 INFO 139866244298560] Epoch[7] Batch [90]#011Speed: 585.54 samples/sec#011loss=2.481557\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:01 INFO 139866244298560] Epoch[7] Batch[95] avg_epoch_loss=2.751731\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=95 train loss <loss>=2.67886543274\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:01 INFO 139866244298560] Epoch[7] Batch [95]#011Speed: 467.41 samples/sec#011loss=2.678865\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:01 INFO 139866244298560] Epoch[7] Batch[100] avg_epoch_loss=2.750861\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=100 train loss <loss>=2.73416891098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:01 INFO 139866244298560] Epoch[7] Batch [100]#011Speed: 567.27 samples/sec#011loss=2.734169\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:02 INFO 139866244298560] Epoch[7] Batch[105] avg_epoch_loss=2.727930\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=105 train loss <loss>=2.26472301483\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:02 INFO 139866244298560] Epoch[7] Batch [105]#011Speed: 474.50 samples/sec#011loss=2.264723\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:03 INFO 139866244298560] Epoch[7] Batch[110] avg_epoch_loss=2.704826\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=110 train loss <loss>=2.21502151489\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:03 INFO 139866244298560] Epoch[7] Batch [110]#011Speed: 591.69 samples/sec#011loss=2.215022\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:03 INFO 139866244298560] Epoch[7] Batch[115] avg_epoch_loss=2.705806\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=115 train loss <loss>=2.72756748199\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:03 INFO 139866244298560] Epoch[7] Batch [115]#011Speed: 476.90 samples/sec#011loss=2.727567\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:04 INFO 139866244298560] Epoch[7] Batch[120] avg_epoch_loss=2.707653\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=120 train loss <loss>=2.75048618317\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:04 INFO 139866244298560] Epoch[7] Batch [120]#011Speed: 592.83 samples/sec#011loss=2.750486\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:05 INFO 139866244298560] Epoch[7] Batch[125] avg_epoch_loss=2.724369\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=125 train loss <loss>=3.1288933754\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:05 INFO 139866244298560] Epoch[7] Batch [125]#011Speed: 479.63 samples/sec#011loss=3.128893\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:05 INFO 139866244298560] Epoch[7] Batch[130] avg_epoch_loss=2.743148\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=130 train loss <loss>=3.21639170647\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:05 INFO 139866244298560] Epoch[7] Batch [130]#011Speed: 573.41 samples/sec#011loss=3.216392\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:06 INFO 139866244298560] Epoch[7] Batch[135] avg_epoch_loss=2.755427\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=135 train loss <loss>=3.07712392807\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:06 INFO 139866244298560] Epoch[7] Batch [135]#011Speed: 477.27 samples/sec#011loss=3.077124\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:06 INFO 139866244298560] Epoch[7] Batch[140] avg_epoch_loss=2.758331\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=140 train loss <loss>=2.83731675148\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:06 INFO 139866244298560] Epoch[7] Batch [140]#011Speed: 591.61 samples/sec#011loss=2.837317\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:07 INFO 139866244298560] Epoch[7] Batch[145] avg_epoch_loss=2.742826\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=145 train loss <loss>=2.30559425354\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:07 INFO 139866244298560] Epoch[7] Batch [145]#011Speed: 481.96 samples/sec#011loss=2.305594\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:07 INFO 139866244298560] Epoch[7] Batch[150] avg_epoch_loss=2.735320\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=150 train loss <loss>=2.51615781784\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:07 INFO 139866244298560] Epoch[7] Batch [150]#011Speed: 589.66 samples/sec#011loss=2.516158\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:08 INFO 139866244298560] Epoch[7] Batch[155] avg_epoch_loss=2.733996\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=155 train loss <loss>=2.69399027824\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:08 INFO 139866244298560] Epoch[7] Batch [155]#011Speed: 469.68 samples/sec#011loss=2.693990\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:09 INFO 139866244298560] Epoch[7] Batch[160] avg_epoch_loss=2.737152\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=160 train loss <loss>=2.83563008308\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:09 INFO 139866244298560] Epoch[7] Batch [160]#011Speed: 591.97 samples/sec#011loss=2.835630\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:09 INFO 139866244298560] Epoch[7] Batch[165] avg_epoch_loss=2.735487\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=165 train loss <loss>=2.68186621666\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:09 INFO 139866244298560] Epoch[7] Batch [165]#011Speed: 472.75 samples/sec#011loss=2.681866\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:10 INFO 139866244298560] Epoch[7] Batch[170] avg_epoch_loss=2.728148\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=170 train loss <loss>=2.48450202942\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:10 INFO 139866244298560] Epoch[7] Batch [170]#011Speed: 543.54 samples/sec#011loss=2.484502\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:11 INFO 139866244298560] Epoch[7] Batch[175] avg_epoch_loss=2.734916\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=175 train loss <loss>=2.96639633179\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:11 INFO 139866244298560] Epoch[7] Batch [175]#011Speed: 433.43 samples/sec#011loss=2.966396\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:11 INFO 139866244298560] Epoch[7] Batch[180] avg_epoch_loss=2.741567\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=180 train loss <loss>=2.97567625046\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:11 INFO 139866244298560] Epoch[7] Batch [180]#011Speed: 598.92 samples/sec#011loss=2.975676\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:12 INFO 139866244298560] Epoch[7] Batch[185] avg_epoch_loss=2.765076\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=185 train loss <loss>=3.61607785225\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:12 INFO 139866244298560] Epoch[7] Batch [185]#011Speed: 481.68 samples/sec#011loss=3.616078\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:12 INFO 139866244298560] Epoch[7] Batch[190] avg_epoch_loss=2.785014\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=190 train loss <loss>=3.52673196793\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:12 INFO 139866244298560] Epoch[7] Batch [190]#011Speed: 597.51 samples/sec#011loss=3.526732\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:13 INFO 139866244298560] Epoch[7] Batch[195] avg_epoch_loss=2.805468\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=195 train loss <loss>=3.58681263924\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:13 INFO 139866244298560] Epoch[7] Batch [195]#011Speed: 476.33 samples/sec#011loss=3.586813\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:14 INFO 139866244298560] Epoch[7] Batch[200] avg_epoch_loss=2.824767\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=200 train loss <loss>=3.58126530647\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:14 INFO 139866244298560] Epoch[7] Batch [200]#011Speed: 596.26 samples/sec#011loss=3.581265\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:14 INFO 139866244298560] Epoch[7] Batch[205] avg_epoch_loss=2.829879\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=205 train loss <loss>=3.03538737297\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:14 INFO 139866244298560] Epoch[7] Batch [205]#011Speed: 481.28 samples/sec#011loss=3.035387\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:15 INFO 139866244298560] Epoch[7] Batch[210] avg_epoch_loss=2.831651\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=210 train loss <loss>=2.90465612411\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:15 INFO 139866244298560] Epoch[7] Batch [210]#011Speed: 587.98 samples/sec#011loss=2.904656\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:16 INFO 139866244298560] Epoch[7] Batch[215] avg_epoch_loss=2.827951\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=215 train loss <loss>=2.67182602882\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:16 INFO 139866244298560] Epoch[7] Batch [215]#011Speed: 481.05 samples/sec#011loss=2.671826\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:16 INFO 139866244298560] Epoch[7] Batch[220] avg_epoch_loss=2.822456\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=220 train loss <loss>=2.58508253098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:16 INFO 139866244298560] Epoch[7] Batch [220]#011Speed: 485.05 samples/sec#011loss=2.585083\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:17 INFO 139866244298560] Epoch[7] Batch[225] avg_epoch_loss=2.817791\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=225 train loss <loss>=2.611566782\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:17 INFO 139866244298560] Epoch[7] Batch [225]#011Speed: 595.08 samples/sec#011loss=2.611567\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:17 INFO 139866244298560] Epoch[7] Batch[230] avg_epoch_loss=2.815567\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=230 train loss <loss>=2.71503210068\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:17 INFO 139866244298560] Epoch[7] Batch [230]#011Speed: 486.32 samples/sec#011loss=2.715032\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:18 INFO 139866244298560] Epoch[7] Batch[235] avg_epoch_loss=2.830866\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=235 train loss <loss>=3.5377178669\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:18 INFO 139866244298560] Epoch[7] Batch [235]#011Speed: 598.63 samples/sec#011loss=3.537718\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:19 INFO 139866244298560] Epoch[7] Batch[240] avg_epoch_loss=2.846145\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=240 train loss <loss>=3.56731534004\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:19 INFO 139866244298560] Epoch[7] Batch [240]#011Speed: 483.69 samples/sec#011loss=3.567315\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:19 INFO 139866244298560] Epoch[7] Batch[245] avg_epoch_loss=2.863585\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=245 train loss <loss>=3.7041615963\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:19 INFO 139866244298560] Epoch[7] Batch [245]#011Speed: 594.97 samples/sec#011loss=3.704162\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:20 INFO 139866244298560] Epoch[7] Batch[250] avg_epoch_loss=2.868031\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=250 train loss <loss>=3.08681111336\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:20 INFO 139866244298560] Epoch[7] Batch [250]#011Speed: 467.08 samples/sec#011loss=3.086811\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:20 INFO 139866244298560] Epoch[7] Batch[255] avg_epoch_loss=2.867074\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=255 train loss <loss>=2.81899266243\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:20 INFO 139866244298560] Epoch[7] Batch [255]#011Speed: 594.58 samples/sec#011loss=2.818993\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:21 INFO 139866244298560] Epoch[7] Batch[260] avg_epoch_loss=2.863488\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=260 train loss <loss>=2.67988967896\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:21 INFO 139866244298560] Epoch[7] Batch [260]#011Speed: 481.35 samples/sec#011loss=2.679890\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:22 INFO 139866244298560] Epoch[7] Batch[265] avg_epoch_loss=2.860159\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, batch=265 train loss <loss>=2.68639221191\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:22 INFO 139866244298560] Epoch[7] Batch [265]#011Speed: 596.81 samples/sec#011loss=2.686392\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:22 INFO 139866244298560] processed a total of 17275 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32980.94987869263, \"sum\": 32980.94987869263, \"min\": 32980.94987869263}}, \"EndTime\": 1599442222.501708, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442189.520669}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:22 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=523.785056434 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:22 INFO 139866244298560] #progress_metric: host=algo-1, completed 10 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=7, train loss <loss>=2.87020876673\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:22 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:22 INFO 139866244298560] Epoch[8] Batch[0] avg_epoch_loss=2.460976\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=0 train loss <loss>=2.46097564697\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:23 INFO 139866244298560] Epoch[8] Batch[5] avg_epoch_loss=2.423887\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=5 train loss <loss>=2.42388737202\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:23 INFO 139866244298560] Epoch[8] Batch [5]#011Speed: 585.51 samples/sec#011loss=2.423887\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:23 INFO 139866244298560] Epoch[8] Batch[10] avg_epoch_loss=2.487208\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=10 train loss <loss>=2.56319205761\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:23 INFO 139866244298560] Epoch[8] Batch [10]#011Speed: 465.96 samples/sec#011loss=2.563192\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:24 INFO 139866244298560] Epoch[8] Batch[15] avg_epoch_loss=2.590252\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=15 train loss <loss>=2.81694808006\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:24 INFO 139866244298560] Epoch[8] Batch [15]#011Speed: 598.02 samples/sec#011loss=2.816948\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:25 INFO 139866244298560] Epoch[8] Batch[20] avg_epoch_loss=2.643699\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=20 train loss <loss>=2.814731884\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:25 INFO 139866244298560] Epoch[8] Batch [20]#011Speed: 470.15 samples/sec#011loss=2.814732\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:25 INFO 139866244298560] Epoch[8] Batch[25] avg_epoch_loss=2.695109\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=25 train loss <loss>=2.91103210449\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:25 INFO 139866244298560] Epoch[8] Batch [25]#011Speed: 574.71 samples/sec#011loss=2.911032\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:26 INFO 139866244298560] Epoch[8] Batch[30] avg_epoch_loss=2.736607\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=30 train loss <loss>=2.95239343643\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:26 INFO 139866244298560] Epoch[8] Batch [30]#011Speed: 472.71 samples/sec#011loss=2.952393\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:26 INFO 139866244298560] Epoch[8] Batch[35] avg_epoch_loss=2.704316\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=35 train loss <loss>=2.5041103363\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:26 INFO 139866244298560] Epoch[8] Batch [35]#011Speed: 593.11 samples/sec#011loss=2.504110\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:27 INFO 139866244298560] Epoch[8] Batch[40] avg_epoch_loss=2.729658\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=40 train loss <loss>=2.91212277412\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:27 INFO 139866244298560] Epoch[8] Batch [40]#011Speed: 482.50 samples/sec#011loss=2.912123\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:28 INFO 139866244298560] Epoch[8] Batch[45] avg_epoch_loss=2.705697\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=45 train loss <loss>=2.50921812057\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:28 INFO 139866244298560] Epoch[8] Batch [45]#011Speed: 595.64 samples/sec#011loss=2.509218\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:28 INFO 139866244298560] Epoch[8] Batch[50] avg_epoch_loss=2.688072\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=50 train loss <loss>=2.52591671944\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:28 INFO 139866244298560] Epoch[8] Batch [50]#011Speed: 475.24 samples/sec#011loss=2.525917\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:29 INFO 139866244298560] Epoch[8] Batch[55] avg_epoch_loss=2.675927\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=55 train loss <loss>=2.55205535889\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:29 INFO 139866244298560] Epoch[8] Batch [55]#011Speed: 592.98 samples/sec#011loss=2.552055\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:30 INFO 139866244298560] Epoch[8] Batch[60] avg_epoch_loss=2.668269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=60 train loss <loss>=2.58249106407\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:30 INFO 139866244298560] Epoch[8] Batch [60]#011Speed: 478.75 samples/sec#011loss=2.582491\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:30 INFO 139866244298560] Epoch[8] Batch[65] avg_epoch_loss=2.660489\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=65 train loss <loss>=2.56557359695\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:30 INFO 139866244298560] Epoch[8] Batch [65]#011Speed: 583.94 samples/sec#011loss=2.565574\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:31 INFO 139866244298560] Epoch[8] Batch[70] avg_epoch_loss=2.678888\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=70 train loss <loss>=2.92176451683\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:31 INFO 139866244298560] Epoch[8] Batch [70]#011Speed: 486.97 samples/sec#011loss=2.921765\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:31 INFO 139866244298560] Epoch[8] Batch[75] avg_epoch_loss=2.703587\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=75 train loss <loss>=3.05430665016\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:31 INFO 139866244298560] Epoch[8] Batch [75]#011Speed: 598.80 samples/sec#011loss=3.054307\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:32 INFO 139866244298560] Epoch[8] Batch[80] avg_epoch_loss=2.737359\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=80 train loss <loss>=3.2506872654\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:32 INFO 139866244298560] Epoch[8] Batch [80]#011Speed: 481.75 samples/sec#011loss=3.250687\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:32 INFO 139866244298560] Epoch[8] Batch[85] avg_epoch_loss=2.772679\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=85 train loss <loss>=3.34486918449\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:32 INFO 139866244298560] Epoch[8] Batch [85]#011Speed: 596.57 samples/sec#011loss=3.344869\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:33 INFO 139866244298560] Epoch[8] Batch[90] avg_epoch_loss=2.780939\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=90 train loss <loss>=2.92301568985\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:33 INFO 139866244298560] Epoch[8] Batch [90]#011Speed: 481.42 samples/sec#011loss=2.923016\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:34 INFO 139866244298560] Epoch[8] Batch[95] avg_epoch_loss=2.783724\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=95 train loss <loss>=2.8343981266\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:34 INFO 139866244298560] Epoch[8] Batch [95]#011Speed: 478.24 samples/sec#011loss=2.834398\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:34 INFO 139866244298560] Epoch[8] Batch[100] avg_epoch_loss=2.782049\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=100 train loss <loss>=2.7498942852\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:34 INFO 139866244298560] Epoch[8] Batch [100]#011Speed: 596.16 samples/sec#011loss=2.749894\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:35 INFO 139866244298560] Epoch[8] Batch[105] avg_epoch_loss=2.767698\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=105 train loss <loss>=2.47780900002\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:35 INFO 139866244298560] Epoch[8] Batch [105]#011Speed: 467.46 samples/sec#011loss=2.477809\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:36 INFO 139866244298560] Epoch[8] Batch[110] avg_epoch_loss=2.742233\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=110 train loss <loss>=2.20237669945\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:36 INFO 139866244298560] Epoch[8] Batch [110]#011Speed: 595.19 samples/sec#011loss=2.202377\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:36 INFO 139866244298560] Epoch[8] Batch[115] avg_epoch_loss=2.728048\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=115 train loss <loss>=2.41313595772\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:36 INFO 139866244298560] Epoch[8] Batch [115]#011Speed: 485.09 samples/sec#011loss=2.413136\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:37 INFO 139866244298560] Epoch[8] Batch[120] avg_epoch_loss=2.706730\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=120 train loss <loss>=2.21214993\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:37 INFO 139866244298560] Epoch[8] Batch [120]#011Speed: 594.47 samples/sec#011loss=2.212150\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:37 INFO 139866244298560] Epoch[8] Batch[125] avg_epoch_loss=2.699098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=125 train loss <loss>=2.51441760063\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:37 INFO 139866244298560] Epoch[8] Batch [125]#011Speed: 479.69 samples/sec#011loss=2.514418\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:38 INFO 139866244298560] Epoch[8] Batch[130] avg_epoch_loss=2.702143\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=130 train loss <loss>=2.77888288498\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:38 INFO 139866244298560] Epoch[8] Batch [130]#011Speed: 597.07 samples/sec#011loss=2.778883\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:39 INFO 139866244298560] Epoch[8] Batch[135] avg_epoch_loss=2.715837\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=135 train loss <loss>=3.07461490631\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:39 INFO 139866244298560] Epoch[8] Batch [135]#011Speed: 477.33 samples/sec#011loss=3.074615\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:39 INFO 139866244298560] Epoch[8] Batch[140] avg_epoch_loss=2.728745\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=140 train loss <loss>=3.07984852791\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:39 INFO 139866244298560] Epoch[8] Batch [140]#011Speed: 598.68 samples/sec#011loss=3.079849\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:40 INFO 139866244298560] Epoch[8] Batch[145] avg_epoch_loss=2.738332\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=145 train loss <loss>=3.00866374969\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:40 INFO 139866244298560] Epoch[8] Batch [145]#011Speed: 483.82 samples/sec#011loss=3.008664\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:40 INFO 139866244298560] Epoch[8] Batch[150] avg_epoch_loss=2.739361\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=150 train loss <loss>=2.76940498352\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:40 INFO 139866244298560] Epoch[8] Batch [150]#011Speed: 590.36 samples/sec#011loss=2.769405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:41 INFO 139866244298560] Epoch[8] Batch[155] avg_epoch_loss=2.744068\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=155 train loss <loss>=2.88622355461\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:41 INFO 139866244298560] Epoch[8] Batch [155]#011Speed: 426.34 samples/sec#011loss=2.886224\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:42 INFO 139866244298560] Epoch[8] Batch[160] avg_epoch_loss=2.747491\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=160 train loss <loss>=2.85429239273\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:42 INFO 139866244298560] Epoch[8] Batch [160]#011Speed: 593.00 samples/sec#011loss=2.854292\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:42 INFO 139866244298560] Epoch[8] Batch[165] avg_epoch_loss=2.742012\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=165 train loss <loss>=2.56558356285\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:42 INFO 139866244298560] Epoch[8] Batch [165]#011Speed: 472.72 samples/sec#011loss=2.565584\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:43 INFO 139866244298560] Epoch[8] Batch[170] avg_epoch_loss=2.742819\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=170 train loss <loss>=2.7696331501\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:43 INFO 139866244298560] Epoch[8] Batch [170]#011Speed: 593.09 samples/sec#011loss=2.769633\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:44 INFO 139866244298560] Epoch[8] Batch[175] avg_epoch_loss=2.739924\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=175 train loss <loss>=2.64091281891\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:44 INFO 139866244298560] Epoch[8] Batch [175]#011Speed: 479.23 samples/sec#011loss=2.640913\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:44 INFO 139866244298560] Epoch[8] Batch[180] avg_epoch_loss=2.737637\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=180 train loss <loss>=2.65712490082\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:44 INFO 139866244298560] Epoch[8] Batch [180]#011Speed: 477.88 samples/sec#011loss=2.657125\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:45 INFO 139866244298560] Epoch[8] Batch[185] avg_epoch_loss=2.742904\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=185 train loss <loss>=2.93355569839\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:45 INFO 139866244298560] Epoch[8] Batch [185]#011Speed: 598.56 samples/sec#011loss=2.933556\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:45 INFO 139866244298560] Epoch[8] Batch[190] avg_epoch_loss=2.754960\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=190 train loss <loss>=3.20345458984\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:45 INFO 139866244298560] Epoch[8] Batch [190]#011Speed: 482.11 samples/sec#011loss=3.203455\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:46 INFO 139866244298560] Epoch[8] Batch[195] avg_epoch_loss=2.778788\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=195 train loss <loss>=3.68901796341\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:46 INFO 139866244298560] Epoch[8] Batch [195]#011Speed: 601.06 samples/sec#011loss=3.689018\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:47 INFO 139866244298560] Epoch[8] Batch[200] avg_epoch_loss=2.798705\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=200 train loss <loss>=3.57944116592\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:47 INFO 139866244298560] Epoch[8] Batch [200]#011Speed: 485.03 samples/sec#011loss=3.579441\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:47 INFO 139866244298560] Epoch[8] Batch[205] avg_epoch_loss=2.820133\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=205 train loss <loss>=3.6815559864\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:47 INFO 139866244298560] Epoch[8] Batch [205]#011Speed: 596.41 samples/sec#011loss=3.681556\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:48 INFO 139866244298560] Epoch[8] Batch[210] avg_epoch_loss=2.822559\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=210 train loss <loss>=2.92251300812\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:48 INFO 139866244298560] Epoch[8] Batch [210]#011Speed: 484.16 samples/sec#011loss=2.922513\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:48 INFO 139866244298560] Epoch[8] Batch[215] avg_epoch_loss=2.815103\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=215 train loss <loss>=2.50044074059\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:48 INFO 139866244298560] Epoch[8] Batch [215]#011Speed: 584.26 samples/sec#011loss=2.500441\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:49 INFO 139866244298560] Epoch[8] Batch[220] avg_epoch_loss=2.805867\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=220 train loss <loss>=2.40688247681\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:49 INFO 139866244298560] Epoch[8] Batch [220]#011Speed: 478.55 samples/sec#011loss=2.406882\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:50 INFO 139866244298560] Epoch[8] Batch[225] avg_epoch_loss=2.796003\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=225 train loss <loss>=2.36002657413\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:50 INFO 139866244298560] Epoch[8] Batch [225]#011Speed: 486.43 samples/sec#011loss=2.360027\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:50 INFO 139866244298560] Epoch[8] Batch[230] avg_epoch_loss=2.796244\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=230 train loss <loss>=2.80710697174\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:50 INFO 139866244298560] Epoch[8] Batch [230]#011Speed: 582.74 samples/sec#011loss=2.807107\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:51 INFO 139866244298560] Epoch[8] Batch[235] avg_epoch_loss=2.797921\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=235 train loss <loss>=2.87539582253\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:51 INFO 139866244298560] Epoch[8] Batch [235]#011Speed: 481.70 samples/sec#011loss=2.875396\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:51 INFO 139866244298560] Epoch[8] Batch[240] avg_epoch_loss=2.808366\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=240 train loss <loss>=3.30138907433\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:51 INFO 139866244298560] Epoch[8] Batch [240]#011Speed: 584.36 samples/sec#011loss=3.301389\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:52 INFO 139866244298560] Epoch[8] Batch[245] avg_epoch_loss=2.817612\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=245 train loss <loss>=3.26327838898\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:52 INFO 139866244298560] Epoch[8] Batch [245]#011Speed: 468.19 samples/sec#011loss=3.263278\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:53 INFO 139866244298560] Epoch[8] Batch[250] avg_epoch_loss=2.832235\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=250 train loss <loss>=3.55167908669\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:53 INFO 139866244298560] Epoch[8] Batch [250]#011Speed: 566.37 samples/sec#011loss=3.551679\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:53 INFO 139866244298560] Epoch[8] Batch[255] avg_epoch_loss=2.844763\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=255 train loss <loss>=3.47364258766\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:53 INFO 139866244298560] Epoch[8] Batch [255]#011Speed: 489.91 samples/sec#011loss=3.473643\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:54 INFO 139866244298560] Epoch[8] Batch[260] avg_epoch_loss=2.846428\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, batch=260 train loss <loss>=2.9316983223\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:54 INFO 139866244298560] Epoch[8] Batch [260]#011Speed: 587.93 samples/sec#011loss=2.931698\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:54 INFO 139866244298560] processed a total of 16880 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32243.80087852478, \"sum\": 32243.80087852478, \"min\": 32243.80087852478}}, \"EndTime\": 1599442254.746219, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442222.501795}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:54 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=523.509988329 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:54 INFO 139866244298560] #progress_metric: host=algo-1, completed 11 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=8, train loss <loss>=2.85057898859\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:54 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:54 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_e4ce2ddf-dae7-4b81-a9c1-1b0d36b66b2d-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.69089698791504, \"sum\": 17.69089698791504, \"min\": 17.69089698791504}}, \"EndTime\": 1599442254.764692, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442254.746278}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:55 INFO 139866244298560] Epoch[9] Batch[0] avg_epoch_loss=2.296748\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=0 train loss <loss>=2.2967479229\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:55 INFO 139866244298560] Epoch[9] Batch[5] avg_epoch_loss=2.292648\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=5 train loss <loss>=2.2926475207\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:55 INFO 139866244298560] Epoch[9] Batch [5]#011Speed: 591.34 samples/sec#011loss=2.292648\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:56 INFO 139866244298560] Epoch[9] Batch[10] avg_epoch_loss=2.236724\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=10 train loss <loss>=2.16961619854\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:56 INFO 139866244298560] Epoch[9] Batch [10]#011Speed: 462.98 samples/sec#011loss=2.169616\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:56 INFO 139866244298560] Epoch[9] Batch[15] avg_epoch_loss=2.415750\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=15 train loss <loss>=2.8096057415\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:56 INFO 139866244298560] Epoch[9] Batch [15]#011Speed: 601.56 samples/sec#011loss=2.809606\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:57 INFO 139866244298560] Epoch[9] Batch[20] avg_epoch_loss=2.485307\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=20 train loss <loss>=2.70788927078\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:57 INFO 139866244298560] Epoch[9] Batch [20]#011Speed: 470.10 samples/sec#011loss=2.707889\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:58 INFO 139866244298560] Epoch[9] Batch[25] avg_epoch_loss=2.515759\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=25 train loss <loss>=2.64365677834\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:58 INFO 139866244298560] Epoch[9] Batch [25]#011Speed: 559.57 samples/sec#011loss=2.643657\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:58 INFO 139866244298560] Epoch[9] Batch[30] avg_epoch_loss=2.561283\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=30 train loss <loss>=2.79800748825\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:58 INFO 139866244298560] Epoch[9] Batch [30]#011Speed: 592.77 samples/sec#011loss=2.798007\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:59 INFO 139866244298560] Epoch[9] Batch[35] avg_epoch_loss=2.592078\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=35 train loss <loss>=2.78300728798\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:59 INFO 139866244298560] Epoch[9] Batch [35]#011Speed: 473.94 samples/sec#011loss=2.783007\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:59 INFO 139866244298560] Epoch[9] Batch[40] avg_epoch_loss=2.610620\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=40 train loss <loss>=2.74412484169\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:30:59 INFO 139866244298560] Epoch[9] Batch [40]#011Speed: 481.34 samples/sec#011loss=2.744125\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:00 INFO 139866244298560] Epoch[9] Batch[45] avg_epoch_loss=2.632374\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=45 train loss <loss>=2.81075911522\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:00 INFO 139866244298560] Epoch[9] Batch [45]#011Speed: 577.67 samples/sec#011loss=2.810759\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:01 INFO 139866244298560] Epoch[9] Batch[50] avg_epoch_loss=2.646715\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=50 train loss <loss>=2.7786503315\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:01 INFO 139866244298560] Epoch[9] Batch [50]#011Speed: 419.91 samples/sec#011loss=2.778650\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:01 INFO 139866244298560] Epoch[9] Batch[55] avg_epoch_loss=2.630795\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=55 train loss <loss>=2.46841182709\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:01 INFO 139866244298560] Epoch[9] Batch [55]#011Speed: 575.08 samples/sec#011loss=2.468412\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:02 INFO 139866244298560] Epoch[9] Batch[60] avg_epoch_loss=2.600407\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=60 train loss <loss>=2.26005442142\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:02 INFO 139866244298560] Epoch[9] Batch [60]#011Speed: 477.60 samples/sec#011loss=2.260054\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:03 INFO 139866244298560] Epoch[9] Batch[65] avg_epoch_loss=2.597378\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=65 train loss <loss>=2.56043248177\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:03 INFO 139866244298560] Epoch[9] Batch [65]#011Speed: 550.54 samples/sec#011loss=2.560432\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:03 INFO 139866244298560] Epoch[9] Batch[70] avg_epoch_loss=2.605270\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=70 train loss <loss>=2.70943789482\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:03 INFO 139866244298560] Epoch[9] Batch [70]#011Speed: 474.60 samples/sec#011loss=2.709438\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:04 INFO 139866244298560] Epoch[9] Batch[75] avg_epoch_loss=2.625523\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=75 train loss <loss>=2.91311335564\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:04 INFO 139866244298560] Epoch[9] Batch [75]#011Speed: 594.32 samples/sec#011loss=2.913113\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:04 INFO 139866244298560] Epoch[9] Batch[80] avg_epoch_loss=2.642349\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=80 train loss <loss>=2.89810709953\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:04 INFO 139866244298560] Epoch[9] Batch [80]#011Speed: 474.91 samples/sec#011loss=2.898107\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:05 INFO 139866244298560] Epoch[9] Batch[85] avg_epoch_loss=2.666083\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=85 train loss <loss>=3.05058002472\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:05 INFO 139866244298560] Epoch[9] Batch [85]#011Speed: 600.02 samples/sec#011loss=3.050580\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:06 INFO 139866244298560] Epoch[9] Batch[90] avg_epoch_loss=2.704824\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=90 train loss <loss>=3.37116341591\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:06 INFO 139866244298560] Epoch[9] Batch [90]#011Speed: 466.76 samples/sec#011loss=3.371163\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:06 INFO 139866244298560] Epoch[9] Batch[95] avg_epoch_loss=2.729385\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=95 train loss <loss>=3.17639503479\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:06 INFO 139866244298560] Epoch[9] Batch [95]#011Speed: 591.03 samples/sec#011loss=3.176395\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:07 INFO 139866244298560] Epoch[9] Batch[100] avg_epoch_loss=2.743155\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=100 train loss <loss>=3.0075442791\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:07 INFO 139866244298560] Epoch[9] Batch [100]#011Speed: 478.82 samples/sec#011loss=3.007544\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:07 INFO 139866244298560] Epoch[9] Batch[105] avg_epoch_loss=2.732933\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=105 train loss <loss>=2.52644619942\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:07 INFO 139866244298560] Epoch[9] Batch [105]#011Speed: 600.97 samples/sec#011loss=2.526446\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:08 INFO 139866244298560] Epoch[9] Batch[110] avg_epoch_loss=2.728108\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=110 train loss <loss>=2.62581853867\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:08 INFO 139866244298560] Epoch[9] Batch [110]#011Speed: 442.15 samples/sec#011loss=2.625819\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:09 INFO 139866244298560] Epoch[9] Batch[115] avg_epoch_loss=2.708268\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=115 train loss <loss>=2.26780788898\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:09 INFO 139866244298560] Epoch[9] Batch [115]#011Speed: 594.64 samples/sec#011loss=2.267808\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:09 INFO 139866244298560] Epoch[9] Batch[120] avg_epoch_loss=2.699221\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=120 train loss <loss>=2.48934659958\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:09 INFO 139866244298560] Epoch[9] Batch [120]#011Speed: 471.49 samples/sec#011loss=2.489347\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:10 INFO 139866244298560] Epoch[9] Batch[125] avg_epoch_loss=2.690228\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=125 train loss <loss>=2.47259721756\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:10 INFO 139866244298560] Epoch[9] Batch [125]#011Speed: 592.46 samples/sec#011loss=2.472597\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:11 INFO 139866244298560] Epoch[9] Batch[130] avg_epoch_loss=2.679730\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=130 train loss <loss>=2.41518163681\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:11 INFO 139866244298560] Epoch[9] Batch [130]#011Speed: 473.47 samples/sec#011loss=2.415182\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:11 INFO 139866244298560] Epoch[9] Batch[135] avg_epoch_loss=2.675373\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=135 train loss <loss>=2.56121888161\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:11 INFO 139866244298560] Epoch[9] Batch [135]#011Speed: 543.57 samples/sec#011loss=2.561219\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:12 INFO 139866244298560] Epoch[9] Batch[140] avg_epoch_loss=2.691262\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=140 train loss <loss>=3.12344274521\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:12 INFO 139866244298560] Epoch[9] Batch [140]#011Speed: 475.09 samples/sec#011loss=3.123443\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:12 INFO 139866244298560] Epoch[9] Batch[145] avg_epoch_loss=2.701942\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=145 train loss <loss>=3.00310535431\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:12 INFO 139866244298560] Epoch[9] Batch [145]#011Speed: 599.39 samples/sec#011loss=3.003105\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:13 INFO 139866244298560] Epoch[9] Batch[150] avg_epoch_loss=2.717677\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=150 train loss <loss>=3.17714486122\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:13 INFO 139866244298560] Epoch[9] Batch [150]#011Speed: 445.54 samples/sec#011loss=3.177145\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:14 INFO 139866244298560] Epoch[9] Batch[155] avg_epoch_loss=2.732175\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=155 train loss <loss>=3.17001690865\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:14 INFO 139866244298560] Epoch[9] Batch [155]#011Speed: 592.39 samples/sec#011loss=3.170017\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:14 INFO 139866244298560] Epoch[9] Batch[160] avg_epoch_loss=2.739715\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=160 train loss <loss>=2.97496857643\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:14 INFO 139866244298560] Epoch[9] Batch [160]#011Speed: 481.64 samples/sec#011loss=2.974969\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:15 INFO 139866244298560] Epoch[9] Batch[165] avg_epoch_loss=2.750036\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=165 train loss <loss>=3.08236365318\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:15 INFO 139866244298560] Epoch[9] Batch [165]#011Speed: 582.57 samples/sec#011loss=3.082364\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:16 INFO 139866244298560] Epoch[9] Batch[170] avg_epoch_loss=2.740192\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=170 train loss <loss>=2.4133849144\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:16 INFO 139866244298560] Epoch[9] Batch [170]#011Speed: 465.75 samples/sec#011loss=2.413385\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:16 INFO 139866244298560] Epoch[9] Batch[175] avg_epoch_loss=2.736033\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=175 train loss <loss>=2.59376735687\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:16 INFO 139866244298560] Epoch[9] Batch [175]#011Speed: 481.10 samples/sec#011loss=2.593767\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:17 INFO 139866244298560] Epoch[9] Batch[180] avg_epoch_loss=2.736100\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=180 train loss <loss>=2.73847150803\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:17 INFO 139866244298560] Epoch[9] Batch [180]#011Speed: 553.28 samples/sec#011loss=2.738472\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:17 INFO 139866244298560] Epoch[9] Batch[185] avg_epoch_loss=2.737138\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=185 train loss <loss>=2.77470912933\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:17 INFO 139866244298560] Epoch[9] Batch [185]#011Speed: 481.63 samples/sec#011loss=2.774709\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:18 INFO 139866244298560] Epoch[9] Batch[190] avg_epoch_loss=2.736912\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=190 train loss <loss>=2.72852125168\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:18 INFO 139866244298560] Epoch[9] Batch [190]#011Speed: 561.96 samples/sec#011loss=2.728521\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:19 INFO 139866244298560] Epoch[9] Batch[195] avg_epoch_loss=2.747202\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=195 train loss <loss>=3.14026737213\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:19 INFO 139866244298560] Epoch[9] Batch [195]#011Speed: 482.46 samples/sec#011loss=3.140267\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:19 INFO 139866244298560] Epoch[9] Batch[200] avg_epoch_loss=2.770173\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=200 train loss <loss>=3.67064137459\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:19 INFO 139866244298560] Epoch[9] Batch [200]#011Speed: 598.20 samples/sec#011loss=3.670641\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:20 INFO 139866244298560] Epoch[9] Batch[205] avg_epoch_loss=2.793966\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=205 train loss <loss>=3.75045208931\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:20 INFO 139866244298560] Epoch[9] Batch [205]#011Speed: 478.87 samples/sec#011loss=3.750452\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:20 INFO 139866244298560] Epoch[9] Batch[210] avg_epoch_loss=2.807105\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=210 train loss <loss>=3.34840283394\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:20 INFO 139866244298560] Epoch[9] Batch [210]#011Speed: 590.40 samples/sec#011loss=3.348403\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:21 INFO 139866244298560] Epoch[9] Batch[215] avg_epoch_loss=2.809566\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=215 train loss <loss>=2.91344304085\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:21 INFO 139866244298560] Epoch[9] Batch [215]#011Speed: 482.55 samples/sec#011loss=2.913443\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:22 INFO 139866244298560] Epoch[9] Batch[220] avg_epoch_loss=2.811433\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=220 train loss <loss>=2.89210524559\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:22 INFO 139866244298560] Epoch[9] Batch [220]#011Speed: 594.57 samples/sec#011loss=2.892105\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:22 INFO 139866244298560] Epoch[9] Batch[225] avg_epoch_loss=2.818868\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=225 train loss <loss>=3.1474799633\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:22 INFO 139866244298560] Epoch[9] Batch [225]#011Speed: 478.34 samples/sec#011loss=3.147480\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:23 INFO 139866244298560] Epoch[9] Batch[230] avg_epoch_loss=2.813843\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=230 train loss <loss>=2.58669342995\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:23 INFO 139866244298560] Epoch[9] Batch [230]#011Speed: 560.84 samples/sec#011loss=2.586693\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:24 INFO 139866244298560] Epoch[9] Batch[235] avg_epoch_loss=2.812583\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=235 train loss <loss>=2.75437216759\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:24 INFO 139866244298560] Epoch[9] Batch [235]#011Speed: 415.95 samples/sec#011loss=2.754372\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:24 INFO 139866244298560] Epoch[9] Batch[240] avg_epoch_loss=2.811171\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=240 train loss <loss>=2.74452338219\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:24 INFO 139866244298560] Epoch[9] Batch [240]#011Speed: 587.99 samples/sec#011loss=2.744523\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:25 INFO 139866244298560] Epoch[9] Batch[245] avg_epoch_loss=2.813215\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=245 train loss <loss>=2.91174278259\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:25 INFO 139866244298560] Epoch[9] Batch [245]#011Speed: 477.67 samples/sec#011loss=2.911743\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:25 INFO 139866244298560] Epoch[9] Batch[250] avg_epoch_loss=2.816206\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=250 train loss <loss>=2.96335229874\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:25 INFO 139866244298560] Epoch[9] Batch [250]#011Speed: 552.75 samples/sec#011loss=2.963352\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:26 INFO 139866244298560] Epoch[9] Batch[255] avg_epoch_loss=2.826772\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=255 train loss <loss>=3.3571826458\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:26 INFO 139866244298560] Epoch[9] Batch [255]#011Speed: 473.80 samples/sec#011loss=3.357183\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:27 INFO 139866244298560] Epoch[9] Batch[260] avg_epoch_loss=2.837112\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=260 train loss <loss>=3.36653776169\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:27 INFO 139866244298560] Epoch[9] Batch [260]#011Speed: 589.87 samples/sec#011loss=3.366538\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:27 INFO 139866244298560] Epoch[9] Batch[265] avg_epoch_loss=2.843962\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=265 train loss <loss>=3.20150837898\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:27 INFO 139866244298560] Epoch[9] Batch [265]#011Speed: 491.53 samples/sec#011loss=3.201508\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:28 INFO 139866244298560] Epoch[9] Batch[270] avg_epoch_loss=2.853347\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, batch=270 train loss <loss>=3.35263476372\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:28 INFO 139866244298560] Epoch[9] Batch [270]#011Speed: 591.81 samples/sec#011loss=3.352635\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:28 INFO 139866244298560] processed a total of 17308 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33541.017055511475, \"sum\": 33541.017055511475, \"min\": 33541.017055511475}}, \"EndTime\": 1599442288.305829, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442254.764752}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:28 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=516.023253889 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:28 INFO 139866244298560] #progress_metric: host=algo-1, completed 12 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=9, train loss <loss>=2.85334661746\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:28 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:28 INFO 139866244298560] Epoch[10] Batch[0] avg_epoch_loss=2.330117\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=0 train loss <loss>=2.33011698723\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:29 INFO 139866244298560] Epoch[10] Batch[5] avg_epoch_loss=2.332720\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=5 train loss <loss>=2.33272023996\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:29 INFO 139866244298560] Epoch[10] Batch [5]#011Speed: 548.58 samples/sec#011loss=2.332720\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:29 INFO 139866244298560] Epoch[10] Batch[10] avg_epoch_loss=2.299225\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=10 train loss <loss>=2.25903139114\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:29 INFO 139866244298560] Epoch[10] Batch [10]#011Speed: 476.58 samples/sec#011loss=2.259031\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:30 INFO 139866244298560] Epoch[10] Batch[15] avg_epoch_loss=2.487902\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=15 train loss <loss>=2.90298995972\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:30 INFO 139866244298560] Epoch[10] Batch [15]#011Speed: 592.50 samples/sec#011loss=2.902990\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:31 INFO 139866244298560] Epoch[10] Batch[20] avg_epoch_loss=2.584681\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=20 train loss <loss>=2.89437441826\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:31 INFO 139866244298560] Epoch[10] Batch [20]#011Speed: 471.53 samples/sec#011loss=2.894374\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:31 INFO 139866244298560] Epoch[10] Batch[25] avg_epoch_loss=2.641658\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=25 train loss <loss>=2.88095908165\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:31 INFO 139866244298560] Epoch[10] Batch [25]#011Speed: 598.64 samples/sec#011loss=2.880959\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:32 INFO 139866244298560] Epoch[10] Batch[30] avg_epoch_loss=2.640184\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=30 train loss <loss>=2.6325193882\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:32 INFO 139866244298560] Epoch[10] Batch [30]#011Speed: 487.05 samples/sec#011loss=2.632519\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:32 INFO 139866244298560] Epoch[10] Batch[35] avg_epoch_loss=2.635463\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=35 train loss <loss>=2.60619840622\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:32 INFO 139866244298560] Epoch[10] Batch [35]#011Speed: 596.97 samples/sec#011loss=2.606198\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:33 INFO 139866244298560] Epoch[10] Batch[40] avg_epoch_loss=2.607350\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=40 train loss <loss>=2.40492973328\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:33 INFO 139866244298560] Epoch[10] Batch [40]#011Speed: 480.56 samples/sec#011loss=2.404930\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:34 INFO 139866244298560] Epoch[10] Batch[45] avg_epoch_loss=2.593384\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=45 train loss <loss>=2.4788620472\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:34 INFO 139866244298560] Epoch[10] Batch [45]#011Speed: 518.74 samples/sec#011loss=2.478862\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:34 INFO 139866244298560] Epoch[10] Batch[50] avg_epoch_loss=2.573614\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=50 train loss <loss>=2.39173536301\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:34 INFO 139866244298560] Epoch[10] Batch [50]#011Speed: 482.39 samples/sec#011loss=2.391735\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:35 INFO 139866244298560] Epoch[10] Batch[55] avg_epoch_loss=2.544430\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=55 train loss <loss>=2.24675211906\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:35 INFO 139866244298560] Epoch[10] Batch [55]#011Speed: 579.55 samples/sec#011loss=2.246752\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:35 INFO 139866244298560] Epoch[10] Batch[60] avg_epoch_loss=2.576057\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=60 train loss <loss>=2.93028025627\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:35 INFO 139866244298560] Epoch[10] Batch [60]#011Speed: 482.73 samples/sec#011loss=2.930280\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:36 INFO 139866244298560] Epoch[10] Batch[65] avg_epoch_loss=2.614449\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=65 train loss <loss>=3.08283367157\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:36 INFO 139866244298560] Epoch[10] Batch [65]#011Speed: 591.92 samples/sec#011loss=3.082834\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:37 INFO 139866244298560] Epoch[10] Batch[70] avg_epoch_loss=2.670200\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=70 train loss <loss>=3.40610551834\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:37 INFO 139866244298560] Epoch[10] Batch [70]#011Speed: 485.45 samples/sec#011loss=3.406106\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:37 INFO 139866244298560] Epoch[10] Batch[75] avg_epoch_loss=2.722517\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=75 train loss <loss>=3.46542963982\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:37 INFO 139866244298560] Epoch[10] Batch [75]#011Speed: 487.18 samples/sec#011loss=3.465430\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:38 INFO 139866244298560] Epoch[10] Batch[80] avg_epoch_loss=2.739667\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=80 train loss <loss>=3.00033707619\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:38 INFO 139866244298560] Epoch[10] Batch [80]#011Speed: 592.58 samples/sec#011loss=3.000337\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:39 INFO 139866244298560] Epoch[10] Batch[85] avg_epoch_loss=2.750800\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=85 train loss <loss>=2.93116025925\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:39 INFO 139866244298560] Epoch[10] Batch [85]#011Speed: 433.87 samples/sec#011loss=2.931160\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:39 INFO 139866244298560] Epoch[10] Batch[90] avg_epoch_loss=2.722480\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=90 train loss <loss>=2.23536999226\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:39 INFO 139866244298560] Epoch[10] Batch [90]#011Speed: 582.17 samples/sec#011loss=2.235370\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:40 INFO 139866244298560] Epoch[10] Batch[95] avg_epoch_loss=2.706212\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=95 train loss <loss>=2.41013240814\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:40 INFO 139866244298560] Epoch[10] Batch [95]#011Speed: 473.65 samples/sec#011loss=2.410132\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:40 INFO 139866244298560] Epoch[10] Batch[100] avg_epoch_loss=2.700228\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=100 train loss <loss>=2.58533654213\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:40 INFO 139866244298560] Epoch[10] Batch [100]#011Speed: 598.36 samples/sec#011loss=2.585337\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:41 INFO 139866244298560] Epoch[10] Batch[105] avg_epoch_loss=2.680595\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=105 train loss <loss>=2.28401956558\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:41 INFO 139866244298560] Epoch[10] Batch [105]#011Speed: 479.50 samples/sec#011loss=2.284020\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:42 INFO 139866244298560] Epoch[10] Batch[110] avg_epoch_loss=2.673161\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=110 train loss <loss>=2.51555376053\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:42 INFO 139866244298560] Epoch[10] Batch [110]#011Speed: 546.31 samples/sec#011loss=2.515554\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:42 INFO 139866244298560] Epoch[10] Batch[115] avg_epoch_loss=2.668450\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=115 train loss <loss>=2.56387593746\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:42 INFO 139866244298560] Epoch[10] Batch [115]#011Speed: 488.09 samples/sec#011loss=2.563876\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:43 INFO 139866244298560] Epoch[10] Batch[120] avg_epoch_loss=2.687857\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=120 train loss <loss>=3.13809013367\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:43 INFO 139866244298560] Epoch[10] Batch [120]#011Speed: 594.62 samples/sec#011loss=3.138090\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:43 INFO 139866244298560] Epoch[10] Batch[125] avg_epoch_loss=2.697425\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=125 train loss <loss>=2.92896814346\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:43 INFO 139866244298560] Epoch[10] Batch [125]#011Speed: 482.32 samples/sec#011loss=2.928968\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:44 INFO 139866244298560] Epoch[10] Batch[130] avg_epoch_loss=2.712347\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=130 train loss <loss>=3.08837957382\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:44 INFO 139866244298560] Epoch[10] Batch [130]#011Speed: 550.22 samples/sec#011loss=3.088380\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:45 INFO 139866244298560] Epoch[10] Batch[135] avg_epoch_loss=2.723073\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=135 train loss <loss>=3.00408344269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:45 INFO 139866244298560] Epoch[10] Batch [135]#011Speed: 461.76 samples/sec#011loss=3.004083\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:45 INFO 139866244298560] Epoch[10] Batch[140] avg_epoch_loss=2.724363\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=140 train loss <loss>=2.75947623253\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:45 INFO 139866244298560] Epoch[10] Batch [140]#011Speed: 592.73 samples/sec#011loss=2.759476\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:46 INFO 139866244298560] Epoch[10] Batch[145] avg_epoch_loss=2.717095\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=145 train loss <loss>=2.5121234417\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:46 INFO 139866244298560] Epoch[10] Batch [145]#011Speed: 478.47 samples/sec#011loss=2.512123\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:46 INFO 139866244298560] Epoch[10] Batch[150] avg_epoch_loss=2.708281\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=150 train loss <loss>=2.45092668533\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:46 INFO 139866244298560] Epoch[10] Batch [150]#011Speed: 600.75 samples/sec#011loss=2.450927\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:47 INFO 139866244298560] Epoch[10] Batch[155] avg_epoch_loss=2.705917\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=155 train loss <loss>=2.6345225811\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:47 INFO 139866244298560] Epoch[10] Batch [155]#011Speed: 473.35 samples/sec#011loss=2.634523\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:48 INFO 139866244298560] Epoch[10] Batch[160] avg_epoch_loss=2.700805\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=160 train loss <loss>=2.54129796028\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:48 INFO 139866244298560] Epoch[10] Batch [160]#011Speed: 594.32 samples/sec#011loss=2.541298\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:48 INFO 139866244298560] Epoch[10] Batch[165] avg_epoch_loss=2.704028\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=165 train loss <loss>=2.80780587196\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:48 INFO 139866244298560] Epoch[10] Batch [165]#011Speed: 479.99 samples/sec#011loss=2.807806\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:49 INFO 139866244298560] Epoch[10] Batch[170] avg_epoch_loss=2.694900\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=170 train loss <loss>=2.39187111855\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:49 INFO 139866244298560] Epoch[10] Batch [170]#011Speed: 548.58 samples/sec#011loss=2.391871\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:50 INFO 139866244298560] Epoch[10] Batch[175] avg_epoch_loss=2.705405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=175 train loss <loss>=3.06465969086\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:50 INFO 139866244298560] Epoch[10] Batch [175]#011Speed: 477.44 samples/sec#011loss=3.064660\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:50 INFO 139866244298560] Epoch[10] Batch[180] avg_epoch_loss=2.716159\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=180 train loss <loss>=3.09471745491\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:50 INFO 139866244298560] Epoch[10] Batch [180]#011Speed: 588.61 samples/sec#011loss=3.094717\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:51 INFO 139866244298560] Epoch[10] Batch[185] avg_epoch_loss=2.749594\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=185 train loss <loss>=3.95992293358\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:51 INFO 139866244298560] Epoch[10] Batch [185]#011Speed: 472.91 samples/sec#011loss=3.959923\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:51 INFO 139866244298560] Epoch[10] Batch[190] avg_epoch_loss=2.775341\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=190 train loss <loss>=3.7331193924\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:51 INFO 139866244298560] Epoch[10] Batch [190]#011Speed: 487.39 samples/sec#011loss=3.733119\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:52 INFO 139866244298560] Epoch[10] Batch[195] avg_epoch_loss=2.784161\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=195 train loss <loss>=3.12107715607\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:52 INFO 139866244298560] Epoch[10] Batch [195]#011Speed: 581.52 samples/sec#011loss=3.121077\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:53 INFO 139866244298560] Epoch[10] Batch[200] avg_epoch_loss=2.788111\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=200 train loss <loss>=2.94295907021\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:53 INFO 139866244298560] Epoch[10] Batch [200]#011Speed: 481.66 samples/sec#011loss=2.942959\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:53 INFO 139866244298560] Epoch[10] Batch[205] avg_epoch_loss=2.787445\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=205 train loss <loss>=2.76069803238\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:53 INFO 139866244298560] Epoch[10] Batch [205]#011Speed: 598.07 samples/sec#011loss=2.760698\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:54 INFO 139866244298560] Epoch[10] Batch[210] avg_epoch_loss=2.787319\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=210 train loss <loss>=2.78211460114\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:54 INFO 139866244298560] Epoch[10] Batch [210]#011Speed: 454.58 samples/sec#011loss=2.782115\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:54 INFO 139866244298560] Epoch[10] Batch[215] avg_epoch_loss=2.785520\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=215 train loss <loss>=2.70961289406\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:54 INFO 139866244298560] Epoch[10] Batch [215]#011Speed: 601.78 samples/sec#011loss=2.709613\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:55 INFO 139866244298560] Epoch[10] Batch[220] avg_epoch_loss=2.782272\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=220 train loss <loss>=2.64196081161\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:55 INFO 139866244298560] Epoch[10] Batch [220]#011Speed: 473.64 samples/sec#011loss=2.641961\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:56 INFO 139866244298560] Epoch[10] Batch[225] avg_epoch_loss=2.778768\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=225 train loss <loss>=2.62389688492\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:56 INFO 139866244298560] Epoch[10] Batch [225]#011Speed: 580.91 samples/sec#011loss=2.623897\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:56 INFO 139866244298560] Epoch[10] Batch[230] avg_epoch_loss=2.783386\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=230 train loss <loss>=2.99210233688\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:56 INFO 139866244298560] Epoch[10] Batch [230]#011Speed: 484.80 samples/sec#011loss=2.992102\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:57 INFO 139866244298560] Epoch[10] Batch[235] avg_epoch_loss=2.798276\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=235 train loss <loss>=3.48617186546\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:57 INFO 139866244298560] Epoch[10] Batch [235]#011Speed: 594.83 samples/sec#011loss=3.486172\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:58 INFO 139866244298560] Epoch[10] Batch[240] avg_epoch_loss=2.813170\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=240 train loss <loss>=3.51617827415\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:58 INFO 139866244298560] Epoch[10] Batch [240]#011Speed: 489.49 samples/sec#011loss=3.516178\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:58 INFO 139866244298560] Epoch[10] Batch[245] avg_epoch_loss=2.825009\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=245 train loss <loss>=3.39565405846\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:58 INFO 139866244298560] Epoch[10] Batch [245]#011Speed: 593.43 samples/sec#011loss=3.395654\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:59 INFO 139866244298560] Epoch[10] Batch[250] avg_epoch_loss=2.827193\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=250 train loss <loss>=2.93462677002\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:59 INFO 139866244298560] Epoch[10] Batch [250]#011Speed: 479.74 samples/sec#011loss=2.934627\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:59 INFO 139866244298560] Epoch[10] Batch[255] avg_epoch_loss=2.826649\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=255 train loss <loss>=2.79936990738\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:31:59 INFO 139866244298560] Epoch[10] Batch [255]#011Speed: 550.73 samples/sec#011loss=2.799370\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:00 INFO 139866244298560] Epoch[10] Batch[260] avg_epoch_loss=2.819760\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=260 train loss <loss>=2.46705832481\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:00 INFO 139866244298560] Epoch[10] Batch [260]#011Speed: 477.39 samples/sec#011loss=2.467058\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:01 INFO 139866244298560] Epoch[10] Batch[265] avg_epoch_loss=2.813023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=265 train loss <loss>=2.46134300232\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:01 INFO 139866244298560] Epoch[10] Batch [265]#011Speed: 591.30 samples/sec#011loss=2.461343\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:01 INFO 139866244298560] Epoch[10] Batch[270] avg_epoch_loss=2.834988\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, batch=270 train loss <loss>=4.0034907341\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:01 INFO 139866244298560] Epoch[10] Batch [270]#011Speed: 527.73 samples/sec#011loss=4.003491\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:01 INFO 139866244298560] processed a total of 17290 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33320.49918174744, \"sum\": 33320.49918174744, \"min\": 33320.49918174744}}, \"EndTime\": 1599442321.627009, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442288.305902}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:01 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=518.898422817 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:01 INFO 139866244298560] #progress_metric: host=algo-1, completed 13 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=10, train loss <loss>=2.83498764214\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:01 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:01 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_93778d68-5421-40b2-ad98-4a1df2865e88-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.490076065063477, \"sum\": 18.490076065063477, \"min\": 18.490076065063477}}, \"EndTime\": 1599442321.646612, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442321.627066}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:01 INFO 139866244298560] Epoch[11] Batch[0] avg_epoch_loss=2.343204\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=0 train loss <loss>=2.34320378304\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:02 INFO 139866244298560] Epoch[11] Batch[5] avg_epoch_loss=2.202467\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=5 train loss <loss>=2.2024674813\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:02 INFO 139866244298560] Epoch[11] Batch [5]#011Speed: 591.60 samples/sec#011loss=2.202467\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:03 INFO 139866244298560] Epoch[11] Batch[10] avg_epoch_loss=2.318054\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=10 train loss <loss>=2.45675721169\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:03 INFO 139866244298560] Epoch[11] Batch [10]#011Speed: 469.74 samples/sec#011loss=2.456757\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:03 INFO 139866244298560] Epoch[11] Batch[15] avg_epoch_loss=2.504476\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=15 train loss <loss>=2.91460533142\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:03 INFO 139866244298560] Epoch[11] Batch [15]#011Speed: 596.13 samples/sec#011loss=2.914605\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:04 INFO 139866244298560] Epoch[11] Batch[20] avg_epoch_loss=2.655129\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=20 train loss <loss>=3.13721985817\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:04 INFO 139866244298560] Epoch[11] Batch [20]#011Speed: 475.34 samples/sec#011loss=3.137220\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:04 INFO 139866244298560] Epoch[11] Batch[25] avg_epoch_loss=2.738591\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=25 train loss <loss>=3.08912949562\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:04 INFO 139866244298560] Epoch[11] Batch [25]#011Speed: 541.33 samples/sec#011loss=3.089129\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:05 INFO 139866244298560] Epoch[11] Batch[30] avg_epoch_loss=2.727458\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=30 train loss <loss>=2.66956791878\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:05 INFO 139866244298560] Epoch[11] Batch [30]#011Speed: 467.91 samples/sec#011loss=2.669568\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:06 INFO 139866244298560] Epoch[11] Batch[35] avg_epoch_loss=2.702208\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=35 train loss <loss>=2.54566025734\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:06 INFO 139866244298560] Epoch[11] Batch [35]#011Speed: 586.15 samples/sec#011loss=2.545660\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:06 INFO 139866244298560] Epoch[11] Batch[40] avg_epoch_loss=2.659486\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=40 train loss <loss>=2.35188341141\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:06 INFO 139866244298560] Epoch[11] Batch [40]#011Speed: 473.37 samples/sec#011loss=2.351883\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:07 INFO 139866244298560] Epoch[11] Batch[45] avg_epoch_loss=2.647275\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=45 train loss <loss>=2.54714918137\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:07 INFO 139866244298560] Epoch[11] Batch [45]#011Speed: 596.73 samples/sec#011loss=2.547149\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:08 INFO 139866244298560] Epoch[11] Batch[50] avg_epoch_loss=2.651036\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=50 train loss <loss>=2.68563027382\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:08 INFO 139866244298560] Epoch[11] Batch [50]#011Speed: 469.04 samples/sec#011loss=2.685630\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:08 INFO 139866244298560] Epoch[11] Batch[55] avg_epoch_loss=2.641980\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=55 train loss <loss>=2.54960660934\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:08 INFO 139866244298560] Epoch[11] Batch [55]#011Speed: 593.23 samples/sec#011loss=2.549607\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:09 INFO 139866244298560] Epoch[11] Batch[60] avg_epoch_loss=2.636698\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=60 train loss <loss>=2.57754487991\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:09 INFO 139866244298560] Epoch[11] Batch [60]#011Speed: 462.48 samples/sec#011loss=2.577545\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:09 INFO 139866244298560] Epoch[11] Batch[65] avg_epoch_loss=2.622392\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=65 train loss <loss>=2.44785246849\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:09 INFO 139866244298560] Epoch[11] Batch [65]#011Speed: 557.78 samples/sec#011loss=2.447852\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:10 INFO 139866244298560] Epoch[11] Batch[70] avg_epoch_loss=2.657686\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=70 train loss <loss>=3.12357096672\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:10 INFO 139866244298560] Epoch[11] Batch [70]#011Speed: 480.79 samples/sec#011loss=3.123571\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:11 INFO 139866244298560] Epoch[11] Batch[75] avg_epoch_loss=2.682229\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=75 train loss <loss>=3.03074421883\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:11 INFO 139866244298560] Epoch[11] Batch [75]#011Speed: 587.37 samples/sec#011loss=3.030744\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:11 INFO 139866244298560] Epoch[11] Batch[80] avg_epoch_loss=2.720186\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=80 train loss <loss>=3.29713664055\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:11 INFO 139866244298560] Epoch[11] Batch [80]#011Speed: 475.33 samples/sec#011loss=3.297137\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:12 INFO 139866244298560] Epoch[11] Batch[85] avg_epoch_loss=2.754729\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=85 train loss <loss>=3.31431846619\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:12 INFO 139866244298560] Epoch[11] Batch [85]#011Speed: 538.63 samples/sec#011loss=3.314318\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:12 INFO 139866244298560] Epoch[11] Batch[90] avg_epoch_loss=2.765730\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=90 train loss <loss>=2.95495095253\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:12 INFO 139866244298560] Epoch[11] Batch [90]#011Speed: 479.44 samples/sec#011loss=2.954951\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:13 INFO 139866244298560] Epoch[11] Batch[95] avg_epoch_loss=2.766849\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=95 train loss <loss>=2.78720331192\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:13 INFO 139866244298560] Epoch[11] Batch [95]#011Speed: 484.27 samples/sec#011loss=2.787203\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:14 INFO 139866244298560] Epoch[11] Batch[100] avg_epoch_loss=2.753133\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=100 train loss <loss>=2.48979697227\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:14 INFO 139866244298560] Epoch[11] Batch [100]#011Speed: 591.92 samples/sec#011loss=2.489797\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:14 INFO 139866244298560] Epoch[11] Batch[105] avg_epoch_loss=2.737979\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=105 train loss <loss>=2.4318754673\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:14 INFO 139866244298560] Epoch[11] Batch [105]#011Speed: 449.94 samples/sec#011loss=2.431875\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:15 INFO 139866244298560] Epoch[11] Batch[110] avg_epoch_loss=2.717211\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=110 train loss <loss>=2.27691130638\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:15 INFO 139866244298560] Epoch[11] Batch [110]#011Speed: 585.74 samples/sec#011loss=2.276911\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:16 INFO 139866244298560] Epoch[11] Batch[115] avg_epoch_loss=2.708208\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=115 train loss <loss>=2.50834302902\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:16 INFO 139866244298560] Epoch[11] Batch [115]#011Speed: 464.12 samples/sec#011loss=2.508343\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:16 INFO 139866244298560] Epoch[11] Batch[120] avg_epoch_loss=2.714640\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=120 train loss <loss>=2.86385931969\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:16 INFO 139866244298560] Epoch[11] Batch [120]#011Speed: 600.11 samples/sec#011loss=2.863859\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:17 INFO 139866244298560] Epoch[11] Batch[125] avg_epoch_loss=2.719633\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=125 train loss <loss>=2.84047040939\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:17 INFO 139866244298560] Epoch[11] Batch [125]#011Speed: 478.78 samples/sec#011loss=2.840470\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:17 INFO 139866244298560] Epoch[11] Batch[130] avg_epoch_loss=2.726996\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=130 train loss <loss>=2.91254010201\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:17 INFO 139866244298560] Epoch[11] Batch [130]#011Speed: 594.34 samples/sec#011loss=2.912540\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:18 INFO 139866244298560] Epoch[11] Batch[135] avg_epoch_loss=2.735474\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=135 train loss <loss>=2.95761628151\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:18 INFO 139866244298560] Epoch[11] Batch [135]#011Speed: 475.75 samples/sec#011loss=2.957616\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:19 INFO 139866244298560] Epoch[11] Batch[140] avg_epoch_loss=2.743640\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=140 train loss <loss>=2.96575345993\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:19 INFO 139866244298560] Epoch[11] Batch [140]#011Speed: 590.71 samples/sec#011loss=2.965753\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:19 INFO 139866244298560] Epoch[11] Batch[145] avg_epoch_loss=2.741457\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=145 train loss <loss>=2.67987360954\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:19 INFO 139866244298560] Epoch[11] Batch [145]#011Speed: 473.42 samples/sec#011loss=2.679874\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:20 INFO 139866244298560] Epoch[11] Batch[150] avg_epoch_loss=2.740386\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=150 train loss <loss>=2.70912909508\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:20 INFO 139866244298560] Epoch[11] Batch [150]#011Speed: 533.62 samples/sec#011loss=2.709129\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:21 INFO 139866244298560] Epoch[11] Batch[155] avg_epoch_loss=2.735969\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=155 train loss <loss>=2.60258271694\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:21 INFO 139866244298560] Epoch[11] Batch [155]#011Speed: 473.67 samples/sec#011loss=2.602583\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:21 INFO 139866244298560] Epoch[11] Batch[160] avg_epoch_loss=2.733665\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=160 train loss <loss>=2.66177153587\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:21 INFO 139866244298560] Epoch[11] Batch [160]#011Speed: 596.46 samples/sec#011loss=2.661772\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:22 INFO 139866244298560] Epoch[11] Batch[165] avg_epoch_loss=2.731209\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=165 train loss <loss>=2.65212416649\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:22 INFO 139866244298560] Epoch[11] Batch [165]#011Speed: 478.15 samples/sec#011loss=2.652124\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:22 INFO 139866244298560] Epoch[11] Batch[170] avg_epoch_loss=2.726312\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=170 train loss <loss>=2.56372361183\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:22 INFO 139866244298560] Epoch[11] Batch [170]#011Speed: 594.73 samples/sec#011loss=2.563724\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:23 INFO 139866244298560] Epoch[11] Batch[175] avg_epoch_loss=2.732211\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=175 train loss <loss>=2.93394813538\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:23 INFO 139866244298560] Epoch[11] Batch [175]#011Speed: 477.76 samples/sec#011loss=2.933948\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:24 INFO 139866244298560] Epoch[11] Batch[180] avg_epoch_loss=2.727906\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=180 train loss <loss>=2.57639431953\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:24 INFO 139866244298560] Epoch[11] Batch [180]#011Speed: 592.19 samples/sec#011loss=2.576394\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:24 INFO 139866244298560] Epoch[11] Batch[185] avg_epoch_loss=2.733003\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=185 train loss <loss>=2.9175160408\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:24 INFO 139866244298560] Epoch[11] Batch [185]#011Speed: 477.11 samples/sec#011loss=2.917516\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:25 INFO 139866244298560] Epoch[11] Batch[190] avg_epoch_loss=2.745670\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=190 train loss <loss>=3.21686635017\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:25 INFO 139866244298560] Epoch[11] Batch [190]#011Speed: 551.38 samples/sec#011loss=3.216866\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:25 INFO 139866244298560] Epoch[11] Batch[195] avg_epoch_loss=2.763441\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=195 train loss <loss>=3.44230656624\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:25 INFO 139866244298560] Epoch[11] Batch [195]#011Speed: 481.26 samples/sec#011loss=3.442307\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:26 INFO 139866244298560] Epoch[11] Batch[200] avg_epoch_loss=2.783407\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=200 train loss <loss>=3.56604814529\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:26 INFO 139866244298560] Epoch[11] Batch [200]#011Speed: 485.59 samples/sec#011loss=3.566048\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:27 INFO 139866244298560] Epoch[11] Batch[205] avg_epoch_loss=2.792652\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=205 train loss <loss>=3.16432933807\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:27 INFO 139866244298560] Epoch[11] Batch [205]#011Speed: 594.41 samples/sec#011loss=3.164329\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:27 INFO 139866244298560] Epoch[11] Batch[210] avg_epoch_loss=2.796298\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=210 train loss <loss>=2.94648656845\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:27 INFO 139866244298560] Epoch[11] Batch [210]#011Speed: 478.04 samples/sec#011loss=2.946487\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:28 INFO 139866244298560] Epoch[11] Batch[215] avg_epoch_loss=2.790551\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=215 train loss <loss>=2.54806261063\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:28 INFO 139866244298560] Epoch[11] Batch [215]#011Speed: 593.65 samples/sec#011loss=2.548063\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:29 INFO 139866244298560] Epoch[11] Batch[220] avg_epoch_loss=2.785095\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=220 train loss <loss>=2.54936022758\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:29 INFO 139866244298560] Epoch[11] Batch [220]#011Speed: 473.80 samples/sec#011loss=2.549360\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:29 INFO 139866244298560] Epoch[11] Batch[225] avg_epoch_loss=2.782215\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=225 train loss <loss>=2.65495247841\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:29 INFO 139866244298560] Epoch[11] Batch [225]#011Speed: 592.00 samples/sec#011loss=2.654952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:30 INFO 139866244298560] Epoch[11] Batch[230] avg_epoch_loss=2.782208\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=230 train loss <loss>=2.78187251091\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:30 INFO 139866244298560] Epoch[11] Batch [230]#011Speed: 439.08 samples/sec#011loss=2.781873\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:30 INFO 139866244298560] Epoch[11] Batch[235] avg_epoch_loss=2.784394\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=235 train loss <loss>=2.88538489342\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:30 INFO 139866244298560] Epoch[11] Batch [235]#011Speed: 597.78 samples/sec#011loss=2.885385\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:31 INFO 139866244298560] Epoch[11] Batch[240] avg_epoch_loss=2.790431\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=240 train loss <loss>=3.07540183067\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:31 INFO 139866244298560] Epoch[11] Batch [240]#011Speed: 478.85 samples/sec#011loss=3.075402\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:32 INFO 139866244298560] Epoch[11] Batch[245] avg_epoch_loss=2.803641\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=245 train loss <loss>=3.44032239914\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:32 INFO 139866244298560] Epoch[11] Batch [245]#011Speed: 596.11 samples/sec#011loss=3.440322\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:32 INFO 139866244298560] Epoch[11] Batch[250] avg_epoch_loss=2.819448\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=250 train loss <loss>=3.59719810486\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:32 INFO 139866244298560] Epoch[11] Batch [250]#011Speed: 486.52 samples/sec#011loss=3.597198\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:33 INFO 139866244298560] Epoch[11] Batch[255] avg_epoch_loss=2.830092\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=255 train loss <loss>=3.36440987587\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:33 INFO 139866244298560] Epoch[11] Batch [255]#011Speed: 596.65 samples/sec#011loss=3.364410\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:33 INFO 139866244298560] Epoch[11] Batch[260] avg_epoch_loss=2.832582\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=260 train loss <loss>=2.96004252434\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:33 INFO 139866244298560] Epoch[11] Batch [260]#011Speed: 483.48 samples/sec#011loss=2.960043\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:34 INFO 139866244298560] Epoch[11] Batch[265] avg_epoch_loss=2.829272\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, batch=265 train loss <loss>=2.65649533272\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:34 INFO 139866244298560] Epoch[11] Batch [265]#011Speed: 583.79 samples/sec#011loss=2.656495\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:34 INFO 139866244298560] processed a total of 17144 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32987.6070022583, \"sum\": 32987.6070022583, \"min\": 32987.6070022583}}, \"EndTime\": 1599442354.634372, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442321.646671}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:34 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=519.70846701 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:34 INFO 139866244298560] #progress_metric: host=algo-1, completed 15 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=11, train loss <loss>=2.83151259307\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:34 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:34 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_2c365a18-901d-40c1-9758-450f2fd54069-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 19.62900161743164, \"sum\": 19.62900161743164, \"min\": 19.62900161743164}}, \"EndTime\": 1599442354.655199, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442354.634434}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:34 INFO 139866244298560] Epoch[12] Batch[0] avg_epoch_loss=2.325665\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=0 train loss <loss>=2.32566523552\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:35 INFO 139866244298560] Epoch[12] Batch[5] avg_epoch_loss=2.287381\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=5 train loss <loss>=2.28738113244\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:35 INFO 139866244298560] Epoch[12] Batch [5]#011Speed: 537.91 samples/sec#011loss=2.287381\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:36 INFO 139866244298560] Epoch[12] Batch[10] avg_epoch_loss=2.286181\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=10 train loss <loss>=2.28473987579\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:36 INFO 139866244298560] Epoch[12] Batch [10]#011Speed: 470.31 samples/sec#011loss=2.284740\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:36 INFO 139866244298560] Epoch[12] Batch[15] avg_epoch_loss=2.466062\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=15 train loss <loss>=2.86180257797\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:36 INFO 139866244298560] Epoch[12] Batch [15]#011Speed: 590.96 samples/sec#011loss=2.861803\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:37 INFO 139866244298560] Epoch[12] Batch[20] avg_epoch_loss=2.548442\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=20 train loss <loss>=2.81205811501\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:37 INFO 139866244298560] Epoch[12] Batch [20]#011Speed: 473.98 samples/sec#011loss=2.812058\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:37 INFO 139866244298560] Epoch[12] Batch[25] avg_epoch_loss=2.600649\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=25 train loss <loss>=2.8199154377\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:37 INFO 139866244298560] Epoch[12] Batch [25]#011Speed: 597.27 samples/sec#011loss=2.819915\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:38 INFO 139866244298560] Epoch[12] Batch[30] avg_epoch_loss=2.640009\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=30 train loss <loss>=2.84468355179\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:38 INFO 139866244298560] Epoch[12] Batch [30]#011Speed: 476.45 samples/sec#011loss=2.844684\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:39 INFO 139866244298560] Epoch[12] Batch[35] avg_epoch_loss=2.669931\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=35 train loss <loss>=2.85544948578\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:39 INFO 139866244298560] Epoch[12] Batch [35]#011Speed: 591.41 samples/sec#011loss=2.855449\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:39 INFO 139866244298560] Epoch[12] Batch[40] avg_epoch_loss=2.653689\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=40 train loss <loss>=2.53674292564\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:39 INFO 139866244298560] Epoch[12] Batch [40]#011Speed: 476.85 samples/sec#011loss=2.536743\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:40 INFO 139866244298560] Epoch[12] Batch[45] avg_epoch_loss=2.650362\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=45 train loss <loss>=2.62308506966\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:40 INFO 139866244298560] Epoch[12] Batch [45]#011Speed: 556.62 samples/sec#011loss=2.623085\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:41 INFO 139866244298560] Epoch[12] Batch[50] avg_epoch_loss=2.637582\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=50 train loss <loss>=2.51999802589\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:41 INFO 139866244298560] Epoch[12] Batch [50]#011Speed: 473.19 samples/sec#011loss=2.519998\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:41 INFO 139866244298560] Epoch[12] Batch[55] avg_epoch_loss=2.639774\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=55 train loss <loss>=2.66214075089\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:41 INFO 139866244298560] Epoch[12] Batch [55]#011Speed: 595.05 samples/sec#011loss=2.662141\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:42 INFO 139866244298560] Epoch[12] Batch[60] avg_epoch_loss=2.624975\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=60 train loss <loss>=2.459217453\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:42 INFO 139866244298560] Epoch[12] Batch [60]#011Speed: 438.63 samples/sec#011loss=2.459217\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:42 INFO 139866244298560] Epoch[12] Batch[65] avg_epoch_loss=2.607249\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=65 train loss <loss>=2.39099826813\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:42 INFO 139866244298560] Epoch[12] Batch [65]#011Speed: 596.77 samples/sec#011loss=2.390998\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:43 INFO 139866244298560] Epoch[12] Batch[70] avg_epoch_loss=2.636135\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=70 train loss <loss>=3.01742782593\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:43 INFO 139866244298560] Epoch[12] Batch [70]#011Speed: 482.62 samples/sec#011loss=3.017428\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:44 INFO 139866244298560] Epoch[12] Batch[75] avg_epoch_loss=2.650870\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=75 train loss <loss>=2.86011333466\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:44 INFO 139866244298560] Epoch[12] Batch [75]#011Speed: 598.74 samples/sec#011loss=2.860113\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:44 INFO 139866244298560] Epoch[12] Batch[80] avg_epoch_loss=2.693984\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=80 train loss <loss>=3.34931044579\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:44 INFO 139866244298560] Epoch[12] Batch [80]#011Speed: 472.59 samples/sec#011loss=3.349310\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:45 INFO 139866244298560] Epoch[12] Batch[85] avg_epoch_loss=2.732460\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=85 train loss <loss>=3.35576815605\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:45 INFO 139866244298560] Epoch[12] Batch [85]#011Speed: 593.48 samples/sec#011loss=3.355768\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:45 INFO 139866244298560] Epoch[12] Batch[90] avg_epoch_loss=2.737700\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=90 train loss <loss>=2.82783350945\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:45 INFO 139866244298560] Epoch[12] Batch [90]#011Speed: 451.05 samples/sec#011loss=2.827834\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:46 INFO 139866244298560] Epoch[12] Batch[95] avg_epoch_loss=2.739113\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=95 train loss <loss>=2.76482195854\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:46 INFO 139866244298560] Epoch[12] Batch [95]#011Speed: 480.75 samples/sec#011loss=2.764822\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:47 INFO 139866244298560] Epoch[12] Batch[100] avg_epoch_loss=2.734074\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=100 train loss <loss>=2.63733959198\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:47 INFO 139866244298560] Epoch[12] Batch [100]#011Speed: 589.47 samples/sec#011loss=2.637340\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:47 INFO 139866244298560] Epoch[12] Batch[105] avg_epoch_loss=2.719115\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=105 train loss <loss>=2.41693935394\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:47 INFO 139866244298560] Epoch[12] Batch [105]#011Speed: 476.57 samples/sec#011loss=2.416939\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:48 INFO 139866244298560] Epoch[12] Batch[110] avg_epoch_loss=2.714585\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=110 train loss <loss>=2.61854295731\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:48 INFO 139866244298560] Epoch[12] Batch [110]#011Speed: 589.75 samples/sec#011loss=2.618543\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:49 INFO 139866244298560] Epoch[12] Batch[115] avg_epoch_loss=2.706789\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=115 train loss <loss>=2.53371114731\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:49 INFO 139866244298560] Epoch[12] Batch [115]#011Speed: 484.90 samples/sec#011loss=2.533711\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:49 INFO 139866244298560] Epoch[12] Batch[120] avg_epoch_loss=2.694700\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=120 train loss <loss>=2.41424188614\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:49 INFO 139866244298560] Epoch[12] Batch [120]#011Speed: 588.49 samples/sec#011loss=2.414242\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:50 INFO 139866244298560] Epoch[12] Batch[125] avg_epoch_loss=2.694239\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=125 train loss <loss>=2.68308501244\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:50 INFO 139866244298560] Epoch[12] Batch [125]#011Speed: 486.29 samples/sec#011loss=2.683085\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:50 INFO 139866244298560] Epoch[12] Batch[130] avg_epoch_loss=2.709556\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=130 train loss <loss>=3.09553079605\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:50 INFO 139866244298560] Epoch[12] Batch [130]#011Speed: 562.65 samples/sec#011loss=3.095531\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:51 INFO 139866244298560] Epoch[12] Batch[135] avg_epoch_loss=2.714855\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=135 train loss <loss>=2.8537027359\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:51 INFO 139866244298560] Epoch[12] Batch [135]#011Speed: 468.94 samples/sec#011loss=2.853703\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:52 INFO 139866244298560] Epoch[12] Batch[140] avg_epoch_loss=2.728220\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=140 train loss <loss>=3.09175362587\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:52 INFO 139866244298560] Epoch[12] Batch [140]#011Speed: 590.99 samples/sec#011loss=3.091754\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:52 INFO 139866244298560] Epoch[12] Batch[145] avg_epoch_loss=2.728472\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=145 train loss <loss>=2.73556671143\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:52 INFO 139866244298560] Epoch[12] Batch [145]#011Speed: 461.30 samples/sec#011loss=2.735567\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:53 INFO 139866244298560] Epoch[12] Batch[150] avg_epoch_loss=2.723859\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=150 train loss <loss>=2.58917222023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:53 INFO 139866244298560] Epoch[12] Batch [150]#011Speed: 593.67 samples/sec#011loss=2.589172\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:53 INFO 139866244298560] Epoch[12] Batch[155] avg_epoch_loss=2.712849\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=155 train loss <loss>=2.38034071922\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:53 INFO 139866244298560] Epoch[12] Batch [155]#011Speed: 480.62 samples/sec#011loss=2.380341\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:54 INFO 139866244298560] Epoch[12] Batch[160] avg_epoch_loss=2.711240\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=160 train loss <loss>=2.66103425026\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:54 INFO 139866244298560] Epoch[12] Batch [160]#011Speed: 572.63 samples/sec#011loss=2.661034\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:55 INFO 139866244298560] Epoch[12] Batch[165] avg_epoch_loss=2.706967\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=165 train loss <loss>=2.56937465668\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:55 INFO 139866244298560] Epoch[12] Batch [165]#011Speed: 467.65 samples/sec#011loss=2.569375\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:55 INFO 139866244298560] Epoch[12] Batch[170] avg_epoch_loss=2.705777\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=170 train loss <loss>=2.66627035141\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:55 INFO 139866244298560] Epoch[12] Batch [170]#011Speed: 556.84 samples/sec#011loss=2.666270\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:56 INFO 139866244298560] Epoch[12] Batch[175] avg_epoch_loss=2.704051\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=175 train loss <loss>=2.64503011703\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:56 INFO 139866244298560] Epoch[12] Batch [175]#011Speed: 469.07 samples/sec#011loss=2.645030\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:57 INFO 139866244298560] Epoch[12] Batch[180] avg_epoch_loss=2.705682\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=180 train loss <loss>=2.76308727264\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:57 INFO 139866244298560] Epoch[12] Batch [180]#011Speed: 582.17 samples/sec#011loss=2.763087\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:57 INFO 139866244298560] Epoch[12] Batch[185] avg_epoch_loss=2.723827\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=185 train loss <loss>=3.38068213463\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:57 INFO 139866244298560] Epoch[12] Batch [185]#011Speed: 484.73 samples/sec#011loss=3.380682\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:58 INFO 139866244298560] Epoch[12] Batch[190] avg_epoch_loss=2.734199\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=190 train loss <loss>=3.12004947662\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:58 INFO 139866244298560] Epoch[12] Batch [190]#011Speed: 481.59 samples/sec#011loss=3.120049\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:58 INFO 139866244298560] Epoch[12] Batch[195] avg_epoch_loss=2.758124\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=195 train loss <loss>=3.67202854156\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:58 INFO 139866244298560] Epoch[12] Batch [195]#011Speed: 597.05 samples/sec#011loss=3.672029\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:59 INFO 139866244298560] Epoch[12] Batch[200] avg_epoch_loss=2.773058\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=200 train loss <loss>=3.35847606659\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:32:59 INFO 139866244298560] Epoch[12] Batch [200]#011Speed: 478.84 samples/sec#011loss=3.358476\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:00 INFO 139866244298560] Epoch[12] Batch[205] avg_epoch_loss=2.778275\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=205 train loss <loss>=2.98802080154\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:00 INFO 139866244298560] Epoch[12] Batch [205]#011Speed: 595.07 samples/sec#011loss=2.988021\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:00 INFO 139866244298560] Epoch[12] Batch[210] avg_epoch_loss=2.777271\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=210 train loss <loss>=2.73589477539\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:00 INFO 139866244298560] Epoch[12] Batch [210]#011Speed: 446.96 samples/sec#011loss=2.735895\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:01 INFO 139866244298560] Epoch[12] Batch[215] avg_epoch_loss=2.768897\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=215 train loss <loss>=2.4155192852\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:01 INFO 139866244298560] Epoch[12] Batch [215]#011Speed: 588.29 samples/sec#011loss=2.415519\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:02 INFO 139866244298560] Epoch[12] Batch[220] avg_epoch_loss=2.761767\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=220 train loss <loss>=2.4537630558\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:02 INFO 139866244298560] Epoch[12] Batch [220]#011Speed: 459.72 samples/sec#011loss=2.453763\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:02 INFO 139866244298560] Epoch[12] Batch[225] avg_epoch_loss=2.756976\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=225 train loss <loss>=2.54520082474\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:02 INFO 139866244298560] Epoch[12] Batch [225]#011Speed: 591.79 samples/sec#011loss=2.545201\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:03 INFO 139866244298560] Epoch[12] Batch[230] avg_epoch_loss=2.755701\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=230 train loss <loss>=2.69805555344\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:03 INFO 139866244298560] Epoch[12] Batch [230]#011Speed: 477.64 samples/sec#011loss=2.698056\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:03 INFO 139866244298560] Epoch[12] Batch[235] avg_epoch_loss=2.756242\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=235 train loss <loss>=2.7812306881\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:03 INFO 139866244298560] Epoch[12] Batch [235]#011Speed: 591.91 samples/sec#011loss=2.781231\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:04 INFO 139866244298560] Epoch[12] Batch[240] avg_epoch_loss=2.764437\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=240 train loss <loss>=3.15125689507\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:04 INFO 139866244298560] Epoch[12] Batch [240]#011Speed: 479.83 samples/sec#011loss=3.151257\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:05 INFO 139866244298560] Epoch[12] Batch[245] avg_epoch_loss=2.776783\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=245 train loss <loss>=3.3718421936\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:05 INFO 139866244298560] Epoch[12] Batch [245]#011Speed: 588.28 samples/sec#011loss=3.371842\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:05 INFO 139866244298560] Epoch[12] Batch[250] avg_epoch_loss=2.794285\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=250 train loss <loss>=3.65540566444\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:05 INFO 139866244298560] Epoch[12] Batch [250]#011Speed: 481.50 samples/sec#011loss=3.655406\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:06 INFO 139866244298560] Epoch[12] Batch[255] avg_epoch_loss=2.807240\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=255 train loss <loss>=3.45757303238\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:06 INFO 139866244298560] Epoch[12] Batch [255]#011Speed: 549.75 samples/sec#011loss=3.457573\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:06 INFO 139866244298560] Epoch[12] Batch[260] avg_epoch_loss=2.810681\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=260 train loss <loss>=2.98688030243\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:06 INFO 139866244298560] Epoch[12] Batch [260]#011Speed: 470.58 samples/sec#011loss=2.986880\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:07 INFO 139866244298560] Epoch[12] Batch[265] avg_epoch_loss=2.808773\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, batch=265 train loss <loss>=2.70915908813\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:07 INFO 139866244298560] Epoch[12] Batch [265]#011Speed: 593.57 samples/sec#011loss=2.709159\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:07 INFO 139866244298560] processed a total of 17010 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32822.42298126221, \"sum\": 32822.42298126221, \"min\": 32822.42298126221}}, \"EndTime\": 1599442387.477745, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442354.655259}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:07 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=518.241397172 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:07 INFO 139866244298560] #progress_metric: host=algo-1, completed 16 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=12, train loss <loss>=2.80877304346\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:07 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:07 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_9195af79-1a95-43e6-b392-1503159fa3a6-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.530202865600586, \"sum\": 17.530202865600586, \"min\": 17.530202865600586}}, \"EndTime\": 1599442387.496033, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442387.477827}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:07 INFO 139866244298560] Epoch[13] Batch[0] avg_epoch_loss=2.074534\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=0 train loss <loss>=2.07453417778\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:08 INFO 139866244298560] Epoch[13] Batch[5] avg_epoch_loss=2.168912\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=5 train loss <loss>=2.16891249021\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:08 INFO 139866244298560] Epoch[13] Batch [5]#011Speed: 594.04 samples/sec#011loss=2.168912\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:08 INFO 139866244298560] Epoch[13] Batch[10] avg_epoch_loss=2.205893\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=10 train loss <loss>=2.25026865005\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:08 INFO 139866244298560] Epoch[13] Batch [10]#011Speed: 476.87 samples/sec#011loss=2.250269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:09 INFO 139866244298560] Epoch[13] Batch[15] avg_epoch_loss=2.353763\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=15 train loss <loss>=2.67907886505\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:09 INFO 139866244298560] Epoch[13] Batch [15]#011Speed: 591.10 samples/sec#011loss=2.679079\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:10 INFO 139866244298560] Epoch[13] Batch[20] avg_epoch_loss=2.423733\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=20 train loss <loss>=2.6476369381\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:10 INFO 139866244298560] Epoch[13] Batch [20]#011Speed: 463.20 samples/sec#011loss=2.647637\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:10 INFO 139866244298560] Epoch[13] Batch[25] avg_epoch_loss=2.529606\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=25 train loss <loss>=2.97427325249\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:10 INFO 139866244298560] Epoch[13] Batch [25]#011Speed: 599.41 samples/sec#011loss=2.974273\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:11 INFO 139866244298560] Epoch[13] Batch[30] avg_epoch_loss=2.540392\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=30 train loss <loss>=2.59648041725\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:11 INFO 139866244298560] Epoch[13] Batch [30]#011Speed: 438.72 samples/sec#011loss=2.596480\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:11 INFO 139866244298560] Epoch[13] Batch[35] avg_epoch_loss=2.565907\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=35 train loss <loss>=2.72409629822\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:11 INFO 139866244298560] Epoch[13] Batch [35]#011Speed: 598.31 samples/sec#011loss=2.724096\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:12 INFO 139866244298560] Epoch[13] Batch[40] avg_epoch_loss=2.580805\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=40 train loss <loss>=2.68807168007\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:12 INFO 139866244298560] Epoch[13] Batch [40]#011Speed: 443.48 samples/sec#011loss=2.688072\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:13 INFO 139866244298560] Epoch[13] Batch[45] avg_epoch_loss=2.590179\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=45 train loss <loss>=2.66704292297\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:13 INFO 139866244298560] Epoch[13] Batch [45]#011Speed: 597.05 samples/sec#011loss=2.667043\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:13 INFO 139866244298560] Epoch[13] Batch[50] avg_epoch_loss=2.593728\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=50 train loss <loss>=2.6263821125\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:13 INFO 139866244298560] Epoch[13] Batch [50]#011Speed: 478.54 samples/sec#011loss=2.626382\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:14 INFO 139866244298560] Epoch[13] Batch[55] avg_epoch_loss=2.564680\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=55 train loss <loss>=2.2683945179\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:14 INFO 139866244298560] Epoch[13] Batch [55]#011Speed: 594.95 samples/sec#011loss=2.268395\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:15 INFO 139866244298560] Epoch[13] Batch[60] avg_epoch_loss=2.548024\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=60 train loss <loss>=2.36146707535\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:15 INFO 139866244298560] Epoch[13] Batch [60]#011Speed: 469.42 samples/sec#011loss=2.361467\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:15 INFO 139866244298560] Epoch[13] Batch[65] avg_epoch_loss=2.560854\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=65 train loss <loss>=2.71737933159\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:15 INFO 139866244298560] Epoch[13] Batch [65]#011Speed: 593.00 samples/sec#011loss=2.717379\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:16 INFO 139866244298560] Epoch[13] Batch[70] avg_epoch_loss=2.589593\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=70 train loss <loss>=2.96895046234\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:16 INFO 139866244298560] Epoch[13] Batch [70]#011Speed: 456.61 samples/sec#011loss=2.968950\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:16 INFO 139866244298560] Epoch[13] Batch[75] avg_epoch_loss=2.620449\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=75 train loss <loss>=3.05860157013\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:16 INFO 139866244298560] Epoch[13] Batch [75]#011Speed: 593.29 samples/sec#011loss=3.058602\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:17 INFO 139866244298560] Epoch[13] Batch[80] avg_epoch_loss=2.663290\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=80 train loss <loss>=3.31447882652\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:17 INFO 139866244298560] Epoch[13] Batch [80]#011Speed: 481.81 samples/sec#011loss=3.314479\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:18 INFO 139866244298560] Epoch[13] Batch[85] avg_epoch_loss=2.710027\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=85 train loss <loss>=3.46717457771\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:18 INFO 139866244298560] Epoch[13] Batch [85]#011Speed: 601.15 samples/sec#011loss=3.467175\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:18 INFO 139866244298560] Epoch[13] Batch[90] avg_epoch_loss=2.702783\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=90 train loss <loss>=2.5781781435\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:18 INFO 139866244298560] Epoch[13] Batch [90]#011Speed: 478.16 samples/sec#011loss=2.578178\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:19 INFO 139866244298560] Epoch[13] Batch[95] avg_epoch_loss=2.699933\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=95 train loss <loss>=2.64806280136\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:19 INFO 139866244298560] Epoch[13] Batch [95]#011Speed: 600.00 samples/sec#011loss=2.648063\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:19 INFO 139866244298560] Epoch[13] Batch[100] avg_epoch_loss=2.689930\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=100 train loss <loss>=2.49787964821\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:19 INFO 139866244298560] Epoch[13] Batch [100]#011Speed: 467.79 samples/sec#011loss=2.497880\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:20 INFO 139866244298560] Epoch[13] Batch[105] avg_epoch_loss=2.677016\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=105 train loss <loss>=2.41614670753\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:20 INFO 139866244298560] Epoch[13] Batch [105]#011Speed: 593.76 samples/sec#011loss=2.416147\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:21 INFO 139866244298560] Epoch[13] Batch[110] avg_epoch_loss=2.662673\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=110 train loss <loss>=2.35859560966\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:21 INFO 139866244298560] Epoch[13] Batch [110]#011Speed: 437.98 samples/sec#011loss=2.358596\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:21 INFO 139866244298560] Epoch[13] Batch[115] avg_epoch_loss=2.645877\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=115 train loss <loss>=2.27302188873\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:21 INFO 139866244298560] Epoch[13] Batch [115]#011Speed: 481.03 samples/sec#011loss=2.273022\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:22 INFO 139866244298560] Epoch[13] Batch[120] avg_epoch_loss=2.642412\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=120 train loss <loss>=2.5620218277\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:22 INFO 139866244298560] Epoch[13] Batch [120]#011Speed: 588.87 samples/sec#011loss=2.562022\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:23 INFO 139866244298560] Epoch[13] Batch[125] avg_epoch_loss=2.645390\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=125 train loss <loss>=2.71745991707\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:23 INFO 139866244298560] Epoch[13] Batch [125]#011Speed: 490.99 samples/sec#011loss=2.717460\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:23 INFO 139866244298560] Epoch[13] Batch[130] avg_epoch_loss=2.662824\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=130 train loss <loss>=3.10215878487\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:23 INFO 139866244298560] Epoch[13] Batch [130]#011Speed: 596.74 samples/sec#011loss=3.102159\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:24 INFO 139866244298560] Epoch[13] Batch[135] avg_epoch_loss=2.681797\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=135 train loss <loss>=3.17888145447\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:24 INFO 139866244298560] Epoch[13] Batch [135]#011Speed: 477.01 samples/sec#011loss=3.178881\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:24 INFO 139866244298560] Epoch[13] Batch[140] avg_epoch_loss=2.690895\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=140 train loss <loss>=2.93835892677\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:24 INFO 139866244298560] Epoch[13] Batch [140]#011Speed: 587.79 samples/sec#011loss=2.938359\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:25 INFO 139866244298560] Epoch[13] Batch[145] avg_epoch_loss=2.683934\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=145 train loss <loss>=2.4876452446\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:25 INFO 139866244298560] Epoch[13] Batch [145]#011Speed: 481.82 samples/sec#011loss=2.487645\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:26 INFO 139866244298560] Epoch[13] Batch[150] avg_epoch_loss=2.670397\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=150 train loss <loss>=2.2751203537\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:26 INFO 139866244298560] Epoch[13] Batch [150]#011Speed: 597.90 samples/sec#011loss=2.275120\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:26 INFO 139866244298560] Epoch[13] Batch[155] avg_epoch_loss=2.667600\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=155 train loss <loss>=2.58310799599\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:26 INFO 139866244298560] Epoch[13] Batch [155]#011Speed: 436.12 samples/sec#011loss=2.583108\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:27 INFO 139866244298560] Epoch[13] Batch[160] avg_epoch_loss=2.665461\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=160 train loss <loss>=2.59874339104\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:27 INFO 139866244298560] Epoch[13] Batch [160]#011Speed: 594.72 samples/sec#011loss=2.598743\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:28 INFO 139866244298560] Epoch[13] Batch[165] avg_epoch_loss=2.660577\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=165 train loss <loss>=2.5033041954\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:28 INFO 139866244298560] Epoch[13] Batch [165]#011Speed: 477.67 samples/sec#011loss=2.503304\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:28 INFO 139866244298560] Epoch[13] Batch[170] avg_epoch_loss=2.657343\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=170 train loss <loss>=2.54998540878\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:28 INFO 139866244298560] Epoch[13] Batch [170]#011Speed: 479.12 samples/sec#011loss=2.549985\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:29 INFO 139866244298560] Epoch[13] Batch[175] avg_epoch_loss=2.656371\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=175 train loss <loss>=2.62312350273\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:29 INFO 139866244298560] Epoch[13] Batch [175]#011Speed: 597.64 samples/sec#011loss=2.623124\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:29 INFO 139866244298560] Epoch[13] Batch[180] avg_epoch_loss=2.668566\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=180 train loss <loss>=3.09782710075\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:29 INFO 139866244298560] Epoch[13] Batch [180]#011Speed: 475.51 samples/sec#011loss=3.097827\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:30 INFO 139866244298560] Epoch[13] Batch[185] avg_epoch_loss=2.689170\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=185 train loss <loss>=3.43503484726\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:30 INFO 139866244298560] Epoch[13] Batch [185]#011Speed: 592.50 samples/sec#011loss=3.435035\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:31 INFO 139866244298560] Epoch[13] Batch[190] avg_epoch_loss=2.708971\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=190 train loss <loss>=3.44557161331\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:31 INFO 139866244298560] Epoch[13] Batch [190]#011Speed: 482.92 samples/sec#011loss=3.445572\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:31 INFO 139866244298560] Epoch[13] Batch[195] avg_epoch_loss=2.725342\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=195 train loss <loss>=3.3506998539\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:31 INFO 139866244298560] Epoch[13] Batch [195]#011Speed: 539.58 samples/sec#011loss=3.350700\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:32 INFO 139866244298560] Epoch[13] Batch[200] avg_epoch_loss=2.735839\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=200 train loss <loss>=3.14733939171\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:32 INFO 139866244298560] Epoch[13] Batch [200]#011Speed: 478.09 samples/sec#011loss=3.147339\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:32 INFO 139866244298560] Epoch[13] Batch[205] avg_epoch_loss=2.738184\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=205 train loss <loss>=2.83244824409\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:32 INFO 139866244298560] Epoch[13] Batch [205]#011Speed: 592.39 samples/sec#011loss=2.832448\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:33 INFO 139866244298560] Epoch[13] Batch[210] avg_epoch_loss=2.736529\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=210 train loss <loss>=2.668328619\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:33 INFO 139866244298560] Epoch[13] Batch [210]#011Speed: 477.78 samples/sec#011loss=2.668329\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:34 INFO 139866244298560] Epoch[13] Batch[215] avg_epoch_loss=2.729214\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=215 train loss <loss>=2.42050795555\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:34 INFO 139866244298560] Epoch[13] Batch [215]#011Speed: 599.02 samples/sec#011loss=2.420508\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:34 INFO 139866244298560] Epoch[13] Batch[220] avg_epoch_loss=2.723734\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=220 train loss <loss>=2.48700652122\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:34 INFO 139866244298560] Epoch[13] Batch [220]#011Speed: 482.23 samples/sec#011loss=2.487007\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:35 INFO 139866244298560] Epoch[13] Batch[225] avg_epoch_loss=2.721991\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=225 train loss <loss>=2.64498252869\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:35 INFO 139866244298560] Epoch[13] Batch [225]#011Speed: 592.49 samples/sec#011loss=2.644983\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:35 INFO 139866244298560] Epoch[13] Batch[230] avg_epoch_loss=2.729932\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=230 train loss <loss>=3.08883171082\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:35 INFO 139866244298560] Epoch[13] Batch [230]#011Speed: 489.88 samples/sec#011loss=3.088832\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:36 INFO 139866244298560] Epoch[13] Batch[235] avg_epoch_loss=2.742921\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=235 train loss <loss>=3.34303131104\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:36 INFO 139866244298560] Epoch[13] Batch [235]#011Speed: 544.14 samples/sec#011loss=3.343031\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:37 INFO 139866244298560] Epoch[13] Batch[240] avg_epoch_loss=2.765192\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=240 train loss <loss>=3.81636996269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:37 INFO 139866244298560] Epoch[13] Batch [240]#011Speed: 483.16 samples/sec#011loss=3.816370\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:37 INFO 139866244298560] Epoch[13] Batch[245] avg_epoch_loss=2.778499\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=245 train loss <loss>=3.41991386414\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:37 INFO 139866244298560] Epoch[13] Batch [245]#011Speed: 474.64 samples/sec#011loss=3.419914\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:38 INFO 139866244298560] Epoch[13] Batch[250] avg_epoch_loss=2.780010\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=250 train loss <loss>=2.85433974266\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:38 INFO 139866244298560] Epoch[13] Batch [250]#011Speed: 593.90 samples/sec#011loss=2.854340\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:39 INFO 139866244298560] Epoch[13] Batch[255] avg_epoch_loss=2.781255\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=255 train loss <loss>=2.84374313354\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:39 INFO 139866244298560] Epoch[13] Batch [255]#011Speed: 476.53 samples/sec#011loss=2.843743\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:39 INFO 139866244298560] Epoch[13] Batch[260] avg_epoch_loss=2.777992\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=260 train loss <loss>=2.61096286774\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:39 INFO 139866244298560] Epoch[13] Batch [260]#011Speed: 595.50 samples/sec#011loss=2.610963\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:40 INFO 139866244298560] Epoch[13] Batch[265] avg_epoch_loss=2.778858\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, batch=265 train loss <loss>=2.82402381897\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:40 INFO 139866244298560] Epoch[13] Batch [265]#011Speed: 562.12 samples/sec#011loss=2.824024\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:40 INFO 139866244298560] processed a total of 17109 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32923.75302314758, \"sum\": 32923.75302314758, \"min\": 32923.75302314758}}, \"EndTime\": 1599442420.419924, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442387.496096}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:40 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=519.653052566 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:40 INFO 139866244298560] #progress_metric: host=algo-1, completed 17 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=13, train loss <loss>=2.7906697557\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:40 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:40 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_7c04675c-f07c-43e6-a4db-fbd060250e36-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 23.875951766967773, \"sum\": 23.875951766967773, \"min\": 23.875951766967773}}, \"EndTime\": 1599442420.444588, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442420.42001}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:40 INFO 139866244298560] Epoch[14] Batch[0] avg_epoch_loss=2.688014\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=0 train loss <loss>=2.68801379204\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:41 INFO 139866244298560] Epoch[14] Batch[5] avg_epoch_loss=2.241004\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=5 train loss <loss>=2.2410043478\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:41 INFO 139866244298560] Epoch[14] Batch [5]#011Speed: 596.67 samples/sec#011loss=2.241004\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:42 INFO 139866244298560] Epoch[14] Batch[10] avg_epoch_loss=2.286258\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=10 train loss <loss>=2.3405626297\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:42 INFO 139866244298560] Epoch[14] Batch [10]#011Speed: 401.52 samples/sec#011loss=2.340563\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:42 INFO 139866244298560] Epoch[14] Batch[15] avg_epoch_loss=2.414566\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=15 train loss <loss>=2.69684433937\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:42 INFO 139866244298560] Epoch[14] Batch [15]#011Speed: 523.26 samples/sec#011loss=2.696844\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:43 INFO 139866244298560] Epoch[14] Batch[20] avg_epoch_loss=2.480027\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=20 train loss <loss>=2.68950128555\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:43 INFO 139866244298560] Epoch[14] Batch [20]#011Speed: 460.59 samples/sec#011loss=2.689501\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:43 INFO 139866244298560] Epoch[14] Batch[25] avg_epoch_loss=2.566573\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=25 train loss <loss>=2.93006420135\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:43 INFO 139866244298560] Epoch[14] Batch [25]#011Speed: 596.67 samples/sec#011loss=2.930064\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:44 INFO 139866244298560] Epoch[14] Batch[30] avg_epoch_loss=2.602146\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=30 train loss <loss>=2.78712792397\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:44 INFO 139866244298560] Epoch[14] Batch [30]#011Speed: 482.02 samples/sec#011loss=2.787128\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:45 INFO 139866244298560] Epoch[14] Batch[35] avg_epoch_loss=2.659571\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=35 train loss <loss>=3.01560430527\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:45 INFO 139866244298560] Epoch[14] Batch [35]#011Speed: 584.57 samples/sec#011loss=3.015604\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:45 INFO 139866244298560] Epoch[14] Batch[40] avg_epoch_loss=2.629710\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=40 train loss <loss>=2.41471610069\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:45 INFO 139866244298560] Epoch[14] Batch [40]#011Speed: 482.42 samples/sec#011loss=2.414716\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:46 INFO 139866244298560] Epoch[14] Batch[45] avg_epoch_loss=2.617869\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=45 train loss <loss>=2.52076992989\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:46 INFO 139866244298560] Epoch[14] Batch [45]#011Speed: 595.36 samples/sec#011loss=2.520770\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:46 INFO 139866244298560] Epoch[14] Batch[50] avg_epoch_loss=2.600917\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=50 train loss <loss>=2.44495668411\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:46 INFO 139866244298560] Epoch[14] Batch [50]#011Speed: 451.72 samples/sec#011loss=2.444957\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:47 INFO 139866244298560] Epoch[14] Batch[55] avg_epoch_loss=2.548820\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=55 train loss <loss>=2.01743402481\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:47 INFO 139866244298560] Epoch[14] Batch [55]#011Speed: 593.22 samples/sec#011loss=2.017434\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:48 INFO 139866244298560] Epoch[14] Batch[60] avg_epoch_loss=2.524140\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=60 train loss <loss>=2.24772500992\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:48 INFO 139866244298560] Epoch[14] Batch [60]#011Speed: 475.02 samples/sec#011loss=2.247725\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:48 INFO 139866244298560] Epoch[14] Batch[65] avg_epoch_loss=2.526685\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=65 train loss <loss>=2.55773031712\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:48 INFO 139866244298560] Epoch[14] Batch [65]#011Speed: 593.16 samples/sec#011loss=2.557730\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:49 INFO 139866244298560] Epoch[14] Batch[70] avg_epoch_loss=2.577179\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=70 train loss <loss>=3.24370279312\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:49 INFO 139866244298560] Epoch[14] Batch [70]#011Speed: 479.48 samples/sec#011loss=3.243703\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:49 INFO 139866244298560] Epoch[14] Batch[75] avg_epoch_loss=2.599805\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=75 train loss <loss>=2.9210914135\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:49 INFO 139866244298560] Epoch[14] Batch [75]#011Speed: 589.17 samples/sec#011loss=2.921091\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:50 INFO 139866244298560] Epoch[14] Batch[80] avg_epoch_loss=2.628704\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=80 train loss <loss>=3.06797542572\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:50 INFO 139866244298560] Epoch[14] Batch [80]#011Speed: 483.94 samples/sec#011loss=3.067975\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:51 INFO 139866244298560] Epoch[14] Batch[85] avg_epoch_loss=2.670521\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=85 train loss <loss>=3.34795212746\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:51 INFO 139866244298560] Epoch[14] Batch [85]#011Speed: 470.46 samples/sec#011loss=3.347952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:51 INFO 139866244298560] Epoch[14] Batch[90] avg_epoch_loss=2.670453\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=90 train loss <loss>=2.6692761898\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:51 INFO 139866244298560] Epoch[14] Batch [90]#011Speed: 597.88 samples/sec#011loss=2.669276\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:52 INFO 139866244298560] Epoch[14] Batch[95] avg_epoch_loss=2.663913\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=95 train loss <loss>=2.54488015175\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:52 INFO 139866244298560] Epoch[14] Batch [95]#011Speed: 437.00 samples/sec#011loss=2.544880\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:53 INFO 139866244298560] Epoch[14] Batch[100] avg_epoch_loss=2.658376\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=100 train loss <loss>=2.55207438469\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:53 INFO 139866244298560] Epoch[14] Batch [100]#011Speed: 596.75 samples/sec#011loss=2.552074\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:53 INFO 139866244298560] Epoch[14] Batch[105] avg_epoch_loss=2.660247\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=105 train loss <loss>=2.69805107117\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:53 INFO 139866244298560] Epoch[14] Batch [105]#011Speed: 470.68 samples/sec#011loss=2.698051\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:54 INFO 139866244298560] Epoch[14] Batch[110] avg_epoch_loss=2.645591\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=110 train loss <loss>=2.33488485813\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:54 INFO 139866244298560] Epoch[14] Batch [110]#011Speed: 587.11 samples/sec#011loss=2.334885\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:55 INFO 139866244298560] Epoch[14] Batch[115] avg_epoch_loss=2.626802\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=115 train loss <loss>=2.20968661308\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:55 INFO 139866244298560] Epoch[14] Batch [115]#011Speed: 465.81 samples/sec#011loss=2.209687\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:55 INFO 139866244298560] Epoch[14] Batch[120] avg_epoch_loss=2.628316\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=120 train loss <loss>=2.6634244442\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:55 INFO 139866244298560] Epoch[14] Batch [120]#011Speed: 593.50 samples/sec#011loss=2.663424\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:56 INFO 139866244298560] Epoch[14] Batch[125] avg_epoch_loss=2.629355\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=125 train loss <loss>=2.65450139046\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:56 INFO 139866244298560] Epoch[14] Batch [125]#011Speed: 490.23 samples/sec#011loss=2.654501\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:56 INFO 139866244298560] Epoch[14] Batch[130] avg_epoch_loss=2.644632\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=130 train loss <loss>=3.02961001396\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:56 INFO 139866244298560] Epoch[14] Batch [130]#011Speed: 586.60 samples/sec#011loss=3.029610\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:57 INFO 139866244298560] Epoch[14] Batch[135] avg_epoch_loss=2.659860\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=135 train loss <loss>=3.05882606506\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:57 INFO 139866244298560] Epoch[14] Batch [135]#011Speed: 455.57 samples/sec#011loss=3.058826\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:57 INFO 139866244298560] Epoch[14] Batch[140] avg_epoch_loss=2.670919\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=140 train loss <loss>=2.97174940109\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:57 INFO 139866244298560] Epoch[14] Batch [140]#011Speed: 584.68 samples/sec#011loss=2.971749\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:58 INFO 139866244298560] Epoch[14] Batch[145] avg_epoch_loss=2.667909\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=145 train loss <loss>=2.58302288055\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:58 INFO 139866244298560] Epoch[14] Batch [145]#011Speed: 471.93 samples/sec#011loss=2.583023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:59 INFO 139866244298560] Epoch[14] Batch[150] avg_epoch_loss=2.654990\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=150 train loss <loss>=2.27774014473\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:59 INFO 139866244298560] Epoch[14] Batch [150]#011Speed: 596.08 samples/sec#011loss=2.277740\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:59 INFO 139866244298560] Epoch[14] Batch[155] avg_epoch_loss=2.653121\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=155 train loss <loss>=2.59667277336\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:33:59 INFO 139866244298560] Epoch[14] Batch [155]#011Speed: 476.22 samples/sec#011loss=2.596673\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:00 INFO 139866244298560] Epoch[14] Batch[160] avg_epoch_loss=2.649478\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=160 train loss <loss>=2.53582901955\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:00 INFO 139866244298560] Epoch[14] Batch [160]#011Speed: 588.50 samples/sec#011loss=2.535829\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:01 INFO 139866244298560] Epoch[14] Batch[165] avg_epoch_loss=2.639794\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=165 train loss <loss>=2.32795987129\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:01 INFO 139866244298560] Epoch[14] Batch [165]#011Speed: 477.40 samples/sec#011loss=2.327960\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:01 INFO 139866244298560] Epoch[14] Batch[170] avg_epoch_loss=2.631034\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=170 train loss <loss>=2.3401995182\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:01 INFO 139866244298560] Epoch[14] Batch [170]#011Speed: 590.59 samples/sec#011loss=2.340200\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:02 INFO 139866244298560] Epoch[14] Batch[175] avg_epoch_loss=2.633674\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=175 train loss <loss>=2.7239824295\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:02 INFO 139866244298560] Epoch[14] Batch [175]#011Speed: 433.45 samples/sec#011loss=2.723982\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:02 INFO 139866244298560] Epoch[14] Batch[180] avg_epoch_loss=2.638859\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=180 train loss <loss>=2.82135806084\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:02 INFO 139866244298560] Epoch[14] Batch [180]#011Speed: 587.54 samples/sec#011loss=2.821358\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:03 INFO 139866244298560] Epoch[14] Batch[185] avg_epoch_loss=2.659648\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=185 train loss <loss>=3.41220932007\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:03 INFO 139866244298560] Epoch[14] Batch [185]#011Speed: 347.20 samples/sec#011loss=3.412209\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:04 INFO 139866244298560] Epoch[14] Batch[190] avg_epoch_loss=2.680650\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=190 train loss <loss>=3.46191720963\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:04 INFO 139866244298560] Epoch[14] Batch [190]#011Speed: 416.06 samples/sec#011loss=3.461917\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:05 INFO 139866244298560] Epoch[14] Batch[195] avg_epoch_loss=2.702338\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=195 train loss <loss>=3.53084402084\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:05 INFO 139866244298560] Epoch[14] Batch [195]#011Speed: 577.56 samples/sec#011loss=3.530844\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:05 INFO 139866244298560] Epoch[14] Batch[200] avg_epoch_loss=2.712717\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=200 train loss <loss>=3.1195751667\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:05 INFO 139866244298560] Epoch[14] Batch [200]#011Speed: 480.23 samples/sec#011loss=3.119575\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:06 INFO 139866244298560] Epoch[14] Batch[205] avg_epoch_loss=2.714914\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=205 train loss <loss>=2.80320544243\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:06 INFO 139866244298560] Epoch[14] Batch [205]#011Speed: 591.70 samples/sec#011loss=2.803205\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:07 INFO 139866244298560] Epoch[14] Batch[210] avg_epoch_loss=2.714761\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=210 train loss <loss>=2.70847630501\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:07 INFO 139866244298560] Epoch[14] Batch [210]#011Speed: 459.36 samples/sec#011loss=2.708476\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:07 INFO 139866244298560] Epoch[14] Batch[215] avg_epoch_loss=2.708311\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=215 train loss <loss>=2.43610076904\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:07 INFO 139866244298560] Epoch[14] Batch [215]#011Speed: 546.50 samples/sec#011loss=2.436101\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:08 INFO 139866244298560] Epoch[14] Batch[220] avg_epoch_loss=2.708878\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=220 train loss <loss>=2.73340539932\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:08 INFO 139866244298560] Epoch[14] Batch [220]#011Speed: 480.34 samples/sec#011loss=2.733405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:08 INFO 139866244298560] Epoch[14] Batch[225] avg_epoch_loss=2.707400\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=225 train loss <loss>=2.6420466423\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:08 INFO 139866244298560] Epoch[14] Batch [225]#011Speed: 593.83 samples/sec#011loss=2.642047\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:09 INFO 139866244298560] Epoch[14] Batch[230] avg_epoch_loss=2.716851\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=230 train loss <loss>=3.14403986931\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:09 INFO 139866244298560] Epoch[14] Batch [230]#011Speed: 476.68 samples/sec#011loss=3.144040\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:10 INFO 139866244298560] Epoch[14] Batch[235] avg_epoch_loss=2.729446\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=235 train loss <loss>=3.31135606766\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:10 INFO 139866244298560] Epoch[14] Batch [235]#011Speed: 592.68 samples/sec#011loss=3.311356\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:10 INFO 139866244298560] Epoch[14] Batch[240] avg_epoch_loss=2.746077\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=240 train loss <loss>=3.53103427887\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:10 INFO 139866244298560] Epoch[14] Batch [240]#011Speed: 479.43 samples/sec#011loss=3.531034\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:11 INFO 139866244298560] Epoch[14] Batch[245] avg_epoch_loss=2.763060\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=245 train loss <loss>=3.58162989616\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:11 INFO 139866244298560] Epoch[14] Batch [245]#011Speed: 594.20 samples/sec#011loss=3.581630\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:11 INFO 139866244298560] Epoch[14] Batch[250] avg_epoch_loss=2.771613\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=250 train loss <loss>=3.19243559837\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:11 INFO 139866244298560] Epoch[14] Batch [250]#011Speed: 482.45 samples/sec#011loss=3.192436\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:12 INFO 139866244298560] Epoch[14] Batch[255] avg_epoch_loss=2.775271\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=255 train loss <loss>=2.95891571045\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:12 INFO 139866244298560] Epoch[14] Batch [255]#011Speed: 562.60 samples/sec#011loss=2.958916\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:13 INFO 139866244298560] Epoch[14] Batch[260] avg_epoch_loss=2.773994\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=260 train loss <loss>=2.70858201981\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:13 INFO 139866244298560] Epoch[14] Batch [260]#011Speed: 433.23 samples/sec#011loss=2.708582\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:13 INFO 139866244298560] Epoch[14] Batch[265] avg_epoch_loss=2.771171\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, batch=265 train loss <loss>=2.6238093853\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:13 INFO 139866244298560] Epoch[14] Batch [265]#011Speed: 594.46 samples/sec#011loss=2.623809\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:14 INFO 139866244298560] processed a total of 17164 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33677.93416976929, \"sum\": 33677.93416976929, \"min\": 33677.93416976929}}, \"EndTime\": 1599442454.122662, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442420.44465}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:14 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=509.648337404 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:14 INFO 139866244298560] #progress_metric: host=algo-1, completed 18 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=14, train loss <loss>=2.78208250982\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:14 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:14 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_317ed0b6-ab68-4644-b16e-9f905cba2ead-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 20.470857620239258, \"sum\": 20.470857620239258, \"min\": 20.470857620239258}}, \"EndTime\": 1599442454.144112, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442454.122784}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:14 INFO 139866244298560] Epoch[15] Batch[0] avg_epoch_loss=1.426229\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=0 train loss <loss>=1.42622888088\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:14 INFO 139866244298560] Epoch[15] Batch[5] avg_epoch_loss=2.077743\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=5 train loss <loss>=2.07774323225\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:14 INFO 139866244298560] Epoch[15] Batch [5]#011Speed: 595.95 samples/sec#011loss=2.077743\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:15 INFO 139866244298560] Epoch[15] Batch[10] avg_epoch_loss=2.252329\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=10 train loss <loss>=2.46183280945\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:15 INFO 139866244298560] Epoch[15] Batch [10]#011Speed: 470.74 samples/sec#011loss=2.461833\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:16 INFO 139866244298560] Epoch[15] Batch[15] avg_epoch_loss=2.396769\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=15 train loss <loss>=2.71453490257\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:16 INFO 139866244298560] Epoch[15] Batch [15]#011Speed: 597.93 samples/sec#011loss=2.714535\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:16 INFO 139866244298560] Epoch[15] Batch[20] avg_epoch_loss=2.497512\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=20 train loss <loss>=2.81989207268\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:16 INFO 139866244298560] Epoch[15] Batch [20]#011Speed: 475.82 samples/sec#011loss=2.819892\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:17 INFO 139866244298560] Epoch[15] Batch[25] avg_epoch_loss=2.567139\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=25 train loss <loss>=2.85956993103\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:17 INFO 139866244298560] Epoch[15] Batch [25]#011Speed: 598.48 samples/sec#011loss=2.859570\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:18 INFO 139866244298560] Epoch[15] Batch[30] avg_epoch_loss=2.592314\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=30 train loss <loss>=2.72322354317\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:18 INFO 139866244298560] Epoch[15] Batch [30]#011Speed: 446.24 samples/sec#011loss=2.723224\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:18 INFO 139866244298560] Epoch[15] Batch[35] avg_epoch_loss=2.579681\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=35 train loss <loss>=2.50136041641\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:18 INFO 139866244298560] Epoch[15] Batch [35]#011Speed: 592.87 samples/sec#011loss=2.501360\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:19 INFO 139866244298560] Epoch[15] Batch[40] avg_epoch_loss=2.583272\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=40 train loss <loss>=2.60912690163\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:19 INFO 139866244298560] Epoch[15] Batch [40]#011Speed: 477.15 samples/sec#011loss=2.609127\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:19 INFO 139866244298560] Epoch[15] Batch[45] avg_epoch_loss=2.584232\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=45 train loss <loss>=2.59210529327\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:19 INFO 139866244298560] Epoch[15] Batch [45]#011Speed: 594.37 samples/sec#011loss=2.592105\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:20 INFO 139866244298560] Epoch[15] Batch[50] avg_epoch_loss=2.568602\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=50 train loss <loss>=2.42480254173\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:20 INFO 139866244298560] Epoch[15] Batch [50]#011Speed: 475.65 samples/sec#011loss=2.424803\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:21 INFO 139866244298560] Epoch[15] Batch[55] avg_epoch_loss=2.558518\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=55 train loss <loss>=2.45566654205\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:21 INFO 139866244298560] Epoch[15] Batch [55]#011Speed: 594.12 samples/sec#011loss=2.455667\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:21 INFO 139866244298560] Epoch[15] Batch[60] avg_epoch_loss=2.550128\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=60 train loss <loss>=2.45614933968\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:21 INFO 139866244298560] Epoch[15] Batch [60]#011Speed: 463.20 samples/sec#011loss=2.456149\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:22 INFO 139866244298560] Epoch[15] Batch[65] avg_epoch_loss=2.564085\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=65 train loss <loss>=2.73437199593\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:22 INFO 139866244298560] Epoch[15] Batch [65]#011Speed: 588.70 samples/sec#011loss=2.734372\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:22 INFO 139866244298560] Epoch[15] Batch[70] avg_epoch_loss=2.613980\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=70 train loss <loss>=3.27259440422\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:22 INFO 139866244298560] Epoch[15] Batch [70]#011Speed: 452.22 samples/sec#011loss=3.272594\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:23 INFO 139866244298560] Epoch[15] Batch[75] avg_epoch_loss=2.647448\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=75 train loss <loss>=3.12268972397\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:23 INFO 139866244298560] Epoch[15] Batch [75]#011Speed: 483.93 samples/sec#011loss=3.122690\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:24 INFO 139866244298560] Epoch[15] Batch[80] avg_epoch_loss=2.697071\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=80 train loss <loss>=3.45133166313\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:24 INFO 139866244298560] Epoch[15] Batch [80]#011Speed: 587.85 samples/sec#011loss=3.451332\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:24 INFO 139866244298560] Epoch[15] Batch[85] avg_epoch_loss=2.721005\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=85 train loss <loss>=3.10875062943\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:24 INFO 139866244298560] Epoch[15] Batch [85]#011Speed: 470.78 samples/sec#011loss=3.108751\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:25 INFO 139866244298560] Epoch[15] Batch[90] avg_epoch_loss=2.710794\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=90 train loss <loss>=2.53516435623\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:25 INFO 139866244298560] Epoch[15] Batch [90]#011Speed: 596.04 samples/sec#011loss=2.535164\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:26 INFO 139866244298560] Epoch[15] Batch[95] avg_epoch_loss=2.706389\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=95 train loss <loss>=2.62621912956\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:26 INFO 139866244298560] Epoch[15] Batch [95]#011Speed: 479.25 samples/sec#011loss=2.626219\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:26 INFO 139866244298560] Epoch[15] Batch[100] avg_epoch_loss=2.690979\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=100 train loss <loss>=2.39509758949\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:26 INFO 139866244298560] Epoch[15] Batch [100]#011Speed: 594.92 samples/sec#011loss=2.395098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:27 INFO 139866244298560] Epoch[15] Batch[105] avg_epoch_loss=2.679359\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=105 train loss <loss>=2.44463114738\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:27 INFO 139866244298560] Epoch[15] Batch [105]#011Speed: 478.80 samples/sec#011loss=2.444631\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:27 INFO 139866244298560] Epoch[15] Batch[110] avg_epoch_loss=2.663303\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=110 train loss <loss>=2.32290911674\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:27 INFO 139866244298560] Epoch[15] Batch [110]#011Speed: 542.85 samples/sec#011loss=2.322909\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:28 INFO 139866244298560] Epoch[15] Batch[115] avg_epoch_loss=2.674479\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=115 train loss <loss>=2.92260222435\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:28 INFO 139866244298560] Epoch[15] Batch [115]#011Speed: 468.23 samples/sec#011loss=2.922602\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:29 INFO 139866244298560] Epoch[15] Batch[120] avg_epoch_loss=2.685849\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=120 train loss <loss>=2.94962925911\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:29 INFO 139866244298560] Epoch[15] Batch [120]#011Speed: 589.64 samples/sec#011loss=2.949629\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:29 INFO 139866244298560] Epoch[15] Batch[125] avg_epoch_loss=2.691901\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=125 train loss <loss>=2.83836197853\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:29 INFO 139866244298560] Epoch[15] Batch [125]#011Speed: 464.62 samples/sec#011loss=2.838362\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:30 INFO 139866244298560] Epoch[15] Batch[130] avg_epoch_loss=2.711930\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=130 train loss <loss>=3.21666412354\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:30 INFO 139866244298560] Epoch[15] Batch [130]#011Speed: 596.33 samples/sec#011loss=3.216664\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:30 INFO 139866244298560] Epoch[15] Batch[135] avg_epoch_loss=2.711066\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=135 train loss <loss>=2.68842339516\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:30 INFO 139866244298560] Epoch[15] Batch [135]#011Speed: 476.62 samples/sec#011loss=2.688423\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:31 INFO 139866244298560] Epoch[15] Batch[140] avg_epoch_loss=2.711534\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=140 train loss <loss>=2.72425332069\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:31 INFO 139866244298560] Epoch[15] Batch [140]#011Speed: 593.90 samples/sec#011loss=2.724253\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:32 INFO 139866244298560] Epoch[15] Batch[145] avg_epoch_loss=2.696795\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=145 train loss <loss>=2.28117752075\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:32 INFO 139866244298560] Epoch[15] Batch [145]#011Speed: 471.05 samples/sec#011loss=2.281178\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:32 INFO 139866244298560] Epoch[15] Batch[150] avg_epoch_loss=2.684225\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=150 train loss <loss>=2.31718063354\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:32 INFO 139866244298560] Epoch[15] Batch [150]#011Speed: 598.92 samples/sec#011loss=2.317181\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:33 INFO 139866244298560] Epoch[15] Batch[155] avg_epoch_loss=2.679699\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=155 train loss <loss>=2.54299201965\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:33 INFO 139866244298560] Epoch[15] Batch [155]#011Speed: 434.74 samples/sec#011loss=2.542992\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:34 INFO 139866244298560] Epoch[15] Batch[160] avg_epoch_loss=2.675153\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=160 train loss <loss>=2.53334002495\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:34 INFO 139866244298560] Epoch[15] Batch [160]#011Speed: 598.78 samples/sec#011loss=2.533340\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:34 INFO 139866244298560] Epoch[15] Batch[165] avg_epoch_loss=2.668711\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=165 train loss <loss>=2.46127181053\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:34 INFO 139866244298560] Epoch[15] Batch [165]#011Speed: 460.76 samples/sec#011loss=2.461272\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:35 INFO 139866244298560] Epoch[15] Batch[170] avg_epoch_loss=2.663222\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=170 train loss <loss>=2.4809738636\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:35 INFO 139866244298560] Epoch[15] Batch [170]#011Speed: 481.05 samples/sec#011loss=2.480974\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:35 INFO 139866244298560] Epoch[15] Batch[175] avg_epoch_loss=2.673395\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=175 train loss <loss>=3.0213098526\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:35 INFO 139866244298560] Epoch[15] Batch [175]#011Speed: 590.15 samples/sec#011loss=3.021310\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:36 INFO 139866244298560] Epoch[15] Batch[180] avg_epoch_loss=2.690437\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=180 train loss <loss>=3.29031910896\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:36 INFO 139866244298560] Epoch[15] Batch [180]#011Speed: 482.83 samples/sec#011loss=3.290319\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:37 INFO 139866244298560] Epoch[15] Batch[185] avg_epoch_loss=2.717497\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=185 train loss <loss>=3.69706201553\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:37 INFO 139866244298560] Epoch[15] Batch [185]#011Speed: 593.16 samples/sec#011loss=3.697062\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:37 INFO 139866244298560] Epoch[15] Batch[190] avg_epoch_loss=2.734296\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=190 train loss <loss>=3.35923995972\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:37 INFO 139866244298560] Epoch[15] Batch [190]#011Speed: 481.10 samples/sec#011loss=3.359240\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:38 INFO 139866244298560] Epoch[15] Batch[195] avg_epoch_loss=2.743650\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=195 train loss <loss>=3.10096311569\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:38 INFO 139866244298560] Epoch[15] Batch [195]#011Speed: 552.83 samples/sec#011loss=3.100963\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:39 INFO 139866244298560] Epoch[15] Batch[200] avg_epoch_loss=2.746434\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=200 train loss <loss>=2.85556020737\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:39 INFO 139866244298560] Epoch[15] Batch [200]#011Speed: 481.72 samples/sec#011loss=2.855560\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:39 INFO 139866244298560] Epoch[15] Batch[205] avg_epoch_loss=2.748863\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=205 train loss <loss>=2.84649796486\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:39 INFO 139866244298560] Epoch[15] Batch [205]#011Speed: 587.88 samples/sec#011loss=2.846498\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:40 INFO 139866244298560] Epoch[15] Batch[210] avg_epoch_loss=2.741627\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=210 train loss <loss>=2.44352972507\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:40 INFO 139866244298560] Epoch[15] Batch [210]#011Speed: 480.44 samples/sec#011loss=2.443530\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:40 INFO 139866244298560] Epoch[15] Batch[215] avg_epoch_loss=2.734228\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=215 train loss <loss>=2.42196731567\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:40 INFO 139866244298560] Epoch[15] Batch [215]#011Speed: 599.53 samples/sec#011loss=2.421967\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:41 INFO 139866244298560] Epoch[15] Batch[220] avg_epoch_loss=2.732600\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=220 train loss <loss>=2.66228671074\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:41 INFO 139866244298560] Epoch[15] Batch [220]#011Speed: 483.93 samples/sec#011loss=2.662287\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:41 INFO 139866244298560] Epoch[15] Batch[225] avg_epoch_loss=2.728033\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=225 train loss <loss>=2.52616004944\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:41 INFO 139866244298560] Epoch[15] Batch [225]#011Speed: 597.92 samples/sec#011loss=2.526160\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:42 INFO 139866244298560] Epoch[15] Batch[230] avg_epoch_loss=2.740581\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=230 train loss <loss>=3.30777106285\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:42 INFO 139866244298560] Epoch[15] Batch [230]#011Speed: 475.50 samples/sec#011loss=3.307771\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:43 INFO 139866244298560] Epoch[15] Batch[235] avg_epoch_loss=2.748795\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=235 train loss <loss>=3.128266716\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:43 INFO 139866244298560] Epoch[15] Batch [235]#011Speed: 480.50 samples/sec#011loss=3.128267\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:43 INFO 139866244298560] Epoch[15] Batch[240] avg_epoch_loss=2.765865\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=240 train loss <loss>=3.57158441544\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:43 INFO 139866244298560] Epoch[15] Batch [240]#011Speed: 476.67 samples/sec#011loss=3.571584\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:44 INFO 139866244298560] Epoch[15] Batch[245] avg_epoch_loss=2.778964\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=245 train loss <loss>=3.41031579971\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:44 INFO 139866244298560] Epoch[15] Batch [245]#011Speed: 576.97 samples/sec#011loss=3.410316\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:45 INFO 139866244298560] Epoch[15] Batch[250] avg_epoch_loss=2.784274\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=250 train loss <loss>=3.04552879333\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:45 INFO 139866244298560] Epoch[15] Batch [250]#011Speed: 472.83 samples/sec#011loss=3.045529\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:45 INFO 139866244298560] Epoch[15] Batch[255] avg_epoch_loss=2.785790\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=255 train loss <loss>=2.86188607216\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:45 INFO 139866244298560] Epoch[15] Batch [255]#011Speed: 591.27 samples/sec#011loss=2.861886\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:46 INFO 139866244298560] Epoch[15] Batch[260] avg_epoch_loss=2.782473\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=260 train loss <loss>=2.61264004707\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:46 INFO 139866244298560] Epoch[15] Batch [260]#011Speed: 484.87 samples/sec#011loss=2.612640\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:46 INFO 139866244298560] Epoch[15] Batch[265] avg_epoch_loss=2.777086\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, batch=265 train loss <loss>=2.49589824677\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:46 INFO 139866244298560] Epoch[15] Batch [265]#011Speed: 569.65 samples/sec#011loss=2.495898\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:47 INFO 139866244298560] processed a total of 17156 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33175.93693733215, \"sum\": 33175.93693733215, \"min\": 33175.93693733215}}, \"EndTime\": 1599442487.320274, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442454.144252}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:47 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=517.119890462 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:47 INFO 139866244298560] #progress_metric: host=algo-1, completed 20 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=15, train loss <loss>=2.79163581465\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:47 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:47 INFO 139866244298560] Epoch[16] Batch[0] avg_epoch_loss=2.166511\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=0 train loss <loss>=2.16651082039\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:48 INFO 139866244298560] Epoch[16] Batch[5] avg_epoch_loss=2.286942\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=5 train loss <loss>=2.28694212437\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:48 INFO 139866244298560] Epoch[16] Batch [5]#011Speed: 593.77 samples/sec#011loss=2.286942\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:48 INFO 139866244298560] Epoch[16] Batch[10] avg_epoch_loss=2.240909\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=10 train loss <loss>=2.18566944599\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:48 INFO 139866244298560] Epoch[16] Batch [10]#011Speed: 418.80 samples/sec#011loss=2.185669\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:49 INFO 139866244298560] Epoch[16] Batch[15] avg_epoch_loss=2.412789\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=15 train loss <loss>=2.79092617035\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:49 INFO 139866244298560] Epoch[16] Batch [15]#011Speed: 589.18 samples/sec#011loss=2.790926\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:50 INFO 139866244298560] Epoch[16] Batch[20] avg_epoch_loss=2.515971\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=20 train loss <loss>=2.84615268707\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:50 INFO 139866244298560] Epoch[16] Batch [20]#011Speed: 469.50 samples/sec#011loss=2.846153\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:50 INFO 139866244298560] Epoch[16] Batch[25] avg_epoch_loss=2.559706\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=25 train loss <loss>=2.74339032173\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:50 INFO 139866244298560] Epoch[16] Batch [25]#011Speed: 599.08 samples/sec#011loss=2.743390\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:51 INFO 139866244298560] Epoch[16] Batch[30] avg_epoch_loss=2.553191\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=30 train loss <loss>=2.51931381226\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:51 INFO 139866244298560] Epoch[16] Batch [30]#011Speed: 482.96 samples/sec#011loss=2.519314\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:51 INFO 139866244298560] Epoch[16] Batch[35] avg_epoch_loss=2.583968\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=35 train loss <loss>=2.77478723526\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:51 INFO 139866244298560] Epoch[16] Batch [35]#011Speed: 595.96 samples/sec#011loss=2.774787\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:52 INFO 139866244298560] Epoch[16] Batch[40] avg_epoch_loss=2.582706\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=40 train loss <loss>=2.57361750603\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:52 INFO 139866244298560] Epoch[16] Batch [40]#011Speed: 469.50 samples/sec#011loss=2.573618\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:53 INFO 139866244298560] Epoch[16] Batch[45] avg_epoch_loss=2.581263\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=45 train loss <loss>=2.56943221092\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:53 INFO 139866244298560] Epoch[16] Batch [45]#011Speed: 585.79 samples/sec#011loss=2.569432\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:53 INFO 139866244298560] Epoch[16] Batch[50] avg_epoch_loss=2.532193\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=50 train loss <loss>=2.08075184822\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:53 INFO 139866244298560] Epoch[16] Batch [50]#011Speed: 486.37 samples/sec#011loss=2.080752\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:54 INFO 139866244298560] Epoch[16] Batch[55] avg_epoch_loss=2.501400\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=55 train loss <loss>=2.18730823994\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:54 INFO 139866244298560] Epoch[16] Batch [55]#011Speed: 591.79 samples/sec#011loss=2.187308\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:54 INFO 139866244298560] Epoch[16] Batch[60] avg_epoch_loss=2.515827\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=60 train loss <loss>=2.67740488052\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:54 INFO 139866244298560] Epoch[16] Batch [60]#011Speed: 476.33 samples/sec#011loss=2.677405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:55 INFO 139866244298560] Epoch[16] Batch[65] avg_epoch_loss=2.538919\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=65 train loss <loss>=2.82064733505\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:55 INFO 139866244298560] Epoch[16] Batch [65]#011Speed: 482.65 samples/sec#011loss=2.820647\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:56 INFO 139866244298560] Epoch[16] Batch[70] avg_epoch_loss=2.603227\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=70 train loss <loss>=3.45209388733\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:56 INFO 139866244298560] Epoch[16] Batch [70]#011Speed: 594.68 samples/sec#011loss=3.452094\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:56 INFO 139866244298560] Epoch[16] Batch[75] avg_epoch_loss=2.651129\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=75 train loss <loss>=3.33133125305\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:56 INFO 139866244298560] Epoch[16] Batch [75]#011Speed: 481.00 samples/sec#011loss=3.331331\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:57 INFO 139866244298560] Epoch[16] Batch[80] avg_epoch_loss=2.677742\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=80 train loss <loss>=3.08226270676\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:57 INFO 139866244298560] Epoch[16] Batch [80]#011Speed: 592.21 samples/sec#011loss=3.082263\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:58 INFO 139866244298560] Epoch[16] Batch[85] avg_epoch_loss=2.691041\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=85 train loss <loss>=2.90648531914\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:58 INFO 139866244298560] Epoch[16] Batch [85]#011Speed: 471.83 samples/sec#011loss=2.906485\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:58 INFO 139866244298560] Epoch[16] Batch[90] avg_epoch_loss=2.690615\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=90 train loss <loss>=2.68328700066\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:58 INFO 139866244298560] Epoch[16] Batch [90]#011Speed: 595.32 samples/sec#011loss=2.683287\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:59 INFO 139866244298560] Epoch[16] Batch[95] avg_epoch_loss=2.688679\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=95 train loss <loss>=2.65345044136\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:59 INFO 139866244298560] Epoch[16] Batch [95]#011Speed: 475.43 samples/sec#011loss=2.653450\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:59 INFO 139866244298560] Epoch[16] Batch[100] avg_epoch_loss=2.679958\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=100 train loss <loss>=2.51251530647\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:34:59 INFO 139866244298560] Epoch[16] Batch [100]#011Speed: 587.44 samples/sec#011loss=2.512515\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:00 INFO 139866244298560] Epoch[16] Batch[105] avg_epoch_loss=2.674756\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=105 train loss <loss>=2.569668293\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:00 INFO 139866244298560] Epoch[16] Batch [105]#011Speed: 480.26 samples/sec#011loss=2.569668\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:00 INFO 139866244298560] Epoch[16] Batch[110] avg_epoch_loss=2.653685\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=110 train loss <loss>=2.20697793961\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:00 INFO 139866244298560] Epoch[16] Batch [110]#011Speed: 595.04 samples/sec#011loss=2.206978\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:01 INFO 139866244298560] Epoch[16] Batch[115] avg_epoch_loss=2.643685\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=115 train loss <loss>=2.42168159485\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:01 INFO 139866244298560] Epoch[16] Batch [115]#011Speed: 470.28 samples/sec#011loss=2.421682\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:02 INFO 139866244298560] Epoch[16] Batch[120] avg_epoch_loss=2.635552\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=120 train loss <loss>=2.44687986374\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:02 INFO 139866244298560] Epoch[16] Batch [120]#011Speed: 582.48 samples/sec#011loss=2.446880\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:02 INFO 139866244298560] Epoch[16] Batch[125] avg_epoch_loss=2.642911\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=125 train loss <loss>=2.82098507881\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:02 INFO 139866244298560] Epoch[16] Batch [125]#011Speed: 479.89 samples/sec#011loss=2.820985\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:03 INFO 139866244298560] Epoch[16] Batch[130] avg_epoch_loss=2.650692\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=130 train loss <loss>=2.84677805901\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:03 INFO 139866244298560] Epoch[16] Batch [130]#011Speed: 597.19 samples/sec#011loss=2.846778\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:04 INFO 139866244298560] Epoch[16] Batch[135] avg_epoch_loss=2.666371\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=135 train loss <loss>=3.07716078758\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:04 INFO 139866244298560] Epoch[16] Batch [135]#011Speed: 468.19 samples/sec#011loss=3.077161\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:04 INFO 139866244298560] Epoch[16] Batch[140] avg_epoch_loss=2.680150\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=140 train loss <loss>=3.05494737625\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:04 INFO 139866244298560] Epoch[16] Batch [140]#011Speed: 591.08 samples/sec#011loss=3.054947\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:05 INFO 139866244298560] Epoch[16] Batch[145] avg_epoch_loss=2.678888\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=145 train loss <loss>=2.64330487251\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:05 INFO 139866244298560] Epoch[16] Batch [145]#011Speed: 472.35 samples/sec#011loss=2.643305\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:05 INFO 139866244298560] Epoch[16] Batch[150] avg_epoch_loss=2.673438\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=150 train loss <loss>=2.51427760124\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:05 INFO 139866244298560] Epoch[16] Batch [150]#011Speed: 596.79 samples/sec#011loss=2.514278\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:06 INFO 139866244298560] Epoch[16] Batch[155] avg_epoch_loss=2.672388\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=155 train loss <loss>=2.64067201614\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:06 INFO 139866244298560] Epoch[16] Batch [155]#011Speed: 465.72 samples/sec#011loss=2.640672\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:07 INFO 139866244298560] Epoch[16] Batch[160] avg_epoch_loss=2.672454\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=160 train loss <loss>=2.67452836037\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:07 INFO 139866244298560] Epoch[16] Batch [160]#011Speed: 589.23 samples/sec#011loss=2.674528\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:07 INFO 139866244298560] Epoch[16] Batch[165] avg_epoch_loss=2.668738\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=165 train loss <loss>=2.5490773201\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:07 INFO 139866244298560] Epoch[16] Batch [165]#011Speed: 475.94 samples/sec#011loss=2.549077\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:08 INFO 139866244298560] Epoch[16] Batch[170] avg_epoch_loss=2.656925\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=170 train loss <loss>=2.26472578049\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:08 INFO 139866244298560] Epoch[16] Batch [170]#011Speed: 595.04 samples/sec#011loss=2.264726\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:08 INFO 139866244298560] Epoch[16] Batch[175] avg_epoch_loss=2.652347\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=175 train loss <loss>=2.49578595161\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:08 INFO 139866244298560] Epoch[16] Batch [175]#011Speed: 473.21 samples/sec#011loss=2.495786\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:09 INFO 139866244298560] Epoch[16] Batch[180] avg_epoch_loss=2.652583\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=180 train loss <loss>=2.66089873314\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:09 INFO 139866244298560] Epoch[16] Batch [180]#011Speed: 599.06 samples/sec#011loss=2.660899\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:10 INFO 139866244298560] Epoch[16] Batch[185] avg_epoch_loss=2.664255\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=185 train loss <loss>=3.08678975105\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:10 INFO 139866244298560] Epoch[16] Batch [185]#011Speed: 472.76 samples/sec#011loss=3.086790\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:10 INFO 139866244298560] Epoch[16] Batch[190] avg_epoch_loss=2.674634\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=190 train loss <loss>=3.0607339859\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:10 INFO 139866244298560] Epoch[16] Batch [190]#011Speed: 594.42 samples/sec#011loss=3.060734\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:11 INFO 139866244298560] Epoch[16] Batch[195] avg_epoch_loss=2.690674\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=195 train loss <loss>=3.30337061882\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:11 INFO 139866244298560] Epoch[16] Batch [195]#011Speed: 479.20 samples/sec#011loss=3.303371\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:11 INFO 139866244298560] Epoch[16] Batch[200] avg_epoch_loss=2.709134\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=200 train loss <loss>=3.43280410767\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:11 INFO 139866244298560] Epoch[16] Batch [200]#011Speed: 593.77 samples/sec#011loss=3.432804\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:12 INFO 139866244298560] Epoch[16] Batch[205] avg_epoch_loss=2.728624\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=205 train loss <loss>=3.51212277412\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:12 INFO 139866244298560] Epoch[16] Batch [205]#011Speed: 466.56 samples/sec#011loss=3.512123\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:13 INFO 139866244298560] Epoch[16] Batch[210] avg_epoch_loss=2.745124\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=210 train loss <loss>=3.42490148544\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:13 INFO 139866244298560] Epoch[16] Batch [210]#011Speed: 540.07 samples/sec#011loss=3.424901\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:13 INFO 139866244298560] Epoch[16] Batch[215] avg_epoch_loss=2.745002\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=215 train loss <loss>=2.73984494209\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:13 INFO 139866244298560] Epoch[16] Batch [215]#011Speed: 484.99 samples/sec#011loss=2.739845\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:14 INFO 139866244298560] Epoch[16] Batch[220] avg_epoch_loss=2.747567\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=220 train loss <loss>=2.85840334892\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:14 INFO 139866244298560] Epoch[16] Batch [220]#011Speed: 478.47 samples/sec#011loss=2.858403\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:15 INFO 139866244298560] Epoch[16] Batch[225] avg_epoch_loss=2.738847\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=225 train loss <loss>=2.3534116745\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:15 INFO 139866244298560] Epoch[16] Batch [225]#011Speed: 580.63 samples/sec#011loss=2.353412\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:15 INFO 139866244298560] Epoch[16] Batch[230] avg_epoch_loss=2.730218\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=230 train loss <loss>=2.34020078182\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:15 INFO 139866244298560] Epoch[16] Batch [230]#011Speed: 596.84 samples/sec#011loss=2.340201\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:16 INFO 139866244298560] Epoch[16] Batch[235] avg_epoch_loss=2.732025\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=235 train loss <loss>=2.81546850204\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:16 INFO 139866244298560] Epoch[16] Batch [235]#011Speed: 475.19 samples/sec#011loss=2.815469\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:16 INFO 139866244298560] Epoch[16] Batch[240] avg_epoch_loss=2.738212\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=240 train loss <loss>=3.03027644157\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:16 INFO 139866244298560] Epoch[16] Batch [240]#011Speed: 488.62 samples/sec#011loss=3.030276\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:17 INFO 139866244298560] Epoch[16] Batch[245] avg_epoch_loss=2.747600\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=245 train loss <loss>=3.20010094643\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:17 INFO 139866244298560] Epoch[16] Batch [245]#011Speed: 591.21 samples/sec#011loss=3.200101\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:18 INFO 139866244298560] Epoch[16] Batch[250] avg_epoch_loss=2.767264\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=250 train loss <loss>=3.73472185135\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:18 INFO 139866244298560] Epoch[16] Batch [250]#011Speed: 480.25 samples/sec#011loss=3.734722\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:18 INFO 139866244298560] Epoch[16] Batch[255] avg_epoch_loss=2.781869\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=255 train loss <loss>=3.51505589485\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:18 INFO 139866244298560] Epoch[16] Batch [255]#011Speed: 597.71 samples/sec#011loss=3.515056\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:19 INFO 139866244298560] Epoch[16] Batch[260] avg_epoch_loss=2.793939\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=260 train loss <loss>=3.41190519333\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:19 INFO 139866244298560] Epoch[16] Batch [260]#011Speed: 485.31 samples/sec#011loss=3.411905\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:19 INFO 139866244298560] Epoch[16] Batch[265] avg_epoch_loss=2.790392\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, batch=265 train loss <loss>=2.60525746346\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:19 INFO 139866244298560] Epoch[16] Batch [265]#011Speed: 572.56 samples/sec#011loss=2.605257\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:20 INFO 139866244298560] processed a total of 17189 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32911.537170410156, \"sum\": 32911.537170410156, \"min\": 32911.537170410156}}, \"EndTime\": 1599442520.232539, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442487.320336}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:20 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=522.27641618 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:20 INFO 139866244298560] #progress_metric: host=algo-1, completed 21 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=16, train loss <loss>=2.79249776828\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:20 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:20 INFO 139866244298560] Epoch[17] Batch[0] avg_epoch_loss=2.114049\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=0 train loss <loss>=2.11404919624\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:21 INFO 139866244298560] Epoch[17] Batch[5] avg_epoch_loss=2.102304\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=5 train loss <loss>=2.10230390231\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:21 INFO 139866244298560] Epoch[17] Batch [5]#011Speed: 595.09 samples/sec#011loss=2.102304\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:21 INFO 139866244298560] Epoch[17] Batch[10] avg_epoch_loss=2.176325\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=10 train loss <loss>=2.26515026093\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:21 INFO 139866244298560] Epoch[17] Batch [10]#011Speed: 473.17 samples/sec#011loss=2.265150\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:22 INFO 139866244298560] Epoch[17] Batch[15] avg_epoch_loss=2.326638\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=15 train loss <loss>=2.65732712746\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:22 INFO 139866244298560] Epoch[17] Batch [15]#011Speed: 593.95 samples/sec#011loss=2.657327\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:22 INFO 139866244298560] Epoch[17] Batch[20] avg_epoch_loss=2.410541\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=20 train loss <loss>=2.67902851105\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:22 INFO 139866244298560] Epoch[17] Batch [20]#011Speed: 467.41 samples/sec#011loss=2.679029\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:23 INFO 139866244298560] Epoch[17] Batch[25] avg_epoch_loss=2.485490\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=25 train loss <loss>=2.80027794838\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:23 INFO 139866244298560] Epoch[17] Batch [25]#011Speed: 591.55 samples/sec#011loss=2.800278\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:24 INFO 139866244298560] Epoch[17] Batch[30] avg_epoch_loss=2.548808\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=30 train loss <loss>=2.87806310654\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:24 INFO 139866244298560] Epoch[17] Batch [30]#011Speed: 473.89 samples/sec#011loss=2.878063\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:24 INFO 139866244298560] Epoch[17] Batch[35] avg_epoch_loss=2.602851\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=35 train loss <loss>=2.93791203499\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:24 INFO 139866244298560] Epoch[17] Batch [35]#011Speed: 595.38 samples/sec#011loss=2.937912\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:25 INFO 139866244298560] Epoch[17] Batch[40] avg_epoch_loss=2.647193\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=40 train loss <loss>=2.96645627022\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:25 INFO 139866244298560] Epoch[17] Batch [40]#011Speed: 468.46 samples/sec#011loss=2.966456\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:25 INFO 139866244298560] Epoch[17] Batch[45] avg_epoch_loss=2.664696\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=45 train loss <loss>=2.80822577477\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:25 INFO 139866244298560] Epoch[17] Batch [45]#011Speed: 593.98 samples/sec#011loss=2.808226\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:26 INFO 139866244298560] Epoch[17] Batch[50] avg_epoch_loss=2.654523\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=50 train loss <loss>=2.56093244553\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:26 INFO 139866244298560] Epoch[17] Batch [50]#011Speed: 479.99 samples/sec#011loss=2.560932\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:27 INFO 139866244298560] Epoch[17] Batch[55] avg_epoch_loss=2.635754\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=55 train loss <loss>=2.44430134296\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:27 INFO 139866244298560] Epoch[17] Batch [55]#011Speed: 593.80 samples/sec#011loss=2.444301\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:27 INFO 139866244298560] Epoch[17] Batch[60] avg_epoch_loss=2.603256\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=60 train loss <loss>=2.23928470612\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:27 INFO 139866244298560] Epoch[17] Batch [60]#011Speed: 466.76 samples/sec#011loss=2.239285\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:28 INFO 139866244298560] Epoch[17] Batch[65] avg_epoch_loss=2.593876\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=65 train loss <loss>=2.4794356823\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:28 INFO 139866244298560] Epoch[17] Batch [65]#011Speed: 595.97 samples/sec#011loss=2.479436\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:28 INFO 139866244298560] Epoch[17] Batch[70] avg_epoch_loss=2.600505\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=70 train loss <loss>=2.68801598549\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:28 INFO 139866244298560] Epoch[17] Batch [70]#011Speed: 476.37 samples/sec#011loss=2.688016\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:29 INFO 139866244298560] Epoch[17] Batch[75] avg_epoch_loss=2.605117\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=75 train loss <loss>=2.67059512138\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:29 INFO 139866244298560] Epoch[17] Batch [75]#011Speed: 596.17 samples/sec#011loss=2.670595\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:30 INFO 139866244298560] Epoch[17] Batch[80] avg_epoch_loss=2.609156\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=80 train loss <loss>=2.67055220604\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:30 INFO 139866244298560] Epoch[17] Batch [80]#011Speed: 472.31 samples/sec#011loss=2.670552\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:30 INFO 139866244298560] Epoch[17] Batch[85] avg_epoch_loss=2.644852\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=85 train loss <loss>=3.22313494682\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:30 INFO 139866244298560] Epoch[17] Batch [85]#011Speed: 600.43 samples/sec#011loss=3.223135\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:31 INFO 139866244298560] Epoch[17] Batch[90] avg_epoch_loss=2.674837\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=90 train loss <loss>=3.19057378769\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:31 INFO 139866244298560] Epoch[17] Batch [90]#011Speed: 471.48 samples/sec#011loss=3.190574\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:31 INFO 139866244298560] Epoch[17] Batch[95] avg_epoch_loss=2.708366\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=95 train loss <loss>=3.3185986042\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:31 INFO 139866244298560] Epoch[17] Batch [95]#011Speed: 594.23 samples/sec#011loss=3.318599\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:32 INFO 139866244298560] Epoch[17] Batch[100] avg_epoch_loss=2.730044\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=100 train loss <loss>=3.14626612663\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:32 INFO 139866244298560] Epoch[17] Batch [100]#011Speed: 478.85 samples/sec#011loss=3.146266\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:33 INFO 139866244298560] Epoch[17] Batch[105] avg_epoch_loss=2.727387\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=105 train loss <loss>=2.67370886803\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:33 INFO 139866244298560] Epoch[17] Batch [105]#011Speed: 596.78 samples/sec#011loss=2.673709\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:33 INFO 139866244298560] Epoch[17] Batch[110] avg_epoch_loss=2.718623\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=110 train loss <loss>=2.53281846046\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:33 INFO 139866244298560] Epoch[17] Batch [110]#011Speed: 483.24 samples/sec#011loss=2.532818\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:34 INFO 139866244298560] Epoch[17] Batch[115] avg_epoch_loss=2.706466\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=115 train loss <loss>=2.43657889366\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:34 INFO 139866244298560] Epoch[17] Batch [115]#011Speed: 590.55 samples/sec#011loss=2.436579\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:35 INFO 139866244298560] Epoch[17] Batch[120] avg_epoch_loss=2.691606\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=120 train loss <loss>=2.34685082436\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:35 INFO 139866244298560] Epoch[17] Batch [120]#011Speed: 466.43 samples/sec#011loss=2.346851\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:35 INFO 139866244298560] Epoch[17] Batch[125] avg_epoch_loss=2.689735\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=125 train loss <loss>=2.64446544647\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:35 INFO 139866244298560] Epoch[17] Batch [125]#011Speed: 598.31 samples/sec#011loss=2.644465\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:36 INFO 139866244298560] Epoch[17] Batch[130] avg_epoch_loss=2.682652\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=130 train loss <loss>=2.50415620804\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:36 INFO 139866244298560] Epoch[17] Batch [130]#011Speed: 482.22 samples/sec#011loss=2.504156\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:36 INFO 139866244298560] Epoch[17] Batch[135] avg_epoch_loss=2.664574\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=135 train loss <loss>=2.1909422636\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:36 INFO 139866244298560] Epoch[17] Batch [135]#011Speed: 582.49 samples/sec#011loss=2.190942\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:37 INFO 139866244298560] Epoch[17] Batch[140] avg_epoch_loss=2.676106\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=140 train loss <loss>=2.98975906372\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:37 INFO 139866244298560] Epoch[17] Batch [140]#011Speed: 472.81 samples/sec#011loss=2.989759\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:38 INFO 139866244298560] Epoch[17] Batch[145] avg_epoch_loss=2.691950\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=145 train loss <loss>=3.13875026703\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:38 INFO 139866244298560] Epoch[17] Batch [145]#011Speed: 593.52 samples/sec#011loss=3.138750\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:38 INFO 139866244298560] Epoch[17] Batch[150] avg_epoch_loss=2.698495\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=150 train loss <loss>=2.88961486816\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:38 INFO 139866244298560] Epoch[17] Batch [150]#011Speed: 473.53 samples/sec#011loss=2.889615\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:39 INFO 139866244298560] Epoch[17] Batch[155] avg_epoch_loss=2.707698\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=155 train loss <loss>=2.98564043045\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:39 INFO 139866244298560] Epoch[17] Batch [155]#011Speed: 596.49 samples/sec#011loss=2.985640\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:39 INFO 139866244298560] Epoch[17] Batch[160] avg_epoch_loss=2.714697\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=160 train loss <loss>=2.93306999207\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:39 INFO 139866244298560] Epoch[17] Batch [160]#011Speed: 474.61 samples/sec#011loss=2.933070\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:40 INFO 139866244298560] Epoch[17] Batch[165] avg_epoch_loss=2.716976\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=165 train loss <loss>=2.79035429955\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:40 INFO 139866244298560] Epoch[17] Batch [165]#011Speed: 584.87 samples/sec#011loss=2.790354\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:41 INFO 139866244298560] Epoch[17] Batch[170] avg_epoch_loss=2.708762\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=170 train loss <loss>=2.436059618\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:41 INFO 139866244298560] Epoch[17] Batch [170]#011Speed: 468.89 samples/sec#011loss=2.436060\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:41 INFO 139866244298560] Epoch[17] Batch[175] avg_epoch_loss=2.704358\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=175 train loss <loss>=2.55374112129\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:41 INFO 139866244298560] Epoch[17] Batch [175]#011Speed: 594.46 samples/sec#011loss=2.553741\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:42 INFO 139866244298560] Epoch[17] Batch[180] avg_epoch_loss=2.708533\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=180 train loss <loss>=2.85547590256\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:42 INFO 139866244298560] Epoch[17] Batch [180]#011Speed: 479.01 samples/sec#011loss=2.855476\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:42 INFO 139866244298560] Epoch[17] Batch[185] avg_epoch_loss=2.704939\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=185 train loss <loss>=2.57485685349\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:42 INFO 139866244298560] Epoch[17] Batch [185]#011Speed: 594.36 samples/sec#011loss=2.574857\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:43 INFO 139866244298560] Epoch[17] Batch[190] avg_epoch_loss=2.707983\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=190 train loss <loss>=2.82119936943\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:43 INFO 139866244298560] Epoch[17] Batch [190]#011Speed: 435.26 samples/sec#011loss=2.821199\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:44 INFO 139866244298560] Epoch[17] Batch[195] avg_epoch_loss=2.710992\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=195 train loss <loss>=2.8259510994\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:44 INFO 139866244298560] Epoch[17] Batch [195]#011Speed: 593.47 samples/sec#011loss=2.825951\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:44 INFO 139866244298560] Epoch[17] Batch[200] avg_epoch_loss=2.724159\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=200 train loss <loss>=3.24031019211\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:44 INFO 139866244298560] Epoch[17] Batch [200]#011Speed: 485.63 samples/sec#011loss=3.240310\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:45 INFO 139866244298560] Epoch[17] Batch[205] avg_epoch_loss=2.737443\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=205 train loss <loss>=3.27143354416\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:45 INFO 139866244298560] Epoch[17] Batch [205]#011Speed: 576.19 samples/sec#011loss=3.271434\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:46 INFO 139866244298560] Epoch[17] Batch[210] avg_epoch_loss=2.758342\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=210 train loss <loss>=3.61939606667\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:46 INFO 139866244298560] Epoch[17] Batch [210]#011Speed: 486.07 samples/sec#011loss=3.619396\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:46 INFO 139866244298560] Epoch[17] Batch[215] avg_epoch_loss=2.779920\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=215 train loss <loss>=3.69050040245\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:46 INFO 139866244298560] Epoch[17] Batch [215]#011Speed: 486.12 samples/sec#011loss=3.690500\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:47 INFO 139866244298560] Epoch[17] Batch[220] avg_epoch_loss=2.781321\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=220 train loss <loss>=2.84187226295\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:47 INFO 139866244298560] Epoch[17] Batch [220]#011Speed: 592.08 samples/sec#011loss=2.841872\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:47 INFO 139866244298560] Epoch[17] Batch[225] avg_epoch_loss=2.779405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=225 train loss <loss>=2.69470152855\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:47 INFO 139866244298560] Epoch[17] Batch [225]#011Speed: 474.36 samples/sec#011loss=2.694702\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:48 INFO 139866244298560] Epoch[17] Batch[230] avg_epoch_loss=2.775065\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=230 train loss <loss>=2.57889990807\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:48 INFO 139866244298560] Epoch[17] Batch [230]#011Speed: 595.93 samples/sec#011loss=2.578900\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:49 INFO 139866244298560] Epoch[17] Batch[235] avg_epoch_loss=2.770999\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=235 train loss <loss>=2.58316764832\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:49 INFO 139866244298560] Epoch[17] Batch [235]#011Speed: 481.62 samples/sec#011loss=2.583168\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:49 INFO 139866244298560] Epoch[17] Batch[240] avg_epoch_loss=2.769605\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=240 train loss <loss>=2.70380625725\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:49 INFO 139866244298560] Epoch[17] Batch [240]#011Speed: 596.23 samples/sec#011loss=2.703806\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:50 INFO 139866244298560] Epoch[17] Batch[245] avg_epoch_loss=2.763704\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=245 train loss <loss>=2.47924599648\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:50 INFO 139866244298560] Epoch[17] Batch [245]#011Speed: 478.91 samples/sec#011loss=2.479246\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:50 INFO 139866244298560] Epoch[17] Batch[250] avg_epoch_loss=2.762811\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=250 train loss <loss>=2.71889190674\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:50 INFO 139866244298560] Epoch[17] Batch [250]#011Speed: 601.35 samples/sec#011loss=2.718892\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:51 INFO 139866244298560] Epoch[17] Batch[255] avg_epoch_loss=2.770041\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=255 train loss <loss>=3.13297324181\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:51 INFO 139866244298560] Epoch[17] Batch [255]#011Speed: 479.39 samples/sec#011loss=3.132973\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:52 INFO 139866244298560] Epoch[17] Batch[260] avg_epoch_loss=2.783239\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=260 train loss <loss>=3.45898342133\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:52 INFO 139866244298560] Epoch[17] Batch [260]#011Speed: 586.31 samples/sec#011loss=3.458983\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:52 INFO 139866244298560] Epoch[17] Batch[265] avg_epoch_loss=2.788409\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, batch=265 train loss <loss>=3.05826320648\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:52 INFO 139866244298560] Epoch[17] Batch [265]#011Speed: 489.61 samples/sec#011loss=3.058263\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:53 INFO 139866244298560] processed a total of 17275 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32908.891916275024, \"sum\": 32908.891916275024, \"min\": 32908.891916275024}}, \"EndTime\": 1599442553.142251, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442520.232627}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:53 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=524.932230867 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:53 INFO 139866244298560] #progress_metric: host=algo-1, completed 22 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=17, train loss <loss>=2.79061558247\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:53 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:53 INFO 139866244298560] Epoch[18] Batch[0] avg_epoch_loss=2.264985\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=0 train loss <loss>=2.26498532295\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:54 INFO 139866244298560] Epoch[18] Batch[5] avg_epoch_loss=2.179052\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=5 train loss <loss>=2.17905211449\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:54 INFO 139866244298560] Epoch[18] Batch [5]#011Speed: 525.45 samples/sec#011loss=2.179052\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:54 INFO 139866244298560] Epoch[18] Batch[10] avg_epoch_loss=2.193761\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=10 train loss <loss>=2.21141171455\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:54 INFO 139866244298560] Epoch[18] Batch [10]#011Speed: 473.09 samples/sec#011loss=2.211412\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:55 INFO 139866244298560] Epoch[18] Batch[15] avg_epoch_loss=2.352571\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=15 train loss <loss>=2.70195236206\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:55 INFO 139866244298560] Epoch[18] Batch [15]#011Speed: 581.91 samples/sec#011loss=2.701952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:55 INFO 139866244298560] Epoch[18] Batch[20] avg_epoch_loss=2.447901\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=20 train loss <loss>=2.75295934677\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:55 INFO 139866244298560] Epoch[18] Batch [20]#011Speed: 476.80 samples/sec#011loss=2.752959\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:56 INFO 139866244298560] Epoch[18] Batch[25] avg_epoch_loss=2.521912\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=25 train loss <loss>=2.83275637627\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:56 INFO 139866244298560] Epoch[18] Batch [25]#011Speed: 589.26 samples/sec#011loss=2.832756\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:57 INFO 139866244298560] Epoch[18] Batch[30] avg_epoch_loss=2.531893\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=30 train loss <loss>=2.58379154205\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:57 INFO 139866244298560] Epoch[18] Batch [30]#011Speed: 466.26 samples/sec#011loss=2.583792\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:57 INFO 139866244298560] Epoch[18] Batch[35] avg_epoch_loss=2.564590\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=35 train loss <loss>=2.76731142998\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:57 INFO 139866244298560] Epoch[18] Batch [35]#011Speed: 594.65 samples/sec#011loss=2.767311\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:58 INFO 139866244298560] Epoch[18] Batch[40] avg_epoch_loss=2.571194\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=40 train loss <loss>=2.61874761581\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:58 INFO 139866244298560] Epoch[18] Batch [40]#011Speed: 478.72 samples/sec#011loss=2.618748\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:58 INFO 139866244298560] Epoch[18] Batch[45] avg_epoch_loss=2.561335\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=45 train loss <loss>=2.48049154282\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:58 INFO 139866244298560] Epoch[18] Batch [45]#011Speed: 522.47 samples/sec#011loss=2.480492\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:59 INFO 139866244298560] Epoch[18] Batch[50] avg_epoch_loss=2.544158\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=50 train loss <loss>=2.3861225605\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:35:59 INFO 139866244298560] Epoch[18] Batch [50]#011Speed: 468.50 samples/sec#011loss=2.386123\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:00 INFO 139866244298560] Epoch[18] Batch[55] avg_epoch_loss=2.540046\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=55 train loss <loss>=2.49810643196\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:00 INFO 139866244298560] Epoch[18] Batch [55]#011Speed: 591.64 samples/sec#011loss=2.498106\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:00 INFO 139866244298560] Epoch[18] Batch[60] avg_epoch_loss=2.544196\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=60 train loss <loss>=2.59067444801\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:00 INFO 139866244298560] Epoch[18] Batch [60]#011Speed: 487.88 samples/sec#011loss=2.590674\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:01 INFO 139866244298560] Epoch[18] Batch[65] avg_epoch_loss=2.550145\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=65 train loss <loss>=2.62272334099\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:01 INFO 139866244298560] Epoch[18] Batch [65]#011Speed: 596.89 samples/sec#011loss=2.622723\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:02 INFO 139866244298560] Epoch[18] Batch[70] avg_epoch_loss=2.617466\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=70 train loss <loss>=3.50610895157\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:02 INFO 139866244298560] Epoch[18] Batch [70]#011Speed: 459.75 samples/sec#011loss=3.506109\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:02 INFO 139866244298560] Epoch[18] Batch[75] avg_epoch_loss=2.657237\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=75 train loss <loss>=3.22198801041\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:02 INFO 139866244298560] Epoch[18] Batch [75]#011Speed: 468.94 samples/sec#011loss=3.221988\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:03 INFO 139866244298560] Epoch[18] Batch[80] avg_epoch_loss=2.687854\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=80 train loss <loss>=3.1532248497\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:03 INFO 139866244298560] Epoch[18] Batch [80]#011Speed: 588.42 samples/sec#011loss=3.153225\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:04 INFO 139866244298560] Epoch[18] Batch[85] avg_epoch_loss=2.709753\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=85 train loss <loss>=3.06451311111\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:04 INFO 139866244298560] Epoch[18] Batch [85]#011Speed: 445.45 samples/sec#011loss=3.064513\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:04 INFO 139866244298560] Epoch[18] Batch[90] avg_epoch_loss=2.701540\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=90 train loss <loss>=2.56028971672\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:04 INFO 139866244298560] Epoch[18] Batch [90]#011Speed: 564.74 samples/sec#011loss=2.560290\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:05 INFO 139866244298560] Epoch[18] Batch[95] avg_epoch_loss=2.683608\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=95 train loss <loss>=2.35723023415\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:05 INFO 139866244298560] Epoch[18] Batch [95]#011Speed: 460.83 samples/sec#011loss=2.357230\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:05 INFO 139866244298560] Epoch[18] Batch[100] avg_epoch_loss=2.667909\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=100 train loss <loss>=2.36649928093\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:05 INFO 139866244298560] Epoch[18] Batch [100]#011Speed: 597.47 samples/sec#011loss=2.366499\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:06 INFO 139866244298560] Epoch[18] Batch[105] avg_epoch_loss=2.664457\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=105 train loss <loss>=2.59473199844\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:06 INFO 139866244298560] Epoch[18] Batch [105]#011Speed: 479.08 samples/sec#011loss=2.594732\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:07 INFO 139866244298560] Epoch[18] Batch[110] avg_epoch_loss=2.657486\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=110 train loss <loss>=2.50968270302\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:07 INFO 139866244298560] Epoch[18] Batch [110]#011Speed: 589.96 samples/sec#011loss=2.509683\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:07 INFO 139866244298560] Epoch[18] Batch[115] avg_epoch_loss=2.658405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=115 train loss <loss>=2.67881696224\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:07 INFO 139866244298560] Epoch[18] Batch [115]#011Speed: 471.44 samples/sec#011loss=2.678817\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:08 INFO 139866244298560] Epoch[18] Batch[120] avg_epoch_loss=2.678429\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=120 train loss <loss>=3.14298996925\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:08 INFO 139866244298560] Epoch[18] Batch [120]#011Speed: 587.19 samples/sec#011loss=3.142990\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:08 INFO 139866244298560] Epoch[18] Batch[125] avg_epoch_loss=2.691205\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=125 train loss <loss>=3.00038323402\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:08 INFO 139866244298560] Epoch[18] Batch [125]#011Speed: 484.57 samples/sec#011loss=3.000383\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:09 INFO 139866244298560] Epoch[18] Batch[130] avg_epoch_loss=2.702225\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=130 train loss <loss>=2.97993369102\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:09 INFO 139866244298560] Epoch[18] Batch [130]#011Speed: 523.26 samples/sec#011loss=2.979934\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:10 INFO 139866244298560] Epoch[18] Batch[135] avg_epoch_loss=2.697491\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=135 train loss <loss>=2.57345614433\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:10 INFO 139866244298560] Epoch[18] Batch [135]#011Speed: 476.51 samples/sec#011loss=2.573456\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:10 INFO 139866244298560] Epoch[18] Batch[140] avg_epoch_loss=2.679344\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=140 train loss <loss>=2.18574512005\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:10 INFO 139866244298560] Epoch[18] Batch [140]#011Speed: 594.11 samples/sec#011loss=2.185745\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:11 INFO 139866244298560] Epoch[18] Batch[145] avg_epoch_loss=2.671145\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=145 train loss <loss>=2.43992772102\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:11 INFO 139866244298560] Epoch[18] Batch [145]#011Speed: 469.94 samples/sec#011loss=2.439928\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:11 INFO 139866244298560] Epoch[18] Batch[150] avg_epoch_loss=2.655708\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=150 train loss <loss>=2.20494971275\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:11 INFO 139866244298560] Epoch[18] Batch [150]#011Speed: 594.27 samples/sec#011loss=2.204950\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:12 INFO 139866244298560] Epoch[18] Batch[155] avg_epoch_loss=2.649162\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=155 train loss <loss>=2.45145974159\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:12 INFO 139866244298560] Epoch[18] Batch [155]#011Speed: 463.79 samples/sec#011loss=2.451460\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:13 INFO 139866244298560] Epoch[18] Batch[160] avg_epoch_loss=2.645970\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=160 train loss <loss>=2.54639344215\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:13 INFO 139866244298560] Epoch[18] Batch [160]#011Speed: 594.96 samples/sec#011loss=2.546393\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:13 INFO 139866244298560] Epoch[18] Batch[165] avg_epoch_loss=2.647651\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=165 train loss <loss>=2.70176143646\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:13 INFO 139866244298560] Epoch[18] Batch [165]#011Speed: 429.10 samples/sec#011loss=2.701761\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:14 INFO 139866244298560] Epoch[18] Batch[170] avg_epoch_loss=2.638170\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=170 train loss <loss>=2.32342896461\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:14 INFO 139866244298560] Epoch[18] Batch [170]#011Speed: 535.65 samples/sec#011loss=2.323429\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:15 INFO 139866244298560] Epoch[18] Batch[175] avg_epoch_loss=2.642664\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=175 train loss <loss>=2.79633927345\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:15 INFO 139866244298560] Epoch[18] Batch [175]#011Speed: 473.34 samples/sec#011loss=2.796339\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:15 INFO 139866244298560] Epoch[18] Batch[180] avg_epoch_loss=2.658021\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=180 train loss <loss>=3.19859800339\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:15 INFO 139866244298560] Epoch[18] Batch [180]#011Speed: 598.99 samples/sec#011loss=3.198598\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:16 INFO 139866244298560] Epoch[18] Batch[185] avg_epoch_loss=2.689176\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=185 train loss <loss>=3.8169986248\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:16 INFO 139866244298560] Epoch[18] Batch [185]#011Speed: 474.04 samples/sec#011loss=3.816999\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:16 INFO 139866244298560] Epoch[18] Batch[190] avg_epoch_loss=2.708802\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=190 train loss <loss>=3.43887763023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:16 INFO 139866244298560] Epoch[18] Batch [190]#011Speed: 594.73 samples/sec#011loss=3.438878\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:17 INFO 139866244298560] Epoch[18] Batch[195] avg_epoch_loss=2.721311\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=195 train loss <loss>=3.19915552139\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:17 INFO 139866244298560] Epoch[18] Batch [195]#011Speed: 482.61 samples/sec#011loss=3.199156\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:18 INFO 139866244298560] Epoch[18] Batch[200] avg_epoch_loss=2.735066\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=200 train loss <loss>=3.27427053452\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:18 INFO 139866244298560] Epoch[18] Batch [200]#011Speed: 592.01 samples/sec#011loss=3.274271\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:18 INFO 139866244298560] Epoch[18] Batch[205] avg_epoch_loss=2.741825\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=205 train loss <loss>=3.01351451874\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:18 INFO 139866244298560] Epoch[18] Batch [205]#011Speed: 470.86 samples/sec#011loss=3.013515\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:19 INFO 139866244298560] Epoch[18] Batch[210] avg_epoch_loss=2.745216\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=210 train loss <loss>=2.88493757248\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:19 INFO 139866244298560] Epoch[18] Batch [210]#011Speed: 535.70 samples/sec#011loss=2.884938\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:20 INFO 139866244298560] Epoch[18] Batch[215] avg_epoch_loss=2.740939\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=215 train loss <loss>=2.56045942307\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:20 INFO 139866244298560] Epoch[18] Batch [215]#011Speed: 474.34 samples/sec#011loss=2.560459\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:20 INFO 139866244298560] Epoch[18] Batch[220] avg_epoch_loss=2.737261\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=220 train loss <loss>=2.57834606171\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:20 INFO 139866244298560] Epoch[18] Batch [220]#011Speed: 592.70 samples/sec#011loss=2.578346\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:21 INFO 139866244298560] Epoch[18] Batch[225] avg_epoch_loss=2.732114\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=225 train loss <loss>=2.50461773872\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:21 INFO 139866244298560] Epoch[18] Batch [225]#011Speed: 474.26 samples/sec#011loss=2.504618\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:21 INFO 139866244298560] Epoch[18] Batch[230] avg_epoch_loss=2.728898\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=230 train loss <loss>=2.58352441788\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:21 INFO 139866244298560] Epoch[18] Batch [230]#011Speed: 588.10 samples/sec#011loss=2.583524\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:22 INFO 139866244298560] Epoch[18] Batch[235] avg_epoch_loss=2.741314\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=235 train loss <loss>=3.31493492126\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:22 INFO 139866244298560] Epoch[18] Batch [235]#011Speed: 483.73 samples/sec#011loss=3.314935\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:23 INFO 139866244298560] Epoch[18] Batch[240] avg_epoch_loss=2.751774\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=240 train loss <loss>=3.24549107552\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:23 INFO 139866244298560] Epoch[18] Batch [240]#011Speed: 483.98 samples/sec#011loss=3.245491\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:23 INFO 139866244298560] Epoch[18] Batch[245] avg_epoch_loss=2.770035\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=245 train loss <loss>=3.65021195412\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:23 INFO 139866244298560] Epoch[18] Batch [245]#011Speed: 595.48 samples/sec#011loss=3.650212\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:24 INFO 139866244298560] Epoch[18] Batch[250] avg_epoch_loss=2.779446\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=250 train loss <loss>=3.24246311188\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:24 INFO 139866244298560] Epoch[18] Batch [250]#011Speed: 460.29 samples/sec#011loss=3.242463\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:24 INFO 139866244298560] Epoch[18] Batch[255] avg_epoch_loss=2.781112\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=255 train loss <loss>=2.86474294662\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:24 INFO 139866244298560] Epoch[18] Batch [255]#011Speed: 572.14 samples/sec#011loss=2.864743\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:25 INFO 139866244298560] Epoch[18] Batch[260] avg_epoch_loss=2.779746\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=260 train loss <loss>=2.70981178284\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:25 INFO 139866244298560] Epoch[18] Batch [260]#011Speed: 475.72 samples/sec#011loss=2.709812\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:26 INFO 139866244298560] Epoch[18] Batch[265] avg_epoch_loss=2.774623\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=265 train loss <loss>=2.50722503662\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:26 INFO 139866244298560] Epoch[18] Batch [265]#011Speed: 589.37 samples/sec#011loss=2.507225\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:26 INFO 139866244298560] Epoch[18] Batch[270] avg_epoch_loss=2.793969\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, batch=270 train loss <loss>=3.82319917679\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:26 INFO 139866244298560] Epoch[18] Batch [270]#011Speed: 556.54 samples/sec#011loss=3.823199\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:26 INFO 139866244298560] processed a total of 17317 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33616.71590805054, \"sum\": 33616.71590805054, \"min\": 33616.71590805054}}, \"EndTime\": 1599442586.759734, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442553.142332}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:26 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=515.128590071 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:26 INFO 139866244298560] #progress_metric: host=algo-1, completed 23 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=18, train loss <loss>=2.79396947548\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:26 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:27 INFO 139866244298560] Epoch[19] Batch[0] avg_epoch_loss=2.118646\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=0 train loss <loss>=2.11864638329\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:27 INFO 139866244298560] Epoch[19] Batch[5] avg_epoch_loss=2.140866\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=5 train loss <loss>=2.14086610079\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:27 INFO 139866244298560] Epoch[19] Batch [5]#011Speed: 579.95 samples/sec#011loss=2.140866\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:28 INFO 139866244298560] Epoch[19] Batch[10] avg_epoch_loss=2.194465\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=10 train loss <loss>=2.2587831974\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:28 INFO 139866244298560] Epoch[19] Batch [10]#011Speed: 456.84 samples/sec#011loss=2.258783\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:28 INFO 139866244298560] Epoch[19] Batch[15] avg_epoch_loss=2.374621\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=15 train loss <loss>=2.77096605301\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:28 INFO 139866244298560] Epoch[19] Batch [15]#011Speed: 590.78 samples/sec#011loss=2.770966\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:29 INFO 139866244298560] Epoch[19] Batch[20] avg_epoch_loss=2.425661\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=20 train loss <loss>=2.58898630142\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:29 INFO 139866244298560] Epoch[19] Batch [20]#011Speed: 454.81 samples/sec#011loss=2.588986\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:30 INFO 139866244298560] Epoch[19] Batch[25] avg_epoch_loss=2.536136\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=25 train loss <loss>=3.00013055801\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:30 INFO 139866244298560] Epoch[19] Batch [25]#011Speed: 569.80 samples/sec#011loss=3.000131\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:30 INFO 139866244298560] Epoch[19] Batch[30] avg_epoch_loss=2.565192\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=30 train loss <loss>=2.71628460884\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:30 INFO 139866244298560] Epoch[19] Batch [30]#011Speed: 476.15 samples/sec#011loss=2.716285\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:31 INFO 139866244298560] Epoch[19] Batch[35] avg_epoch_loss=2.565636\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=35 train loss <loss>=2.56838717461\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:31 INFO 139866244298560] Epoch[19] Batch [35]#011Speed: 591.51 samples/sec#011loss=2.568387\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:31 INFO 139866244298560] Epoch[19] Batch[40] avg_epoch_loss=2.557320\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=40 train loss <loss>=2.49744911194\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:31 INFO 139866244298560] Epoch[19] Batch [40]#011Speed: 475.37 samples/sec#011loss=2.497449\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:32 INFO 139866244298560] Epoch[19] Batch[45] avg_epoch_loss=2.567761\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=45 train loss <loss>=2.65337095261\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:32 INFO 139866244298560] Epoch[19] Batch [45]#011Speed: 597.35 samples/sec#011loss=2.653371\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:33 INFO 139866244298560] Epoch[19] Batch[50] avg_epoch_loss=2.562497\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=50 train loss <loss>=2.51407394409\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:33 INFO 139866244298560] Epoch[19] Batch [50]#011Speed: 474.59 samples/sec#011loss=2.514074\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:33 INFO 139866244298560] Epoch[19] Batch[55] avg_epoch_loss=2.542416\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=55 train loss <loss>=2.33758587837\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:33 INFO 139866244298560] Epoch[19] Batch [55]#011Speed: 595.62 samples/sec#011loss=2.337586\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:34 INFO 139866244298560] Epoch[19] Batch[60] avg_epoch_loss=2.544583\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=60 train loss <loss>=2.56884996891\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:34 INFO 139866244298560] Epoch[19] Batch [60]#011Speed: 473.60 samples/sec#011loss=2.568850\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:35 INFO 139866244298560] Epoch[19] Batch[65] avg_epoch_loss=2.545350\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=65 train loss <loss>=2.55471711159\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:35 INFO 139866244298560] Epoch[19] Batch [65]#011Speed: 512.64 samples/sec#011loss=2.554717\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:35 INFO 139866244298560] Epoch[19] Batch[70] avg_epoch_loss=2.542049\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=70 train loss <loss>=2.49847106934\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:35 INFO 139866244298560] Epoch[19] Batch [70]#011Speed: 474.80 samples/sec#011loss=2.498471\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:36 INFO 139866244298560] Epoch[19] Batch[75] avg_epoch_loss=2.577980\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=75 train loss <loss>=3.0882083416\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:36 INFO 139866244298560] Epoch[19] Batch [75]#011Speed: 590.54 samples/sec#011loss=3.088208\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:36 INFO 139866244298560] Epoch[19] Batch[80] avg_epoch_loss=2.616161\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=80 train loss <loss>=3.19650497437\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:36 INFO 139866244298560] Epoch[19] Batch [80]#011Speed: 465.64 samples/sec#011loss=3.196505\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:37 INFO 139866244298560] Epoch[19] Batch[85] avg_epoch_loss=2.651743\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=85 train loss <loss>=3.22817006111\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:37 INFO 139866244298560] Epoch[19] Batch [85]#011Speed: 590.16 samples/sec#011loss=3.228170\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:38 INFO 139866244298560] Epoch[19] Batch[90] avg_epoch_loss=2.679744\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=90 train loss <loss>=3.16135473251\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:38 INFO 139866244298560] Epoch[19] Batch [90]#011Speed: 472.66 samples/sec#011loss=3.161355\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:38 INFO 139866244298560] Epoch[19] Batch[95] avg_epoch_loss=2.687936\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=95 train loss <loss>=2.83703827858\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:38 INFO 139866244298560] Epoch[19] Batch [95]#011Speed: 596.35 samples/sec#011loss=2.837038\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:39 INFO 139866244298560] Epoch[19] Batch[100] avg_epoch_loss=2.694141\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=100 train loss <loss>=2.81327352524\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:39 INFO 139866244298560] Epoch[19] Batch [100]#011Speed: 477.06 samples/sec#011loss=2.813274\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:39 INFO 139866244298560] Epoch[19] Batch[105] avg_epoch_loss=2.685962\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=105 train loss <loss>=2.52075567245\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:39 INFO 139866244298560] Epoch[19] Batch [105]#011Speed: 522.83 samples/sec#011loss=2.520756\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:40 INFO 139866244298560] Epoch[19] Batch[110] avg_epoch_loss=2.676419\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=110 train loss <loss>=2.47409791946\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:40 INFO 139866244298560] Epoch[19] Batch [110]#011Speed: 449.26 samples/sec#011loss=2.474098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:41 INFO 139866244298560] Epoch[19] Batch[115] avg_epoch_loss=2.652570\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=115 train loss <loss>=2.12312855721\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:41 INFO 139866244298560] Epoch[19] Batch [115]#011Speed: 586.20 samples/sec#011loss=2.123129\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:41 INFO 139866244298560] Epoch[19] Batch[120] avg_epoch_loss=2.640233\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=120 train loss <loss>=2.35401849747\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:41 INFO 139866244298560] Epoch[19] Batch [120]#011Speed: 471.92 samples/sec#011loss=2.354018\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:42 INFO 139866244298560] Epoch[19] Batch[125] avg_epoch_loss=2.638264\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=125 train loss <loss>=2.59061927795\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:42 INFO 139866244298560] Epoch[19] Batch [125]#011Speed: 599.06 samples/sec#011loss=2.590619\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:43 INFO 139866244298560] Epoch[19] Batch[130] avg_epoch_loss=2.637284\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=130 train loss <loss>=2.61257147789\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:43 INFO 139866244298560] Epoch[19] Batch [130]#011Speed: 480.52 samples/sec#011loss=2.612571\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:43 INFO 139866244298560] Epoch[19] Batch[135] avg_epoch_loss=2.624722\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=135 train loss <loss>=2.29560422897\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:43 INFO 139866244298560] Epoch[19] Batch [135]#011Speed: 543.54 samples/sec#011loss=2.295604\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:44 INFO 139866244298560] Epoch[19] Batch[140] avg_epoch_loss=2.634227\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=140 train loss <loss>=2.89274983406\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:44 INFO 139866244298560] Epoch[19] Batch [140]#011Speed: 472.19 samples/sec#011loss=2.892750\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:44 INFO 139866244298560] Epoch[19] Batch[145] avg_epoch_loss=2.646263\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=145 train loss <loss>=2.98567996025\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:44 INFO 139866244298560] Epoch[19] Batch [145]#011Speed: 593.00 samples/sec#011loss=2.985680\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:45 INFO 139866244298560] Epoch[19] Batch[150] avg_epoch_loss=2.653147\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=150 train loss <loss>=2.85415897369\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:45 INFO 139866244298560] Epoch[19] Batch [150]#011Speed: 425.31 samples/sec#011loss=2.854159\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:46 INFO 139866244298560] Epoch[19] Batch[155] avg_epoch_loss=2.672278\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=155 train loss <loss>=3.25005259514\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:46 INFO 139866244298560] Epoch[19] Batch [155]#011Speed: 592.11 samples/sec#011loss=3.250053\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:46 INFO 139866244298560] Epoch[19] Batch[160] avg_epoch_loss=2.676810\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=160 train loss <loss>=2.81820969582\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:46 INFO 139866244298560] Epoch[19] Batch [160]#011Speed: 476.14 samples/sec#011loss=2.818210\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:47 INFO 139866244298560] Epoch[19] Batch[165] avg_epoch_loss=2.677539\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=165 train loss <loss>=2.70100259781\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:47 INFO 139866244298560] Epoch[19] Batch [165]#011Speed: 580.20 samples/sec#011loss=2.701003\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:48 INFO 139866244298560] Epoch[19] Batch[170] avg_epoch_loss=2.665099\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=170 train loss <loss>=2.25209000111\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:48 INFO 139866244298560] Epoch[19] Batch [170]#011Speed: 481.32 samples/sec#011loss=2.252090\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:48 INFO 139866244298560] Epoch[19] Batch[175] avg_epoch_loss=2.655244\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=175 train loss <loss>=2.3181940794\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:48 INFO 139866244298560] Epoch[19] Batch [175]#011Speed: 594.23 samples/sec#011loss=2.318194\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:49 INFO 139866244298560] Epoch[19] Batch[180] avg_epoch_loss=2.657463\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=180 train loss <loss>=2.73558216095\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:49 INFO 139866244298560] Epoch[19] Batch [180]#011Speed: 474.03 samples/sec#011loss=2.735582\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:49 INFO 139866244298560] Epoch[19] Batch[185] avg_epoch_loss=2.656814\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=185 train loss <loss>=2.63330874443\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:49 INFO 139866244298560] Epoch[19] Batch [185]#011Speed: 587.48 samples/sec#011loss=2.633309\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:50 INFO 139866244298560] Epoch[19] Batch[190] avg_epoch_loss=2.657899\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=190 train loss <loss>=2.69827623367\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:50 INFO 139866244298560] Epoch[19] Batch [190]#011Speed: 438.45 samples/sec#011loss=2.698276\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:51 INFO 139866244298560] Epoch[19] Batch[195] avg_epoch_loss=2.657089\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=195 train loss <loss>=2.6261557579\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:51 INFO 139866244298560] Epoch[19] Batch [195]#011Speed: 470.61 samples/sec#011loss=2.626156\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:51 INFO 139866244298560] Epoch[19] Batch[200] avg_epoch_loss=2.682203\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=200 train loss <loss>=3.66664376259\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:51 INFO 139866244298560] Epoch[19] Batch [200]#011Speed: 596.41 samples/sec#011loss=3.666644\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:52 INFO 139866244298560] Epoch[19] Batch[205] avg_epoch_loss=2.698134\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=205 train loss <loss>=3.338585186\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:52 INFO 139866244298560] Epoch[19] Batch [205]#011Speed: 469.82 samples/sec#011loss=3.338585\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:53 INFO 139866244298560] Epoch[19] Batch[210] avg_epoch_loss=2.716166\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=210 train loss <loss>=3.45905809402\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:53 INFO 139866244298560] Epoch[19] Batch [210]#011Speed: 581.12 samples/sec#011loss=3.459058\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:53 INFO 139866244298560] Epoch[19] Batch[215] avg_epoch_loss=2.725229\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=215 train loss <loss>=3.10772066116\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:53 INFO 139866244298560] Epoch[19] Batch [215]#011Speed: 483.31 samples/sec#011loss=3.107721\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:54 INFO 139866244298560] Epoch[19] Batch[220] avg_epoch_loss=2.714905\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=220 train loss <loss>=2.2689050436\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:54 INFO 139866244298560] Epoch[19] Batch [220]#011Speed: 599.76 samples/sec#011loss=2.268905\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:54 INFO 139866244298560] Epoch[19] Batch[225] avg_epoch_loss=2.710462\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=225 train loss <loss>=2.51407084465\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:54 INFO 139866244298560] Epoch[19] Batch [225]#011Speed: 468.64 samples/sec#011loss=2.514071\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:55 INFO 139866244298560] Epoch[19] Batch[230] avg_epoch_loss=2.709217\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=230 train loss <loss>=2.65294494629\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:55 INFO 139866244298560] Epoch[19] Batch [230]#011Speed: 539.01 samples/sec#011loss=2.652945\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:56 INFO 139866244298560] Epoch[19] Batch[235] avg_epoch_loss=2.703630\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=235 train loss <loss>=2.4455010891\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:56 INFO 139866244298560] Epoch[19] Batch [235]#011Speed: 480.35 samples/sec#011loss=2.445501\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:56 INFO 139866244298560] Epoch[19] Batch[240] avg_epoch_loss=2.703369\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=240 train loss <loss>=2.69105372429\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:56 INFO 139866244298560] Epoch[19] Batch [240]#011Speed: 593.76 samples/sec#011loss=2.691054\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:57 INFO 139866244298560] Epoch[19] Batch[245] avg_epoch_loss=2.705165\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=245 train loss <loss>=2.79171681404\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:57 INFO 139866244298560] Epoch[19] Batch [245]#011Speed: 472.05 samples/sec#011loss=2.791717\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:57 INFO 139866244298560] Epoch[19] Batch[250] avg_epoch_loss=2.708100\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=250 train loss <loss>=2.85251684189\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:57 INFO 139866244298560] Epoch[19] Batch [250]#011Speed: 591.47 samples/sec#011loss=2.852517\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:58 INFO 139866244298560] Epoch[19] Batch[255] avg_epoch_loss=2.722050\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=255 train loss <loss>=3.42236537933\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:58 INFO 139866244298560] Epoch[19] Batch [255]#011Speed: 472.71 samples/sec#011loss=3.422365\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:59 INFO 139866244298560] Epoch[19] Batch[260] avg_epoch_loss=2.733462\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=260 train loss <loss>=3.31773586273\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:59 INFO 139866244298560] Epoch[19] Batch [260]#011Speed: 598.26 samples/sec#011loss=3.317736\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:59 INFO 139866244298560] Epoch[19] Batch[265] avg_epoch_loss=2.744845\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=265 train loss <loss>=3.33903188705\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:36:59 INFO 139866244298560] Epoch[19] Batch [265]#011Speed: 487.49 samples/sec#011loss=3.339032\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:00 INFO 139866244298560] Epoch[19] Batch[270] avg_epoch_loss=2.752313\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, batch=270 train loss <loss>=3.14958910942\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:00 INFO 139866244298560] Epoch[19] Batch [270]#011Speed: 592.41 samples/sec#011loss=3.149589\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:00 INFO 139866244298560] processed a total of 17387 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33663.50698471069, \"sum\": 33663.50698471069, \"min\": 33663.50698471069}}, \"EndTime\": 1599442620.423922, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442586.759805}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:00 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=516.490828746 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:00 INFO 139866244298560] #progress_metric: host=algo-1, completed 25 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=19, train loss <loss>=2.74999416883\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:00 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:00 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_208a0437-f74a-4503-8204-0b021698c92f-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.947912216186523, \"sum\": 17.947912216186523, \"min\": 17.947912216186523}}, \"EndTime\": 1599442620.442701, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442620.424084}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:00 INFO 139866244298560] Epoch[20] Batch[0] avg_epoch_loss=2.574623\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=0 train loss <loss>=2.57462310791\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:01 INFO 139866244298560] Epoch[20] Batch[5] avg_epoch_loss=2.244305\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=5 train loss <loss>=2.24430521329\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:01 INFO 139866244298560] Epoch[20] Batch [5]#011Speed: 594.85 samples/sec#011loss=2.244305\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:01 INFO 139866244298560] Epoch[20] Batch[10] avg_epoch_loss=2.265168\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=10 train loss <loss>=2.29020256996\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:01 INFO 139866244298560] Epoch[20] Batch [10]#011Speed: 461.38 samples/sec#011loss=2.290203\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:02 INFO 139866244298560] Epoch[20] Batch[15] avg_epoch_loss=2.447686\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=15 train loss <loss>=2.84922537804\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:02 INFO 139866244298560] Epoch[20] Batch [15]#011Speed: 582.59 samples/sec#011loss=2.849225\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:03 INFO 139866244298560] Epoch[20] Batch[20] avg_epoch_loss=2.552462\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=20 train loss <loss>=2.88774738312\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:03 INFO 139866244298560] Epoch[20] Batch [20]#011Speed: 479.01 samples/sec#011loss=2.887747\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:03 INFO 139866244298560] Epoch[20] Batch[25] avg_epoch_loss=2.602875\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=25 train loss <loss>=2.81460690498\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:03 INFO 139866244298560] Epoch[20] Batch [25]#011Speed: 590.58 samples/sec#011loss=2.814607\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:04 INFO 139866244298560] Epoch[20] Batch[30] avg_epoch_loss=2.562304\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=30 train loss <loss>=2.35133810043\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:04 INFO 139866244298560] Epoch[20] Batch [30]#011Speed: 481.10 samples/sec#011loss=2.351338\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:04 INFO 139866244298560] Epoch[20] Batch[35] avg_epoch_loss=2.556209\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=35 train loss <loss>=2.51841893196\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:04 INFO 139866244298560] Epoch[20] Batch [35]#011Speed: 590.38 samples/sec#011loss=2.518419\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:05 INFO 139866244298560] Epoch[20] Batch[40] avg_epoch_loss=2.555258\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=40 train loss <loss>=2.54841194153\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:05 INFO 139866244298560] Epoch[20] Batch [40]#011Speed: 456.50 samples/sec#011loss=2.548412\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:06 INFO 139866244298560] Epoch[20] Batch[45] avg_epoch_loss=2.536211\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=45 train loss <loss>=2.38002285957\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:06 INFO 139866244298560] Epoch[20] Batch [45]#011Speed: 575.82 samples/sec#011loss=2.380023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:06 INFO 139866244298560] Epoch[20] Batch[50] avg_epoch_loss=2.500604\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=50 train loss <loss>=2.17302184105\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:06 INFO 139866244298560] Epoch[20] Batch [50]#011Speed: 467.28 samples/sec#011loss=2.173022\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:07 INFO 139866244298560] Epoch[20] Batch[55] avg_epoch_loss=2.510469\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=55 train loss <loss>=2.61109509468\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:07 INFO 139866244298560] Epoch[20] Batch [55]#011Speed: 586.99 samples/sec#011loss=2.611095\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:08 INFO 139866244298560] Epoch[20] Batch[60] avg_epoch_loss=2.544748\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=60 train loss <loss>=2.92866644859\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:08 INFO 139866244298560] Epoch[20] Batch [60]#011Speed: 483.25 samples/sec#011loss=2.928666\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:08 INFO 139866244298560] Epoch[20] Batch[65] avg_epoch_loss=2.555829\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=65 train loss <loss>=2.69101610184\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:08 INFO 139866244298560] Epoch[20] Batch [65]#011Speed: 593.64 samples/sec#011loss=2.691016\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:09 INFO 139866244298560] Epoch[20] Batch[70] avg_epoch_loss=2.610102\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=70 train loss <loss>=3.32650899887\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:09 INFO 139866244298560] Epoch[20] Batch [70]#011Speed: 488.47 samples/sec#011loss=3.326509\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:09 INFO 139866244298560] Epoch[20] Batch[75] avg_epoch_loss=2.658349\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=75 train loss <loss>=3.34345412254\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:09 INFO 139866244298560] Epoch[20] Batch [75]#011Speed: 479.71 samples/sec#011loss=3.343454\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:10 INFO 139866244298560] Epoch[20] Batch[80] avg_epoch_loss=2.678537\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=80 train loss <loss>=2.98540143967\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:10 INFO 139866244298560] Epoch[20] Batch [80]#011Speed: 591.30 samples/sec#011loss=2.985401\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:11 INFO 139866244298560] Epoch[20] Batch[85] avg_epoch_loss=2.688702\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=85 train loss <loss>=2.85336976051\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:11 INFO 139866244298560] Epoch[20] Batch [85]#011Speed: 445.33 samples/sec#011loss=2.853370\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:11 INFO 139866244298560] Epoch[20] Batch[90] avg_epoch_loss=2.677524\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=90 train loss <loss>=2.48526473045\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:11 INFO 139866244298560] Epoch[20] Batch [90]#011Speed: 593.80 samples/sec#011loss=2.485265\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:12 INFO 139866244298560] Epoch[20] Batch[95] avg_epoch_loss=2.656077\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=95 train loss <loss>=2.26574778557\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:12 INFO 139866244298560] Epoch[20] Batch [95]#011Speed: 471.98 samples/sec#011loss=2.265748\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:12 INFO 139866244298560] Epoch[20] Batch[100] avg_epoch_loss=2.648648\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=100 train loss <loss>=2.50599858761\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:12 INFO 139866244298560] Epoch[20] Batch [100]#011Speed: 592.88 samples/sec#011loss=2.505999\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:13 INFO 139866244298560] Epoch[20] Batch[105] avg_epoch_loss=2.636589\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=105 train loss <loss>=2.39299807549\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:13 INFO 139866244298560] Epoch[20] Batch [105]#011Speed: 482.42 samples/sec#011loss=2.392998\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:14 INFO 139866244298560] Epoch[20] Batch[110] avg_epoch_loss=2.628747\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=110 train loss <loss>=2.46250441074\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:14 INFO 139866244298560] Epoch[20] Batch [110]#011Speed: 538.06 samples/sec#011loss=2.462504\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:14 INFO 139866244298560] Epoch[20] Batch[115] avg_epoch_loss=2.640062\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=115 train loss <loss>=2.89125351906\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:14 INFO 139866244298560] Epoch[20] Batch [115]#011Speed: 473.35 samples/sec#011loss=2.891254\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:15 INFO 139866244298560] Epoch[20] Batch[120] avg_epoch_loss=2.653978\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=120 train loss <loss>=2.97681765556\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:15 INFO 139866244298560] Epoch[20] Batch [120]#011Speed: 587.09 samples/sec#011loss=2.976818\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:16 INFO 139866244298560] Epoch[20] Batch[125] avg_epoch_loss=2.672132\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=125 train loss <loss>=3.11146764755\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:16 INFO 139866244298560] Epoch[20] Batch [125]#011Speed: 449.06 samples/sec#011loss=3.111468\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:16 INFO 139866244298560] Epoch[20] Batch[130] avg_epoch_loss=2.688464\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=130 train loss <loss>=3.10003824234\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:16 INFO 139866244298560] Epoch[20] Batch [130]#011Speed: 596.08 samples/sec#011loss=3.100038\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:17 INFO 139866244298560] Epoch[20] Batch[135] avg_epoch_loss=2.679807\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=135 train loss <loss>=2.45298266411\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:17 INFO 139866244298560] Epoch[20] Batch [135]#011Speed: 478.63 samples/sec#011loss=2.452983\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:18 INFO 139866244298560] Epoch[20] Batch[140] avg_epoch_loss=2.667520\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=140 train loss <loss>=2.33330893517\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:18 INFO 139866244298560] Epoch[20] Batch [140]#011Speed: 472.47 samples/sec#011loss=2.333309\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:18 INFO 139866244298560] Epoch[20] Batch[145] avg_epoch_loss=2.651484\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=145 train loss <loss>=2.19926662445\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:18 INFO 139866244298560] Epoch[20] Batch [145]#011Speed: 594.08 samples/sec#011loss=2.199267\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:19 INFO 139866244298560] Epoch[20] Batch[150] avg_epoch_loss=2.638126\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=150 train loss <loss>=2.24806776047\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:19 INFO 139866244298560] Epoch[20] Batch [150]#011Speed: 473.44 samples/sec#011loss=2.248068\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:19 INFO 139866244298560] Epoch[20] Batch[155] avg_epoch_loss=2.638823\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=155 train loss <loss>=2.65990228653\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:19 INFO 139866244298560] Epoch[20] Batch [155]#011Speed: 586.56 samples/sec#011loss=2.659902\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:20 INFO 139866244298560] Epoch[20] Batch[160] avg_epoch_loss=2.635618\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=160 train loss <loss>=2.53559393883\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:20 INFO 139866244298560] Epoch[20] Batch [160]#011Speed: 473.06 samples/sec#011loss=2.535594\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:21 INFO 139866244298560] Epoch[20] Batch[165] avg_epoch_loss=2.639832\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=165 train loss <loss>=2.77554140091\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:21 INFO 139866244298560] Epoch[20] Batch [165]#011Speed: 527.03 samples/sec#011loss=2.775541\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:21 INFO 139866244298560] Epoch[20] Batch[170] avg_epoch_loss=2.653023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=170 train loss <loss>=3.09094905853\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:21 INFO 139866244298560] Epoch[20] Batch [170]#011Speed: 477.03 samples/sec#011loss=3.090949\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:22 INFO 139866244298560] Epoch[20] Batch[175] avg_epoch_loss=2.676951\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=175 train loss <loss>=3.49529123306\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:22 INFO 139866244298560] Epoch[20] Batch [175]#011Speed: 587.82 samples/sec#011loss=3.495291\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:22 INFO 139866244298560] Epoch[20] Batch[180] avg_epoch_loss=2.696003\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=180 train loss <loss>=3.36665549278\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:22 INFO 139866244298560] Epoch[20] Batch [180]#011Speed: 479.55 samples/sec#011loss=3.366655\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:23 INFO 139866244298560] Epoch[20] Batch[185] avg_epoch_loss=2.709078\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=185 train loss <loss>=3.18236293793\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:23 INFO 139866244298560] Epoch[20] Batch [185]#011Speed: 591.08 samples/sec#011loss=3.182363\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:24 INFO 139866244298560] Epoch[20] Batch[190] avg_epoch_loss=2.712779\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=190 train loss <loss>=2.85047974586\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:24 INFO 139866244298560] Epoch[20] Batch [190]#011Speed: 483.55 samples/sec#011loss=2.850480\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:24 INFO 139866244298560] Epoch[20] Batch[195] avg_epoch_loss=2.710674\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=195 train loss <loss>=2.63025813103\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:24 INFO 139866244298560] Epoch[20] Batch [195]#011Speed: 588.25 samples/sec#011loss=2.630258\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:25 INFO 139866244298560] Epoch[20] Batch[200] avg_epoch_loss=2.713042\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=200 train loss <loss>=2.80586185455\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:25 INFO 139866244298560] Epoch[20] Batch [200]#011Speed: 467.34 samples/sec#011loss=2.805862\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:25 INFO 139866244298560] Epoch[20] Batch[205] avg_epoch_loss=2.717258\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=205 train loss <loss>=2.88672924042\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:25 INFO 139866244298560] Epoch[20] Batch [205]#011Speed: 584.34 samples/sec#011loss=2.886729\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:26 INFO 139866244298560] Epoch[20] Batch[210] avg_epoch_loss=2.721660\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=210 train loss <loss>=2.90303583145\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:26 INFO 139866244298560] Epoch[20] Batch [210]#011Speed: 439.55 samples/sec#011loss=2.903036\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:27 INFO 139866244298560] Epoch[20] Batch[215] avg_epoch_loss=2.713291\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=215 train loss <loss>=2.36011776924\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:27 INFO 139866244298560] Epoch[20] Batch [215]#011Speed: 582.73 samples/sec#011loss=2.360118\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:27 INFO 139866244298560] Epoch[20] Batch[220] avg_epoch_loss=2.716873\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=220 train loss <loss>=2.87162070274\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:27 INFO 139866244298560] Epoch[20] Batch [220]#011Speed: 476.81 samples/sec#011loss=2.871621\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:28 INFO 139866244298560] Epoch[20] Batch[225] avg_epoch_loss=2.719111\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=225 train loss <loss>=2.81804056168\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:28 INFO 139866244298560] Epoch[20] Batch [225]#011Speed: 594.94 samples/sec#011loss=2.818041\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:29 INFO 139866244298560] Epoch[20] Batch[230] avg_epoch_loss=2.733192\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=230 train loss <loss>=3.36964049339\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:29 INFO 139866244298560] Epoch[20] Batch [230]#011Speed: 477.77 samples/sec#011loss=3.369640\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:29 INFO 139866244298560] Epoch[20] Batch[235] avg_epoch_loss=2.746824\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=235 train loss <loss>=3.37661476135\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:29 INFO 139866244298560] Epoch[20] Batch [235]#011Speed: 594.07 samples/sec#011loss=3.376615\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:30 INFO 139866244298560] Epoch[20] Batch[240] avg_epoch_loss=2.761713\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=240 train loss <loss>=3.4644780159\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:30 INFO 139866244298560] Epoch[20] Batch [240]#011Speed: 474.15 samples/sec#011loss=3.464478\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:30 INFO 139866244298560] Epoch[20] Batch[245] avg_epoch_loss=2.778082\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=245 train loss <loss>=3.56708669662\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:30 INFO 139866244298560] Epoch[20] Batch [245]#011Speed: 595.48 samples/sec#011loss=3.567087\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:31 INFO 139866244298560] Epoch[20] Batch[250] avg_epoch_loss=2.781946\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=250 train loss <loss>=2.97202281952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:31 INFO 139866244298560] Epoch[20] Batch [250]#011Speed: 442.88 samples/sec#011loss=2.972023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:32 INFO 139866244298560] Epoch[20] Batch[255] avg_epoch_loss=2.782299\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=255 train loss <loss>=2.80006065369\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:32 INFO 139866244298560] Epoch[20] Batch [255]#011Speed: 595.56 samples/sec#011loss=2.800061\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:32 INFO 139866244298560] Epoch[20] Batch[260] avg_epoch_loss=2.778377\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=260 train loss <loss>=2.57754559517\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:32 INFO 139866244298560] Epoch[20] Batch [260]#011Speed: 473.46 samples/sec#011loss=2.577546\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:33 INFO 139866244298560] Epoch[20] Batch[265] avg_epoch_loss=2.770728\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, batch=265 train loss <loss>=2.37144780159\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:33 INFO 139866244298560] Epoch[20] Batch [265]#011Speed: 594.87 samples/sec#011loss=2.371448\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:33 INFO 139866244298560] processed a total of 17208 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33246.522188186646, \"sum\": 33246.522188186646, \"min\": 33246.522188186646}}, \"EndTime\": 1599442653.68934, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442620.442758}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:33 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=517.586402074 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:33 INFO 139866244298560] #progress_metric: host=algo-1, completed 26 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=20, train loss <loss>=2.78273989809\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:33 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:33 INFO 139866244298560] Epoch[21] Batch[0] avg_epoch_loss=2.026177\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=0 train loss <loss>=2.02617740631\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:34 INFO 139866244298560] Epoch[21] Batch[5] avg_epoch_loss=2.215453\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=5 train loss <loss>=2.21545298894\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:34 INFO 139866244298560] Epoch[21] Batch [5]#011Speed: 592.23 samples/sec#011loss=2.215453\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:35 INFO 139866244298560] Epoch[21] Batch[10] avg_epoch_loss=2.272658\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=10 train loss <loss>=2.34130420685\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:35 INFO 139866244298560] Epoch[21] Batch [10]#011Speed: 472.64 samples/sec#011loss=2.341304\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:35 INFO 139866244298560] Epoch[21] Batch[15] avg_epoch_loss=2.470113\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=15 train loss <loss>=2.90451440811\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:35 INFO 139866244298560] Epoch[21] Batch [15]#011Speed: 589.19 samples/sec#011loss=2.904514\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:36 INFO 139866244298560] Epoch[21] Batch[20] avg_epoch_loss=2.543483\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=20 train loss <loss>=2.77826666832\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:36 INFO 139866244298560] Epoch[21] Batch [20]#011Speed: 441.16 samples/sec#011loss=2.778267\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:36 INFO 139866244298560] Epoch[21] Batch[25] avg_epoch_loss=2.585111\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=25 train loss <loss>=2.75994720459\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:36 INFO 139866244298560] Epoch[21] Batch [25]#011Speed: 582.35 samples/sec#011loss=2.759947\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:37 INFO 139866244298560] Epoch[21] Batch[30] avg_epoch_loss=2.603841\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=30 train loss <loss>=2.70123672485\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:37 INFO 139866244298560] Epoch[21] Batch [30]#011Speed: 456.85 samples/sec#011loss=2.701237\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:38 INFO 139866244298560] Epoch[21] Batch[35] avg_epoch_loss=2.580817\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=35 train loss <loss>=2.43807091713\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:38 INFO 139866244298560] Epoch[21] Batch [35]#011Speed: 596.58 samples/sec#011loss=2.438071\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:38 INFO 139866244298560] Epoch[21] Batch[40] avg_epoch_loss=2.567306\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=40 train loss <loss>=2.47002472878\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:38 INFO 139866244298560] Epoch[21] Batch [40]#011Speed: 472.95 samples/sec#011loss=2.470025\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:39 INFO 139866244298560] Epoch[21] Batch[45] avg_epoch_loss=2.571314\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=45 train loss <loss>=2.60418438911\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:39 INFO 139866244298560] Epoch[21] Batch [45]#011Speed: 594.45 samples/sec#011loss=2.604184\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:40 INFO 139866244298560] Epoch[21] Batch[50] avg_epoch_loss=2.548927\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=50 train loss <loss>=2.34296422005\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:40 INFO 139866244298560] Epoch[21] Batch [50]#011Speed: 470.91 samples/sec#011loss=2.342964\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:40 INFO 139866244298560] Epoch[21] Batch[55] avg_epoch_loss=2.527225\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=55 train loss <loss>=2.30586779118\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:40 INFO 139866244298560] Epoch[21] Batch [55]#011Speed: 598.63 samples/sec#011loss=2.305868\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:41 INFO 139866244298560] Epoch[21] Batch[60] avg_epoch_loss=2.520296\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=60 train loss <loss>=2.44268522263\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:41 INFO 139866244298560] Epoch[21] Batch [60]#011Speed: 473.50 samples/sec#011loss=2.442685\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:41 INFO 139866244298560] Epoch[21] Batch[65] avg_epoch_loss=2.515422\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=65 train loss <loss>=2.4559627533\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:41 INFO 139866244298560] Epoch[21] Batch [65]#011Speed: 568.20 samples/sec#011loss=2.455963\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:42 INFO 139866244298560] Epoch[21] Batch[70] avg_epoch_loss=2.523111\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=70 train loss <loss>=2.62460951805\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:42 INFO 139866244298560] Epoch[21] Batch [70]#011Speed: 477.29 samples/sec#011loss=2.624610\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:43 INFO 139866244298560] Epoch[21] Batch[75] avg_epoch_loss=2.541037\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=75 train loss <loss>=2.79558653831\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:43 INFO 139866244298560] Epoch[21] Batch [75]#011Speed: 566.56 samples/sec#011loss=2.795587\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:43 INFO 139866244298560] Epoch[21] Batch[80] avg_epoch_loss=2.571125\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=80 train loss <loss>=3.02846226692\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:43 INFO 139866244298560] Epoch[21] Batch [80]#011Speed: 474.61 samples/sec#011loss=3.028462\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:44 INFO 139866244298560] Epoch[21] Batch[85] avg_epoch_loss=2.619980\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=85 train loss <loss>=3.41143012047\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:44 INFO 139866244298560] Epoch[21] Batch [85]#011Speed: 540.83 samples/sec#011loss=3.411430\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:45 INFO 139866244298560] Epoch[21] Batch[90] avg_epoch_loss=2.656571\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=90 train loss <loss>=3.28593130112\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:45 INFO 139866244298560] Epoch[21] Batch [90]#011Speed: 474.25 samples/sec#011loss=3.285931\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:45 INFO 139866244298560] Epoch[21] Batch[95] avg_epoch_loss=2.678985\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=95 train loss <loss>=3.08691315651\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:45 INFO 139866244298560] Epoch[21] Batch [95]#011Speed: 596.92 samples/sec#011loss=3.086913\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:46 INFO 139866244298560] Epoch[21] Batch[100] avg_epoch_loss=2.679309\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=100 train loss <loss>=2.68553218842\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:46 INFO 139866244298560] Epoch[21] Batch [100]#011Speed: 484.40 samples/sec#011loss=2.685532\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:46 INFO 139866244298560] Epoch[21] Batch[105] avg_epoch_loss=2.666720\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=105 train loss <loss>=2.41243267059\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:46 INFO 139866244298560] Epoch[21] Batch [105]#011Speed: 552.16 samples/sec#011loss=2.412433\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:47 INFO 139866244298560] Epoch[21] Batch[110] avg_epoch_loss=2.644105\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=110 train loss <loss>=2.16465981007\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:47 INFO 139866244298560] Epoch[21] Batch [110]#011Speed: 475.73 samples/sec#011loss=2.164660\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:48 INFO 139866244298560] Epoch[21] Batch[115] avg_epoch_loss=2.629432\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=115 train loss <loss>=2.30368266106\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:48 INFO 139866244298560] Epoch[21] Batch [115]#011Speed: 582.70 samples/sec#011loss=2.303683\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:48 INFO 139866244298560] Epoch[21] Batch[120] avg_epoch_loss=2.622073\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=120 train loss <loss>=2.45134887695\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:48 INFO 139866244298560] Epoch[21] Batch [120]#011Speed: 477.15 samples/sec#011loss=2.451349\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:49 INFO 139866244298560] Epoch[21] Batch[125] avg_epoch_loss=2.620804\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=125 train loss <loss>=2.59009151459\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:49 INFO 139866244298560] Epoch[21] Batch [125]#011Speed: 596.03 samples/sec#011loss=2.590092\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:49 INFO 139866244298560] Epoch[21] Batch[130] avg_epoch_loss=2.632606\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=130 train loss <loss>=2.93003196716\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:49 INFO 139866244298560] Epoch[21] Batch [130]#011Speed: 482.20 samples/sec#011loss=2.930032\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:50 INFO 139866244298560] Epoch[21] Batch[135] avg_epoch_loss=2.634631\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=135 train loss <loss>=2.68768367767\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:50 INFO 139866244298560] Epoch[21] Batch [135]#011Speed: 590.62 samples/sec#011loss=2.687684\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:51 INFO 139866244298560] Epoch[21] Batch[140] avg_epoch_loss=2.653873\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=140 train loss <loss>=3.17724504471\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:51 INFO 139866244298560] Epoch[21] Batch [140]#011Speed: 473.25 samples/sec#011loss=3.177245\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:51 INFO 139866244298560] Epoch[21] Batch[145] avg_epoch_loss=2.669710\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=145 train loss <loss>=3.11631684303\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:51 INFO 139866244298560] Epoch[21] Batch [145]#011Speed: 554.46 samples/sec#011loss=3.116317\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:52 INFO 139866244298560] Epoch[21] Batch[150] avg_epoch_loss=2.669024\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=150 train loss <loss>=2.64899053574\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:52 INFO 139866244298560] Epoch[21] Batch [150]#011Speed: 477.34 samples/sec#011loss=2.648991\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:53 INFO 139866244298560] Epoch[21] Batch[155] avg_epoch_loss=2.670947\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=155 train loss <loss>=2.72903571129\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:53 INFO 139866244298560] Epoch[21] Batch [155]#011Speed: 469.46 samples/sec#011loss=2.729036\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:53 INFO 139866244298560] Epoch[21] Batch[160] avg_epoch_loss=2.661639\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=160 train loss <loss>=2.37123236656\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:53 INFO 139866244298560] Epoch[21] Batch [160]#011Speed: 593.00 samples/sec#011loss=2.371232\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:54 INFO 139866244298560] Epoch[21] Batch[165] avg_epoch_loss=2.653234\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=165 train loss <loss>=2.38257989883\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:54 INFO 139866244298560] Epoch[21] Batch [165]#011Speed: 472.55 samples/sec#011loss=2.382580\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:54 INFO 139866244298560] Epoch[21] Batch[170] avg_epoch_loss=2.649139\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=170 train loss <loss>=2.51318645477\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:54 INFO 139866244298560] Epoch[21] Batch [170]#011Speed: 593.73 samples/sec#011loss=2.513186\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:55 INFO 139866244298560] Epoch[21] Batch[175] avg_epoch_loss=2.644865\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=175 train loss <loss>=2.49867491722\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:55 INFO 139866244298560] Epoch[21] Batch [175]#011Speed: 474.00 samples/sec#011loss=2.498675\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:56 INFO 139866244298560] Epoch[21] Batch[180] avg_epoch_loss=2.639108\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=180 train loss <loss>=2.43647480011\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:56 INFO 139866244298560] Epoch[21] Batch [180]#011Speed: 598.93 samples/sec#011loss=2.436475\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:56 INFO 139866244298560] Epoch[21] Batch[185] avg_epoch_loss=2.650257\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=185 train loss <loss>=3.05384101868\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:56 INFO 139866244298560] Epoch[21] Batch [185]#011Speed: 484.77 samples/sec#011loss=3.053841\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:57 INFO 139866244298560] Epoch[21] Batch[190] avg_epoch_loss=2.666012\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=190 train loss <loss>=3.25212750435\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:57 INFO 139866244298560] Epoch[21] Batch [190]#011Speed: 538.91 samples/sec#011loss=3.252128\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:57 INFO 139866244298560] Epoch[21] Batch[195] avg_epoch_loss=2.688511\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=195 train loss <loss>=3.54795861244\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:57 INFO 139866244298560] Epoch[21] Batch [195]#011Speed: 475.61 samples/sec#011loss=3.547959\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:58 INFO 139866244298560] Epoch[21] Batch[200] avg_epoch_loss=2.705319\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=200 train loss <loss>=3.36417140961\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:58 INFO 139866244298560] Epoch[21] Batch [200]#011Speed: 592.36 samples/sec#011loss=3.364171\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:59 INFO 139866244298560] Epoch[21] Batch[205] avg_epoch_loss=2.710973\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=205 train loss <loss>=2.93826732635\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:59 INFO 139866244298560] Epoch[21] Batch [205]#011Speed: 481.68 samples/sec#011loss=2.938267\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:59 INFO 139866244298560] Epoch[21] Batch[210] avg_epoch_loss=2.716246\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=210 train loss <loss>=2.93350772858\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:37:59 INFO 139866244298560] Epoch[21] Batch [210]#011Speed: 587.60 samples/sec#011loss=2.933508\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:00 INFO 139866244298560] Epoch[21] Batch[215] avg_epoch_loss=2.715247\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=215 train loss <loss>=2.67307844162\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:00 INFO 139866244298560] Epoch[21] Batch [215]#011Speed: 471.89 samples/sec#011loss=2.673078\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:00 INFO 139866244298560] Epoch[21] Batch[220] avg_epoch_loss=2.709359\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=220 train loss <loss>=2.45501418114\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:00 INFO 139866244298560] Epoch[21] Batch [220]#011Speed: 598.89 samples/sec#011loss=2.455014\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:01 INFO 139866244298560] Epoch[21] Batch[225] avg_epoch_loss=2.710212\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=225 train loss <loss>=2.74789266586\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:01 INFO 139866244298560] Epoch[21] Batch [225]#011Speed: 483.74 samples/sec#011loss=2.747893\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:02 INFO 139866244298560] Epoch[21] Batch[230] avg_epoch_loss=2.704263\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=230 train loss <loss>=2.43536920547\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:02 INFO 139866244298560] Epoch[21] Batch [230]#011Speed: 436.04 samples/sec#011loss=2.435369\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:03 INFO 139866244298560] Epoch[21] Batch[235] avg_epoch_loss=2.708991\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=235 train loss <loss>=2.92743039131\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:03 INFO 139866244298560] Epoch[21] Batch [235]#011Speed: 320.17 samples/sec#011loss=2.927430\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:04 INFO 139866244298560] Epoch[21] Batch[240] avg_epoch_loss=2.713855\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=240 train loss <loss>=2.94343643188\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:04 INFO 139866244298560] Epoch[21] Batch [240]#011Speed: 329.40 samples/sec#011loss=2.943436\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:05 INFO 139866244298560] Epoch[21] Batch[245] avg_epoch_loss=2.738104\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=245 train loss <loss>=3.90692667961\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:05 INFO 139866244298560] Epoch[21] Batch [245]#011Speed: 413.74 samples/sec#011loss=3.906927\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:05 INFO 139866244298560] Epoch[21] Batch[250] avg_epoch_loss=2.752334\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=250 train loss <loss>=3.45244603157\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:05 INFO 139866244298560] Epoch[21] Batch [250]#011Speed: 472.07 samples/sec#011loss=3.452446\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:06 INFO 139866244298560] Epoch[21] Batch[255] avg_epoch_loss=2.758476\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=255 train loss <loss>=3.06681203842\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:06 INFO 139866244298560] Epoch[21] Batch [255]#011Speed: 590.49 samples/sec#011loss=3.066812\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:06 INFO 139866244298560] Epoch[21] Batch[260] avg_epoch_loss=2.762935\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=260 train loss <loss>=2.99123911858\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:06 INFO 139866244298560] Epoch[21] Batch [260]#011Speed: 461.03 samples/sec#011loss=2.991239\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:07 INFO 139866244298560] Epoch[21] Batch[265] avg_epoch_loss=2.763294\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, batch=265 train loss <loss>=2.78204131126\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:07 INFO 139866244298560] Epoch[21] Batch [265]#011Speed: 536.02 samples/sec#011loss=2.782041\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:08 INFO 139866244298560] processed a total of 17252 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 34341.98307991028, \"sum\": 34341.98307991028, \"min\": 34341.98307991028}}, \"EndTime\": 1599442688.032032, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442653.689405}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:08 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=502.357295543 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:08 INFO 139866244298560] #progress_metric: host=algo-1, completed 27 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=21, train loss <loss>=2.76619215718\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:08 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:08 INFO 139866244298560] Epoch[22] Batch[0] avg_epoch_loss=2.457651\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=0 train loss <loss>=2.45765066147\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:08 INFO 139866244298560] Epoch[22] Batch[5] avg_epoch_loss=2.153634\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=5 train loss <loss>=2.15363381306\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:08 INFO 139866244298560] Epoch[22] Batch [5]#011Speed: 590.71 samples/sec#011loss=2.153634\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:09 INFO 139866244298560] Epoch[22] Batch[10] avg_epoch_loss=2.267132\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=10 train loss <loss>=2.40332899094\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:09 INFO 139866244298560] Epoch[22] Batch [10]#011Speed: 473.38 samples/sec#011loss=2.403329\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:10 INFO 139866244298560] Epoch[22] Batch[15] avg_epoch_loss=2.443888\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=15 train loss <loss>=2.83275094032\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:10 INFO 139866244298560] Epoch[22] Batch [15]#011Speed: 592.80 samples/sec#011loss=2.832751\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:10 INFO 139866244298560] Epoch[22] Batch[20] avg_epoch_loss=2.530129\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=20 train loss <loss>=2.8060997963\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:10 INFO 139866244298560] Epoch[22] Batch [20]#011Speed: 469.51 samples/sec#011loss=2.806100\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:11 INFO 139866244298560] Epoch[22] Batch[25] avg_epoch_loss=2.575355\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=25 train loss <loss>=2.76530513763\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:11 INFO 139866244298560] Epoch[22] Batch [25]#011Speed: 590.56 samples/sec#011loss=2.765305\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:11 INFO 139866244298560] Epoch[22] Batch[30] avg_epoch_loss=2.583478\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=30 train loss <loss>=2.62571635246\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:11 INFO 139866244298560] Epoch[22] Batch [30]#011Speed: 477.84 samples/sec#011loss=2.625716\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:12 INFO 139866244298560] Epoch[22] Batch[35] avg_epoch_loss=2.576761\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=35 train loss <loss>=2.53511724472\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:12 INFO 139866244298560] Epoch[22] Batch [35]#011Speed: 551.22 samples/sec#011loss=2.535117\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:13 INFO 139866244298560] Epoch[22] Batch[40] avg_epoch_loss=2.564303\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=40 train loss <loss>=2.47460517883\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:13 INFO 139866244298560] Epoch[22] Batch [40]#011Speed: 473.01 samples/sec#011loss=2.474605\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:13 INFO 139866244298560] Epoch[22] Batch[45] avg_epoch_loss=2.566195\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=45 train loss <loss>=2.58171286583\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:13 INFO 139866244298560] Epoch[22] Batch [45]#011Speed: 589.52 samples/sec#011loss=2.581713\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:14 INFO 139866244298560] Epoch[22] Batch[50] avg_epoch_loss=2.560568\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=50 train loss <loss>=2.50879788399\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:14 INFO 139866244298560] Epoch[22] Batch [50]#011Speed: 440.05 samples/sec#011loss=2.508798\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:15 INFO 139866244298560] Epoch[22] Batch[55] avg_epoch_loss=2.544128\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=55 train loss <loss>=2.37643828392\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:15 INFO 139866244298560] Epoch[22] Batch [55]#011Speed: 585.71 samples/sec#011loss=2.376438\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:15 INFO 139866244298560] Epoch[22] Batch[60] avg_epoch_loss=2.537407\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=60 train loss <loss>=2.46213726997\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:15 INFO 139866244298560] Epoch[22] Batch [60]#011Speed: 470.79 samples/sec#011loss=2.462137\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:16 INFO 139866244298560] Epoch[22] Batch[65] avg_epoch_loss=2.538932\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=65 train loss <loss>=2.55753593445\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:16 INFO 139866244298560] Epoch[22] Batch [65]#011Speed: 592.45 samples/sec#011loss=2.557536\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:16 INFO 139866244298560] Epoch[22] Batch[70] avg_epoch_loss=2.549994\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=70 train loss <loss>=2.69600172043\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:16 INFO 139866244298560] Epoch[22] Batch [70]#011Speed: 479.12 samples/sec#011loss=2.696002\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:17 INFO 139866244298560] Epoch[22] Batch[75] avg_epoch_loss=2.595621\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=75 train loss <loss>=3.24352397919\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:17 INFO 139866244298560] Epoch[22] Batch [75]#011Speed: 550.38 samples/sec#011loss=3.243524\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:18 INFO 139866244298560] Epoch[22] Batch[80] avg_epoch_loss=2.637678\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=80 train loss <loss>=3.27695207596\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:18 INFO 139866244298560] Epoch[22] Batch [80]#011Speed: 479.77 samples/sec#011loss=3.276952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:18 INFO 139866244298560] Epoch[22] Batch[85] avg_epoch_loss=2.684405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=85 train loss <loss>=3.44138092995\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:18 INFO 139866244298560] Epoch[22] Batch [85]#011Speed: 586.49 samples/sec#011loss=3.441381\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:19 INFO 139866244298560] Epoch[22] Batch[90] avg_epoch_loss=2.691456\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=90 train loss <loss>=2.81273798943\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:19 INFO 139866244298560] Epoch[22] Batch [90]#011Speed: 474.71 samples/sec#011loss=2.812738\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:19 INFO 139866244298560] Epoch[22] Batch[95] avg_epoch_loss=2.692725\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=95 train loss <loss>=2.71582026482\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:19 INFO 139866244298560] Epoch[22] Batch [95]#011Speed: 591.99 samples/sec#011loss=2.715820\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:20 INFO 139866244298560] Epoch[22] Batch[100] avg_epoch_loss=2.683756\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=100 train loss <loss>=2.5115404129\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:20 INFO 139866244298560] Epoch[22] Batch [100]#011Speed: 473.88 samples/sec#011loss=2.511540\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:21 INFO 139866244298560] Epoch[22] Batch[105] avg_epoch_loss=2.671958\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=105 train loss <loss>=2.43364744186\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:21 INFO 139866244298560] Epoch[22] Batch [105]#011Speed: 591.65 samples/sec#011loss=2.433647\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:21 INFO 139866244298560] Epoch[22] Batch[110] avg_epoch_loss=2.663797\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=110 train loss <loss>=2.49079318047\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:21 INFO 139866244298560] Epoch[22] Batch [110]#011Speed: 483.48 samples/sec#011loss=2.490793\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:22 INFO 139866244298560] Epoch[22] Batch[115] avg_epoch_loss=2.654567\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=115 train loss <loss>=2.44964182377\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:22 INFO 139866244298560] Epoch[22] Batch [115]#011Speed: 429.28 samples/sec#011loss=2.449642\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:23 INFO 139866244298560] Epoch[22] Batch[120] avg_epoch_loss=2.646370\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=120 train loss <loss>=2.45620245934\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:23 INFO 139866244298560] Epoch[22] Batch [120]#011Speed: 586.44 samples/sec#011loss=2.456202\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:23 INFO 139866244298560] Epoch[22] Batch[125] avg_epoch_loss=2.650382\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=125 train loss <loss>=2.74747748375\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:23 INFO 139866244298560] Epoch[22] Batch [125]#011Speed: 476.64 samples/sec#011loss=2.747477\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:24 INFO 139866244298560] Epoch[22] Batch[130] avg_epoch_loss=2.660272\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=130 train loss <loss>=2.90950846672\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:24 INFO 139866244298560] Epoch[22] Batch [130]#011Speed: 587.59 samples/sec#011loss=2.909508\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:24 INFO 139866244298560] Epoch[22] Batch[135] avg_epoch_loss=2.664800\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=135 train loss <loss>=2.78343081474\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:24 INFO 139866244298560] Epoch[22] Batch [135]#011Speed: 474.93 samples/sec#011loss=2.783431\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:25 INFO 139866244298560] Epoch[22] Batch[140] avg_epoch_loss=2.676326\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=140 train loss <loss>=2.98982338905\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:25 INFO 139866244298560] Epoch[22] Batch [140]#011Speed: 587.67 samples/sec#011loss=2.989823\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:26 INFO 139866244298560] Epoch[22] Batch[145] avg_epoch_loss=2.673091\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=145 train loss <loss>=2.58187747002\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:26 INFO 139866244298560] Epoch[22] Batch [145]#011Speed: 480.41 samples/sec#011loss=2.581877\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:26 INFO 139866244298560] Epoch[22] Batch[150] avg_epoch_loss=2.668802\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=150 train loss <loss>=2.54354119301\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:26 INFO 139866244298560] Epoch[22] Batch [150]#011Speed: 594.06 samples/sec#011loss=2.543541\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:27 INFO 139866244298560] Epoch[22] Batch[155] avg_epoch_loss=2.660760\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=155 train loss <loss>=2.41789422035\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:27 INFO 139866244298560] Epoch[22] Batch [155]#011Speed: 470.47 samples/sec#011loss=2.417894\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:28 INFO 139866244298560] Epoch[22] Batch[160] avg_epoch_loss=2.658808\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=160 train loss <loss>=2.59792537689\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:28 INFO 139866244298560] Epoch[22] Batch [160]#011Speed: 521.43 samples/sec#011loss=2.597925\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:28 INFO 139866244298560] Epoch[22] Batch[165] avg_epoch_loss=2.659388\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=165 train loss <loss>=2.67805581093\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:28 INFO 139866244298560] Epoch[22] Batch [165]#011Speed: 473.56 samples/sec#011loss=2.678056\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:29 INFO 139866244298560] Epoch[22] Batch[170] avg_epoch_loss=2.650781\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=170 train loss <loss>=2.36501431465\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:29 INFO 139866244298560] Epoch[22] Batch [170]#011Speed: 592.53 samples/sec#011loss=2.365014\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:29 INFO 139866244298560] Epoch[22] Batch[175] avg_epoch_loss=2.644321\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=175 train loss <loss>=2.42341041565\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:29 INFO 139866244298560] Epoch[22] Batch [175]#011Speed: 479.70 samples/sec#011loss=2.423410\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:30 INFO 139866244298560] Epoch[22] Batch[180] avg_epoch_loss=2.643410\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=180 train loss <loss>=2.61132144928\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:30 INFO 139866244298560] Epoch[22] Batch [180]#011Speed: 578.83 samples/sec#011loss=2.611321\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:31 INFO 139866244298560] Epoch[22] Batch[185] avg_epoch_loss=2.655351\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=185 train loss <loss>=3.08762283325\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:31 INFO 139866244298560] Epoch[22] Batch [185]#011Speed: 481.17 samples/sec#011loss=3.087623\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:31 INFO 139866244298560] Epoch[22] Batch[190] avg_epoch_loss=2.677693\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=190 train loss <loss>=3.50882310867\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:31 INFO 139866244298560] Epoch[22] Batch [190]#011Speed: 590.85 samples/sec#011loss=3.508823\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:32 INFO 139866244298560] Epoch[22] Batch[195] avg_epoch_loss=2.698269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=195 train loss <loss>=3.4842792511\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:32 INFO 139866244298560] Epoch[22] Batch [195]#011Speed: 484.97 samples/sec#011loss=3.484279\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:32 INFO 139866244298560] Epoch[22] Batch[200] avg_epoch_loss=2.716065\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=200 train loss <loss>=3.41366295815\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:32 INFO 139866244298560] Epoch[22] Batch [200]#011Speed: 531.63 samples/sec#011loss=3.413663\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:33 INFO 139866244298560] Epoch[22] Batch[205] avg_epoch_loss=2.717444\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=205 train loss <loss>=2.7728621006\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:33 INFO 139866244298560] Epoch[22] Batch [205]#011Speed: 480.93 samples/sec#011loss=2.772862\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:34 INFO 139866244298560] Epoch[22] Batch[210] avg_epoch_loss=2.719300\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=210 train loss <loss>=2.79577083588\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:34 INFO 139866244298560] Epoch[22] Batch [210]#011Speed: 584.11 samples/sec#011loss=2.795771\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:34 INFO 139866244298560] Epoch[22] Batch[215] avg_epoch_loss=2.720186\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=215 train loss <loss>=2.75760016441\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:34 INFO 139866244298560] Epoch[22] Batch [215]#011Speed: 477.25 samples/sec#011loss=2.757600\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:35 INFO 139866244298560] Epoch[22] Batch[220] avg_epoch_loss=2.711751\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=220 train loss <loss>=2.34733872414\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:35 INFO 139866244298560] Epoch[22] Batch [220]#011Speed: 587.45 samples/sec#011loss=2.347339\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:36 INFO 139866244298560] Epoch[22] Batch[225] avg_epoch_loss=2.703773\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=225 train loss <loss>=2.35115594864\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:36 INFO 139866244298560] Epoch[22] Batch [225]#011Speed: 477.67 samples/sec#011loss=2.351156\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:36 INFO 139866244298560] Epoch[22] Batch[230] avg_epoch_loss=2.702983\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=230 train loss <loss>=2.66725039482\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:36 INFO 139866244298560] Epoch[22] Batch [230]#011Speed: 483.92 samples/sec#011loss=2.667250\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:37 INFO 139866244298560] Epoch[22] Batch[235] avg_epoch_loss=2.716432\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=235 train loss <loss>=3.33780221939\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:37 INFO 139866244298560] Epoch[22] Batch [235]#011Speed: 583.88 samples/sec#011loss=3.337802\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:37 INFO 139866244298560] Epoch[22] Batch[240] avg_epoch_loss=2.733405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=240 train loss <loss>=3.5345164299\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:37 INFO 139866244298560] Epoch[22] Batch [240]#011Speed: 447.12 samples/sec#011loss=3.534516\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:38 INFO 139866244298560] Epoch[22] Batch[245] avg_epoch_loss=2.753310\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=245 train loss <loss>=3.71273961067\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:38 INFO 139866244298560] Epoch[22] Batch [245]#011Speed: 591.21 samples/sec#011loss=3.712740\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:39 INFO 139866244298560] Epoch[22] Batch[250] avg_epoch_loss=2.759194\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=250 train loss <loss>=3.04868888855\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:39 INFO 139866244298560] Epoch[22] Batch [250]#011Speed: 464.55 samples/sec#011loss=3.048689\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:39 INFO 139866244298560] Epoch[22] Batch[255] avg_epoch_loss=2.759732\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=255 train loss <loss>=2.78676018715\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:39 INFO 139866244298560] Epoch[22] Batch [255]#011Speed: 592.05 samples/sec#011loss=2.786760\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:40 INFO 139866244298560] Epoch[22] Batch[260] avg_epoch_loss=2.751831\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=260 train loss <loss>=2.34726030827\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:40 INFO 139866244298560] Epoch[22] Batch [260]#011Speed: 472.10 samples/sec#011loss=2.347260\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:40 INFO 139866244298560] Epoch[22] Batch[265] avg_epoch_loss=2.748704\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=265 train loss <loss>=2.58551030159\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:40 INFO 139866244298560] Epoch[22] Batch [265]#011Speed: 592.86 samples/sec#011loss=2.585510\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:41 INFO 139866244298560] Epoch[22] Batch[270] avg_epoch_loss=2.758233\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, batch=270 train loss <loss>=3.26515612602\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:41 INFO 139866244298560] Epoch[22] Batch [270]#011Speed: 567.89 samples/sec#011loss=3.265156\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:41 INFO 139866244298560] processed a total of 17343 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33455.360889434814, \"sum\": 33455.360889434814, \"min\": 33455.360889434814}}, \"EndTime\": 1599442721.487949, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442688.032102}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:41 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=518.38788547 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:41 INFO 139866244298560] #progress_metric: host=algo-1, completed 28 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=22, train loss <loss>=2.75823301715\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:41 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:41 INFO 139866244298560] Epoch[23] Batch[0] avg_epoch_loss=1.936603\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=0 train loss <loss>=1.93660330772\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:42 INFO 139866244298560] Epoch[23] Batch[5] avg_epoch_loss=2.118883\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=5 train loss <loss>=2.11888259649\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:42 INFO 139866244298560] Epoch[23] Batch [5]#011Speed: 591.96 samples/sec#011loss=2.118883\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:42 INFO 139866244298560] Epoch[23] Batch[10] avg_epoch_loss=2.215064\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=10 train loss <loss>=2.33048110008\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:42 INFO 139866244298560] Epoch[23] Batch [10]#011Speed: 446.82 samples/sec#011loss=2.330481\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:43 INFO 139866244298560] Epoch[23] Batch[15] avg_epoch_loss=2.372639\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=15 train loss <loss>=2.71930322647\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:43 INFO 139866244298560] Epoch[23] Batch [15]#011Speed: 583.87 samples/sec#011loss=2.719303\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:44 INFO 139866244298560] Epoch[23] Batch[20] avg_epoch_loss=2.476646\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=20 train loss <loss>=2.80947041512\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:44 INFO 139866244298560] Epoch[23] Batch [20]#011Speed: 468.65 samples/sec#011loss=2.809470\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:44 INFO 139866244298560] Epoch[23] Batch[25] avg_epoch_loss=2.514854\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=25 train loss <loss>=2.67532844543\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:44 INFO 139866244298560] Epoch[23] Batch [25]#011Speed: 532.76 samples/sec#011loss=2.675328\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:45 INFO 139866244298560] Epoch[23] Batch[30] avg_epoch_loss=2.556225\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=30 train loss <loss>=2.77135310173\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:45 INFO 139866244298560] Epoch[23] Batch [30]#011Speed: 471.02 samples/sec#011loss=2.771353\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:46 INFO 139866244298560] Epoch[23] Batch[35] avg_epoch_loss=2.576410\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=35 train loss <loss>=2.70155797005\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:46 INFO 139866244298560] Epoch[23] Batch [35]#011Speed: 592.51 samples/sec#011loss=2.701558\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:46 INFO 139866244298560] Epoch[23] Batch[40] avg_epoch_loss=2.572337\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=40 train loss <loss>=2.54300980568\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:46 INFO 139866244298560] Epoch[23] Batch [40]#011Speed: 482.68 samples/sec#011loss=2.543010\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:47 INFO 139866244298560] Epoch[23] Batch[45] avg_epoch_loss=2.566642\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=45 train loss <loss>=2.51994299889\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:47 INFO 139866244298560] Epoch[23] Batch [45]#011Speed: 593.22 samples/sec#011loss=2.519943\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:47 INFO 139866244298560] Epoch[23] Batch[50] avg_epoch_loss=2.530932\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=50 train loss <loss>=2.20239987373\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:47 INFO 139866244298560] Epoch[23] Batch [50]#011Speed: 478.40 samples/sec#011loss=2.202400\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:48 INFO 139866244298560] Epoch[23] Batch[55] avg_epoch_loss=2.512107\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=55 train loss <loss>=2.32009305954\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:48 INFO 139866244298560] Epoch[23] Batch [55]#011Speed: 535.77 samples/sec#011loss=2.320093\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:49 INFO 139866244298560] Epoch[23] Batch[60] avg_epoch_loss=2.512417\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=60 train loss <loss>=2.51588244438\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:49 INFO 139866244298560] Epoch[23] Batch [60]#011Speed: 461.19 samples/sec#011loss=2.515882\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:49 INFO 139866244298560] Epoch[23] Batch[65] avg_epoch_loss=2.511246\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=65 train loss <loss>=2.49696397781\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:49 INFO 139866244298560] Epoch[23] Batch [65]#011Speed: 595.18 samples/sec#011loss=2.496964\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:50 INFO 139866244298560] Epoch[23] Batch[70] avg_epoch_loss=2.527401\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=70 train loss <loss>=2.74064702988\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:50 INFO 139866244298560] Epoch[23] Batch [70]#011Speed: 473.11 samples/sec#011loss=2.740647\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:50 INFO 139866244298560] Epoch[23] Batch[75] avg_epoch_loss=2.553453\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=75 train loss <loss>=2.92338833809\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:50 INFO 139866244298560] Epoch[23] Batch [75]#011Speed: 595.76 samples/sec#011loss=2.923388\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:51 INFO 139866244298560] Epoch[23] Batch[80] avg_epoch_loss=2.589760\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=80 train loss <loss>=3.14162797928\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:51 INFO 139866244298560] Epoch[23] Batch [80]#011Speed: 478.85 samples/sec#011loss=3.141628\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:52 INFO 139866244298560] Epoch[23] Batch[85] avg_epoch_loss=2.638753\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=85 train loss <loss>=3.43244290352\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:52 INFO 139866244298560] Epoch[23] Batch [85]#011Speed: 595.31 samples/sec#011loss=3.432443\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:52 INFO 139866244298560] Epoch[23] Batch[90] avg_epoch_loss=2.663280\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=90 train loss <loss>=3.08514251709\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:52 INFO 139866244298560] Epoch[23] Batch [90]#011Speed: 464.23 samples/sec#011loss=3.085143\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:53 INFO 139866244298560] Epoch[23] Batch[95] avg_epoch_loss=2.671440\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=95 train loss <loss>=2.81995191574\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:53 INFO 139866244298560] Epoch[23] Batch [95]#011Speed: 491.64 samples/sec#011loss=2.819952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:54 INFO 139866244298560] Epoch[23] Batch[100] avg_epoch_loss=2.670250\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=100 train loss <loss>=2.64739842415\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:54 INFO 139866244298560] Epoch[23] Batch [100]#011Speed: 481.11 samples/sec#011loss=2.647398\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:54 INFO 139866244298560] Epoch[23] Batch[105] avg_epoch_loss=2.660160\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=105 train loss <loss>=2.45633702278\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:54 INFO 139866244298560] Epoch[23] Batch [105]#011Speed: 588.61 samples/sec#011loss=2.456337\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:55 INFO 139866244298560] Epoch[23] Batch[110] avg_epoch_loss=2.645201\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=110 train loss <loss>=2.3280826807\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:55 INFO 139866244298560] Epoch[23] Batch [110]#011Speed: 471.37 samples/sec#011loss=2.328083\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:55 INFO 139866244298560] Epoch[23] Batch[115] avg_epoch_loss=2.640895\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=115 train loss <loss>=2.54530515671\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:55 INFO 139866244298560] Epoch[23] Batch [115]#011Speed: 571.20 samples/sec#011loss=2.545305\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:56 INFO 139866244298560] Epoch[23] Batch[120] avg_epoch_loss=2.623146\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=120 train loss <loss>=2.21135883331\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:56 INFO 139866244298560] Epoch[23] Batch [120]#011Speed: 480.78 samples/sec#011loss=2.211359\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:57 INFO 139866244298560] Epoch[23] Batch[125] avg_epoch_loss=2.616215\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=125 train loss <loss>=2.44849901199\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:57 INFO 139866244298560] Epoch[23] Batch [125]#011Speed: 595.15 samples/sec#011loss=2.448499\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:57 INFO 139866244298560] Epoch[23] Batch[130] avg_epoch_loss=2.624314\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=130 train loss <loss>=2.82839975357\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:57 INFO 139866244298560] Epoch[23] Batch [130]#011Speed: 484.67 samples/sec#011loss=2.828400\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:58 INFO 139866244298560] Epoch[23] Batch[135] avg_epoch_loss=2.633232\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=135 train loss <loss>=2.86687612534\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:58 INFO 139866244298560] Epoch[23] Batch [135]#011Speed: 458.90 samples/sec#011loss=2.866876\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:59 INFO 139866244298560] Epoch[23] Batch[140] avg_epoch_loss=2.643245\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=140 train loss <loss>=2.91561689377\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:59 INFO 139866244298560] Epoch[23] Batch [140]#011Speed: 578.24 samples/sec#011loss=2.915617\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:59 INFO 139866244298560] Epoch[23] Batch[145] avg_epoch_loss=2.649968\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=145 train loss <loss>=2.83954439163\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:38:59 INFO 139866244298560] Epoch[23] Batch [145]#011Speed: 467.74 samples/sec#011loss=2.839544\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:00 INFO 139866244298560] Epoch[23] Batch[150] avg_epoch_loss=2.647631\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=150 train loss <loss>=2.57938942909\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:00 INFO 139866244298560] Epoch[23] Batch [150]#011Speed: 591.48 samples/sec#011loss=2.579389\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:00 INFO 139866244298560] Epoch[23] Batch[155] avg_epoch_loss=2.644764\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=155 train loss <loss>=2.55818839073\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:00 INFO 139866244298560] Epoch[23] Batch [155]#011Speed: 463.85 samples/sec#011loss=2.558188\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:01 INFO 139866244298560] Epoch[23] Batch[160] avg_epoch_loss=2.640128\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=160 train loss <loss>=2.49549136162\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:01 INFO 139866244298560] Epoch[23] Batch [160]#011Speed: 594.92 samples/sec#011loss=2.495491\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:02 INFO 139866244298560] Epoch[23] Batch[165] avg_epoch_loss=2.640096\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=165 train loss <loss>=2.63906331062\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:02 INFO 139866244298560] Epoch[23] Batch [165]#011Speed: 459.21 samples/sec#011loss=2.639063\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:02 INFO 139866244298560] Epoch[23] Batch[170] avg_epoch_loss=2.631714\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=170 train loss <loss>=2.35342512131\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:02 INFO 139866244298560] Epoch[23] Batch [170]#011Speed: 584.73 samples/sec#011loss=2.353425\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:03 INFO 139866244298560] Epoch[23] Batch[175] avg_epoch_loss=2.633307\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=175 train loss <loss>=2.68778967857\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:03 INFO 139866244298560] Epoch[23] Batch [175]#011Speed: 471.41 samples/sec#011loss=2.687790\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:04 INFO 139866244298560] Epoch[23] Batch[180] avg_epoch_loss=2.630095\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=180 train loss <loss>=2.5170416832\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:04 INFO 139866244298560] Epoch[23] Batch [180]#011Speed: 535.21 samples/sec#011loss=2.517042\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:04 INFO 139866244298560] Epoch[23] Batch[185] avg_epoch_loss=2.636768\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=185 train loss <loss>=2.87830142975\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:04 INFO 139866244298560] Epoch[23] Batch [185]#011Speed: 475.07 samples/sec#011loss=2.878301\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:05 INFO 139866244298560] Epoch[23] Batch[190] avg_epoch_loss=2.644180\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=190 train loss <loss>=2.91992673874\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:05 INFO 139866244298560] Epoch[23] Batch [190]#011Speed: 595.57 samples/sec#011loss=2.919927\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:05 INFO 139866244298560] Epoch[23] Batch[195] avg_epoch_loss=2.667912\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=195 train loss <loss>=3.57448701859\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:05 INFO 139866244298560] Epoch[23] Batch [195]#011Speed: 479.29 samples/sec#011loss=3.574487\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:06 INFO 139866244298560] Epoch[23] Batch[200] avg_epoch_loss=2.690740\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=200 train loss <loss>=3.58559641838\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:06 INFO 139866244298560] Epoch[23] Batch [200]#011Speed: 594.27 samples/sec#011loss=3.585596\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:07 INFO 139866244298560] Epoch[23] Batch[205] avg_epoch_loss=2.708793\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=205 train loss <loss>=3.43451499939\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:07 INFO 139866244298560] Epoch[23] Batch [205]#011Speed: 476.16 samples/sec#011loss=3.434515\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:07 INFO 139866244298560] Epoch[23] Batch[210] avg_epoch_loss=2.719543\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=210 train loss <loss>=3.16242637634\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:07 INFO 139866244298560] Epoch[23] Batch [210]#011Speed: 593.37 samples/sec#011loss=3.162426\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:08 INFO 139866244298560] Epoch[23] Batch[215] avg_epoch_loss=2.718220\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=215 train loss <loss>=2.6624112606\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:08 INFO 139866244298560] Epoch[23] Batch [215]#011Speed: 479.01 samples/sec#011loss=2.662411\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:08 INFO 139866244298560] Epoch[23] Batch[220] avg_epoch_loss=2.714784\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=220 train loss <loss>=2.5663424015\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:08 INFO 139866244298560] Epoch[23] Batch [220]#011Speed: 537.88 samples/sec#011loss=2.566342\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:09 INFO 139866244298560] Epoch[23] Batch[225] avg_epoch_loss=2.714927\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=225 train loss <loss>=2.72125864029\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:09 INFO 139866244298560] Epoch[23] Batch [225]#011Speed: 469.19 samples/sec#011loss=2.721259\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:10 INFO 139866244298560] Epoch[23] Batch[230] avg_epoch_loss=2.714203\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=230 train loss <loss>=2.68146400452\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:10 INFO 139866244298560] Epoch[23] Batch [230]#011Speed: 597.77 samples/sec#011loss=2.681464\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:10 INFO 139866244298560] Epoch[23] Batch[235] avg_epoch_loss=2.715891\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=235 train loss <loss>=2.79388647079\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:10 INFO 139866244298560] Epoch[23] Batch [235]#011Speed: 472.04 samples/sec#011loss=2.793886\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:11 INFO 139866244298560] Epoch[23] Batch[240] avg_epoch_loss=2.715567\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=240 train loss <loss>=2.7002696991\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:11 INFO 139866244298560] Epoch[23] Batch [240]#011Speed: 594.99 samples/sec#011loss=2.700270\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:12 INFO 139866244298560] Epoch[23] Batch[245] avg_epoch_loss=2.725063\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=245 train loss <loss>=3.18274431229\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:12 INFO 139866244298560] Epoch[23] Batch [245]#011Speed: 483.21 samples/sec#011loss=3.182744\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:12 INFO 139866244298560] Epoch[23] Batch[250] avg_epoch_loss=2.734931\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=250 train loss <loss>=3.22043004036\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:12 INFO 139866244298560] Epoch[23] Batch [250]#011Speed: 479.39 samples/sec#011loss=3.220430\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:13 INFO 139866244298560] Epoch[23] Batch[255] avg_epoch_loss=2.745924\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=255 train loss <loss>=3.2977856636\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:13 INFO 139866244298560] Epoch[23] Batch [255]#011Speed: 593.45 samples/sec#011loss=3.297786\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:13 INFO 139866244298560] Epoch[23] Batch[260] avg_epoch_loss=2.755464\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=260 train loss <loss>=3.24393000603\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:13 INFO 139866244298560] Epoch[23] Batch [260]#011Speed: 452.73 samples/sec#011loss=3.243930\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:14 INFO 139866244298560] Epoch[23] Batch[265] avg_epoch_loss=2.752859\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, batch=265 train loss <loss>=2.6168633461\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:14 INFO 139866244298560] Epoch[23] Batch [265]#011Speed: 576.72 samples/sec#011loss=2.616863\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:14 INFO 139866244298560] processed a total of 17213 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33385.676860809326, \"sum\": 33385.676860809326, \"min\": 33385.676860809326}}, \"EndTime\": 1599442754.874394, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442721.488197}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:14 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=515.578216155 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:14 INFO 139866244298560] #progress_metric: host=algo-1, completed 30 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=23, train loss <loss>=2.75593619098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:14 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:15 INFO 139866244298560] Epoch[24] Batch[0] avg_epoch_loss=2.085310\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=0 train loss <loss>=2.08531022072\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:15 INFO 139866244298560] Epoch[24] Batch[5] avg_epoch_loss=2.159314\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=5 train loss <loss>=2.1593135198\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:15 INFO 139866244298560] Epoch[24] Batch [5]#011Speed: 586.26 samples/sec#011loss=2.159314\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:16 INFO 139866244298560] Epoch[24] Batch[10] avg_epoch_loss=2.193863\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=10 train loss <loss>=2.23532149792\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:16 INFO 139866244298560] Epoch[24] Batch [10]#011Speed: 474.72 samples/sec#011loss=2.235321\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:16 INFO 139866244298560] Epoch[24] Batch[15] avg_epoch_loss=2.385971\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=15 train loss <loss>=2.80861001015\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:16 INFO 139866244298560] Epoch[24] Batch [15]#011Speed: 595.63 samples/sec#011loss=2.808610\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:17 INFO 139866244298560] Epoch[24] Batch[20] avg_epoch_loss=2.495429\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=20 train loss <loss>=2.84569473267\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:17 INFO 139866244298560] Epoch[24] Batch [20]#011Speed: 473.84 samples/sec#011loss=2.845695\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:18 INFO 139866244298560] Epoch[24] Batch[25] avg_epoch_loss=2.560028\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=25 train loss <loss>=2.83134541512\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:18 INFO 139866244298560] Epoch[24] Batch [25]#011Speed: 580.37 samples/sec#011loss=2.831345\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:18 INFO 139866244298560] Epoch[24] Batch[30] avg_epoch_loss=2.563736\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=30 train loss <loss>=2.58301262856\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:18 INFO 139866244298560] Epoch[24] Batch [30]#011Speed: 481.53 samples/sec#011loss=2.583013\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:19 INFO 139866244298560] Epoch[24] Batch[35] avg_epoch_loss=2.557552\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=35 train loss <loss>=2.5192158699\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:19 INFO 139866244298560] Epoch[24] Batch [35]#011Speed: 559.26 samples/sec#011loss=2.519216\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:20 INFO 139866244298560] Epoch[24] Batch[40] avg_epoch_loss=2.558865\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=40 train loss <loss>=2.56831994057\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:20 INFO 139866244298560] Epoch[24] Batch [40]#011Speed: 477.66 samples/sec#011loss=2.568320\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:20 INFO 139866244298560] Epoch[24] Batch[45] avg_epoch_loss=2.554680\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=45 train loss <loss>=2.52035856247\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:20 INFO 139866244298560] Epoch[24] Batch [45]#011Speed: 551.78 samples/sec#011loss=2.520359\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:21 INFO 139866244298560] Epoch[24] Batch[50] avg_epoch_loss=2.543345\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=50 train loss <loss>=2.43906769753\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:21 INFO 139866244298560] Epoch[24] Batch [50]#011Speed: 419.74 samples/sec#011loss=2.439068\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:21 INFO 139866244298560] Epoch[24] Batch[55] avg_epoch_loss=2.519659\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=55 train loss <loss>=2.27806172371\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:21 INFO 139866244298560] Epoch[24] Batch [55]#011Speed: 601.79 samples/sec#011loss=2.278062\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:22 INFO 139866244298560] Epoch[24] Batch[60] avg_epoch_loss=2.506872\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=60 train loss <loss>=2.36365537643\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:22 INFO 139866244298560] Epoch[24] Batch [60]#011Speed: 482.75 samples/sec#011loss=2.363655\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:23 INFO 139866244298560] Epoch[24] Batch[65] avg_epoch_loss=2.513812\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=65 train loss <loss>=2.59847698212\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:23 INFO 139866244298560] Epoch[24] Batch [65]#011Speed: 480.18 samples/sec#011loss=2.598477\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:23 INFO 139866244298560] Epoch[24] Batch[70] avg_epoch_loss=2.561850\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=70 train loss <loss>=3.19594860077\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:23 INFO 139866244298560] Epoch[24] Batch [70]#011Speed: 591.91 samples/sec#011loss=3.195949\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:24 INFO 139866244298560] Epoch[24] Batch[75] avg_epoch_loss=2.603657\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=75 train loss <loss>=3.19732317924\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:24 INFO 139866244298560] Epoch[24] Batch [75]#011Speed: 443.29 samples/sec#011loss=3.197323\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:25 INFO 139866244298560] Epoch[24] Batch[80] avg_epoch_loss=2.624206\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=80 train loss <loss>=2.9365527153\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:25 INFO 139866244298560] Epoch[24] Batch [80]#011Speed: 586.05 samples/sec#011loss=2.936553\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:25 INFO 139866244298560] Epoch[24] Batch[85] avg_epoch_loss=2.645975\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=85 train loss <loss>=2.99862155914\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:25 INFO 139866244298560] Epoch[24] Batch [85]#011Speed: 483.22 samples/sec#011loss=2.998622\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:26 INFO 139866244298560] Epoch[24] Batch[90] avg_epoch_loss=2.647392\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=90 train loss <loss>=2.67176566124\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:26 INFO 139866244298560] Epoch[24] Batch [90]#011Speed: 587.88 samples/sec#011loss=2.671766\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:26 INFO 139866244298560] Epoch[24] Batch[95] avg_epoch_loss=2.633146\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=95 train loss <loss>=2.37386951447\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:26 INFO 139866244298560] Epoch[24] Batch [95]#011Speed: 464.16 samples/sec#011loss=2.373870\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:27 INFO 139866244298560] Epoch[24] Batch[100] avg_epoch_loss=2.625758\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=100 train loss <loss>=2.48390445709\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:27 INFO 139866244298560] Epoch[24] Batch [100]#011Speed: 593.98 samples/sec#011loss=2.483904\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:28 INFO 139866244298560] Epoch[24] Batch[105] avg_epoch_loss=2.615377\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=105 train loss <loss>=2.40568966866\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:28 INFO 139866244298560] Epoch[24] Batch [105]#011Speed: 465.80 samples/sec#011loss=2.405690\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:28 INFO 139866244298560] Epoch[24] Batch[110] avg_epoch_loss=2.595410\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=110 train loss <loss>=2.17210493088\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:28 INFO 139866244298560] Epoch[24] Batch [110]#011Speed: 585.09 samples/sec#011loss=2.172105\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:29 INFO 139866244298560] Epoch[24] Batch[115] avg_epoch_loss=2.583781\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=115 train loss <loss>=2.32561762333\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:29 INFO 139866244298560] Epoch[24] Batch [115]#011Speed: 446.71 samples/sec#011loss=2.325618\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:29 INFO 139866244298560] Epoch[24] Batch[120] avg_epoch_loss=2.588631\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=120 train loss <loss>=2.70114545822\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:29 INFO 139866244298560] Epoch[24] Batch [120]#011Speed: 588.71 samples/sec#011loss=2.701145\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:30 INFO 139866244298560] Epoch[24] Batch[125] avg_epoch_loss=2.593967\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=125 train loss <loss>=2.72309823036\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:30 INFO 139866244298560] Epoch[24] Batch [125]#011Speed: 472.46 samples/sec#011loss=2.723098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:31 INFO 139866244298560] Epoch[24] Batch[130] avg_epoch_loss=2.604626\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=130 train loss <loss>=2.87323346138\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:31 INFO 139866244298560] Epoch[24] Batch [130]#011Speed: 589.43 samples/sec#011loss=2.873233\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:31 INFO 139866244298560] Epoch[24] Batch[135] avg_epoch_loss=2.617039\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=135 train loss <loss>=2.94227604866\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:31 INFO 139866244298560] Epoch[24] Batch [135]#011Speed: 478.11 samples/sec#011loss=2.942276\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:32 INFO 139866244298560] Epoch[24] Batch[140] avg_epoch_loss=2.635266\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=140 train loss <loss>=3.13102464676\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:32 INFO 139866244298560] Epoch[24] Batch [140]#011Speed: 597.81 samples/sec#011loss=3.131025\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:33 INFO 139866244298560] Epoch[24] Batch[145] avg_epoch_loss=2.641206\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=145 train loss <loss>=2.80872516632\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:33 INFO 139866244298560] Epoch[24] Batch [145]#011Speed: 478.40 samples/sec#011loss=2.808725\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:33 INFO 139866244298560] Epoch[24] Batch[150] avg_epoch_loss=2.638677\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=150 train loss <loss>=2.56483073235\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:33 INFO 139866244298560] Epoch[24] Batch [150]#011Speed: 593.75 samples/sec#011loss=2.564831\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:34 INFO 139866244298560] Epoch[24] Batch[155] avg_epoch_loss=2.640028\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=155 train loss <loss>=2.68083939552\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:34 INFO 139866244298560] Epoch[24] Batch [155]#011Speed: 444.57 samples/sec#011loss=2.680839\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:34 INFO 139866244298560] Epoch[24] Batch[160] avg_epoch_loss=2.637391\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=160 train loss <loss>=2.55510187149\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:34 INFO 139866244298560] Epoch[24] Batch [160]#011Speed: 588.52 samples/sec#011loss=2.555102\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:35 INFO 139866244298560] Epoch[24] Batch[165] avg_epoch_loss=2.632360\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=165 train loss <loss>=2.4703537941\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:35 INFO 139866244298560] Epoch[24] Batch [165]#011Speed: 473.75 samples/sec#011loss=2.470354\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:36 INFO 139866244298560] Epoch[24] Batch[170] avg_epoch_loss=2.620422\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=170 train loss <loss>=2.2240790844\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:36 INFO 139866244298560] Epoch[24] Batch [170]#011Speed: 589.22 samples/sec#011loss=2.224079\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:36 INFO 139866244298560] Epoch[24] Batch[175] avg_epoch_loss=2.618892\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=175 train loss <loss>=2.56658616066\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:36 INFO 139866244298560] Epoch[24] Batch [175]#011Speed: 475.01 samples/sec#011loss=2.566586\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:37 INFO 139866244298560] Epoch[24] Batch[180] avg_epoch_loss=2.618628\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=180 train loss <loss>=2.60932655334\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:37 INFO 139866244298560] Epoch[24] Batch [180]#011Speed: 592.35 samples/sec#011loss=2.609327\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:37 INFO 139866244298560] Epoch[24] Batch[185] avg_epoch_loss=2.636108\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=185 train loss <loss>=3.26886439323\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:37 INFO 139866244298560] Epoch[24] Batch [185]#011Speed: 481.39 samples/sec#011loss=3.268864\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:38 INFO 139866244298560] Epoch[24] Batch[190] avg_epoch_loss=2.654515\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=190 train loss <loss>=3.33926877975\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:38 INFO 139866244298560] Epoch[24] Batch [190]#011Speed: 487.56 samples/sec#011loss=3.339269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:39 INFO 139866244298560] Epoch[24] Batch[195] avg_epoch_loss=2.681185\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=195 train loss <loss>=3.69999265671\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:39 INFO 139866244298560] Epoch[24] Batch [195]#011Speed: 599.76 samples/sec#011loss=3.699993\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:39 INFO 139866244298560] Epoch[24] Batch[200] avg_epoch_loss=2.702909\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=200 train loss <loss>=3.5544629097\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:39 INFO 139866244298560] Epoch[24] Batch [200]#011Speed: 449.50 samples/sec#011loss=3.554463\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:40 INFO 139866244298560] Epoch[24] Batch[205] avg_epoch_loss=2.711191\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=205 train loss <loss>=3.0441532135\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:40 INFO 139866244298560] Epoch[24] Batch [205]#011Speed: 590.68 samples/sec#011loss=3.044153\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:41 INFO 139866244298560] Epoch[24] Batch[210] avg_epoch_loss=2.713266\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=210 train loss <loss>=2.79872822762\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:41 INFO 139866244298560] Epoch[24] Batch [210]#011Speed: 469.98 samples/sec#011loss=2.798728\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:41 INFO 139866244298560] Epoch[24] Batch[215] avg_epoch_loss=2.710185\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=215 train loss <loss>=2.58020815849\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:41 INFO 139866244298560] Epoch[24] Batch [215]#011Speed: 595.49 samples/sec#011loss=2.580208\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:42 INFO 139866244298560] Epoch[24] Batch[220] avg_epoch_loss=2.706285\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=220 train loss <loss>=2.53780212402\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:42 INFO 139866244298560] Epoch[24] Batch [220]#011Speed: 484.25 samples/sec#011loss=2.537802\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:42 INFO 139866244298560] Epoch[24] Batch[225] avg_epoch_loss=2.700623\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=225 train loss <loss>=2.45032200813\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:42 INFO 139866244298560] Epoch[24] Batch [225]#011Speed: 591.98 samples/sec#011loss=2.450322\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:43 INFO 139866244298560] Epoch[24] Batch[230] avg_epoch_loss=2.701679\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=230 train loss <loss>=2.74945058823\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:43 INFO 139866244298560] Epoch[24] Batch [230]#011Speed: 483.51 samples/sec#011loss=2.749451\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:44 INFO 139866244298560] Epoch[24] Batch[235] avg_epoch_loss=2.709691\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=235 train loss <loss>=3.07984371185\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:44 INFO 139866244298560] Epoch[24] Batch [235]#011Speed: 587.36 samples/sec#011loss=3.079844\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:44 INFO 139866244298560] Epoch[24] Batch[240] avg_epoch_loss=2.721976\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=240 train loss <loss>=3.30180912018\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:44 INFO 139866244298560] Epoch[24] Batch [240]#011Speed: 433.81 samples/sec#011loss=3.301809\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:45 INFO 139866244298560] Epoch[24] Batch[245] avg_epoch_loss=2.736953\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=245 train loss <loss>=3.45883097649\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:45 INFO 139866244298560] Epoch[24] Batch [245]#011Speed: 563.16 samples/sec#011loss=3.458831\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:46 INFO 139866244298560] Epoch[24] Batch[250] avg_epoch_loss=2.744981\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=250 train loss <loss>=3.13995933533\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:46 INFO 139866244298560] Epoch[24] Batch [250]#011Speed: 469.77 samples/sec#011loss=3.139959\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:46 INFO 139866244298560] Epoch[24] Batch[255] avg_epoch_loss=2.752271\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=255 train loss <loss>=3.11826834679\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:46 INFO 139866244298560] Epoch[24] Batch [255]#011Speed: 589.50 samples/sec#011loss=3.118268\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:47 INFO 139866244298560] Epoch[24] Batch[260] avg_epoch_loss=2.747881\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=260 train loss <loss>=2.52310962677\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:47 INFO 139866244298560] Epoch[24] Batch [260]#011Speed: 480.95 samples/sec#011loss=2.523110\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:47 INFO 139866244298560] Epoch[24] Batch[265] avg_epoch_loss=2.745187\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, batch=265 train loss <loss>=2.60455188751\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:47 INFO 139866244298560] Epoch[24] Batch [265]#011Speed: 593.12 samples/sec#011loss=2.604552\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:47 INFO 139866244298560] processed a total of 17069 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33002.788066864014, \"sum\": 33002.788066864014, \"min\": 33002.788066864014}}, \"EndTime\": 1599442787.877923, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442754.874461}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:47 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=517.197020235 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:47 INFO 139866244298560] #progress_metric: host=algo-1, completed 31 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=24, train loss <loss>=2.74689931459\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:47 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:47 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_fcf8d4fb-1eb3-435e-8a3e-08a3fbe49ee9-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.950057983398438, \"sum\": 17.950057983398438, \"min\": 17.950057983398438}}, \"EndTime\": 1599442787.896423, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442787.87799}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:48 INFO 139866244298560] Epoch[25] Batch[0] avg_epoch_loss=2.127682\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=0 train loss <loss>=2.12768244743\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:48 INFO 139866244298560] Epoch[25] Batch[5] avg_epoch_loss=2.059260\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=5 train loss <loss>=2.05926011006\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:48 INFO 139866244298560] Epoch[25] Batch [5]#011Speed: 592.81 samples/sec#011loss=2.059260\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:49 INFO 139866244298560] Epoch[25] Batch[10] avg_epoch_loss=2.137439\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=10 train loss <loss>=2.23125448227\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:49 INFO 139866244298560] Epoch[25] Batch [10]#011Speed: 479.31 samples/sec#011loss=2.231254\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:49 INFO 139866244298560] Epoch[25] Batch[15] avg_epoch_loss=2.340529\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=15 train loss <loss>=2.78732461929\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:49 INFO 139866244298560] Epoch[25] Batch [15]#011Speed: 548.72 samples/sec#011loss=2.787325\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:50 INFO 139866244298560] Epoch[25] Batch[20] avg_epoch_loss=2.470757\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=20 train loss <loss>=2.88748836517\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:50 INFO 139866244298560] Epoch[25] Batch [20]#011Speed: 477.73 samples/sec#011loss=2.887488\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:51 INFO 139866244298560] Epoch[25] Batch[25] avg_epoch_loss=2.535759\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=25 train loss <loss>=2.80876865387\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:51 INFO 139866244298560] Epoch[25] Batch [25]#011Speed: 571.56 samples/sec#011loss=2.808769\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:51 INFO 139866244298560] Epoch[25] Batch[30] avg_epoch_loss=2.538683\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=30 train loss <loss>=2.55388417244\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:51 INFO 139866244298560] Epoch[25] Batch [30]#011Speed: 484.71 samples/sec#011loss=2.553884\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:52 INFO 139866244298560] Epoch[25] Batch[35] avg_epoch_loss=2.529356\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=35 train loss <loss>=2.47152895927\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:52 INFO 139866244298560] Epoch[25] Batch [35]#011Speed: 591.46 samples/sec#011loss=2.471529\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:53 INFO 139866244298560] Epoch[25] Batch[40] avg_epoch_loss=2.548561\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=40 train loss <loss>=2.68683991432\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:53 INFO 139866244298560] Epoch[25] Batch [40]#011Speed: 471.86 samples/sec#011loss=2.686840\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:53 INFO 139866244298560] Epoch[25] Batch[45] avg_epoch_loss=2.512883\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=45 train loss <loss>=2.2203265667\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:53 INFO 139866244298560] Epoch[25] Batch [45]#011Speed: 597.58 samples/sec#011loss=2.220327\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:54 INFO 139866244298560] Epoch[25] Batch[50] avg_epoch_loss=2.474484\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=50 train loss <loss>=2.12121033669\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:54 INFO 139866244298560] Epoch[25] Batch [50]#011Speed: 479.85 samples/sec#011loss=2.121210\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:54 INFO 139866244298560] Epoch[25] Batch[55] avg_epoch_loss=2.459100\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=55 train loss <loss>=2.30217909813\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:54 INFO 139866244298560] Epoch[25] Batch [55]#011Speed: 594.59 samples/sec#011loss=2.302179\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:55 INFO 139866244298560] Epoch[25] Batch[60] avg_epoch_loss=2.478598\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=60 train loss <loss>=2.69697394371\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:55 INFO 139866244298560] Epoch[25] Batch [60]#011Speed: 473.57 samples/sec#011loss=2.696974\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:56 INFO 139866244298560] Epoch[25] Batch[65] avg_epoch_loss=2.489626\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=65 train loss <loss>=2.62417235374\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:56 INFO 139866244298560] Epoch[25] Batch [65]#011Speed: 583.51 samples/sec#011loss=2.624172\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:56 INFO 139866244298560] Epoch[25] Batch[70] avg_epoch_loss=2.554267\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=70 train loss <loss>=3.4075316906\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:56 INFO 139866244298560] Epoch[25] Batch [70]#011Speed: 466.27 samples/sec#011loss=3.407532\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:57 INFO 139866244298560] Epoch[25] Batch[75] avg_epoch_loss=2.609573\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=75 train loss <loss>=3.39491257668\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:57 INFO 139866244298560] Epoch[25] Batch [75]#011Speed: 482.83 samples/sec#011loss=3.394913\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:57 INFO 139866244298560] Epoch[25] Batch[80] avg_epoch_loss=2.651089\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=80 train loss <loss>=3.28213415146\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:57 INFO 139866244298560] Epoch[25] Batch [80]#011Speed: 594.55 samples/sec#011loss=3.282134\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:58 INFO 139866244298560] Epoch[25] Batch[85] avg_epoch_loss=2.672422\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=85 train loss <loss>=3.01801328659\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:58 INFO 139866244298560] Epoch[25] Batch [85]#011Speed: 477.86 samples/sec#011loss=3.018013\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:59 INFO 139866244298560] Epoch[25] Batch[90] avg_epoch_loss=2.655886\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=90 train loss <loss>=2.37147285938\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:59 INFO 139866244298560] Epoch[25] Batch [90]#011Speed: 598.45 samples/sec#011loss=2.371473\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:59 INFO 139866244298560] Epoch[25] Batch[95] avg_epoch_loss=2.644410\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=95 train loss <loss>=2.43554968834\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:39:59 INFO 139866244298560] Epoch[25] Batch [95]#011Speed: 478.13 samples/sec#011loss=2.435550\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:00 INFO 139866244298560] Epoch[25] Batch[100] avg_epoch_loss=2.649778\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=100 train loss <loss>=2.75284092426\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:00 INFO 139866244298560] Epoch[25] Batch [100]#011Speed: 589.44 samples/sec#011loss=2.752841\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:00 INFO 139866244298560] Epoch[25] Batch[105] avg_epoch_loss=2.643659\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=105 train loss <loss>=2.52005124092\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:00 INFO 139866244298560] Epoch[25] Batch [105]#011Speed: 476.29 samples/sec#011loss=2.520051\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:01 INFO 139866244298560] Epoch[25] Batch[110] avg_epoch_loss=2.626308\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=110 train loss <loss>=2.25846817493\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:01 INFO 139866244298560] Epoch[25] Batch [110]#011Speed: 592.35 samples/sec#011loss=2.258468\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:02 INFO 139866244298560] Epoch[25] Batch[115] avg_epoch_loss=2.630796\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=115 train loss <loss>=2.73042392731\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:02 INFO 139866244298560] Epoch[25] Batch [115]#011Speed: 459.72 samples/sec#011loss=2.730424\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:02 INFO 139866244298560] Epoch[25] Batch[120] avg_epoch_loss=2.633541\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=120 train loss <loss>=2.69724197388\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:02 INFO 139866244298560] Epoch[25] Batch [120]#011Speed: 588.31 samples/sec#011loss=2.697242\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:03 INFO 139866244298560] Epoch[25] Batch[125] avg_epoch_loss=2.639891\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=125 train loss <loss>=2.79355792999\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:03 INFO 139866244298560] Epoch[25] Batch [125]#011Speed: 474.82 samples/sec#011loss=2.793558\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:03 INFO 139866244298560] Epoch[25] Batch[130] avg_epoch_loss=2.646776\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=130 train loss <loss>=2.82025680542\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:03 INFO 139866244298560] Epoch[25] Batch [130]#011Speed: 591.73 samples/sec#011loss=2.820257\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:04 INFO 139866244298560] Epoch[25] Batch[135] avg_epoch_loss=2.656328\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=135 train loss <loss>=2.9066010952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:04 INFO 139866244298560] Epoch[25] Batch [135]#011Speed: 471.57 samples/sec#011loss=2.906601\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:05 INFO 139866244298560] Epoch[25] Batch[140] avg_epoch_loss=2.667354\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=140 train loss <loss>=2.967253685\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:05 INFO 139866244298560] Epoch[25] Batch [140]#011Speed: 587.45 samples/sec#011loss=2.967254\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:05 INFO 139866244298560] Epoch[25] Batch[145] avg_epoch_loss=2.659084\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=145 train loss <loss>=2.42589221001\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:05 INFO 139866244298560] Epoch[25] Batch [145]#011Speed: 476.07 samples/sec#011loss=2.425892\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:06 INFO 139866244298560] Epoch[25] Batch[150] avg_epoch_loss=2.646302\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=150 train loss <loss>=2.273052001\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:06 INFO 139866244298560] Epoch[25] Batch [150]#011Speed: 591.27 samples/sec#011loss=2.273052\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:07 INFO 139866244298560] Epoch[25] Batch[155] avg_epoch_loss=2.649191\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=155 train loss <loss>=2.73643803596\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:07 INFO 139866244298560] Epoch[25] Batch [155]#011Speed: 475.94 samples/sec#011loss=2.736438\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:07 INFO 139866244298560] Epoch[25] Batch[160] avg_epoch_loss=2.645974\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=160 train loss <loss>=2.54561481476\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:07 INFO 139866244298560] Epoch[25] Batch [160]#011Speed: 477.40 samples/sec#011loss=2.545615\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:08 INFO 139866244298560] Epoch[25] Batch[165] avg_epoch_loss=2.639825\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=165 train loss <loss>=2.44182133675\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:08 INFO 139866244298560] Epoch[25] Batch [165]#011Speed: 583.57 samples/sec#011loss=2.441821\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:08 INFO 139866244298560] Epoch[25] Batch[170] avg_epoch_loss=2.635070\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=170 train loss <loss>=2.47719397545\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:08 INFO 139866244298560] Epoch[25] Batch [170]#011Speed: 477.93 samples/sec#011loss=2.477194\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:09 INFO 139866244298560] Epoch[25] Batch[175] avg_epoch_loss=2.643269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=175 train loss <loss>=2.92368268967\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:09 INFO 139866244298560] Epoch[25] Batch [175]#011Speed: 594.70 samples/sec#011loss=2.923683\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:10 INFO 139866244298560] Epoch[25] Batch[180] avg_epoch_loss=2.656700\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=180 train loss <loss>=3.12948927879\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:10 INFO 139866244298560] Epoch[25] Batch [180]#011Speed: 479.99 samples/sec#011loss=3.129489\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:10 INFO 139866244298560] Epoch[25] Batch[185] avg_epoch_loss=2.679168\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=185 train loss <loss>=3.49248065948\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:10 INFO 139866244298560] Epoch[25] Batch [185]#011Speed: 594.10 samples/sec#011loss=3.492481\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:11 INFO 139866244298560] Epoch[25] Batch[190] avg_epoch_loss=2.694902\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=190 train loss <loss>=3.28023200035\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:11 INFO 139866244298560] Epoch[25] Batch [190]#011Speed: 457.40 samples/sec#011loss=3.280232\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:11 INFO 139866244298560] Epoch[25] Batch[195] avg_epoch_loss=2.704110\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=195 train loss <loss>=3.05582342148\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:11 INFO 139866244298560] Epoch[25] Batch [195]#011Speed: 598.52 samples/sec#011loss=3.055823\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:12 INFO 139866244298560] Epoch[25] Batch[200] avg_epoch_loss=2.714070\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=200 train loss <loss>=3.10451726913\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:12 INFO 139866244298560] Epoch[25] Batch [200]#011Speed: 470.32 samples/sec#011loss=3.104517\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:13 INFO 139866244298560] Epoch[25] Batch[205] avg_epoch_loss=2.722539\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=205 train loss <loss>=3.06299667358\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:13 INFO 139866244298560] Epoch[25] Batch [205]#011Speed: 593.06 samples/sec#011loss=3.062997\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:13 INFO 139866244298560] Epoch[25] Batch[210] avg_epoch_loss=2.718096\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=210 train loss <loss>=2.53505992889\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:13 INFO 139866244298560] Epoch[25] Batch [210]#011Speed: 474.38 samples/sec#011loss=2.535060\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:14 INFO 139866244298560] Epoch[25] Batch[215] avg_epoch_loss=2.718187\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=215 train loss <loss>=2.72202029228\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:14 INFO 139866244298560] Epoch[25] Batch [215]#011Speed: 592.06 samples/sec#011loss=2.722020\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:15 INFO 139866244298560] Epoch[25] Batch[220] avg_epoch_loss=2.715525\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=220 train loss <loss>=2.60051670074\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:15 INFO 139866244298560] Epoch[25] Batch [220]#011Speed: 433.18 samples/sec#011loss=2.600517\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:15 INFO 139866244298560] Epoch[25] Batch[225] avg_epoch_loss=2.708392\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=225 train loss <loss>=2.39311156273\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:15 INFO 139866244298560] Epoch[25] Batch [225]#011Speed: 593.91 samples/sec#011loss=2.393112\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:16 INFO 139866244298560] Epoch[25] Batch[230] avg_epoch_loss=2.713760\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=230 train loss <loss>=2.95638093948\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:16 INFO 139866244298560] Epoch[25] Batch [230]#011Speed: 474.23 samples/sec#011loss=2.956381\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:16 INFO 139866244298560] Epoch[25] Batch[235] avg_epoch_loss=2.716252\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=235 train loss <loss>=2.83140692711\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:16 INFO 139866244298560] Epoch[25] Batch [235]#011Speed: 594.67 samples/sec#011loss=2.831407\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:17 INFO 139866244298560] Epoch[25] Batch[240] avg_epoch_loss=2.736132\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=240 train loss <loss>=3.67446751595\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:17 INFO 139866244298560] Epoch[25] Batch [240]#011Speed: 486.81 samples/sec#011loss=3.674468\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:18 INFO 139866244298560] Epoch[25] Batch[245] avg_epoch_loss=2.750917\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=245 train loss <loss>=3.46354417801\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:18 INFO 139866244298560] Epoch[25] Batch [245]#011Speed: 593.83 samples/sec#011loss=3.463544\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:18 INFO 139866244298560] Epoch[25] Batch[250] avg_epoch_loss=2.762306\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=250 train loss <loss>=3.32263092995\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:18 INFO 139866244298560] Epoch[25] Batch [250]#011Speed: 470.63 samples/sec#011loss=3.322631\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:19 INFO 139866244298560] Epoch[25] Batch[255] avg_epoch_loss=2.768042\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=255 train loss <loss>=3.05599050522\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:19 INFO 139866244298560] Epoch[25] Batch [255]#011Speed: 487.21 samples/sec#011loss=3.055991\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:19 INFO 139866244298560] Epoch[25] Batch[260] avg_epoch_loss=2.765628\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=260 train loss <loss>=2.64204399586\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:19 INFO 139866244298560] Epoch[25] Batch [260]#011Speed: 595.62 samples/sec#011loss=2.642044\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:20 INFO 139866244298560] Epoch[25] Batch[265] avg_epoch_loss=2.758123\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, batch=265 train loss <loss>=2.36636395454\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:20 INFO 139866244298560] Epoch[25] Batch [265]#011Speed: 581.62 samples/sec#011loss=2.366364\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:20 INFO 139866244298560] processed a total of 16987 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32615.280866622925, \"sum\": 32615.280866622925, \"min\": 32615.280866622925}}, \"EndTime\": 1599442820.511824, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442787.896482}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:20 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=520.827788895 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:20 INFO 139866244298560] #progress_metric: host=algo-1, completed 32 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=25, train loss <loss>=2.75812303393\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:20 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:20 INFO 139866244298560] Epoch[26] Batch[0] avg_epoch_loss=2.739937\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=0 train loss <loss>=2.73993659019\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:21 INFO 139866244298560] Epoch[26] Batch[5] avg_epoch_loss=2.370159\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=5 train loss <loss>=2.37015938759\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:21 INFO 139866244298560] Epoch[26] Batch [5]#011Speed: 589.76 samples/sec#011loss=2.370159\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:21 INFO 139866244298560] Epoch[26] Batch[10] avg_epoch_loss=2.329461\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=10 train loss <loss>=2.28062343597\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:21 INFO 139866244298560] Epoch[26] Batch [10]#011Speed: 473.52 samples/sec#011loss=2.280623\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:22 INFO 139866244298560] Epoch[26] Batch[15] avg_epoch_loss=2.477265\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=15 train loss <loss>=2.80243191719\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:22 INFO 139866244298560] Epoch[26] Batch [15]#011Speed: 598.54 samples/sec#011loss=2.802432\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:23 INFO 139866244298560] Epoch[26] Batch[20] avg_epoch_loss=2.511453\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=20 train loss <loss>=2.62085647583\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:23 INFO 139866244298560] Epoch[26] Batch [20]#011Speed: 472.66 samples/sec#011loss=2.620856\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:23 INFO 139866244298560] Epoch[26] Batch[25] avg_epoch_loss=2.585781\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=25 train loss <loss>=2.89795598984\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:23 INFO 139866244298560] Epoch[26] Batch [25]#011Speed: 596.07 samples/sec#011loss=2.897956\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:24 INFO 139866244298560] Epoch[26] Batch[30] avg_epoch_loss=2.618328\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=30 train loss <loss>=2.78757214546\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:24 INFO 139866244298560] Epoch[26] Batch [30]#011Speed: 477.72 samples/sec#011loss=2.787572\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:24 INFO 139866244298560] Epoch[26] Batch[35] avg_epoch_loss=2.632600\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=35 train loss <loss>=2.72109065056\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:24 INFO 139866244298560] Epoch[26] Batch [35]#011Speed: 590.15 samples/sec#011loss=2.721091\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:25 INFO 139866244298560] Epoch[26] Batch[40] avg_epoch_loss=2.636033\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=40 train loss <loss>=2.66075105667\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:25 INFO 139866244298560] Epoch[26] Batch [40]#011Speed: 475.32 samples/sec#011loss=2.660751\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:26 INFO 139866244298560] Epoch[26] Batch[45] avg_epoch_loss=2.634112\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=45 train loss <loss>=2.61835818291\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:26 INFO 139866244298560] Epoch[26] Batch [45]#011Speed: 589.52 samples/sec#011loss=2.618358\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:26 INFO 139866244298560] Epoch[26] Batch[50] avg_epoch_loss=2.614156\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=50 train loss <loss>=2.43055992126\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:26 INFO 139866244298560] Epoch[26] Batch [50]#011Speed: 487.96 samples/sec#011loss=2.430560\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:27 INFO 139866244298560] Epoch[26] Batch[55] avg_epoch_loss=2.583786\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=55 train loss <loss>=2.27401247025\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:27 INFO 139866244298560] Epoch[26] Batch [55]#011Speed: 596.78 samples/sec#011loss=2.274012\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:28 INFO 139866244298560] Epoch[26] Batch[60] avg_epoch_loss=2.575201\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=60 train loss <loss>=2.47904362679\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:28 INFO 139866244298560] Epoch[26] Batch [60]#011Speed: 477.24 samples/sec#011loss=2.479044\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:28 INFO 139866244298560] Epoch[26] Batch[65] avg_epoch_loss=2.576432\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=65 train loss <loss>=2.59145832062\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:28 INFO 139866244298560] Epoch[26] Batch [65]#011Speed: 594.23 samples/sec#011loss=2.591458\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:29 INFO 139866244298560] Epoch[26] Batch[70] avg_epoch_loss=2.605475\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=70 train loss <loss>=2.98884396553\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:29 INFO 139866244298560] Epoch[26] Batch [70]#011Speed: 480.88 samples/sec#011loss=2.988844\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:29 INFO 139866244298560] Epoch[26] Batch[75] avg_epoch_loss=2.638194\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=75 train loss <loss>=3.10279350281\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:29 INFO 139866244298560] Epoch[26] Batch [75]#011Speed: 592.48 samples/sec#011loss=3.102794\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:30 INFO 139866244298560] Epoch[26] Batch[80] avg_epoch_loss=2.681010\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=80 train loss <loss>=3.33182582855\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:30 INFO 139866244298560] Epoch[26] Batch [80]#011Speed: 480.91 samples/sec#011loss=3.331826\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:30 INFO 139866244298560] Epoch[26] Batch[85] avg_epoch_loss=2.719145\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=85 train loss <loss>=3.33693370819\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:30 INFO 139866244298560] Epoch[26] Batch [85]#011Speed: 585.18 samples/sec#011loss=3.336934\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:31 INFO 139866244298560] Epoch[26] Batch[90] avg_epoch_loss=2.709830\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=90 train loss <loss>=2.54961261749\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:31 INFO 139866244298560] Epoch[26] Batch [90]#011Speed: 480.26 samples/sec#011loss=2.549613\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:32 INFO 139866244298560] Epoch[26] Batch[95] avg_epoch_loss=2.710498\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=95 train loss <loss>=2.72264456749\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:32 INFO 139866244298560] Epoch[26] Batch [95]#011Speed: 595.55 samples/sec#011loss=2.722645\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:32 INFO 139866244298560] Epoch[26] Batch[100] avg_epoch_loss=2.706791\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=100 train loss <loss>=2.63561038971\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:32 INFO 139866244298560] Epoch[26] Batch [100]#011Speed: 476.64 samples/sec#011loss=2.635610\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:33 INFO 139866244298560] Epoch[26] Batch[105] avg_epoch_loss=2.692470\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=105 train loss <loss>=2.40319037437\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:33 INFO 139866244298560] Epoch[26] Batch [105]#011Speed: 591.53 samples/sec#011loss=2.403190\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:34 INFO 139866244298560] Epoch[26] Batch[110] avg_epoch_loss=2.679992\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=110 train loss <loss>=2.4154706955\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:34 INFO 139866244298560] Epoch[26] Batch [110]#011Speed: 476.16 samples/sec#011loss=2.415471\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:34 INFO 139866244298560] Epoch[26] Batch[115] avg_epoch_loss=2.665791\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=115 train loss <loss>=2.35051846504\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:34 INFO 139866244298560] Epoch[26] Batch [115]#011Speed: 478.01 samples/sec#011loss=2.350518\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:35 INFO 139866244298560] Epoch[26] Batch[120] avg_epoch_loss=2.651441\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=120 train loss <loss>=2.3185198307\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:35 INFO 139866244298560] Epoch[26] Batch [120]#011Speed: 585.65 samples/sec#011loss=2.318520\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:35 INFO 139866244298560] Epoch[26] Batch[125] avg_epoch_loss=2.644677\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=125 train loss <loss>=2.4809858799\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:35 INFO 139866244298560] Epoch[26] Batch [125]#011Speed: 475.76 samples/sec#011loss=2.480986\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:36 INFO 139866244298560] Epoch[26] Batch[130] avg_epoch_loss=2.656792\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=130 train loss <loss>=2.96210689545\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:36 INFO 139866244298560] Epoch[26] Batch [130]#011Speed: 587.89 samples/sec#011loss=2.962107\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:37 INFO 139866244298560] Epoch[26] Batch[135] avg_epoch_loss=2.673157\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=135 train loss <loss>=3.10190405846\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:37 INFO 139866244298560] Epoch[26] Batch [135]#011Speed: 466.95 samples/sec#011loss=3.101904\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:37 INFO 139866244298560] Epoch[26] Batch[140] avg_epoch_loss=2.684459\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=140 train loss <loss>=2.99187412262\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:37 INFO 139866244298560] Epoch[26] Batch [140]#011Speed: 596.61 samples/sec#011loss=2.991874\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:38 INFO 139866244298560] Epoch[26] Batch[145] avg_epoch_loss=2.684873\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=145 train loss <loss>=2.69654774666\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:38 INFO 139866244298560] Epoch[26] Batch [145]#011Speed: 477.40 samples/sec#011loss=2.696548\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:38 INFO 139866244298560] Epoch[26] Batch[150] avg_epoch_loss=2.679660\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=150 train loss <loss>=2.52743225098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:38 INFO 139866244298560] Epoch[26] Batch [150]#011Speed: 594.27 samples/sec#011loss=2.527432\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:39 INFO 139866244298560] Epoch[26] Batch[155] avg_epoch_loss=2.673246\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=155 train loss <loss>=2.47954640388\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:39 INFO 139866244298560] Epoch[26] Batch [155]#011Speed: 479.20 samples/sec#011loss=2.479546\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:40 INFO 139866244298560] Epoch[26] Batch[160] avg_epoch_loss=2.672886\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=160 train loss <loss>=2.66167154312\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:40 INFO 139866244298560] Epoch[26] Batch [160]#011Speed: 588.30 samples/sec#011loss=2.661672\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:40 INFO 139866244298560] Epoch[26] Batch[165] avg_epoch_loss=2.665585\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=165 train loss <loss>=2.43049049377\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:40 INFO 139866244298560] Epoch[26] Batch [165]#011Speed: 475.59 samples/sec#011loss=2.430490\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:41 INFO 139866244298560] Epoch[26] Batch[170] avg_epoch_loss=2.657416\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=170 train loss <loss>=2.38619399071\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:41 INFO 139866244298560] Epoch[26] Batch [170]#011Speed: 584.53 samples/sec#011loss=2.386194\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:42 INFO 139866244298560] Epoch[26] Batch[175] avg_epoch_loss=2.652337\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=175 train loss <loss>=2.47864589691\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:42 INFO 139866244298560] Epoch[26] Batch [175]#011Speed: 477.54 samples/sec#011loss=2.478646\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:42 INFO 139866244298560] Epoch[26] Batch[180] avg_epoch_loss=2.649878\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=180 train loss <loss>=2.56331193447\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:42 INFO 139866244298560] Epoch[26] Batch [180]#011Speed: 594.72 samples/sec#011loss=2.563312\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:43 INFO 139866244298560] Epoch[26] Batch[185] avg_epoch_loss=2.659862\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=185 train loss <loss>=3.02128505707\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:43 INFO 139866244298560] Epoch[26] Batch [185]#011Speed: 483.09 samples/sec#011loss=3.021285\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:43 INFO 139866244298560] Epoch[26] Batch[190] avg_epoch_loss=2.673396\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=190 train loss <loss>=3.17686042786\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:43 INFO 139866244298560] Epoch[26] Batch [190]#011Speed: 596.91 samples/sec#011loss=3.176860\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:44 INFO 139866244298560] Epoch[26] Batch[195] avg_epoch_loss=2.690717\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=195 train loss <loss>=3.35237569809\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:44 INFO 139866244298560] Epoch[26] Batch [195]#011Speed: 480.63 samples/sec#011loss=3.352376\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:44 INFO 139866244298560] Epoch[26] Batch[200] avg_epoch_loss=2.705889\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=200 train loss <loss>=3.30064783096\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:44 INFO 139866244298560] Epoch[26] Batch [200]#011Speed: 595.88 samples/sec#011loss=3.300648\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:45 INFO 139866244298560] Epoch[26] Batch[205] avg_epoch_loss=2.712779\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=205 train loss <loss>=2.98973526955\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:45 INFO 139866244298560] Epoch[26] Batch [205]#011Speed: 441.50 samples/sec#011loss=2.989735\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:46 INFO 139866244298560] Epoch[26] Batch[210] avg_epoch_loss=2.724095\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=210 train loss <loss>=3.1903172493\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:46 INFO 139866244298560] Epoch[26] Batch [210]#011Speed: 577.25 samples/sec#011loss=3.190317\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:46 INFO 139866244298560] Epoch[26] Batch[215] avg_epoch_loss=2.717625\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=215 train loss <loss>=2.44459843636\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:46 INFO 139866244298560] Epoch[26] Batch [215]#011Speed: 471.17 samples/sec#011loss=2.444598\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:47 INFO 139866244298560] Epoch[26] Batch[220] avg_epoch_loss=2.713910\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=220 train loss <loss>=2.55342640877\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:47 INFO 139866244298560] Epoch[26] Batch [220]#011Speed: 589.75 samples/sec#011loss=2.553426\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:48 INFO 139866244298560] Epoch[26] Batch[225] avg_epoch_loss=2.710493\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=225 train loss <loss>=2.55945134163\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:48 INFO 139866244298560] Epoch[26] Batch [225]#011Speed: 468.15 samples/sec#011loss=2.559451\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:48 INFO 139866244298560] Epoch[26] Batch[230] avg_epoch_loss=2.707646\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=230 train loss <loss>=2.57896699905\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:48 INFO 139866244298560] Epoch[26] Batch [230]#011Speed: 483.95 samples/sec#011loss=2.578967\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:49 INFO 139866244298560] Epoch[26] Batch[235] avg_epoch_loss=2.711471\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=235 train loss <loss>=2.88818855286\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:49 INFO 139866244298560] Epoch[26] Batch [235]#011Speed: 593.29 samples/sec#011loss=2.888189\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:50 INFO 139866244298560] Epoch[26] Batch[240] avg_epoch_loss=2.721310\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=240 train loss <loss>=3.18570203781\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:50 INFO 139866244298560] Epoch[26] Batch [240]#011Speed: 485.85 samples/sec#011loss=3.185702\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:50 INFO 139866244298560] Epoch[26] Batch[245] avg_epoch_loss=2.736804\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=245 train loss <loss>=3.48364005089\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:50 INFO 139866244298560] Epoch[26] Batch [245]#011Speed: 592.70 samples/sec#011loss=3.483640\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:51 INFO 139866244298560] Epoch[26] Batch[250] avg_epoch_loss=2.749055\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=250 train loss <loss>=3.35177874565\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:51 INFO 139866244298560] Epoch[26] Batch [250]#011Speed: 466.45 samples/sec#011loss=3.351779\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:51 INFO 139866244298560] Epoch[26] Batch[255] avg_epoch_loss=2.760878\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=255 train loss <loss>=3.35439429283\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:51 INFO 139866244298560] Epoch[26] Batch [255]#011Speed: 593.79 samples/sec#011loss=3.354394\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:52 INFO 139866244298560] Epoch[26] Batch[260] avg_epoch_loss=2.756187\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=260 train loss <loss>=2.51600043774\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:52 INFO 139866244298560] Epoch[26] Batch [260]#011Speed: 467.01 samples/sec#011loss=2.516000\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:53 INFO 139866244298560] Epoch[26] Batch[265] avg_epoch_loss=2.757109\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, batch=265 train loss <loss>=2.80524888039\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:53 INFO 139866244298560] Epoch[26] Batch [265]#011Speed: 593.69 samples/sec#011loss=2.805249\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:53 INFO 139866244298560] processed a total of 17227 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32924.06606674194, \"sum\": 32924.06606674194, \"min\": 32924.06606674194}}, \"EndTime\": 1599442853.436585, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442820.511897}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:53 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=523.232756738 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:53 INFO 139866244298560] #progress_metric: host=algo-1, completed 33 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=26, train loss <loss>=2.75067087787\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:53 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:53 INFO 139866244298560] Epoch[27] Batch[0] avg_epoch_loss=2.277208\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=0 train loss <loss>=2.27720761299\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:54 INFO 139866244298560] Epoch[27] Batch[5] avg_epoch_loss=2.098404\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=5 train loss <loss>=2.09840442737\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:54 INFO 139866244298560] Epoch[27] Batch [5]#011Speed: 588.90 samples/sec#011loss=2.098404\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:54 INFO 139866244298560] Epoch[27] Batch[10] avg_epoch_loss=2.182069\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=10 train loss <loss>=2.28246569633\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:54 INFO 139866244298560] Epoch[27] Batch [10]#011Speed: 471.83 samples/sec#011loss=2.282466\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:55 INFO 139866244298560] Epoch[27] Batch[15] avg_epoch_loss=2.406781\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=15 train loss <loss>=2.90114793777\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:55 INFO 139866244298560] Epoch[27] Batch [15]#011Speed: 510.23 samples/sec#011loss=2.901148\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:56 INFO 139866244298560] Epoch[27] Batch[20] avg_epoch_loss=2.478395\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=20 train loss <loss>=2.70755834579\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:56 INFO 139866244298560] Epoch[27] Batch [20]#011Speed: 475.95 samples/sec#011loss=2.707558\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:56 INFO 139866244298560] Epoch[27] Batch[25] avg_epoch_loss=2.538233\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=25 train loss <loss>=2.78955411911\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:56 INFO 139866244298560] Epoch[27] Batch [25]#011Speed: 598.06 samples/sec#011loss=2.789554\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:57 INFO 139866244298560] Epoch[27] Batch[30] avg_epoch_loss=2.538947\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=30 train loss <loss>=2.54265832901\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:57 INFO 139866244298560] Epoch[27] Batch [30]#011Speed: 478.11 samples/sec#011loss=2.542658\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:57 INFO 139866244298560] Epoch[27] Batch[35] avg_epoch_loss=2.529671\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=35 train loss <loss>=2.47216486931\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:57 INFO 139866244298560] Epoch[27] Batch [35]#011Speed: 598.73 samples/sec#011loss=2.472165\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:58 INFO 139866244298560] Epoch[27] Batch[40] avg_epoch_loss=2.529817\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=40 train loss <loss>=2.53086137772\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:58 INFO 139866244298560] Epoch[27] Batch [40]#011Speed: 473.53 samples/sec#011loss=2.530861\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:59 INFO 139866244298560] Epoch[27] Batch[45] avg_epoch_loss=2.526026\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=45 train loss <loss>=2.49494109154\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:59 INFO 139866244298560] Epoch[27] Batch [45]#011Speed: 591.65 samples/sec#011loss=2.494941\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:59 INFO 139866244298560] Epoch[27] Batch[50] avg_epoch_loss=2.491867\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=50 train loss <loss>=2.17760198116\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:40:59 INFO 139866244298560] Epoch[27] Batch [50]#011Speed: 480.55 samples/sec#011loss=2.177602\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:00 INFO 139866244298560] Epoch[27] Batch[55] avg_epoch_loss=2.472356\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=55 train loss <loss>=2.27335355282\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:00 INFO 139866244298560] Epoch[27] Batch [55]#011Speed: 525.60 samples/sec#011loss=2.273354\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:01 INFO 139866244298560] Epoch[27] Batch[60] avg_epoch_loss=2.505618\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=60 train loss <loss>=2.8781414032\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:01 INFO 139866244298560] Epoch[27] Batch [60]#011Speed: 475.69 samples/sec#011loss=2.878141\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:01 INFO 139866244298560] Epoch[27] Batch[65] avg_epoch_loss=2.515725\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=65 train loss <loss>=2.63903522491\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:01 INFO 139866244298560] Epoch[27] Batch [65]#011Speed: 590.16 samples/sec#011loss=2.639035\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:02 INFO 139866244298560] Epoch[27] Batch[70] avg_epoch_loss=2.560147\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=70 train loss <loss>=3.14652323723\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:02 INFO 139866244298560] Epoch[27] Batch [70]#011Speed: 463.98 samples/sec#011loss=3.146523\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:03 INFO 139866244298560] Epoch[27] Batch[75] avg_epoch_loss=2.602667\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=75 train loss <loss>=3.20644493103\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:03 INFO 139866244298560] Epoch[27] Batch [75]#011Speed: 486.76 samples/sec#011loss=3.206445\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:03 INFO 139866244298560] Epoch[27] Batch[80] avg_epoch_loss=2.633310\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=80 train loss <loss>=3.09908342361\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:03 INFO 139866244298560] Epoch[27] Batch [80]#011Speed: 579.75 samples/sec#011loss=3.099083\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:04 INFO 139866244298560] Epoch[27] Batch[85] avg_epoch_loss=2.649093\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=85 train loss <loss>=2.90478496552\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:04 INFO 139866244298560] Epoch[27] Batch [85]#011Speed: 477.45 samples/sec#011loss=2.904785\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:04 INFO 139866244298560] Epoch[27] Batch[90] avg_epoch_loss=2.647280\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=90 train loss <loss>=2.61608333588\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:04 INFO 139866244298560] Epoch[27] Batch [90]#011Speed: 592.47 samples/sec#011loss=2.616083\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:05 INFO 139866244298560] Epoch[27] Batch[95] avg_epoch_loss=2.634444\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=95 train loss <loss>=2.40083723068\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:05 INFO 139866244298560] Epoch[27] Batch [95]#011Speed: 416.52 samples/sec#011loss=2.400837\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:06 INFO 139866244298560] Epoch[27] Batch[100] avg_epoch_loss=2.623432\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=100 train loss <loss>=2.4120010376\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:06 INFO 139866244298560] Epoch[27] Batch [100]#011Speed: 590.62 samples/sec#011loss=2.412001\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:06 INFO 139866244298560] Epoch[27] Batch[105] avg_epoch_loss=2.606142\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=105 train loss <loss>=2.25689148903\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:06 INFO 139866244298560] Epoch[27] Batch [105]#011Speed: 481.62 samples/sec#011loss=2.256891\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:07 INFO 139866244298560] Epoch[27] Batch[110] avg_epoch_loss=2.589426\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=110 train loss <loss>=2.23503563404\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:07 INFO 139866244298560] Epoch[27] Batch [110]#011Speed: 584.46 samples/sec#011loss=2.235036\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:07 INFO 139866244298560] Epoch[27] Batch[115] avg_epoch_loss=2.593867\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=115 train loss <loss>=2.69244890213\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:07 INFO 139866244298560] Epoch[27] Batch [115]#011Speed: 477.77 samples/sec#011loss=2.692449\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:08 INFO 139866244298560] Epoch[27] Batch[120] avg_epoch_loss=2.605592\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=120 train loss <loss>=2.87763023376\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:08 INFO 139866244298560] Epoch[27] Batch [120]#011Speed: 593.30 samples/sec#011loss=2.877630\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:09 INFO 139866244298560] Epoch[27] Batch[125] avg_epoch_loss=2.617266\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=125 train loss <loss>=2.89977693558\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:09 INFO 139866244298560] Epoch[27] Batch [125]#011Speed: 480.09 samples/sec#011loss=2.899777\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:09 INFO 139866244298560] Epoch[27] Batch[130] avg_epoch_loss=2.632651\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=130 train loss <loss>=3.02033867836\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:09 INFO 139866244298560] Epoch[27] Batch [130]#011Speed: 590.71 samples/sec#011loss=3.020339\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:10 INFO 139866244298560] Epoch[27] Batch[135] avg_epoch_loss=2.634840\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=135 train loss <loss>=2.69219675064\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:10 INFO 139866244298560] Epoch[27] Batch [135]#011Speed: 463.78 samples/sec#011loss=2.692197\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:10 INFO 139866244298560] Epoch[27] Batch[140] avg_epoch_loss=2.633966\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=140 train loss <loss>=2.61019802094\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:10 INFO 139866244298560] Epoch[27] Batch [140]#011Speed: 560.65 samples/sec#011loss=2.610198\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:11 INFO 139866244298560] Epoch[27] Batch[145] avg_epoch_loss=2.621507\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=145 train loss <loss>=2.27017173767\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:11 INFO 139866244298560] Epoch[27] Batch [145]#011Speed: 472.60 samples/sec#011loss=2.270172\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:12 INFO 139866244298560] Epoch[27] Batch[150] avg_epoch_loss=2.609213\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=150 train loss <loss>=2.25021774769\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:12 INFO 139866244298560] Epoch[27] Batch [150]#011Speed: 590.37 samples/sec#011loss=2.250218\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:12 INFO 139866244298560] Epoch[27] Batch[155] avg_epoch_loss=2.599205\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=155 train loss <loss>=2.29695410728\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:12 INFO 139866244298560] Epoch[27] Batch [155]#011Speed: 480.68 samples/sec#011loss=2.296954\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:13 INFO 139866244298560] Epoch[27] Batch[160] avg_epoch_loss=2.599713\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=160 train loss <loss>=2.61556801796\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:13 INFO 139866244298560] Epoch[27] Batch [160]#011Speed: 594.76 samples/sec#011loss=2.615568\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:14 INFO 139866244298560] Epoch[27] Batch[165] avg_epoch_loss=2.596691\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=165 train loss <loss>=2.49938397408\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:14 INFO 139866244298560] Epoch[27] Batch [165]#011Speed: 464.37 samples/sec#011loss=2.499384\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:14 INFO 139866244298560] Epoch[27] Batch[170] avg_epoch_loss=2.592900\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=170 train loss <loss>=2.4670539856\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:14 INFO 139866244298560] Epoch[27] Batch [170]#011Speed: 585.19 samples/sec#011loss=2.467054\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:15 INFO 139866244298560] Epoch[27] Batch[175] avg_epoch_loss=2.613855\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=175 train loss <loss>=3.33051562309\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:15 INFO 139866244298560] Epoch[27] Batch [175]#011Speed: 470.26 samples/sec#011loss=3.330516\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:16 INFO 139866244298560] Epoch[27] Batch[180] avg_epoch_loss=2.639790\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=180 train loss <loss>=3.55270557404\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:16 INFO 139866244298560] Epoch[27] Batch [180]#011Speed: 418.65 samples/sec#011loss=3.552706\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:16 INFO 139866244298560] Epoch[27] Batch[185] avg_epoch_loss=2.660058\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=185 train loss <loss>=3.39374761581\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:16 INFO 139866244298560] Epoch[27] Batch [185]#011Speed: 590.26 samples/sec#011loss=3.393748\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:17 INFO 139866244298560] Epoch[27] Batch[190] avg_epoch_loss=2.678342\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=190 train loss <loss>=3.35851912498\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:17 INFO 139866244298560] Epoch[27] Batch [190]#011Speed: 476.51 samples/sec#011loss=3.358519\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:17 INFO 139866244298560] Epoch[27] Batch[195] avg_epoch_loss=2.674760\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=195 train loss <loss>=2.53792996407\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:17 INFO 139866244298560] Epoch[27] Batch [195]#011Speed: 589.30 samples/sec#011loss=2.537930\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:18 INFO 139866244298560] Epoch[27] Batch[200] avg_epoch_loss=2.668325\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=200 train loss <loss>=2.41606936455\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:18 INFO 139866244298560] Epoch[27] Batch [200]#011Speed: 476.88 samples/sec#011loss=2.416069\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:19 INFO 139866244298560] Epoch[27] Batch[205] avg_epoch_loss=2.670413\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=205 train loss <loss>=2.7543364048\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:19 INFO 139866244298560] Epoch[27] Batch [205]#011Speed: 594.51 samples/sec#011loss=2.754336\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:19 INFO 139866244298560] Epoch[27] Batch[210] avg_epoch_loss=2.668021\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=210 train loss <loss>=2.56946253777\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:19 INFO 139866244298560] Epoch[27] Batch [210]#011Speed: 480.59 samples/sec#011loss=2.569463\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:20 INFO 139866244298560] Epoch[27] Batch[215] avg_epoch_loss=2.663233\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=215 train loss <loss>=2.4611913681\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:20 INFO 139866244298560] Epoch[27] Batch [215]#011Speed: 595.58 samples/sec#011loss=2.461191\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:20 INFO 139866244298560] Epoch[27] Batch[220] avg_epoch_loss=2.673340\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=220 train loss <loss>=3.10995025635\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:20 INFO 139866244298560] Epoch[27] Batch [220]#011Speed: 422.14 samples/sec#011loss=3.109950\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:21 INFO 139866244298560] Epoch[27] Batch[225] avg_epoch_loss=2.682860\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=225 train loss <loss>=3.10362987518\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:21 INFO 139866244298560] Epoch[27] Batch [225]#011Speed: 591.65 samples/sec#011loss=3.103630\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:22 INFO 139866244298560] Epoch[27] Batch[230] avg_epoch_loss=2.696219\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=230 train loss <loss>=3.30008149147\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:22 INFO 139866244298560] Epoch[27] Batch [230]#011Speed: 474.61 samples/sec#011loss=3.300081\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:22 INFO 139866244298560] Epoch[27] Batch[235] avg_epoch_loss=2.711775\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=235 train loss <loss>=3.43046975136\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:22 INFO 139866244298560] Epoch[27] Batch [235]#011Speed: 596.05 samples/sec#011loss=3.430470\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:23 INFO 139866244298560] Epoch[27] Batch[240] avg_epoch_loss=2.718601\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=240 train loss <loss>=3.04076981544\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:23 INFO 139866244298560] Epoch[27] Batch [240]#011Speed: 481.94 samples/sec#011loss=3.040770\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:23 INFO 139866244298560] Epoch[27] Batch[245] avg_epoch_loss=2.721382\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=245 train loss <loss>=2.85541462898\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:23 INFO 139866244298560] Epoch[27] Batch [245]#011Speed: 595.75 samples/sec#011loss=2.855415\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:24 INFO 139866244298560] Epoch[27] Batch[250] avg_epoch_loss=2.717546\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=250 train loss <loss>=2.52881846428\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:24 INFO 139866244298560] Epoch[27] Batch [250]#011Speed: 472.25 samples/sec#011loss=2.528818\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:25 INFO 139866244298560] Epoch[27] Batch[255] avg_epoch_loss=2.712853\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=255 train loss <loss>=2.47726175785\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:25 INFO 139866244298560] Epoch[27] Batch [255]#011Speed: 593.44 samples/sec#011loss=2.477262\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:25 INFO 139866244298560] Epoch[27] Batch[260] avg_epoch_loss=2.708156\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=260 train loss <loss>=2.46765298843\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:25 INFO 139866244298560] Epoch[27] Batch [260]#011Speed: 474.86 samples/sec#011loss=2.467653\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:26 INFO 139866244298560] Epoch[27] Batch[265] avg_epoch_loss=2.704105\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=265 train loss <loss>=2.49266223907\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:26 INFO 139866244298560] Epoch[27] Batch [265]#011Speed: 534.13 samples/sec#011loss=2.492662\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:27 INFO 139866244298560] Epoch[27] Batch[270] avg_epoch_loss=2.728040\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, batch=270 train loss <loss>=4.00139322281\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:27 INFO 139866244298560] Epoch[27] Batch [270]#011Speed: 547.67 samples/sec#011loss=4.001393\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:27 INFO 139866244298560] processed a total of 17308 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33589.01000022888, \"sum\": 33589.01000022888, \"min\": 33589.01000022888}}, \"EndTime\": 1599442887.02628, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442853.436646}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:27 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=515.286009533 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:27 INFO 139866244298560] #progress_metric: host=algo-1, completed 35 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=27, train loss <loss>=2.72804014181\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:27 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:27 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_e10faff8-29e3-4cba-acb5-59790a977495-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.87590980529785, \"sum\": 17.87590980529785, \"min\": 17.87590980529785}}, \"EndTime\": 1599442887.044892, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442887.026349}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:27 INFO 139866244298560] Epoch[28] Batch[0] avg_epoch_loss=1.935617\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=0 train loss <loss>=1.93561732769\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:27 INFO 139866244298560] Epoch[28] Batch[5] avg_epoch_loss=2.164055\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=5 train loss <loss>=2.16405489047\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:27 INFO 139866244298560] Epoch[28] Batch [5]#011Speed: 594.77 samples/sec#011loss=2.164055\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:28 INFO 139866244298560] Epoch[28] Batch[10] avg_epoch_loss=2.221194\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=10 train loss <loss>=2.28976140022\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:28 INFO 139866244298560] Epoch[28] Batch [10]#011Speed: 474.81 samples/sec#011loss=2.289761\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:29 INFO 139866244298560] Epoch[28] Batch[15] avg_epoch_loss=2.387926\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=15 train loss <loss>=2.75473713875\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:29 INFO 139866244298560] Epoch[28] Batch [15]#011Speed: 586.00 samples/sec#011loss=2.754737\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:29 INFO 139866244298560] Epoch[28] Batch[20] avg_epoch_loss=2.492451\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=20 train loss <loss>=2.82692961693\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:29 INFO 139866244298560] Epoch[28] Batch [20]#011Speed: 470.56 samples/sec#011loss=2.826930\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:30 INFO 139866244298560] Epoch[28] Batch[25] avg_epoch_loss=2.561986\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=25 train loss <loss>=2.85403208733\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:30 INFO 139866244298560] Epoch[28] Batch [25]#011Speed: 588.93 samples/sec#011loss=2.854032\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:30 INFO 139866244298560] Epoch[28] Batch[30] avg_epoch_loss=2.589123\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=30 train loss <loss>=2.73023791313\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:30 INFO 139866244298560] Epoch[28] Batch [30]#011Speed: 472.01 samples/sec#011loss=2.730238\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:31 INFO 139866244298560] Epoch[28] Batch[35] avg_epoch_loss=2.548858\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=35 train loss <loss>=2.29921660423\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:31 INFO 139866244298560] Epoch[28] Batch [35]#011Speed: 526.21 samples/sec#011loss=2.299217\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:32 INFO 139866244298560] Epoch[28] Batch[40] avg_epoch_loss=2.531439\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=40 train loss <loss>=2.40601997375\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:32 INFO 139866244298560] Epoch[28] Batch [40]#011Speed: 481.96 samples/sec#011loss=2.406020\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:32 INFO 139866244298560] Epoch[28] Batch[45] avg_epoch_loss=2.506081\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=45 train loss <loss>=2.2981487751\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:32 INFO 139866244298560] Epoch[28] Batch [45]#011Speed: 595.08 samples/sec#011loss=2.298149\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:33 INFO 139866244298560] Epoch[28] Batch[50] avg_epoch_loss=2.508816\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=50 train loss <loss>=2.53397741318\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:33 INFO 139866244298560] Epoch[28] Batch [50]#011Speed: 478.93 samples/sec#011loss=2.533977\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:33 INFO 139866244298560] Epoch[28] Batch[55] avg_epoch_loss=2.489822\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=55 train loss <loss>=2.29608302116\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:33 INFO 139866244298560] Epoch[28] Batch [55]#011Speed: 595.99 samples/sec#011loss=2.296083\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:34 INFO 139866244298560] Epoch[28] Batch[60] avg_epoch_loss=2.515373\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=60 train loss <loss>=2.80154194832\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:34 INFO 139866244298560] Epoch[28] Batch [60]#011Speed: 470.47 samples/sec#011loss=2.801542\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:35 INFO 139866244298560] Epoch[28] Batch[65] avg_epoch_loss=2.520632\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=65 train loss <loss>=2.58478960991\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:35 INFO 139866244298560] Epoch[28] Batch [65]#011Speed: 594.56 samples/sec#011loss=2.584790\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:35 INFO 139866244298560] Epoch[28] Batch[70] avg_epoch_loss=2.558148\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=70 train loss <loss>=3.05336341858\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:35 INFO 139866244298560] Epoch[28] Batch [70]#011Speed: 473.49 samples/sec#011loss=3.053363\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:36 INFO 139866244298560] Epoch[28] Batch[75] avg_epoch_loss=2.601756\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=75 train loss <loss>=3.22098994255\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:36 INFO 139866244298560] Epoch[28] Batch [75]#011Speed: 550.82 samples/sec#011loss=3.220990\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:37 INFO 139866244298560] Epoch[28] Batch[80] avg_epoch_loss=2.630605\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=80 train loss <loss>=3.06911211014\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:37 INFO 139866244298560] Epoch[28] Batch [80]#011Speed: 462.86 samples/sec#011loss=3.069112\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:37 INFO 139866244298560] Epoch[28] Batch[85] avg_epoch_loss=2.657732\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=85 train loss <loss>=3.09718441963\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:37 INFO 139866244298560] Epoch[28] Batch [85]#011Speed: 590.50 samples/sec#011loss=3.097184\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:38 INFO 139866244298560] Epoch[28] Batch[90] avg_epoch_loss=2.643866\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=90 train loss <loss>=2.4053747654\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:38 INFO 139866244298560] Epoch[28] Batch [90]#011Speed: 474.46 samples/sec#011loss=2.405375\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:38 INFO 139866244298560] Epoch[28] Batch[95] avg_epoch_loss=2.634380\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=95 train loss <loss>=2.46172294617\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:38 INFO 139866244298560] Epoch[28] Batch [95]#011Speed: 596.08 samples/sec#011loss=2.461723\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:39 INFO 139866244298560] Epoch[28] Batch[100] avg_epoch_loss=2.625199\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=100 train loss <loss>=2.44892916679\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:39 INFO 139866244298560] Epoch[28] Batch [100]#011Speed: 466.90 samples/sec#011loss=2.448929\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:40 INFO 139866244298560] Epoch[28] Batch[105] avg_epoch_loss=2.616615\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=105 train loss <loss>=2.4432268858\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:40 INFO 139866244298560] Epoch[28] Batch [105]#011Speed: 594.89 samples/sec#011loss=2.443227\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:40 INFO 139866244298560] Epoch[28] Batch[110] avg_epoch_loss=2.604151\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=110 train loss <loss>=2.33991737366\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:40 INFO 139866244298560] Epoch[28] Batch [110]#011Speed: 473.40 samples/sec#011loss=2.339917\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:41 INFO 139866244298560] Epoch[28] Batch[115] avg_epoch_loss=2.588008\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=115 train loss <loss>=2.22962899208\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:41 INFO 139866244298560] Epoch[28] Batch [115]#011Speed: 517.54 samples/sec#011loss=2.229629\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:42 INFO 139866244298560] Epoch[28] Batch[120] avg_epoch_loss=2.589320\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=120 train loss <loss>=2.61975617409\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:42 INFO 139866244298560] Epoch[28] Batch [120]#011Speed: 486.64 samples/sec#011loss=2.619756\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:42 INFO 139866244298560] Epoch[28] Batch[125] avg_epoch_loss=2.589297\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=125 train loss <loss>=2.5887462616\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:42 INFO 139866244298560] Epoch[28] Batch [125]#011Speed: 592.59 samples/sec#011loss=2.588746\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:43 INFO 139866244298560] Epoch[28] Batch[130] avg_epoch_loss=2.610506\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=130 train loss <loss>=3.14495186806\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:43 INFO 139866244298560] Epoch[28] Batch [130]#011Speed: 487.05 samples/sec#011loss=3.144952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:43 INFO 139866244298560] Epoch[28] Batch[135] avg_epoch_loss=2.627437\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=135 train loss <loss>=3.07103271484\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:43 INFO 139866244298560] Epoch[28] Batch [135]#011Speed: 482.36 samples/sec#011loss=3.071033\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:44 INFO 139866244298560] Epoch[28] Batch[140] avg_epoch_loss=2.623827\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=140 train loss <loss>=2.52563462257\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:44 INFO 139866244298560] Epoch[28] Batch [140]#011Speed: 591.14 samples/sec#011loss=2.525635\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:45 INFO 139866244298560] Epoch[28] Batch[145] avg_epoch_loss=2.613200\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=145 train loss <loss>=2.3135414362\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:45 INFO 139866244298560] Epoch[28] Batch [145]#011Speed: 477.42 samples/sec#011loss=2.313541\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:45 INFO 139866244298560] Epoch[28] Batch[150] avg_epoch_loss=2.600001\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=150 train loss <loss>=2.21456785202\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:45 INFO 139866244298560] Epoch[28] Batch [150]#011Speed: 526.91 samples/sec#011loss=2.214568\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:46 INFO 139866244298560] Epoch[28] Batch[155] avg_epoch_loss=2.597332\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=155 train loss <loss>=2.51674132347\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:46 INFO 139866244298560] Epoch[28] Batch [155]#011Speed: 444.58 samples/sec#011loss=2.516741\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:47 INFO 139866244298560] Epoch[28] Batch[160] avg_epoch_loss=2.598016\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=160 train loss <loss>=2.61933841705\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:47 INFO 139866244298560] Epoch[28] Batch [160]#011Speed: 599.30 samples/sec#011loss=2.619338\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:47 INFO 139866244298560] Epoch[28] Batch[165] avg_epoch_loss=2.588164\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=165 train loss <loss>=2.27095227242\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:47 INFO 139866244298560] Epoch[28] Batch [165]#011Speed: 465.97 samples/sec#011loss=2.270952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:48 INFO 139866244298560] Epoch[28] Batch[170] avg_epoch_loss=2.587026\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=170 train loss <loss>=2.54922785759\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:48 INFO 139866244298560] Epoch[28] Batch [170]#011Speed: 590.44 samples/sec#011loss=2.549228\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:48 INFO 139866244298560] Epoch[28] Batch[175] avg_epoch_loss=2.585369\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=175 train loss <loss>=2.52869367599\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:48 INFO 139866244298560] Epoch[28] Batch [175]#011Speed: 477.19 samples/sec#011loss=2.528694\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:49 INFO 139866244298560] Epoch[28] Batch[180] avg_epoch_loss=2.598995\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=180 train loss <loss>=3.0786593914\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:49 INFO 139866244298560] Epoch[28] Batch [180]#011Speed: 591.32 samples/sec#011loss=3.078659\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:50 INFO 139866244298560] Epoch[28] Batch[185] avg_epoch_loss=2.611817\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=185 train loss <loss>=3.07596182823\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:50 INFO 139866244298560] Epoch[28] Batch [185]#011Speed: 478.18 samples/sec#011loss=3.075962\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:50 INFO 139866244298560] Epoch[28] Batch[190] avg_epoch_loss=2.629533\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=190 train loss <loss>=3.28857746124\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:50 INFO 139866244298560] Epoch[28] Batch [190]#011Speed: 588.14 samples/sec#011loss=3.288577\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:51 INFO 139866244298560] Epoch[28] Batch[195] avg_epoch_loss=2.643469\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=195 train loss <loss>=3.17579202652\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:51 INFO 139866244298560] Epoch[28] Batch [195]#011Speed: 458.93 samples/sec#011loss=3.175792\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:51 INFO 139866244298560] Epoch[28] Batch[200] avg_epoch_loss=2.655982\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=200 train loss <loss>=3.14652018547\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:51 INFO 139866244298560] Epoch[28] Batch [200]#011Speed: 529.27 samples/sec#011loss=3.146520\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:52 INFO 139866244298560] Epoch[28] Batch[205] avg_epoch_loss=2.659665\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=205 train loss <loss>=2.80772652626\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:52 INFO 139866244298560] Epoch[28] Batch [205]#011Speed: 470.02 samples/sec#011loss=2.807727\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:53 INFO 139866244298560] Epoch[28] Batch[210] avg_epoch_loss=2.660610\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=210 train loss <loss>=2.69953927994\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:53 INFO 139866244298560] Epoch[28] Batch [210]#011Speed: 592.02 samples/sec#011loss=2.699539\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:53 INFO 139866244298560] Epoch[28] Batch[215] avg_epoch_loss=2.653102\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=215 train loss <loss>=2.33624668121\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:53 INFO 139866244298560] Epoch[28] Batch [215]#011Speed: 472.02 samples/sec#011loss=2.336247\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:54 INFO 139866244298560] Epoch[28] Batch[220] avg_epoch_loss=2.650240\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=220 train loss <loss>=2.52662110329\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:54 INFO 139866244298560] Epoch[28] Batch [220]#011Speed: 597.17 samples/sec#011loss=2.526621\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:55 INFO 139866244298560] Epoch[28] Batch[225] avg_epoch_loss=2.649073\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=225 train loss <loss>=2.59745726585\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:55 INFO 139866244298560] Epoch[28] Batch [225]#011Speed: 475.62 samples/sec#011loss=2.597457\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:55 INFO 139866244298560] Epoch[28] Batch[230] avg_epoch_loss=2.655675\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=230 train loss <loss>=2.95412869453\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:55 INFO 139866244298560] Epoch[28] Batch [230]#011Speed: 583.61 samples/sec#011loss=2.954129\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:56 INFO 139866244298560] Epoch[28] Batch[235] avg_epoch_loss=2.671161\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=235 train loss <loss>=3.38661584854\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:56 INFO 139866244298560] Epoch[28] Batch [235]#011Speed: 481.45 samples/sec#011loss=3.386616\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:56 INFO 139866244298560] Epoch[28] Batch[240] avg_epoch_loss=2.685177\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=240 train loss <loss>=3.34671525955\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:56 INFO 139866244298560] Epoch[28] Batch [240]#011Speed: 494.87 samples/sec#011loss=3.346715\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:57 INFO 139866244298560] Epoch[28] Batch[245] avg_epoch_loss=2.702816\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=245 train loss <loss>=3.55301289558\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:57 INFO 139866244298560] Epoch[28] Batch [245]#011Speed: 478.83 samples/sec#011loss=3.553013\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:58 INFO 139866244298560] Epoch[28] Batch[250] avg_epoch_loss=2.717636\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=250 train loss <loss>=3.44675264359\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:58 INFO 139866244298560] Epoch[28] Batch [250]#011Speed: 594.80 samples/sec#011loss=3.446753\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:58 INFO 139866244298560] Epoch[28] Batch[255] avg_epoch_loss=2.722621\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=255 train loss <loss>=2.9728905201\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:58 INFO 139866244298560] Epoch[28] Batch [255]#011Speed: 467.55 samples/sec#011loss=2.972891\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:59 INFO 139866244298560] Epoch[28] Batch[260] avg_epoch_loss=2.732074\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=260 train loss <loss>=3.21605863571\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:41:59 INFO 139866244298560] Epoch[28] Batch [260]#011Speed: 595.32 samples/sec#011loss=3.216059\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:00 INFO 139866244298560] Epoch[28] Batch[265] avg_epoch_loss=2.726069\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=265 train loss <loss>=2.41262745857\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:00 INFO 139866244298560] Epoch[28] Batch [265]#011Speed: 477.47 samples/sec#011loss=2.412627\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:00 INFO 139866244298560] Epoch[28] Batch[270] avg_epoch_loss=2.724102\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, batch=270 train loss <loss>=2.61944928169\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:00 INFO 139866244298560] Epoch[28] Batch [270]#011Speed: 581.97 samples/sec#011loss=2.619449\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:00 INFO 139866244298560] processed a total of 17343 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33536.15212440491, \"sum\": 33536.15212440491, \"min\": 33536.15212440491}}, \"EndTime\": 1599442920.581178, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442887.044967}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:00 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=517.141760896 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:00 INFO 139866244298560] #progress_metric: host=algo-1, completed 36 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=28, train loss <loss>=2.72410200839\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:00 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:00 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_38081846-65d7-4639-a07f-b7ec6f113fb4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.115997314453125, \"sum\": 18.115997314453125, \"min\": 18.115997314453125}}, \"EndTime\": 1599442920.600017, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442920.581251}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:00 INFO 139866244298560] Epoch[29] Batch[0] avg_epoch_loss=2.148642\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=0 train loss <loss>=2.14864182472\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:01 INFO 139866244298560] Epoch[29] Batch[5] avg_epoch_loss=2.282513\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=5 train loss <loss>=2.28251349926\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:01 INFO 139866244298560] Epoch[29] Batch [5]#011Speed: 586.67 samples/sec#011loss=2.282513\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:02 INFO 139866244298560] Epoch[29] Batch[10] avg_epoch_loss=2.263193\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=10 train loss <loss>=2.24000742435\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:02 INFO 139866244298560] Epoch[29] Batch [10]#011Speed: 423.18 samples/sec#011loss=2.240007\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:02 INFO 139866244298560] Epoch[29] Batch[15] avg_epoch_loss=2.426111\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=15 train loss <loss>=2.78453087807\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:02 INFO 139866244298560] Epoch[29] Batch [15]#011Speed: 592.55 samples/sec#011loss=2.784531\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:03 INFO 139866244298560] Epoch[29] Batch[20] avg_epoch_loss=2.486693\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=20 train loss <loss>=2.68055768013\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:03 INFO 139866244298560] Epoch[29] Batch [20]#011Speed: 472.38 samples/sec#011loss=2.680558\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:03 INFO 139866244298560] Epoch[29] Batch[25] avg_epoch_loss=2.557029\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=25 train loss <loss>=2.85243911743\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:03 INFO 139866244298560] Epoch[29] Batch [25]#011Speed: 592.10 samples/sec#011loss=2.852439\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:04 INFO 139866244298560] Epoch[29] Batch[30] avg_epoch_loss=2.559778\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=30 train loss <loss>=2.57407193184\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:04 INFO 139866244298560] Epoch[29] Batch [30]#011Speed: 474.41 samples/sec#011loss=2.574072\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:05 INFO 139866244298560] Epoch[29] Batch[35] avg_epoch_loss=2.563287\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=35 train loss <loss>=2.58504447937\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:05 INFO 139866244298560] Epoch[29] Batch [35]#011Speed: 591.22 samples/sec#011loss=2.585044\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:05 INFO 139866244298560] Epoch[29] Batch[40] avg_epoch_loss=2.541516\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=40 train loss <loss>=2.3847619772\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:05 INFO 139866244298560] Epoch[29] Batch [40]#011Speed: 472.88 samples/sec#011loss=2.384762\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:06 INFO 139866244298560] Epoch[29] Batch[45] avg_epoch_loss=2.524138\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=45 train loss <loss>=2.38163685799\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:06 INFO 139866244298560] Epoch[29] Batch [45]#011Speed: 593.65 samples/sec#011loss=2.381637\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:07 INFO 139866244298560] Epoch[29] Batch[50] avg_epoch_loss=2.511598\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=50 train loss <loss>=2.39623785019\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:07 INFO 139866244298560] Epoch[29] Batch [50]#011Speed: 449.30 samples/sec#011loss=2.396238\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:07 INFO 139866244298560] Epoch[29] Batch[55] avg_epoch_loss=2.484397\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=55 train loss <loss>=2.20694406033\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:07 INFO 139866244298560] Epoch[29] Batch [55]#011Speed: 584.94 samples/sec#011loss=2.206944\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:08 INFO 139866244298560] Epoch[29] Batch[60] avg_epoch_loss=2.512872\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=60 train loss <loss>=2.83178634644\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:08 INFO 139866244298560] Epoch[29] Batch [60]#011Speed: 478.15 samples/sec#011loss=2.831786\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:08 INFO 139866244298560] Epoch[29] Batch[65] avg_epoch_loss=2.539475\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=65 train loss <loss>=2.86403799057\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:08 INFO 139866244298560] Epoch[29] Batch [65]#011Speed: 591.76 samples/sec#011loss=2.864038\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:09 INFO 139866244298560] Epoch[29] Batch[70] avg_epoch_loss=2.579228\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=70 train loss <loss>=3.10396318436\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:09 INFO 139866244298560] Epoch[29] Batch [70]#011Speed: 483.63 samples/sec#011loss=3.103963\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:10 INFO 139866244298560] Epoch[29] Batch[75] avg_epoch_loss=2.620606\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=75 train loss <loss>=3.20816774368\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:10 INFO 139866244298560] Epoch[29] Batch [75]#011Speed: 596.23 samples/sec#011loss=3.208168\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:10 INFO 139866244298560] Epoch[29] Batch[80] avg_epoch_loss=2.649643\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=80 train loss <loss>=3.09101047516\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:10 INFO 139866244298560] Epoch[29] Batch [80]#011Speed: 478.25 samples/sec#011loss=3.091010\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:11 INFO 139866244298560] Epoch[29] Batch[85] avg_epoch_loss=2.666596\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=85 train loss <loss>=2.94124426842\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:11 INFO 139866244298560] Epoch[29] Batch [85]#011Speed: 464.69 samples/sec#011loss=2.941244\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:11 INFO 139866244298560] Epoch[29] Batch[90] avg_epoch_loss=2.660826\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=90 train loss <loss>=2.56157474518\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:11 INFO 139866244298560] Epoch[29] Batch [90]#011Speed: 599.64 samples/sec#011loss=2.561575\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:12 INFO 139866244298560] Epoch[29] Batch[95] avg_epoch_loss=2.643903\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=95 train loss <loss>=2.33591113091\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:12 INFO 139866244298560] Epoch[29] Batch [95]#011Speed: 439.43 samples/sec#011loss=2.335911\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:13 INFO 139866244298560] Epoch[29] Batch[100] avg_epoch_loss=2.636312\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=100 train loss <loss>=2.49056038857\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:13 INFO 139866244298560] Epoch[29] Batch [100]#011Speed: 594.50 samples/sec#011loss=2.490560\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:13 INFO 139866244298560] Epoch[29] Batch[105] avg_epoch_loss=2.627345\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=105 train loss <loss>=2.44621071815\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:13 INFO 139866244298560] Epoch[29] Batch [105]#011Speed: 474.65 samples/sec#011loss=2.446211\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:14 INFO 139866244298560] Epoch[29] Batch[110] avg_epoch_loss=2.611942\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=110 train loss <loss>=2.28539898396\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:14 INFO 139866244298560] Epoch[29] Batch [110]#011Speed: 592.84 samples/sec#011loss=2.285399\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:15 INFO 139866244298560] Epoch[29] Batch[115] avg_epoch_loss=2.611914\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=115 train loss <loss>=2.61127877235\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:15 INFO 139866244298560] Epoch[29] Batch [115]#011Speed: 467.86 samples/sec#011loss=2.611279\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:15 INFO 139866244298560] Epoch[29] Batch[120] avg_epoch_loss=2.621798\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=120 train loss <loss>=2.85111303329\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:15 INFO 139866244298560] Epoch[29] Batch [120]#011Speed: 592.00 samples/sec#011loss=2.851113\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:16 INFO 139866244298560] Epoch[29] Batch[125] avg_epoch_loss=2.633808\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=125 train loss <loss>=2.92446246147\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:16 INFO 139866244298560] Epoch[29] Batch [125]#011Speed: 442.21 samples/sec#011loss=2.924462\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:16 INFO 139866244298560] Epoch[29] Batch[130] avg_epoch_loss=2.651178\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=130 train loss <loss>=3.08888516426\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:16 INFO 139866244298560] Epoch[29] Batch [130]#011Speed: 588.65 samples/sec#011loss=3.088885\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:17 INFO 139866244298560] Epoch[29] Batch[135] avg_epoch_loss=2.661912\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=135 train loss <loss>=2.94314661026\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:17 INFO 139866244298560] Epoch[29] Batch [135]#011Speed: 416.01 samples/sec#011loss=2.943147\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:18 INFO 139866244298560] Epoch[29] Batch[140] avg_epoch_loss=2.674065\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=140 train loss <loss>=3.00463018417\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:18 INFO 139866244298560] Epoch[29] Batch [140]#011Speed: 594.97 samples/sec#011loss=3.004630\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:18 INFO 139866244298560] Epoch[29] Batch[145] avg_epoch_loss=2.672283\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=145 train loss <loss>=2.62203569412\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:18 INFO 139866244298560] Epoch[29] Batch [145]#011Speed: 466.93 samples/sec#011loss=2.622036\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:19 INFO 139866244298560] Epoch[29] Batch[150] avg_epoch_loss=2.659923\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=150 train loss <loss>=2.29899849892\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:19 INFO 139866244298560] Epoch[29] Batch [150]#011Speed: 598.38 samples/sec#011loss=2.298998\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:20 INFO 139866244298560] Epoch[29] Batch[155] avg_epoch_loss=2.661105\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=155 train loss <loss>=2.69682497978\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:20 INFO 139866244298560] Epoch[29] Batch [155]#011Speed: 473.60 samples/sec#011loss=2.696825\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:20 INFO 139866244298560] Epoch[29] Batch[160] avg_epoch_loss=2.656456\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=160 train loss <loss>=2.51140494347\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:20 INFO 139866244298560] Epoch[29] Batch [160]#011Speed: 594.30 samples/sec#011loss=2.511405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:21 INFO 139866244298560] Epoch[29] Batch[165] avg_epoch_loss=2.647780\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=165 train loss <loss>=2.36840338707\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:21 INFO 139866244298560] Epoch[29] Batch [165]#011Speed: 474.80 samples/sec#011loss=2.368403\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:21 INFO 139866244298560] Epoch[29] Batch[170] avg_epoch_loss=2.642256\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=170 train loss <loss>=2.45886120796\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:21 INFO 139866244298560] Epoch[29] Batch [170]#011Speed: 593.96 samples/sec#011loss=2.458861\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:22 INFO 139866244298560] Epoch[29] Batch[175] avg_epoch_loss=2.648098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=175 train loss <loss>=2.84789524078\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:22 INFO 139866244298560] Epoch[29] Batch [175]#011Speed: 438.99 samples/sec#011loss=2.847895\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:23 INFO 139866244298560] Epoch[29] Batch[180] avg_epoch_loss=2.649474\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=180 train loss <loss>=2.69790000916\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:23 INFO 139866244298560] Epoch[29] Batch [180]#011Speed: 597.07 samples/sec#011loss=2.697900\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:23 INFO 139866244298560] Epoch[29] Batch[185] avg_epoch_loss=2.665387\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=185 train loss <loss>=3.24145889282\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:23 INFO 139866244298560] Epoch[29] Batch [185]#011Speed: 476.21 samples/sec#011loss=3.241459\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:24 INFO 139866244298560] Epoch[29] Batch[190] avg_epoch_loss=2.687538\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=190 train loss <loss>=3.5115483284\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:24 INFO 139866244298560] Epoch[29] Batch [190]#011Speed: 595.74 samples/sec#011loss=3.511548\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:24 INFO 139866244298560] Epoch[29] Batch[195] avg_epoch_loss=2.702581\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=195 train loss <loss>=3.27722024918\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:24 INFO 139866244298560] Epoch[29] Batch [195]#011Speed: 470.97 samples/sec#011loss=3.277220\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:25 INFO 139866244298560] Epoch[29] Batch[200] avg_epoch_loss=2.713445\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=200 train loss <loss>=3.13932418823\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:25 INFO 139866244298560] Epoch[29] Batch [200]#011Speed: 592.88 samples/sec#011loss=3.139324\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:26 INFO 139866244298560] Epoch[29] Batch[205] avg_epoch_loss=2.725817\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=205 train loss <loss>=3.22313599586\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:26 INFO 139866244298560] Epoch[29] Batch [205]#011Speed: 476.28 samples/sec#011loss=3.223136\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:26 INFO 139866244298560] Epoch[29] Batch[210] avg_epoch_loss=2.736057\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=210 train loss <loss>=3.15795388222\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:26 INFO 139866244298560] Epoch[29] Batch [210]#011Speed: 589.33 samples/sec#011loss=3.157954\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:27 INFO 139866244298560] Epoch[29] Batch[215] avg_epoch_loss=2.729897\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=215 train loss <loss>=2.46997332573\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:27 INFO 139866244298560] Epoch[29] Batch [215]#011Speed: 459.27 samples/sec#011loss=2.469973\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:27 INFO 139866244298560] Epoch[29] Batch[220] avg_epoch_loss=2.729020\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=220 train loss <loss>=2.69113345146\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:27 INFO 139866244298560] Epoch[29] Batch [220]#011Speed: 585.38 samples/sec#011loss=2.691133\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:28 INFO 139866244298560] Epoch[29] Batch[225] avg_epoch_loss=2.728451\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=225 train loss <loss>=2.70327539444\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:28 INFO 139866244298560] Epoch[29] Batch [225]#011Speed: 475.00 samples/sec#011loss=2.703275\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:29 INFO 139866244298560] Epoch[29] Batch[230] avg_epoch_loss=2.719632\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=230 train loss <loss>=2.32101168633\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:29 INFO 139866244298560] Epoch[29] Batch [230]#011Speed: 598.43 samples/sec#011loss=2.321012\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:29 INFO 139866244298560] Epoch[29] Batch[235] avg_epoch_loss=2.721978\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=235 train loss <loss>=2.83039059639\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:29 INFO 139866244298560] Epoch[29] Batch [235]#011Speed: 476.86 samples/sec#011loss=2.830391\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:30 INFO 139866244298560] Epoch[29] Batch[240] avg_epoch_loss=2.724670\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=240 train loss <loss>=2.85169410706\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:30 INFO 139866244298560] Epoch[29] Batch [240]#011Speed: 482.04 samples/sec#011loss=2.851694\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:31 INFO 139866244298560] Epoch[29] Batch[245] avg_epoch_loss=2.741836\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=245 train loss <loss>=3.56923689842\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:31 INFO 139866244298560] Epoch[29] Batch [245]#011Speed: 593.23 samples/sec#011loss=3.569237\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:31 INFO 139866244298560] Epoch[29] Batch[250] avg_epoch_loss=2.752186\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=250 train loss <loss>=3.26144990921\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:31 INFO 139866244298560] Epoch[29] Batch [250]#011Speed: 476.52 samples/sec#011loss=3.261450\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:32 INFO 139866244298560] Epoch[29] Batch[255] avg_epoch_loss=2.767571\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=255 train loss <loss>=3.53987588882\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:32 INFO 139866244298560] Epoch[29] Batch [255]#011Speed: 594.91 samples/sec#011loss=3.539876\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:32 INFO 139866244298560] Epoch[29] Batch[260] avg_epoch_loss=2.774510\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=260 train loss <loss>=3.12978305817\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:32 INFO 139866244298560] Epoch[29] Batch [260]#011Speed: 460.42 samples/sec#011loss=3.129783\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:33 INFO 139866244298560] Epoch[29] Batch[265] avg_epoch_loss=2.771313\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, batch=265 train loss <loss>=2.60442929268\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:33 INFO 139866244298560] Epoch[29] Batch [265]#011Speed: 585.96 samples/sec#011loss=2.604429\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:33 INFO 139866244298560] processed a total of 17246 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33354.50100898743, \"sum\": 33354.50100898743, \"min\": 33354.50100898743}}, \"EndTime\": 1599442953.954652, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442920.60009}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:33 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=517.049797519 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:33 INFO 139866244298560] #progress_metric: host=algo-1, completed 37 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=29, train loss <loss>=2.77282091688\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:33 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:34 INFO 139866244298560] Epoch[30] Batch[0] avg_epoch_loss=2.567419\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=0 train loss <loss>=2.56741857529\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:34 INFO 139866244298560] Epoch[30] Batch[5] avg_epoch_loss=2.318956\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=5 train loss <loss>=2.31895627578\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:34 INFO 139866244298560] Epoch[30] Batch [5]#011Speed: 578.37 samples/sec#011loss=2.318956\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:35 INFO 139866244298560] Epoch[30] Batch[10] avg_epoch_loss=2.211555\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=10 train loss <loss>=2.08267252445\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:35 INFO 139866244298560] Epoch[30] Batch [10]#011Speed: 469.82 samples/sec#011loss=2.082673\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:35 INFO 139866244298560] Epoch[30] Batch[15] avg_epoch_loss=2.335724\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=15 train loss <loss>=2.60889754295\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:35 INFO 139866244298560] Epoch[30] Batch [15]#011Speed: 588.44 samples/sec#011loss=2.608898\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:36 INFO 139866244298560] Epoch[30] Batch[20] avg_epoch_loss=2.365562\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=20 train loss <loss>=2.46104240417\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:36 INFO 139866244298560] Epoch[30] Batch [20]#011Speed: 470.67 samples/sec#011loss=2.461042\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:37 INFO 139866244298560] Epoch[30] Batch[25] avg_epoch_loss=2.478954\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=25 train loss <loss>=2.95520105362\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:37 INFO 139866244298560] Epoch[30] Batch [25]#011Speed: 592.96 samples/sec#011loss=2.955201\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:37 INFO 139866244298560] Epoch[30] Batch[30] avg_epoch_loss=2.531200\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=30 train loss <loss>=2.80287680626\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:37 INFO 139866244298560] Epoch[30] Batch [30]#011Speed: 409.19 samples/sec#011loss=2.802877\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:38 INFO 139866244298560] Epoch[30] Batch[35] avg_epoch_loss=2.532742\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=35 train loss <loss>=2.54230413437\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:38 INFO 139866244298560] Epoch[30] Batch [35]#011Speed: 584.83 samples/sec#011loss=2.542304\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:39 INFO 139866244298560] Epoch[30] Batch[40] avg_epoch_loss=2.533641\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=40 train loss <loss>=2.54011731148\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:39 INFO 139866244298560] Epoch[30] Batch [40]#011Speed: 477.56 samples/sec#011loss=2.540117\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:39 INFO 139866244298560] Epoch[30] Batch[45] avg_epoch_loss=2.506924\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=45 train loss <loss>=2.28784463406\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:39 INFO 139866244298560] Epoch[30] Batch [45]#011Speed: 590.30 samples/sec#011loss=2.287845\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:40 INFO 139866244298560] Epoch[30] Batch[50] avg_epoch_loss=2.494759\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=50 train loss <loss>=2.38284235001\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:40 INFO 139866244298560] Epoch[30] Batch [50]#011Speed: 476.88 samples/sec#011loss=2.382842\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:40 INFO 139866244298560] Epoch[30] Batch[55] avg_epoch_loss=2.494946\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=55 train loss <loss>=2.49685049057\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:40 INFO 139866244298560] Epoch[30] Batch [55]#011Speed: 590.77 samples/sec#011loss=2.496850\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:41 INFO 139866244298560] Epoch[30] Batch[60] avg_epoch_loss=2.482756\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=60 train loss <loss>=2.34623012543\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:41 INFO 139866244298560] Epoch[30] Batch [60]#011Speed: 476.20 samples/sec#011loss=2.346230\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:42 INFO 139866244298560] Epoch[30] Batch[65] avg_epoch_loss=2.474326\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=65 train loss <loss>=2.37147109509\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:42 INFO 139866244298560] Epoch[30] Batch [65]#011Speed: 596.39 samples/sec#011loss=2.371471\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:42 INFO 139866244298560] Epoch[30] Batch[70] avg_epoch_loss=2.490595\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=70 train loss <loss>=2.70535612106\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:42 INFO 139866244298560] Epoch[30] Batch [70]#011Speed: 464.39 samples/sec#011loss=2.705356\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:43 INFO 139866244298560] Epoch[30] Batch[75] avg_epoch_loss=2.522419\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=75 train loss <loss>=2.97432146072\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:43 INFO 139866244298560] Epoch[30] Batch [75]#011Speed: 589.77 samples/sec#011loss=2.974321\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:44 INFO 139866244298560] Epoch[30] Batch[80] avg_epoch_loss=2.551734\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=80 train loss <loss>=2.99732275009\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:44 INFO 139866244298560] Epoch[30] Batch [80]#011Speed: 475.16 samples/sec#011loss=2.997323\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:44 INFO 139866244298560] Epoch[30] Batch[85] avg_epoch_loss=2.583628\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=85 train loss <loss>=3.10030126572\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:44 INFO 139866244298560] Epoch[30] Batch [85]#011Speed: 598.20 samples/sec#011loss=3.100301\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:45 INFO 139866244298560] Epoch[30] Batch[90] avg_epoch_loss=2.607151\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=90 train loss <loss>=3.01175093651\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:45 INFO 139866244298560] Epoch[30] Batch [90]#011Speed: 475.26 samples/sec#011loss=3.011751\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:45 INFO 139866244298560] Epoch[30] Batch[95] avg_epoch_loss=2.625024\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=95 train loss <loss>=2.95031394958\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:45 INFO 139866244298560] Epoch[30] Batch [95]#011Speed: 591.21 samples/sec#011loss=2.950314\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:46 INFO 139866244298560] Epoch[30] Batch[100] avg_epoch_loss=2.621992\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=100 train loss <loss>=2.56377868652\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:46 INFO 139866244298560] Epoch[30] Batch [100]#011Speed: 444.22 samples/sec#011loss=2.563779\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:47 INFO 139866244298560] Epoch[30] Batch[105] avg_epoch_loss=2.614568\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=105 train loss <loss>=2.46458787918\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:47 INFO 139866244298560] Epoch[30] Batch [105]#011Speed: 478.97 samples/sec#011loss=2.464588\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:47 INFO 139866244298560] Epoch[30] Batch[110] avg_epoch_loss=2.606514\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=110 train loss <loss>=2.43578577042\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:47 INFO 139866244298560] Epoch[30] Batch [110]#011Speed: 585.28 samples/sec#011loss=2.435786\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:48 INFO 139866244298560] Epoch[30] Batch[115] avg_epoch_loss=2.589427\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=115 train loss <loss>=2.21008415222\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:48 INFO 139866244298560] Epoch[30] Batch [115]#011Speed: 450.17 samples/sec#011loss=2.210084\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:49 INFO 139866244298560] Epoch[30] Batch[120] avg_epoch_loss=2.584023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=120 train loss <loss>=2.45864701271\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:49 INFO 139866244298560] Epoch[30] Batch [120]#011Speed: 582.90 samples/sec#011loss=2.458647\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:49 INFO 139866244298560] Epoch[30] Batch[125] avg_epoch_loss=2.587403\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=125 train loss <loss>=2.66921532154\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:49 INFO 139866244298560] Epoch[30] Batch [125]#011Speed: 485.28 samples/sec#011loss=2.669215\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:50 INFO 139866244298560] Epoch[30] Batch[130] avg_epoch_loss=2.603089\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=130 train loss <loss>=2.9983561039\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:50 INFO 139866244298560] Epoch[30] Batch [130]#011Speed: 589.57 samples/sec#011loss=2.998356\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:50 INFO 139866244298560] Epoch[30] Batch[135] avg_epoch_loss=2.620280\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=135 train loss <loss>=3.07070188522\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:50 INFO 139866244298560] Epoch[30] Batch [135]#011Speed: 479.98 samples/sec#011loss=3.070702\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:51 INFO 139866244298560] Epoch[30] Batch[140] avg_epoch_loss=2.628554\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=140 train loss <loss>=2.85358805656\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:51 INFO 139866244298560] Epoch[30] Batch [140]#011Speed: 590.28 samples/sec#011loss=2.853588\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:52 INFO 139866244298560] Epoch[30] Batch[145] avg_epoch_loss=2.622365\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=145 train loss <loss>=2.44784297943\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:52 INFO 139866244298560] Epoch[30] Batch [145]#011Speed: 480.99 samples/sec#011loss=2.447843\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:52 INFO 139866244298560] Epoch[30] Batch[150] avg_epoch_loss=2.606297\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=150 train loss <loss>=2.1371060133\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:52 INFO 139866244298560] Epoch[30] Batch [150]#011Speed: 591.02 samples/sec#011loss=2.137106\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:53 INFO 139866244298560] Epoch[30] Batch[155] avg_epoch_loss=2.604652\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=155 train loss <loss>=2.55499210358\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:53 INFO 139866244298560] Epoch[30] Batch [155]#011Speed: 428.54 samples/sec#011loss=2.554992\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:53 INFO 139866244298560] Epoch[30] Batch[160] avg_epoch_loss=2.602901\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=160 train loss <loss>=2.54826159477\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:53 INFO 139866244298560] Epoch[30] Batch [160]#011Speed: 587.81 samples/sec#011loss=2.548262\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:54 INFO 139866244298560] Epoch[30] Batch[165] avg_epoch_loss=2.596635\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=165 train loss <loss>=2.39488217831\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:54 INFO 139866244298560] Epoch[30] Batch [165]#011Speed: 471.02 samples/sec#011loss=2.394882\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:55 INFO 139866244298560] Epoch[30] Batch[170] avg_epoch_loss=2.584705\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=170 train loss <loss>=2.1886316061\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:55 INFO 139866244298560] Epoch[30] Batch [170]#011Speed: 588.24 samples/sec#011loss=2.188632\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:55 INFO 139866244298560] Epoch[30] Batch[175] avg_epoch_loss=2.592793\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=175 train loss <loss>=2.86939024925\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:55 INFO 139866244298560] Epoch[30] Batch [175]#011Speed: 473.21 samples/sec#011loss=2.869390\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:56 INFO 139866244298560] Epoch[30] Batch[180] avg_epoch_loss=2.596394\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=180 train loss <loss>=2.72313289642\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:56 INFO 139866244298560] Epoch[30] Batch [180]#011Speed: 591.15 samples/sec#011loss=2.723133\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:57 INFO 139866244298560] Epoch[30] Batch[185] avg_epoch_loss=2.614811\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=185 train loss <loss>=3.28153605461\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:57 INFO 139866244298560] Epoch[30] Batch [185]#011Speed: 483.87 samples/sec#011loss=3.281536\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:57 INFO 139866244298560] Epoch[30] Batch[190] avg_epoch_loss=2.632845\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=190 train loss <loss>=3.30368170738\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:57 INFO 139866244298560] Epoch[30] Batch [190]#011Speed: 485.02 samples/sec#011loss=3.303682\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:58 INFO 139866244298560] Epoch[30] Batch[195] avg_epoch_loss=2.648877\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=195 train loss <loss>=3.26129951477\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:58 INFO 139866244298560] Epoch[30] Batch [195]#011Speed: 556.06 samples/sec#011loss=3.261300\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:58 INFO 139866244298560] Epoch[30] Batch[200] avg_epoch_loss=2.666441\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=200 train loss <loss>=3.35498194695\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:58 INFO 139866244298560] Epoch[30] Batch [200]#011Speed: 474.19 samples/sec#011loss=3.354982\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:59 INFO 139866244298560] Epoch[30] Batch[205] avg_epoch_loss=2.668087\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=205 train loss <loss>=2.73424725533\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:42:59 INFO 139866244298560] Epoch[30] Batch [205]#011Speed: 593.15 samples/sec#011loss=2.734247\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:00 INFO 139866244298560] Epoch[30] Batch[210] avg_epoch_loss=2.670284\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=210 train loss <loss>=2.76078872681\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:00 INFO 139866244298560] Epoch[30] Batch [210]#011Speed: 476.92 samples/sec#011loss=2.760789\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:00 INFO 139866244298560] Epoch[30] Batch[215] avg_epoch_loss=2.664687\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=215 train loss <loss>=2.42848982811\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:00 INFO 139866244298560] Epoch[30] Batch [215]#011Speed: 594.07 samples/sec#011loss=2.428490\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:01 INFO 139866244298560] Epoch[30] Batch[220] avg_epoch_loss=2.661937\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=220 train loss <loss>=2.54315800667\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:01 INFO 139866244298560] Epoch[30] Batch [220]#011Speed: 451.85 samples/sec#011loss=2.543158\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:01 INFO 139866244298560] Epoch[30] Batch[225] avg_epoch_loss=2.650783\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=225 train loss <loss>=2.15775995255\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:01 INFO 139866244298560] Epoch[30] Batch [225]#011Speed: 588.63 samples/sec#011loss=2.157760\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:02 INFO 139866244298560] Epoch[30] Batch[230] avg_epoch_loss=2.648213\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=230 train loss <loss>=2.53206248283\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:02 INFO 139866244298560] Epoch[30] Batch [230]#011Speed: 475.25 samples/sec#011loss=2.532062\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:03 INFO 139866244298560] Epoch[30] Batch[235] avg_epoch_loss=2.655725\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=235 train loss <loss>=3.00278768539\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:03 INFO 139866244298560] Epoch[30] Batch [235]#011Speed: 588.01 samples/sec#011loss=3.002788\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:03 INFO 139866244298560] Epoch[30] Batch[240] avg_epoch_loss=2.668887\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=240 train loss <loss>=3.2901263237\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:03 INFO 139866244298560] Epoch[30] Batch [240]#011Speed: 460.99 samples/sec#011loss=3.290126\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:04 INFO 139866244298560] Epoch[30] Batch[245] avg_epoch_loss=2.683387\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=245 train loss <loss>=3.38225769997\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:04 INFO 139866244298560] Epoch[30] Batch [245]#011Speed: 595.33 samples/sec#011loss=3.382258\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:05 INFO 139866244298560] Epoch[30] Batch[250] avg_epoch_loss=2.697385\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=250 train loss <loss>=3.38608260155\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:05 INFO 139866244298560] Epoch[30] Batch [250]#011Speed: 465.13 samples/sec#011loss=3.386083\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:05 INFO 139866244298560] Epoch[30] Batch[255] avg_epoch_loss=2.704152\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=255 train loss <loss>=3.04385361671\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:05 INFO 139866244298560] Epoch[30] Batch [255]#011Speed: 594.16 samples/sec#011loss=3.043854\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:06 INFO 139866244298560] Epoch[30] Batch[260] avg_epoch_loss=2.708107\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=260 train loss <loss>=2.91060352325\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:06 INFO 139866244298560] Epoch[30] Batch [260]#011Speed: 481.79 samples/sec#011loss=2.910604\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:06 INFO 139866244298560] Epoch[30] Batch[265] avg_epoch_loss=2.708696\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, batch=265 train loss <loss>=2.73947410583\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:06 INFO 139866244298560] Epoch[30] Batch [265]#011Speed: 581.72 samples/sec#011loss=2.739474\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:07 INFO 139866244298560] processed a total of 17121 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33097.02515602112, \"sum\": 33097.02515602112, \"min\": 33097.02515602112}}, \"EndTime\": 1599442987.052433, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442953.954734}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:07 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=517.295417424 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:07 INFO 139866244298560] #progress_metric: host=algo-1, completed 38 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=30, train loss <loss>=2.71212879135\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:07 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:07 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_116948c0-ab3b-4db7-a1fd-0e5b2a8100d4-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.713069915771484, \"sum\": 17.713069915771484, \"min\": 17.713069915771484}}, \"EndTime\": 1599442987.070793, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442987.052503}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:07 INFO 139866244298560] Epoch[31] Batch[0] avg_epoch_loss=2.030867\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=0 train loss <loss>=2.03086709976\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:07 INFO 139866244298560] Epoch[31] Batch[5] avg_epoch_loss=2.158443\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=5 train loss <loss>=2.15844261646\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:07 INFO 139866244298560] Epoch[31] Batch [5]#011Speed: 592.88 samples/sec#011loss=2.158443\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:08 INFO 139866244298560] Epoch[31] Batch[10] avg_epoch_loss=2.178528\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=10 train loss <loss>=2.20263001919\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:08 INFO 139866244298560] Epoch[31] Batch [10]#011Speed: 451.57 samples/sec#011loss=2.202630\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:09 INFO 139866244298560] Epoch[31] Batch[15] avg_epoch_loss=2.322497\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=15 train loss <loss>=2.63922896385\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:09 INFO 139866244298560] Epoch[31] Batch [15]#011Speed: 591.72 samples/sec#011loss=2.639229\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:09 INFO 139866244298560] Epoch[31] Batch[20] avg_epoch_loss=2.381297\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=20 train loss <loss>=2.56945681572\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:09 INFO 139866244298560] Epoch[31] Batch [20]#011Speed: 472.19 samples/sec#011loss=2.569457\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:10 INFO 139866244298560] Epoch[31] Batch[25] avg_epoch_loss=2.468860\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=25 train loss <loss>=2.83662552834\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:10 INFO 139866244298560] Epoch[31] Batch [25]#011Speed: 584.62 samples/sec#011loss=2.836626\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:11 INFO 139866244298560] Epoch[31] Batch[30] avg_epoch_loss=2.499945\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=30 train loss <loss>=2.66158823967\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:11 INFO 139866244298560] Epoch[31] Batch [30]#011Speed: 476.59 samples/sec#011loss=2.661588\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:11 INFO 139866244298560] Epoch[31] Batch[35] avg_epoch_loss=2.541342\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=35 train loss <loss>=2.79800219536\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:11 INFO 139866244298560] Epoch[31] Batch [35]#011Speed: 582.65 samples/sec#011loss=2.798002\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:12 INFO 139866244298560] Epoch[31] Batch[40] avg_epoch_loss=2.551474\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=40 train loss <loss>=2.62442784309\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:12 INFO 139866244298560] Epoch[31] Batch [40]#011Speed: 478.34 samples/sec#011loss=2.624428\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:12 INFO 139866244298560] Epoch[31] Batch[45] avg_epoch_loss=2.562178\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=45 train loss <loss>=2.64994630814\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:12 INFO 139866244298560] Epoch[31] Batch [45]#011Speed: 594.45 samples/sec#011loss=2.649946\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:13 INFO 139866244298560] Epoch[31] Batch[50] avg_epoch_loss=2.547896\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=50 train loss <loss>=2.4164973259\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:13 INFO 139866244298560] Epoch[31] Batch [50]#011Speed: 436.89 samples/sec#011loss=2.416497\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:14 INFO 139866244298560] Epoch[31] Batch[55] avg_epoch_loss=2.521151\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=55 train loss <loss>=2.24836175442\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:14 INFO 139866244298560] Epoch[31] Batch [55]#011Speed: 595.85 samples/sec#011loss=2.248362\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:14 INFO 139866244298560] Epoch[31] Batch[60] avg_epoch_loss=2.518653\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=60 train loss <loss>=2.49067206383\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:14 INFO 139866244298560] Epoch[31] Batch [60]#011Speed: 473.05 samples/sec#011loss=2.490672\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:15 INFO 139866244298560] Epoch[31] Batch[65] avg_epoch_loss=2.526439\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=65 train loss <loss>=2.62142853737\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:15 INFO 139866244298560] Epoch[31] Batch [65]#011Speed: 581.36 samples/sec#011loss=2.621429\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:15 INFO 139866244298560] Epoch[31] Batch[70] avg_epoch_loss=2.535034\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=70 train loss <loss>=2.64847941399\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:15 INFO 139866244298560] Epoch[31] Batch [70]#011Speed: 485.56 samples/sec#011loss=2.648479\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:16 INFO 139866244298560] Epoch[31] Batch[75] avg_epoch_loss=2.520143\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=75 train loss <loss>=2.30869369507\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:16 INFO 139866244298560] Epoch[31] Batch [75]#011Speed: 534.71 samples/sec#011loss=2.308694\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:17 INFO 139866244298560] Epoch[31] Batch[80] avg_epoch_loss=2.554650\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=80 train loss <loss>=3.07916288376\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:17 INFO 139866244298560] Epoch[31] Batch [80]#011Speed: 481.01 samples/sec#011loss=3.079163\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:17 INFO 139866244298560] Epoch[31] Batch[85] avg_epoch_loss=2.600620\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=85 train loss <loss>=3.34532499313\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:17 INFO 139866244298560] Epoch[31] Batch [85]#011Speed: 595.39 samples/sec#011loss=3.345325\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:18 INFO 139866244298560] Epoch[31] Batch[90] avg_epoch_loss=2.631019\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=90 train loss <loss>=3.15388174057\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:18 INFO 139866244298560] Epoch[31] Batch [90]#011Speed: 460.56 samples/sec#011loss=3.153882\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:19 INFO 139866244298560] Epoch[31] Batch[95] avg_epoch_loss=2.657993\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=95 train loss <loss>=3.14893169403\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:19 INFO 139866244298560] Epoch[31] Batch [95]#011Speed: 545.32 samples/sec#011loss=3.148932\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:19 INFO 139866244298560] Epoch[31] Batch[100] avg_epoch_loss=2.656786\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=100 train loss <loss>=2.6335975647\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:19 INFO 139866244298560] Epoch[31] Batch [100]#011Speed: 480.52 samples/sec#011loss=2.633598\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:20 INFO 139866244298560] Epoch[31] Batch[105] avg_epoch_loss=2.661577\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=105 train loss <loss>=2.758360672\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:20 INFO 139866244298560] Epoch[31] Batch [105]#011Speed: 582.58 samples/sec#011loss=2.758361\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:20 INFO 139866244298560] Epoch[31] Batch[110] avg_epoch_loss=2.649693\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=110 train loss <loss>=2.39776582718\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:20 INFO 139866244298560] Epoch[31] Batch [110]#011Speed: 478.47 samples/sec#011loss=2.397766\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:21 INFO 139866244298560] Epoch[31] Batch[115] avg_epoch_loss=2.627169\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=115 train loss <loss>=2.12711958885\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:21 INFO 139866244298560] Epoch[31] Batch [115]#011Speed: 589.50 samples/sec#011loss=2.127120\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:22 INFO 139866244298560] Epoch[31] Batch[120] avg_epoch_loss=2.612655\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=120 train loss <loss>=2.27592942715\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:22 INFO 139866244298560] Epoch[31] Batch [120]#011Speed: 476.08 samples/sec#011loss=2.275929\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:22 INFO 139866244298560] Epoch[31] Batch[125] avg_epoch_loss=2.604502\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=125 train loss <loss>=2.40720963478\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:22 INFO 139866244298560] Epoch[31] Batch [125]#011Speed: 587.55 samples/sec#011loss=2.407210\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:23 INFO 139866244298560] Epoch[31] Batch[130] avg_epoch_loss=2.601520\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=130 train loss <loss>=2.5263812542\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:23 INFO 139866244298560] Epoch[31] Batch [130]#011Speed: 465.38 samples/sec#011loss=2.526381\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:23 INFO 139866244298560] Epoch[31] Batch[135] avg_epoch_loss=2.596151\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=135 train loss <loss>=2.45548415184\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:23 INFO 139866244298560] Epoch[31] Batch [135]#011Speed: 562.28 samples/sec#011loss=2.455484\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:24 INFO 139866244298560] Epoch[31] Batch[140] avg_epoch_loss=2.608586\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=140 train loss <loss>=2.94680538177\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:24 INFO 139866244298560] Epoch[31] Batch [140]#011Speed: 469.80 samples/sec#011loss=2.946805\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:25 INFO 139866244298560] Epoch[31] Batch[145] avg_epoch_loss=2.621220\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=145 train loss <loss>=2.97750811577\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:25 INFO 139866244298560] Epoch[31] Batch [145]#011Speed: 575.65 samples/sec#011loss=2.977508\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:25 INFO 139866244298560] Epoch[31] Batch[150] avg_epoch_loss=2.629565\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=150 train loss <loss>=2.87321953773\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:25 INFO 139866244298560] Epoch[31] Batch [150]#011Speed: 482.71 samples/sec#011loss=2.873220\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:26 INFO 139866244298560] Epoch[31] Batch[155] avg_epoch_loss=2.638781\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=155 train loss <loss>=2.91710448265\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:26 INFO 139866244298560] Epoch[31] Batch [155]#011Speed: 590.10 samples/sec#011loss=2.917104\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:27 INFO 139866244298560] Epoch[31] Batch[160] avg_epoch_loss=2.644550\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=160 train loss <loss>=2.82455291748\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:27 INFO 139866244298560] Epoch[31] Batch [160]#011Speed: 476.28 samples/sec#011loss=2.824553\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:27 INFO 139866244298560] Epoch[31] Batch[165] avg_epoch_loss=2.641262\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=165 train loss <loss>=2.53537240028\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:27 INFO 139866244298560] Epoch[31] Batch [165]#011Speed: 594.08 samples/sec#011loss=2.535372\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:28 INFO 139866244298560] Epoch[31] Batch[170] avg_epoch_loss=2.638838\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=170 train loss <loss>=2.55836553574\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:28 INFO 139866244298560] Epoch[31] Batch [170]#011Speed: 474.40 samples/sec#011loss=2.558366\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:28 INFO 139866244298560] Epoch[31] Batch[175] avg_epoch_loss=2.640098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=175 train loss <loss>=2.68319354057\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:28 INFO 139866244298560] Epoch[31] Batch [175]#011Speed: 450.84 samples/sec#011loss=2.683194\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:29 INFO 139866244298560] Epoch[31] Batch[180] avg_epoch_loss=2.640591\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=180 train loss <loss>=2.65795707703\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:29 INFO 139866244298560] Epoch[31] Batch [180]#011Speed: 595.03 samples/sec#011loss=2.657957\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:30 INFO 139866244298560] Epoch[31] Batch[185] avg_epoch_loss=2.642350\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=185 train loss <loss>=2.70602245331\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:30 INFO 139866244298560] Epoch[31] Batch [185]#011Speed: 469.29 samples/sec#011loss=2.706022\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:30 INFO 139866244298560] Epoch[31] Batch[190] avg_epoch_loss=2.647167\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=190 train loss <loss>=2.82636752129\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:30 INFO 139866244298560] Epoch[31] Batch [190]#011Speed: 590.90 samples/sec#011loss=2.826368\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:31 INFO 139866244298560] Epoch[31] Batch[195] avg_epoch_loss=2.656338\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=195 train loss <loss>=3.00665340424\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:31 INFO 139866244298560] Epoch[31] Batch [195]#011Speed: 480.54 samples/sec#011loss=3.006653\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:31 INFO 139866244298560] Epoch[31] Batch[200] avg_epoch_loss=2.676782\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=200 train loss <loss>=3.47818579674\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:31 INFO 139866244298560] Epoch[31] Batch [200]#011Speed: 593.53 samples/sec#011loss=3.478186\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:32 INFO 139866244298560] Epoch[31] Batch[205] avg_epoch_loss=2.696144\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=205 train loss <loss>=3.47449679375\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:32 INFO 139866244298560] Epoch[31] Batch [205]#011Speed: 484.67 samples/sec#011loss=3.474497\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:33 INFO 139866244298560] Epoch[31] Batch[210] avg_epoch_loss=2.716146\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=210 train loss <loss>=3.54021868706\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:33 INFO 139866244298560] Epoch[31] Batch [210]#011Speed: 597.22 samples/sec#011loss=3.540219\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:33 INFO 139866244298560] Epoch[31] Batch[215] avg_epoch_loss=2.726831\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=215 train loss <loss>=3.17776193619\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:33 INFO 139866244298560] Epoch[31] Batch [215]#011Speed: 450.60 samples/sec#011loss=3.177762\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:34 INFO 139866244298560] Epoch[31] Batch[220] avg_epoch_loss=2.724968\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=220 train loss <loss>=2.64446668625\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:34 INFO 139866244298560] Epoch[31] Batch [220]#011Speed: 578.98 samples/sec#011loss=2.644467\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:35 INFO 139866244298560] Epoch[31] Batch[225] avg_epoch_loss=2.725960\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=225 train loss <loss>=2.76980047226\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:35 INFO 139866244298560] Epoch[31] Batch [225]#011Speed: 474.20 samples/sec#011loss=2.769800\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:35 INFO 139866244298560] Epoch[31] Batch[230] avg_epoch_loss=2.719769\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=230 train loss <loss>=2.43994379044\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:35 INFO 139866244298560] Epoch[31] Batch [230]#011Speed: 596.50 samples/sec#011loss=2.439944\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:36 INFO 139866244298560] Epoch[31] Batch[235] avg_epoch_loss=2.716888\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=235 train loss <loss>=2.58381352425\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:36 INFO 139866244298560] Epoch[31] Batch [235]#011Speed: 474.87 samples/sec#011loss=2.583814\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:36 INFO 139866244298560] Epoch[31] Batch[240] avg_epoch_loss=2.710972\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=240 train loss <loss>=2.43170528412\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:36 INFO 139866244298560] Epoch[31] Batch [240]#011Speed: 589.41 samples/sec#011loss=2.431705\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:37 INFO 139866244298560] Epoch[31] Batch[245] avg_epoch_loss=2.721460\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=245 train loss <loss>=3.22700138092\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:37 INFO 139866244298560] Epoch[31] Batch [245]#011Speed: 474.19 samples/sec#011loss=3.227001\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:38 INFO 139866244298560] Epoch[31] Batch[250] avg_epoch_loss=2.730555\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=250 train loss <loss>=3.17804455757\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:38 INFO 139866244298560] Epoch[31] Batch [250]#011Speed: 485.98 samples/sec#011loss=3.178045\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:38 INFO 139866244298560] Epoch[31] Batch[255] avg_epoch_loss=2.743277\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=255 train loss <loss>=3.38188471794\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:38 INFO 139866244298560] Epoch[31] Batch [255]#011Speed: 598.48 samples/sec#011loss=3.381885\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:39 INFO 139866244298560] Epoch[31] Batch[260] avg_epoch_loss=2.750827\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=260 train loss <loss>=3.13742527962\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:39 INFO 139866244298560] Epoch[31] Batch [260]#011Speed: 432.16 samples/sec#011loss=3.137425\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:39 INFO 139866244298560] Epoch[31] Batch[265] avg_epoch_loss=2.751462\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, batch=265 train loss <loss>=2.78459300995\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:39 INFO 139866244298560] Epoch[31] Batch [265]#011Speed: 594.88 samples/sec#011loss=2.784593\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:40 INFO 139866244298560] processed a total of 17189 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33223.361015319824, \"sum\": 33223.361015319824, \"min\": 33223.361015319824}}, \"EndTime\": 1599443020.294285, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599442987.070866}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:40 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=517.374593656 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:40 INFO 139866244298560] #progress_metric: host=algo-1, completed 40 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=31, train loss <loss>=2.75444453578\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:40 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:40 INFO 139866244298560] Epoch[32] Batch[0] avg_epoch_loss=2.036026\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=0 train loss <loss>=2.03602600098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:41 INFO 139866244298560] Epoch[32] Batch[5] avg_epoch_loss=2.189648\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=5 train loss <loss>=2.18964769443\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:41 INFO 139866244298560] Epoch[32] Batch [5]#011Speed: 587.75 samples/sec#011loss=2.189648\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:41 INFO 139866244298560] Epoch[32] Batch[10] avg_epoch_loss=2.210713\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=10 train loss <loss>=2.23599154949\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:41 INFO 139866244298560] Epoch[32] Batch [10]#011Speed: 474.64 samples/sec#011loss=2.235992\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:42 INFO 139866244298560] Epoch[32] Batch[15] avg_epoch_loss=2.428951\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=15 train loss <loss>=2.90907416344\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:42 INFO 139866244298560] Epoch[32] Batch [15]#011Speed: 594.19 samples/sec#011loss=2.909074\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:42 INFO 139866244298560] Epoch[32] Batch[20] avg_epoch_loss=2.511537\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=20 train loss <loss>=2.77581424713\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:42 INFO 139866244298560] Epoch[32] Batch [20]#011Speed: 476.57 samples/sec#011loss=2.775814\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:43 INFO 139866244298560] Epoch[32] Batch[25] avg_epoch_loss=2.564026\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=25 train loss <loss>=2.78447561264\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:43 INFO 139866244298560] Epoch[32] Batch [25]#011Speed: 597.04 samples/sec#011loss=2.784476\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:44 INFO 139866244298560] Epoch[32] Batch[30] avg_epoch_loss=2.553885\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=30 train loss <loss>=2.50115160942\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:44 INFO 139866244298560] Epoch[32] Batch [30]#011Speed: 429.03 samples/sec#011loss=2.501152\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:44 INFO 139866244298560] Epoch[32] Batch[35] avg_epoch_loss=2.538791\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=35 train loss <loss>=2.44520916939\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:44 INFO 139866244298560] Epoch[32] Batch [35]#011Speed: 568.21 samples/sec#011loss=2.445209\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:45 INFO 139866244298560] Epoch[32] Batch[40] avg_epoch_loss=2.530344\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=40 train loss <loss>=2.46952943802\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:45 INFO 139866244298560] Epoch[32] Batch [40]#011Speed: 464.97 samples/sec#011loss=2.469529\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:46 INFO 139866244298560] Epoch[32] Batch[45] avg_epoch_loss=2.529313\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=45 train loss <loss>=2.52085528374\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:46 INFO 139866244298560] Epoch[32] Batch [45]#011Speed: 591.29 samples/sec#011loss=2.520855\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:46 INFO 139866244298560] Epoch[32] Batch[50] avg_epoch_loss=2.508774\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=50 train loss <loss>=2.31981406212\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:46 INFO 139866244298560] Epoch[32] Batch [50]#011Speed: 432.94 samples/sec#011loss=2.319814\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:47 INFO 139866244298560] Epoch[32] Batch[55] avg_epoch_loss=2.510157\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=55 train loss <loss>=2.52426600456\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:47 INFO 139866244298560] Epoch[32] Batch [55]#011Speed: 593.36 samples/sec#011loss=2.524266\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:47 INFO 139866244298560] Epoch[32] Batch[60] avg_epoch_loss=2.523879\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=60 train loss <loss>=2.67756056786\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:47 INFO 139866244298560] Epoch[32] Batch [60]#011Speed: 480.06 samples/sec#011loss=2.677561\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:48 INFO 139866244298560] Epoch[32] Batch[65] avg_epoch_loss=2.529603\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=65 train loss <loss>=2.59943962097\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:48 INFO 139866244298560] Epoch[32] Batch [65]#011Speed: 595.33 samples/sec#011loss=2.599440\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:49 INFO 139866244298560] Epoch[32] Batch[70] avg_epoch_loss=2.561644\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=70 train loss <loss>=2.98459157944\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:49 INFO 139866244298560] Epoch[32] Batch [70]#011Speed: 474.25 samples/sec#011loss=2.984592\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:49 INFO 139866244298560] Epoch[32] Batch[75] avg_epoch_loss=2.598460\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=75 train loss <loss>=3.12124824524\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:49 INFO 139866244298560] Epoch[32] Batch [75]#011Speed: 531.75 samples/sec#011loss=3.121248\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:50 INFO 139866244298560] Epoch[32] Batch[80] avg_epoch_loss=2.634107\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=80 train loss <loss>=3.17594013214\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:50 INFO 139866244298560] Epoch[32] Batch [80]#011Speed: 474.32 samples/sec#011loss=3.175940\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:51 INFO 139866244298560] Epoch[32] Batch[85] avg_epoch_loss=2.668933\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=85 train loss <loss>=3.2331158638\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:51 INFO 139866244298560] Epoch[32] Batch [85]#011Speed: 594.50 samples/sec#011loss=3.233116\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:51 INFO 139866244298560] Epoch[32] Batch[90] avg_epoch_loss=2.673058\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=90 train loss <loss>=2.74401006699\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:51 INFO 139866244298560] Epoch[32] Batch [90]#011Speed: 475.67 samples/sec#011loss=2.744010\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:52 INFO 139866244298560] Epoch[32] Batch[95] avg_epoch_loss=2.664267\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=95 train loss <loss>=2.5042637825\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:52 INFO 139866244298560] Epoch[32] Batch [95]#011Speed: 593.70 samples/sec#011loss=2.504264\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:52 INFO 139866244298560] Epoch[32] Batch[100] avg_epoch_loss=2.654660\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=100 train loss <loss>=2.47021346092\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:52 INFO 139866244298560] Epoch[32] Batch [100]#011Speed: 479.49 samples/sec#011loss=2.470213\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:53 INFO 139866244298560] Epoch[32] Batch[105] avg_epoch_loss=2.645207\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=105 train loss <loss>=2.45424449444\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:53 INFO 139866244298560] Epoch[32] Batch [105]#011Speed: 586.90 samples/sec#011loss=2.454244\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:54 INFO 139866244298560] Epoch[32] Batch[110] avg_epoch_loss=2.632765\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=110 train loss <loss>=2.36900596619\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:54 INFO 139866244298560] Epoch[32] Batch [110]#011Speed: 459.37 samples/sec#011loss=2.369006\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:54 INFO 139866244298560] Epoch[32] Batch[115] avg_epoch_loss=2.621013\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=115 train loss <loss>=2.36011157036\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:54 INFO 139866244298560] Epoch[32] Batch [115]#011Speed: 528.69 samples/sec#011loss=2.360112\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:55 INFO 139866244298560] Epoch[32] Batch[120] avg_epoch_loss=2.613406\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=120 train loss <loss>=2.43692717552\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:55 INFO 139866244298560] Epoch[32] Batch [120]#011Speed: 479.14 samples/sec#011loss=2.436927\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:56 INFO 139866244298560] Epoch[32] Batch[125] avg_epoch_loss=2.615019\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=125 train loss <loss>=2.65405216217\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:56 INFO 139866244298560] Epoch[32] Batch [125]#011Speed: 476.14 samples/sec#011loss=2.654052\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:56 INFO 139866244298560] Epoch[32] Batch[130] avg_epoch_loss=2.625265\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=130 train loss <loss>=2.88346261978\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:56 INFO 139866244298560] Epoch[32] Batch [130]#011Speed: 588.77 samples/sec#011loss=2.883463\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:57 INFO 139866244298560] Epoch[32] Batch[135] avg_epoch_loss=2.643617\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=135 train loss <loss>=3.12443704605\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:57 INFO 139866244298560] Epoch[32] Batch [135]#011Speed: 478.73 samples/sec#011loss=3.124437\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:57 INFO 139866244298560] Epoch[32] Batch[140] avg_epoch_loss=2.651703\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=140 train loss <loss>=2.87163844109\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:57 INFO 139866244298560] Epoch[32] Batch [140]#011Speed: 596.18 samples/sec#011loss=2.871638\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:58 INFO 139866244298560] Epoch[32] Batch[145] avg_epoch_loss=2.656006\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=145 train loss <loss>=2.77734751701\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:58 INFO 139866244298560] Epoch[32] Batch [145]#011Speed: 474.25 samples/sec#011loss=2.777348\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:59 INFO 139866244298560] Epoch[32] Batch[150] avg_epoch_loss=2.648886\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=150 train loss <loss>=2.44099340439\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:59 INFO 139866244298560] Epoch[32] Batch [150]#011Speed: 596.87 samples/sec#011loss=2.440993\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:59 INFO 139866244298560] Epoch[32] Batch[155] avg_epoch_loss=2.637322\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=155 train loss <loss>=2.28809161186\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:43:59 INFO 139866244298560] Epoch[32] Batch [155]#011Speed: 431.98 samples/sec#011loss=2.288092\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:00 INFO 139866244298560] Epoch[32] Batch[160] avg_epoch_loss=2.634276\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=160 train loss <loss>=2.53924450874\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:00 INFO 139866244298560] Epoch[32] Batch [160]#011Speed: 586.28 samples/sec#011loss=2.539245\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:01 INFO 139866244298560] Epoch[32] Batch[165] avg_epoch_loss=2.629095\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=165 train loss <loss>=2.46225342751\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:01 INFO 139866244298560] Epoch[32] Batch [165]#011Speed: 476.99 samples/sec#011loss=2.462253\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:01 INFO 139866244298560] Epoch[32] Batch[170] avg_epoch_loss=2.616779\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=170 train loss <loss>=2.20790309906\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:01 INFO 139866244298560] Epoch[32] Batch [170]#011Speed: 561.76 samples/sec#011loss=2.207903\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:02 INFO 139866244298560] Epoch[32] Batch[175] avg_epoch_loss=2.617488\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=175 train loss <loss>=2.64173512459\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:02 INFO 139866244298560] Epoch[32] Batch [175]#011Speed: 475.63 samples/sec#011loss=2.641735\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:02 INFO 139866244298560] Epoch[32] Batch[180] avg_epoch_loss=2.615369\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=180 train loss <loss>=2.54075574875\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:02 INFO 139866244298560] Epoch[32] Batch [180]#011Speed: 590.12 samples/sec#011loss=2.540756\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:03 INFO 139866244298560] Epoch[32] Batch[185] avg_epoch_loss=2.644455\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=185 train loss <loss>=3.69736666679\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:03 INFO 139866244298560] Epoch[32] Batch [185]#011Speed: 483.92 samples/sec#011loss=3.697367\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:04 INFO 139866244298560] Epoch[32] Batch[190] avg_epoch_loss=2.668779\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=190 train loss <loss>=3.57364578247\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:04 INFO 139866244298560] Epoch[32] Batch [190]#011Speed: 484.54 samples/sec#011loss=3.573646\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:04 INFO 139866244298560] Epoch[32] Batch[195] avg_epoch_loss=2.681427\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=195 train loss <loss>=3.16456542015\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:04 INFO 139866244298560] Epoch[32] Batch [195]#011Speed: 595.67 samples/sec#011loss=3.164565\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:05 INFO 139866244298560] Epoch[32] Batch[200] avg_epoch_loss=2.693079\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=200 train loss <loss>=3.14984807968\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:05 INFO 139866244298560] Epoch[32] Batch [200]#011Speed: 422.66 samples/sec#011loss=3.149848\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:05 INFO 139866244298560] Epoch[32] Batch[205] avg_epoch_loss=2.697165\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=205 train loss <loss>=2.86144666672\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:05 INFO 139866244298560] Epoch[32] Batch [205]#011Speed: 591.86 samples/sec#011loss=2.861447\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:06 INFO 139866244298560] Epoch[32] Batch[210] avg_epoch_loss=2.697087\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=210 train loss <loss>=2.69383277893\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:06 INFO 139866244298560] Epoch[32] Batch [210]#011Speed: 473.85 samples/sec#011loss=2.693833\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:07 INFO 139866244298560] Epoch[32] Batch[215] avg_epoch_loss=2.691102\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=215 train loss <loss>=2.43856761456\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:07 INFO 139866244298560] Epoch[32] Batch [215]#011Speed: 590.21 samples/sec#011loss=2.438568\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:07 INFO 139866244298560] Epoch[32] Batch[220] avg_epoch_loss=2.687332\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=220 train loss <loss>=2.52444787025\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:07 INFO 139866244298560] Epoch[32] Batch [220]#011Speed: 473.53 samples/sec#011loss=2.524448\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:08 INFO 139866244298560] Epoch[32] Batch[225] avg_epoch_loss=2.685660\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=225 train loss <loss>=2.61177501678\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:08 INFO 139866244298560] Epoch[32] Batch [225]#011Speed: 591.43 samples/sec#011loss=2.611775\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:09 INFO 139866244298560] Epoch[32] Batch[230] avg_epoch_loss=2.687108\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=230 train loss <loss>=2.75256071091\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:09 INFO 139866244298560] Epoch[32] Batch [230]#011Speed: 483.21 samples/sec#011loss=2.752561\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:09 INFO 139866244298560] Epoch[32] Batch[235] avg_epoch_loss=2.697731\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=235 train loss <loss>=3.18850102425\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:09 INFO 139866244298560] Epoch[32] Batch [235]#011Speed: 593.26 samples/sec#011loss=3.188501\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:10 INFO 139866244298560] Epoch[32] Batch[240] avg_epoch_loss=2.714681\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=240 train loss <loss>=3.51474332809\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:10 INFO 139866244298560] Epoch[32] Batch [240]#011Speed: 434.36 samples/sec#011loss=3.514743\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:10 INFO 139866244298560] Epoch[32] Batch[245] avg_epoch_loss=2.732986\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=245 train loss <loss>=3.61524424553\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:10 INFO 139866244298560] Epoch[32] Batch [245]#011Speed: 591.34 samples/sec#011loss=3.615244\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:11 INFO 139866244298560] Epoch[32] Batch[250] avg_epoch_loss=2.745005\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=250 train loss <loss>=3.33636198044\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:11 INFO 139866244298560] Epoch[32] Batch [250]#011Speed: 470.88 samples/sec#011loss=3.336362\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:12 INFO 139866244298560] Epoch[32] Batch[255] avg_epoch_loss=2.747408\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=255 train loss <loss>=2.86803126335\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:12 INFO 139866244298560] Epoch[32] Batch [255]#011Speed: 594.70 samples/sec#011loss=2.868031\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:12 INFO 139866244298560] Epoch[32] Batch[260] avg_epoch_loss=2.744988\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=260 train loss <loss>=2.62110443115\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:12 INFO 139866244298560] Epoch[32] Batch [260]#011Speed: 478.06 samples/sec#011loss=2.621104\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:13 INFO 139866244298560] Epoch[32] Batch[265] avg_epoch_loss=2.739398\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=265 train loss <loss>=2.44756779671\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:13 INFO 139866244298560] Epoch[32] Batch [265]#011Speed: 597.01 samples/sec#011loss=2.447568\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:13 INFO 139866244298560] Epoch[32] Batch[270] avg_epoch_loss=2.753686\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, batch=270 train loss <loss>=3.51383361816\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:13 INFO 139866244298560] Epoch[32] Batch [270]#011Speed: 568.62 samples/sec#011loss=3.513834\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:13 INFO 139866244298560] processed a total of 17289 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33554.826974868774, \"sum\": 33554.826974868774, \"min\": 33554.826974868774}}, \"EndTime\": 1599443053.849905, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443020.294397}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:13 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=515.243724021 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:13 INFO 139866244298560] #progress_metric: host=algo-1, completed 41 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=32, train loss <loss>=2.75368616062\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:13 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:14 INFO 139866244298560] Epoch[33] Batch[0] avg_epoch_loss=2.024927\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=0 train loss <loss>=2.02492690086\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:14 INFO 139866244298560] Epoch[33] Batch[5] avg_epoch_loss=2.224769\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=5 train loss <loss>=2.22476891677\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:14 INFO 139866244298560] Epoch[33] Batch [5]#011Speed: 587.80 samples/sec#011loss=2.224769\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:15 INFO 139866244298560] Epoch[33] Batch[10] avg_epoch_loss=2.168537\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=10 train loss <loss>=2.1010581255\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:15 INFO 139866244298560] Epoch[33] Batch [10]#011Speed: 374.93 samples/sec#011loss=2.101058\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:16 INFO 139866244298560] Epoch[33] Batch[15] avg_epoch_loss=2.347009\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=15 train loss <loss>=2.73964834213\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:16 INFO 139866244298560] Epoch[33] Batch [15]#011Speed: 589.54 samples/sec#011loss=2.739648\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:16 INFO 139866244298560] Epoch[33] Batch[20] avg_epoch_loss=2.365313\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=20 train loss <loss>=2.42388496399\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:16 INFO 139866244298560] Epoch[33] Batch [20]#011Speed: 432.88 samples/sec#011loss=2.423885\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:17 INFO 139866244298560] Epoch[33] Batch[25] avg_epoch_loss=2.420522\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=25 train loss <loss>=2.65240068436\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:17 INFO 139866244298560] Epoch[33] Batch [25]#011Speed: 596.72 samples/sec#011loss=2.652401\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:17 INFO 139866244298560] Epoch[33] Batch[30] avg_epoch_loss=2.475350\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=30 train loss <loss>=2.7604549408\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:17 INFO 139866244298560] Epoch[33] Batch [30]#011Speed: 481.12 samples/sec#011loss=2.760455\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:18 INFO 139866244298560] Epoch[33] Batch[35] avg_epoch_loss=2.521617\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=35 train loss <loss>=2.80847373009\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:18 INFO 139866244298560] Epoch[33] Batch [35]#011Speed: 585.89 samples/sec#011loss=2.808474\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:19 INFO 139866244298560] Epoch[33] Batch[40] avg_epoch_loss=2.540370\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=40 train loss <loss>=2.67539000511\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:19 INFO 139866244298560] Epoch[33] Batch [40]#011Speed: 460.52 samples/sec#011loss=2.675390\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:19 INFO 139866244298560] Epoch[33] Batch[45] avg_epoch_loss=2.537872\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=45 train loss <loss>=2.51738510132\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:19 INFO 139866244298560] Epoch[33] Batch [45]#011Speed: 580.34 samples/sec#011loss=2.517385\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:20 INFO 139866244298560] Epoch[33] Batch[50] avg_epoch_loss=2.531605\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=50 train loss <loss>=2.47394962311\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:20 INFO 139866244298560] Epoch[33] Batch [50]#011Speed: 458.75 samples/sec#011loss=2.473950\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:21 INFO 139866244298560] Epoch[33] Batch[55] avg_epoch_loss=2.504605\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=55 train loss <loss>=2.22920618057\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:21 INFO 139866244298560] Epoch[33] Batch [55]#011Speed: 564.62 samples/sec#011loss=2.229206\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:21 INFO 139866244298560] Epoch[33] Batch[60] avg_epoch_loss=2.499579\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=60 train loss <loss>=2.44328887463\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:21 INFO 139866244298560] Epoch[33] Batch [60]#011Speed: 471.55 samples/sec#011loss=2.443289\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:22 INFO 139866244298560] Epoch[33] Batch[65] avg_epoch_loss=2.515221\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=65 train loss <loss>=2.70605807304\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:22 INFO 139866244298560] Epoch[33] Batch [65]#011Speed: 585.15 samples/sec#011loss=2.706058\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:22 INFO 139866244298560] Epoch[33] Batch[70] avg_epoch_loss=2.526720\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=70 train loss <loss>=2.67849793434\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:22 INFO 139866244298560] Epoch[33] Batch [70]#011Speed: 476.58 samples/sec#011loss=2.678498\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:23 INFO 139866244298560] Epoch[33] Batch[75] avg_epoch_loss=2.538139\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=75 train loss <loss>=2.70029230118\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:23 INFO 139866244298560] Epoch[33] Batch [75]#011Speed: 598.52 samples/sec#011loss=2.700292\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:24 INFO 139866244298560] Epoch[33] Batch[80] avg_epoch_loss=2.582164\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=80 train loss <loss>=3.25134515762\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:24 INFO 139866244298560] Epoch[33] Batch [80]#011Speed: 486.54 samples/sec#011loss=3.251345\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:24 INFO 139866244298560] Epoch[33] Batch[85] avg_epoch_loss=2.614377\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=85 train loss <loss>=3.13623170853\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:24 INFO 139866244298560] Epoch[33] Batch [85]#011Speed: 478.62 samples/sec#011loss=3.136232\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:25 INFO 139866244298560] Epoch[33] Batch[90] avg_epoch_loss=2.631047\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=90 train loss <loss>=2.91776118279\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:25 INFO 139866244298560] Epoch[33] Batch [90]#011Speed: 589.94 samples/sec#011loss=2.917761\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:26 INFO 139866244298560] Epoch[33] Batch[95] avg_epoch_loss=2.644092\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=95 train loss <loss>=2.88151702881\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:26 INFO 139866244298560] Epoch[33] Batch [95]#011Speed: 438.59 samples/sec#011loss=2.881517\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:26 INFO 139866244298560] Epoch[33] Batch[100] avg_epoch_loss=2.630093\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=100 train loss <loss>=2.36131706238\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:26 INFO 139866244298560] Epoch[33] Batch [100]#011Speed: 590.13 samples/sec#011loss=2.361317\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:27 INFO 139866244298560] Epoch[33] Batch[105] avg_epoch_loss=2.623576\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=105 train loss <loss>=2.4919229269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:27 INFO 139866244298560] Epoch[33] Batch [105]#011Speed: 473.34 samples/sec#011loss=2.491923\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:27 INFO 139866244298560] Epoch[33] Batch[110] avg_epoch_loss=2.603222\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=110 train loss <loss>=2.17172524929\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:27 INFO 139866244298560] Epoch[33] Batch [110]#011Speed: 592.98 samples/sec#011loss=2.171725\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:28 INFO 139866244298560] Epoch[33] Batch[115] avg_epoch_loss=2.598007\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=115 train loss <loss>=2.48222341537\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:28 INFO 139866244298560] Epoch[33] Batch [115]#011Speed: 484.44 samples/sec#011loss=2.482223\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:29 INFO 139866244298560] Epoch[33] Batch[120] avg_epoch_loss=2.587333\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=120 train loss <loss>=2.33971004486\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:29 INFO 139866244298560] Epoch[33] Batch [120]#011Speed: 589.82 samples/sec#011loss=2.339710\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:29 INFO 139866244298560] Epoch[33] Batch[125] avg_epoch_loss=2.593124\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=125 train loss <loss>=2.73325591087\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:29 INFO 139866244298560] Epoch[33] Batch [125]#011Speed: 479.99 samples/sec#011loss=2.733256\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:30 INFO 139866244298560] Epoch[33] Batch[130] avg_epoch_loss=2.603255\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=130 train loss <loss>=2.85855689049\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:30 INFO 139866244298560] Epoch[33] Batch [130]#011Speed: 593.95 samples/sec#011loss=2.858557\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:30 INFO 139866244298560] Epoch[33] Batch[135] avg_epoch_loss=2.613522\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=135 train loss <loss>=2.88250870705\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:30 INFO 139866244298560] Epoch[33] Batch [135]#011Speed: 434.76 samples/sec#011loss=2.882509\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:31 INFO 139866244298560] Epoch[33] Batch[140] avg_epoch_loss=2.627861\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=140 train loss <loss>=3.01788983345\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:31 INFO 139866244298560] Epoch[33] Batch [140]#011Speed: 586.05 samples/sec#011loss=3.017890\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:32 INFO 139866244298560] Epoch[33] Batch[145] avg_epoch_loss=2.629722\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=145 train loss <loss>=2.68221850395\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:32 INFO 139866244298560] Epoch[33] Batch [145]#011Speed: 475.35 samples/sec#011loss=2.682219\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:32 INFO 139866244298560] Epoch[33] Batch[150] avg_epoch_loss=2.621334\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=150 train loss <loss>=2.37638864517\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:32 INFO 139866244298560] Epoch[33] Batch [150]#011Speed: 594.93 samples/sec#011loss=2.376389\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:33 INFO 139866244298560] Epoch[33] Batch[155] avg_epoch_loss=2.615895\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=155 train loss <loss>=2.45163197517\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:33 INFO 139866244298560] Epoch[33] Batch [155]#011Speed: 481.26 samples/sec#011loss=2.451632\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:33 INFO 139866244298560] Epoch[33] Batch[160] avg_epoch_loss=2.615688\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=160 train loss <loss>=2.60923810005\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:33 INFO 139866244298560] Epoch[33] Batch [160]#011Speed: 595.62 samples/sec#011loss=2.609238\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:34 INFO 139866244298560] Epoch[33] Batch[165] avg_epoch_loss=2.609109\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=165 train loss <loss>=2.39726514816\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:34 INFO 139866244298560] Epoch[33] Batch [165]#011Speed: 470.90 samples/sec#011loss=2.397265\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:35 INFO 139866244298560] Epoch[33] Batch[170] avg_epoch_loss=2.598234\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=170 train loss <loss>=2.23717517853\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:35 INFO 139866244298560] Epoch[33] Batch [170]#011Speed: 593.53 samples/sec#011loss=2.237175\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:35 INFO 139866244298560] Epoch[33] Batch[175] avg_epoch_loss=2.598310\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=175 train loss <loss>=2.60091772079\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:35 INFO 139866244298560] Epoch[33] Batch [175]#011Speed: 453.21 samples/sec#011loss=2.600918\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:36 INFO 139866244298560] Epoch[33] Batch[180] avg_epoch_loss=2.602461\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=180 train loss <loss>=2.7485763073\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:36 INFO 139866244298560] Epoch[33] Batch [180]#011Speed: 566.46 samples/sec#011loss=2.748576\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:37 INFO 139866244298560] Epoch[33] Batch[185] avg_epoch_loss=2.621861\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=185 train loss <loss>=3.32413973808\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:37 INFO 139866244298560] Epoch[33] Batch [185]#011Speed: 471.03 samples/sec#011loss=3.324140\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:37 INFO 139866244298560] Epoch[33] Batch[190] avg_epoch_loss=2.641620\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=190 train loss <loss>=3.37666053772\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:37 INFO 139866244298560] Epoch[33] Batch [190]#011Speed: 588.68 samples/sec#011loss=3.376661\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:38 INFO 139866244298560] Epoch[33] Batch[195] avg_epoch_loss=2.661628\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=195 train loss <loss>=3.42592744827\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:38 INFO 139866244298560] Epoch[33] Batch [195]#011Speed: 478.56 samples/sec#011loss=3.425927\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:38 INFO 139866244298560] Epoch[33] Batch[200] avg_epoch_loss=2.679036\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=200 train loss <loss>=3.36142382622\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:38 INFO 139866244298560] Epoch[33] Batch [200]#011Speed: 486.54 samples/sec#011loss=3.361424\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:39 INFO 139866244298560] Epoch[33] Batch[205] avg_epoch_loss=2.692102\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=205 train loss <loss>=3.2173602581\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:39 INFO 139866244298560] Epoch[33] Batch [205]#011Speed: 590.71 samples/sec#011loss=3.217360\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:40 INFO 139866244298560] Epoch[33] Batch[210] avg_epoch_loss=2.697787\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=210 train loss <loss>=2.93200244904\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:40 INFO 139866244298560] Epoch[33] Batch [210]#011Speed: 466.88 samples/sec#011loss=2.932002\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:40 INFO 139866244298560] Epoch[33] Batch[215] avg_epoch_loss=2.690275\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=215 train loss <loss>=2.37327213287\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:40 INFO 139866244298560] Epoch[33] Batch [215]#011Speed: 591.98 samples/sec#011loss=2.373272\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:41 INFO 139866244298560] Epoch[33] Batch[220] avg_epoch_loss=2.687089\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=220 train loss <loss>=2.54944705963\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:41 INFO 139866244298560] Epoch[33] Batch [220]#011Speed: 447.24 samples/sec#011loss=2.549447\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:42 INFO 139866244298560] Epoch[33] Batch[225] avg_epoch_loss=2.680972\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=225 train loss <loss>=2.41061358452\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:42 INFO 139866244298560] Epoch[33] Batch [225]#011Speed: 591.02 samples/sec#011loss=2.410614\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:42 INFO 139866244298560] Epoch[33] Batch[230] avg_epoch_loss=2.677429\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=230 train loss <loss>=2.51730041504\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:42 INFO 139866244298560] Epoch[33] Batch [230]#011Speed: 477.11 samples/sec#011loss=2.517300\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:43 INFO 139866244298560] Epoch[33] Batch[235] avg_epoch_loss=2.678439\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=235 train loss <loss>=2.72506632805\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:43 INFO 139866244298560] Epoch[33] Batch [235]#011Speed: 595.86 samples/sec#011loss=2.725066\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:43 INFO 139866244298560] Epoch[33] Batch[240] avg_epoch_loss=2.680519\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=240 train loss <loss>=2.77870340347\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:43 INFO 139866244298560] Epoch[33] Batch [240]#011Speed: 480.36 samples/sec#011loss=2.778703\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:44 INFO 139866244298560] Epoch[33] Batch[245] avg_epoch_loss=2.692217\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=245 train loss <loss>=3.25607833862\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:44 INFO 139866244298560] Epoch[33] Batch [245]#011Speed: 589.27 samples/sec#011loss=3.256078\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:45 INFO 139866244298560] Epoch[33] Batch[250] avg_epoch_loss=2.706807\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=250 train loss <loss>=3.42462477684\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:45 INFO 139866244298560] Epoch[33] Batch [250]#011Speed: 467.49 samples/sec#011loss=3.424625\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:45 INFO 139866244298560] Epoch[33] Batch[255] avg_epoch_loss=2.716918\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=255 train loss <loss>=3.22447199821\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:45 INFO 139866244298560] Epoch[33] Batch [255]#011Speed: 590.78 samples/sec#011loss=3.224472\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:46 INFO 139866244298560] Epoch[33] Batch[260] avg_epoch_loss=2.720044\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=260 train loss <loss>=2.88010649681\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:46 INFO 139866244298560] Epoch[33] Batch [260]#011Speed: 431.28 samples/sec#011loss=2.880106\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:46 INFO 139866244298560] Epoch[33] Batch[265] avg_epoch_loss=2.721228\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, batch=265 train loss <loss>=2.78303723335\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:46 INFO 139866244298560] Epoch[33] Batch [265]#011Speed: 527.92 samples/sec#011loss=2.783037\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:47 INFO 139866244298560] processed a total of 17158 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33473.588943481445, \"sum\": 33473.588943481445, \"min\": 33473.588943481445}}, \"EndTime\": 1599443087.324153, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443053.849973}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:47 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=512.58176312 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:47 INFO 139866244298560] #progress_metric: host=algo-1, completed 42 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=33, train loss <loss>=2.7208920181\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:47 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:47 INFO 139866244298560] Epoch[34] Batch[0] avg_epoch_loss=2.299246\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=0 train loss <loss>=2.29924607277\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:48 INFO 139866244298560] Epoch[34] Batch[5] avg_epoch_loss=2.228345\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=5 train loss <loss>=2.22834507624\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:48 INFO 139866244298560] Epoch[34] Batch [5]#011Speed: 594.06 samples/sec#011loss=2.228345\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:48 INFO 139866244298560] Epoch[34] Batch[10] avg_epoch_loss=2.330524\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=10 train loss <loss>=2.45313897133\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:48 INFO 139866244298560] Epoch[34] Batch [10]#011Speed: 473.53 samples/sec#011loss=2.453139\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:49 INFO 139866244298560] Epoch[34] Batch[15] avg_epoch_loss=2.368204\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=15 train loss <loss>=2.45110011101\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:49 INFO 139866244298560] Epoch[34] Batch [15]#011Speed: 594.65 samples/sec#011loss=2.451100\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:49 INFO 139866244298560] Epoch[34] Batch[20] avg_epoch_loss=2.483198\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=20 train loss <loss>=2.85117702484\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:49 INFO 139866244298560] Epoch[34] Batch [20]#011Speed: 476.18 samples/sec#011loss=2.851177\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:50 INFO 139866244298560] Epoch[34] Batch[25] avg_epoch_loss=2.574690\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=25 train loss <loss>=2.95895648003\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:50 INFO 139866244298560] Epoch[34] Batch [25]#011Speed: 588.89 samples/sec#011loss=2.958956\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:51 INFO 139866244298560] Epoch[34] Batch[30] avg_epoch_loss=2.567144\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=30 train loss <loss>=2.52790555954\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:51 INFO 139866244298560] Epoch[34] Batch [30]#011Speed: 459.38 samples/sec#011loss=2.527906\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:51 INFO 139866244298560] Epoch[34] Batch[35] avg_epoch_loss=2.534751\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=35 train loss <loss>=2.33391590118\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:51 INFO 139866244298560] Epoch[34] Batch [35]#011Speed: 573.75 samples/sec#011loss=2.333916\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:52 INFO 139866244298560] Epoch[34] Batch[40] avg_epoch_loss=2.535690\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=40 train loss <loss>=2.54245285988\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:52 INFO 139866244298560] Epoch[34] Batch [40]#011Speed: 470.71 samples/sec#011loss=2.542453\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:53 INFO 139866244298560] Epoch[34] Batch[45] avg_epoch_loss=2.513473\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=45 train loss <loss>=2.33129487038\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:53 INFO 139866244298560] Epoch[34] Batch [45]#011Speed: 597.34 samples/sec#011loss=2.331295\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:53 INFO 139866244298560] Epoch[34] Batch[50] avg_epoch_loss=2.502664\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=50 train loss <loss>=2.40321474075\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:53 INFO 139866244298560] Epoch[34] Batch [50]#011Speed: 475.29 samples/sec#011loss=2.403215\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:54 INFO 139866244298560] Epoch[34] Batch[55] avg_epoch_loss=2.491354\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=55 train loss <loss>=2.37599692345\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:54 INFO 139866244298560] Epoch[34] Batch [55]#011Speed: 467.86 samples/sec#011loss=2.375997\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:54 INFO 139866244298560] Epoch[34] Batch[60] avg_epoch_loss=2.500135\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=60 train loss <loss>=2.5984817028\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:54 INFO 139866244298560] Epoch[34] Batch [60]#011Speed: 592.21 samples/sec#011loss=2.598482\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:55 INFO 139866244298560] Epoch[34] Batch[65] avg_epoch_loss=2.517268\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=65 train loss <loss>=2.72629480362\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:55 INFO 139866244298560] Epoch[34] Batch [65]#011Speed: 482.13 samples/sec#011loss=2.726295\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:56 INFO 139866244298560] Epoch[34] Batch[70] avg_epoch_loss=2.567163\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=70 train loss <loss>=3.22577190399\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:56 INFO 139866244298560] Epoch[34] Batch [70]#011Speed: 594.47 samples/sec#011loss=3.225772\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:56 INFO 139866244298560] Epoch[34] Batch[75] avg_epoch_loss=2.612793\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=75 train loss <loss>=3.26073021889\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:56 INFO 139866244298560] Epoch[34] Batch [75]#011Speed: 480.67 samples/sec#011loss=3.260730\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:57 INFO 139866244298560] Epoch[34] Batch[80] avg_epoch_loss=2.630167\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=80 train loss <loss>=2.89426131248\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:57 INFO 139866244298560] Epoch[34] Batch [80]#011Speed: 585.76 samples/sec#011loss=2.894261\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:57 INFO 139866244298560] Epoch[34] Batch[85] avg_epoch_loss=2.638481\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=85 train loss <loss>=2.77315816879\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:57 INFO 139866244298560] Epoch[34] Batch [85]#011Speed: 474.07 samples/sec#011loss=2.773158\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:58 INFO 139866244298560] Epoch[34] Batch[90] avg_epoch_loss=2.632073\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=90 train loss <loss>=2.52185621262\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:58 INFO 139866244298560] Epoch[34] Batch [90]#011Speed: 593.21 samples/sec#011loss=2.521856\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:59 INFO 139866244298560] Epoch[34] Batch[95] avg_epoch_loss=2.630791\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=95 train loss <loss>=2.6074614048\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:59 INFO 139866244298560] Epoch[34] Batch [95]#011Speed: 483.20 samples/sec#011loss=2.607461\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:59 INFO 139866244298560] Epoch[34] Batch[100] avg_epoch_loss=2.621647\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=100 train loss <loss>=2.4460767746\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:44:59 INFO 139866244298560] Epoch[34] Batch [100]#011Speed: 589.70 samples/sec#011loss=2.446077\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:00 INFO 139866244298560] Epoch[34] Batch[105] avg_epoch_loss=2.600839\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=105 train loss <loss>=2.18053541183\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:00 INFO 139866244298560] Epoch[34] Batch [105]#011Speed: 456.09 samples/sec#011loss=2.180535\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:00 INFO 139866244298560] Epoch[34] Batch[110] avg_epoch_loss=2.583803\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=110 train loss <loss>=2.22262253761\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:00 INFO 139866244298560] Epoch[34] Batch [110]#011Speed: 591.73 samples/sec#011loss=2.222623\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:01 INFO 139866244298560] Epoch[34] Batch[115] avg_epoch_loss=2.576277\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=115 train loss <loss>=2.40921843052\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:01 INFO 139866244298560] Epoch[34] Batch [115]#011Speed: 459.38 samples/sec#011loss=2.409218\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:02 INFO 139866244298560] Epoch[34] Batch[120] avg_epoch_loss=2.569612\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=120 train loss <loss>=2.41496808529\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:02 INFO 139866244298560] Epoch[34] Batch [120]#011Speed: 589.54 samples/sec#011loss=2.414968\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:02 INFO 139866244298560] Epoch[34] Batch[125] avg_epoch_loss=2.582565\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=125 train loss <loss>=2.89602303505\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:02 INFO 139866244298560] Epoch[34] Batch [125]#011Speed: 483.21 samples/sec#011loss=2.896023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:03 INFO 139866244298560] Epoch[34] Batch[130] avg_epoch_loss=2.591772\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=130 train loss <loss>=2.82380871773\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:03 INFO 139866244298560] Epoch[34] Batch [130]#011Speed: 592.08 samples/sec#011loss=2.823809\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:04 INFO 139866244298560] Epoch[34] Batch[135] avg_epoch_loss=2.602648\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=135 train loss <loss>=2.88757667542\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:04 INFO 139866244298560] Epoch[34] Batch [135]#011Speed: 480.35 samples/sec#011loss=2.887577\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:04 INFO 139866244298560] Epoch[34] Batch[140] avg_epoch_loss=2.619932\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=140 train loss <loss>=3.0900829792\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:04 INFO 139866244298560] Epoch[34] Batch [140]#011Speed: 578.61 samples/sec#011loss=3.090083\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:05 INFO 139866244298560] Epoch[34] Batch[145] avg_epoch_loss=2.617800\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=145 train loss <loss>=2.55767240524\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:05 INFO 139866244298560] Epoch[34] Batch [145]#011Speed: 461.95 samples/sec#011loss=2.557672\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:05 INFO 139866244298560] Epoch[34] Batch[150] avg_epoch_loss=2.619979\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=150 train loss <loss>=2.68358969688\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:05 INFO 139866244298560] Epoch[34] Batch [150]#011Speed: 593.35 samples/sec#011loss=2.683590\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:06 INFO 139866244298560] Epoch[34] Batch[155] avg_epoch_loss=2.617325\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=155 train loss <loss>=2.53716802597\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:06 INFO 139866244298560] Epoch[34] Batch [155]#011Speed: 470.83 samples/sec#011loss=2.537168\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:07 INFO 139866244298560] Epoch[34] Batch[160] avg_epoch_loss=2.606042\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=160 train loss <loss>=2.25403022766\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:07 INFO 139866244298560] Epoch[34] Batch [160]#011Speed: 591.69 samples/sec#011loss=2.254030\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:07 INFO 139866244298560] Epoch[34] Batch[165] avg_epoch_loss=2.602596\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=165 train loss <loss>=2.49163603783\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:07 INFO 139866244298560] Epoch[34] Batch [165]#011Speed: 460.29 samples/sec#011loss=2.491636\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:08 INFO 139866244298560] Epoch[34] Batch[170] avg_epoch_loss=2.598743\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=170 train loss <loss>=2.47081313133\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:08 INFO 139866244298560] Epoch[34] Batch [170]#011Speed: 584.27 samples/sec#011loss=2.470813\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:09 INFO 139866244298560] Epoch[34] Batch[175] avg_epoch_loss=2.595750\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=175 train loss <loss>=2.49340233803\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:09 INFO 139866244298560] Epoch[34] Batch [175]#011Speed: 469.37 samples/sec#011loss=2.493402\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:09 INFO 139866244298560] Epoch[34] Batch[180] avg_epoch_loss=2.595391\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=180 train loss <loss>=2.58276324272\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:09 INFO 139866244298560] Epoch[34] Batch [180]#011Speed: 589.70 samples/sec#011loss=2.582763\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:10 INFO 139866244298560] Epoch[34] Batch[185] avg_epoch_loss=2.601185\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=185 train loss <loss>=2.81092834473\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:10 INFO 139866244298560] Epoch[34] Batch [185]#011Speed: 463.89 samples/sec#011loss=2.810928\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:10 INFO 139866244298560] Epoch[34] Batch[190] avg_epoch_loss=2.605668\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=190 train loss <loss>=2.77241978645\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:10 INFO 139866244298560] Epoch[34] Batch [190]#011Speed: 595.00 samples/sec#011loss=2.772420\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:11 INFO 139866244298560] Epoch[34] Batch[195] avg_epoch_loss=2.620269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=195 train loss <loss>=3.17803354263\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:11 INFO 139866244298560] Epoch[34] Batch [195]#011Speed: 475.63 samples/sec#011loss=3.178034\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:12 INFO 139866244298560] Epoch[34] Batch[200] avg_epoch_loss=2.634173\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=200 train loss <loss>=3.17921385765\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:12 INFO 139866244298560] Epoch[34] Batch [200]#011Speed: 598.08 samples/sec#011loss=3.179214\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:12 INFO 139866244298560] Epoch[34] Batch[205] avg_epoch_loss=2.655069\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=205 train loss <loss>=3.49508590698\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:12 INFO 139866244298560] Epoch[34] Batch [205]#011Speed: 469.52 samples/sec#011loss=3.495086\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:13 INFO 139866244298560] Epoch[34] Batch[210] avg_epoch_loss=2.673197\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=210 train loss <loss>=3.42007489204\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:13 INFO 139866244298560] Epoch[34] Batch [210]#011Speed: 595.39 samples/sec#011loss=3.420075\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:13 INFO 139866244298560] Epoch[34] Batch[215] avg_epoch_loss=2.677855\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=215 train loss <loss>=2.87441129684\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:13 INFO 139866244298560] Epoch[34] Batch [215]#011Speed: 478.01 samples/sec#011loss=2.874411\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:14 INFO 139866244298560] Epoch[34] Batch[220] avg_epoch_loss=2.676273\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=220 train loss <loss>=2.60792784691\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:14 INFO 139866244298560] Epoch[34] Batch [220]#011Speed: 470.54 samples/sec#011loss=2.607928\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:15 INFO 139866244298560] Epoch[34] Batch[225] avg_epoch_loss=2.674762\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=225 train loss <loss>=2.60795483589\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:15 INFO 139866244298560] Epoch[34] Batch [225]#011Speed: 590.50 samples/sec#011loss=2.607955\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:15 INFO 139866244298560] Epoch[34] Batch[230] avg_epoch_loss=2.672044\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=230 train loss <loss>=2.54923138618\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:15 INFO 139866244298560] Epoch[34] Batch [230]#011Speed: 477.98 samples/sec#011loss=2.549231\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:16 INFO 139866244298560] Epoch[34] Batch[235] avg_epoch_loss=2.669058\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=235 train loss <loss>=2.53107376099\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:16 INFO 139866244298560] Epoch[34] Batch [235]#011Speed: 586.06 samples/sec#011loss=2.531074\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:17 INFO 139866244298560] Epoch[34] Batch[240] avg_epoch_loss=2.664809\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=240 train loss <loss>=2.46426095963\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:17 INFO 139866244298560] Epoch[34] Batch [240]#011Speed: 433.44 samples/sec#011loss=2.464261\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:17 INFO 139866244298560] Epoch[34] Batch[245] avg_epoch_loss=2.667277\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=245 train loss <loss>=2.7862578392\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:17 INFO 139866244298560] Epoch[34] Batch [245]#011Speed: 584.58 samples/sec#011loss=2.786258\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:18 INFO 139866244298560] Epoch[34] Batch[250] avg_epoch_loss=2.671941\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=250 train loss <loss>=2.90138173103\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:18 INFO 139866244298560] Epoch[34] Batch [250]#011Speed: 476.71 samples/sec#011loss=2.901382\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:18 INFO 139866244298560] Epoch[34] Batch[255] avg_epoch_loss=2.684305\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=255 train loss <loss>=3.30496730804\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:18 INFO 139866244298560] Epoch[34] Batch [255]#011Speed: 595.95 samples/sec#011loss=3.304967\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:19 INFO 139866244298560] Epoch[34] Batch[260] avg_epoch_loss=2.694285\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=260 train loss <loss>=3.20525813103\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:19 INFO 139866244298560] Epoch[34] Batch [260]#011Speed: 503.02 samples/sec#011loss=3.205258\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:20 INFO 139866244298560] Epoch[34] Batch[265] avg_epoch_loss=2.703836\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, batch=265 train loss <loss>=3.20239844322\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:20 INFO 139866244298560] Epoch[34] Batch [265]#011Speed: 591.76 samples/sec#011loss=3.202398\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:20 INFO 139866244298560] processed a total of 17060 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32785.979986190796, \"sum\": 32785.979986190796, \"min\": 32785.979986190796}}, \"EndTime\": 1599443120.110819, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443087.324214}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:20 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=520.342399292 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:20 INFO 139866244298560] #progress_metric: host=algo-1, completed 43 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=34, train loss <loss>=2.70749292838\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:20 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:20 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_de307769-9b8d-4713-b8fb-d25042ee0c4e-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.26786994934082, \"sum\": 18.26786994934082, \"min\": 18.26786994934082}}, \"EndTime\": 1599443120.130069, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443120.110909}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:20 INFO 139866244298560] Epoch[35] Batch[0] avg_epoch_loss=2.222598\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=0 train loss <loss>=2.22259759903\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:20 INFO 139866244298560] Epoch[35] Batch[5] avg_epoch_loss=2.014820\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=5 train loss <loss>=2.0148195227\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:20 INFO 139866244298560] Epoch[35] Batch [5]#011Speed: 595.58 samples/sec#011loss=2.014820\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:21 INFO 139866244298560] Epoch[35] Batch[10] avg_epoch_loss=1.981038\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=10 train loss <loss>=1.94050107002\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:21 INFO 139866244298560] Epoch[35] Batch [10]#011Speed: 588.60 samples/sec#011loss=1.940501\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:22 INFO 139866244298560] Epoch[35] Batch[15] avg_epoch_loss=2.174477\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=15 train loss <loss>=2.60004329681\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:22 INFO 139866244298560] Epoch[35] Batch [15]#011Speed: 474.54 samples/sec#011loss=2.600043\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:22 INFO 139866244298560] Epoch[35] Batch[20] avg_epoch_loss=2.316341\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=20 train loss <loss>=2.77030391693\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:22 INFO 139866244298560] Epoch[35] Batch [20]#011Speed: 591.64 samples/sec#011loss=2.770304\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:23 INFO 139866244298560] Epoch[35] Batch[25] avg_epoch_loss=2.377266\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=25 train loss <loss>=2.6331533432\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:23 INFO 139866244298560] Epoch[35] Batch [25]#011Speed: 472.22 samples/sec#011loss=2.633153\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:24 INFO 139866244298560] Epoch[35] Batch[30] avg_epoch_loss=2.447605\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=30 train loss <loss>=2.81336297989\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:24 INFO 139866244298560] Epoch[35] Batch [30]#011Speed: 485.09 samples/sec#011loss=2.813363\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:24 INFO 139866244298560] Epoch[35] Batch[35] avg_epoch_loss=2.503000\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=35 train loss <loss>=2.84645323753\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:24 INFO 139866244298560] Epoch[35] Batch [35]#011Speed: 592.80 samples/sec#011loss=2.846453\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:25 INFO 139866244298560] Epoch[35] Batch[40] avg_epoch_loss=2.527227\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=40 train loss <loss>=2.70166244507\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:25 INFO 139866244298560] Epoch[35] Batch [40]#011Speed: 479.29 samples/sec#011loss=2.701662\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:25 INFO 139866244298560] Epoch[35] Batch[45] avg_epoch_loss=2.528797\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=45 train loss <loss>=2.54166760445\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:25 INFO 139866244298560] Epoch[35] Batch [45]#011Speed: 585.57 samples/sec#011loss=2.541668\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:26 INFO 139866244298560] Epoch[35] Batch[50] avg_epoch_loss=2.498109\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=50 train loss <loss>=2.2157841444\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:26 INFO 139866244298560] Epoch[35] Batch [50]#011Speed: 478.92 samples/sec#011loss=2.215784\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:26 INFO 139866244298560] Epoch[35] Batch[55] avg_epoch_loss=2.479575\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=55 train loss <loss>=2.29052219391\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:26 INFO 139866244298560] Epoch[35] Batch [55]#011Speed: 598.54 samples/sec#011loss=2.290522\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:27 INFO 139866244298560] Epoch[35] Batch[60] avg_epoch_loss=2.468732\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=60 train loss <loss>=2.34729423523\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:27 INFO 139866244298560] Epoch[35] Batch [60]#011Speed: 475.05 samples/sec#011loss=2.347294\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:28 INFO 139866244298560] Epoch[35] Batch[65] avg_epoch_loss=2.479206\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=65 train loss <loss>=2.60698657036\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:28 INFO 139866244298560] Epoch[35] Batch [65]#011Speed: 598.52 samples/sec#011loss=2.606987\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:28 INFO 139866244298560] Epoch[35] Batch[70] avg_epoch_loss=2.516415\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=70 train loss <loss>=3.00757284164\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:28 INFO 139866244298560] Epoch[35] Batch [70]#011Speed: 472.89 samples/sec#011loss=3.007573\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:29 INFO 139866244298560] Epoch[35] Batch[75] avg_epoch_loss=2.550971\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=75 train loss <loss>=3.04166059494\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:29 INFO 139866244298560] Epoch[35] Batch [75]#011Speed: 585.46 samples/sec#011loss=3.041661\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:30 INFO 139866244298560] Epoch[35] Batch[80] avg_epoch_loss=2.595191\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=80 train loss <loss>=3.26734557152\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:30 INFO 139866244298560] Epoch[35] Batch [80]#011Speed: 483.94 samples/sec#011loss=3.267346\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:30 INFO 139866244298560] Epoch[35] Batch[85] avg_epoch_loss=2.626066\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=85 train loss <loss>=3.1262406826\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:30 INFO 139866244298560] Epoch[35] Batch [85]#011Speed: 480.37 samples/sec#011loss=3.126241\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:31 INFO 139866244298560] Epoch[35] Batch[90] avg_epoch_loss=2.616430\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=90 train loss <loss>=2.45069360733\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:31 INFO 139866244298560] Epoch[35] Batch [90]#011Speed: 586.43 samples/sec#011loss=2.450694\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:31 INFO 139866244298560] Epoch[35] Batch[95] avg_epoch_loss=2.608991\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=95 train loss <loss>=2.47358932495\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:31 INFO 139866244298560] Epoch[35] Batch [95]#011Speed: 474.14 samples/sec#011loss=2.473589\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:32 INFO 139866244298560] Epoch[35] Batch[100] avg_epoch_loss=2.597643\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=100 train loss <loss>=2.37977313995\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:32 INFO 139866244298560] Epoch[35] Batch [100]#011Speed: 591.93 samples/sec#011loss=2.379773\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:33 INFO 139866244298560] Epoch[35] Batch[105] avg_epoch_loss=2.584611\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=105 train loss <loss>=2.32135181427\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:33 INFO 139866244298560] Epoch[35] Batch [105]#011Speed: 479.84 samples/sec#011loss=2.321352\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:33 INFO 139866244298560] Epoch[35] Batch[110] avg_epoch_loss=2.568724\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=110 train loss <loss>=2.23193092346\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:33 INFO 139866244298560] Epoch[35] Batch [110]#011Speed: 595.65 samples/sec#011loss=2.231931\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:34 INFO 139866244298560] Epoch[35] Batch[115] avg_epoch_loss=2.558096\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=115 train loss <loss>=2.32215163708\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:34 INFO 139866244298560] Epoch[35] Batch [115]#011Speed: 473.63 samples/sec#011loss=2.322152\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:34 INFO 139866244298560] Epoch[35] Batch[120] avg_epoch_loss=2.553776\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=120 train loss <loss>=2.45354709625\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:34 INFO 139866244298560] Epoch[35] Batch [120]#011Speed: 589.01 samples/sec#011loss=2.453547\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:35 INFO 139866244298560] Epoch[35] Batch[125] avg_epoch_loss=2.549058\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=125 train loss <loss>=2.43488607407\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:35 INFO 139866244298560] Epoch[35] Batch [125]#011Speed: 474.04 samples/sec#011loss=2.434886\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:36 INFO 139866244298560] Epoch[35] Batch[130] avg_epoch_loss=2.557656\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=130 train loss <loss>=2.77432632446\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:36 INFO 139866244298560] Epoch[35] Batch [130]#011Speed: 594.07 samples/sec#011loss=2.774326\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:36 INFO 139866244298560] Epoch[35] Batch[135] avg_epoch_loss=2.570377\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=135 train loss <loss>=2.90367255211\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:36 INFO 139866244298560] Epoch[35] Batch [135]#011Speed: 467.97 samples/sec#011loss=2.903673\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:37 INFO 139866244298560] Epoch[35] Batch[140] avg_epoch_loss=2.587308\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=140 train loss <loss>=3.04783425331\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:37 INFO 139866244298560] Epoch[35] Batch [140]#011Speed: 583.26 samples/sec#011loss=3.047834\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:38 INFO 139866244298560] Epoch[35] Batch[145] avg_epoch_loss=2.598575\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=145 train loss <loss>=2.91630601883\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:38 INFO 139866244298560] Epoch[35] Batch [145]#011Speed: 480.58 samples/sec#011loss=2.916306\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:38 INFO 139866244298560] Epoch[35] Batch[150] avg_epoch_loss=2.593722\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=150 train loss <loss>=2.45201668739\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:38 INFO 139866244298560] Epoch[35] Batch [150]#011Speed: 590.02 samples/sec#011loss=2.452017\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:39 INFO 139866244298560] Epoch[35] Batch[155] avg_epoch_loss=2.591646\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=155 train loss <loss>=2.52894787788\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:39 INFO 139866244298560] Epoch[35] Batch [155]#011Speed: 478.66 samples/sec#011loss=2.528948\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:39 INFO 139866244298560] Epoch[35] Batch[160] avg_epoch_loss=2.593335\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=160 train loss <loss>=2.64600844383\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:39 INFO 139866244298560] Epoch[35] Batch [160]#011Speed: 589.50 samples/sec#011loss=2.646008\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:40 INFO 139866244298560] Epoch[35] Batch[165] avg_epoch_loss=2.584858\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=165 train loss <loss>=2.31191296577\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:40 INFO 139866244298560] Epoch[35] Batch [165]#011Speed: 466.95 samples/sec#011loss=2.311913\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:41 INFO 139866244298560] Epoch[35] Batch[170] avg_epoch_loss=2.577161\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=170 train loss <loss>=2.32160654068\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:41 INFO 139866244298560] Epoch[35] Batch [170]#011Speed: 595.34 samples/sec#011loss=2.321607\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:41 INFO 139866244298560] Epoch[35] Batch[175] avg_epoch_loss=2.569412\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=175 train loss <loss>=2.30442051888\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:41 INFO 139866244298560] Epoch[35] Batch [175]#011Speed: 590.90 samples/sec#011loss=2.304421\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:42 INFO 139866244298560] Epoch[35] Batch[180] avg_epoch_loss=2.571797\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=180 train loss <loss>=2.65574636459\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:42 INFO 139866244298560] Epoch[35] Batch [180]#011Speed: 472.30 samples/sec#011loss=2.655746\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:42 INFO 139866244298560] Epoch[35] Batch[185] avg_epoch_loss=2.569643\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=185 train loss <loss>=2.49164915085\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:42 INFO 139866244298560] Epoch[35] Batch [185]#011Speed: 591.32 samples/sec#011loss=2.491649\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:43 INFO 139866244298560] Epoch[35] Batch[190] avg_epoch_loss=2.578976\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=190 train loss <loss>=2.92616887093\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:43 INFO 139866244298560] Epoch[35] Batch [190]#011Speed: 479.13 samples/sec#011loss=2.926169\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:43 INFO 139866244298560] Epoch[35] Batch[195] avg_epoch_loss=2.588627\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=195 train loss <loss>=2.9572827816\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:43 INFO 139866244298560] Epoch[35] Batch [195]#011Speed: 598.98 samples/sec#011loss=2.957283\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:44 INFO 139866244298560] Epoch[35] Batch[200] avg_epoch_loss=2.607409\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=200 train loss <loss>=3.34367260933\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:44 INFO 139866244298560] Epoch[35] Batch [200]#011Speed: 474.91 samples/sec#011loss=3.343673\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:45 INFO 139866244298560] Epoch[35] Batch[205] avg_epoch_loss=2.627069\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=205 train loss <loss>=3.4174156189\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:45 INFO 139866244298560] Epoch[35] Batch [205]#011Speed: 591.53 samples/sec#011loss=3.417416\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:45 INFO 139866244298560] Epoch[35] Batch[210] avg_epoch_loss=2.639311\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=210 train loss <loss>=3.14369320869\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:45 INFO 139866244298560] Epoch[35] Batch [210]#011Speed: 482.06 samples/sec#011loss=3.143693\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:46 INFO 139866244298560] Epoch[35] Batch[215] avg_epoch_loss=2.649825\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=215 train loss <loss>=3.09348568916\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:46 INFO 139866244298560] Epoch[35] Batch [215]#011Speed: 472.66 samples/sec#011loss=3.093486\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:47 INFO 139866244298560] Epoch[35] Batch[220] avg_epoch_loss=2.647774\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=220 train loss <loss>=2.55916380882\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:47 INFO 139866244298560] Epoch[35] Batch [220]#011Speed: 575.02 samples/sec#011loss=2.559164\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:47 INFO 139866244298560] Epoch[35] Batch[225] avg_epoch_loss=2.645081\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=225 train loss <loss>=2.52607731819\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:47 INFO 139866244298560] Epoch[35] Batch [225]#011Speed: 453.23 samples/sec#011loss=2.526077\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:48 INFO 139866244298560] Epoch[35] Batch[230] avg_epoch_loss=2.636616\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=230 train loss <loss>=2.25400671959\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:48 INFO 139866244298560] Epoch[35] Batch [230]#011Speed: 596.30 samples/sec#011loss=2.254007\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:49 INFO 139866244298560] Epoch[35] Batch[235] avg_epoch_loss=2.638420\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=235 train loss <loss>=2.72173962593\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:49 INFO 139866244298560] Epoch[35] Batch [235]#011Speed: 475.55 samples/sec#011loss=2.721740\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:49 INFO 139866244298560] Epoch[35] Batch[240] avg_epoch_loss=2.637674\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=240 train loss <loss>=2.60246329308\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:49 INFO 139866244298560] Epoch[35] Batch [240]#011Speed: 592.19 samples/sec#011loss=2.602463\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:50 INFO 139866244298560] Epoch[35] Batch[245] avg_epoch_loss=2.639563\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=245 train loss <loss>=2.73060092926\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:50 INFO 139866244298560] Epoch[35] Batch [245]#011Speed: 479.63 samples/sec#011loss=2.730601\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:50 INFO 139866244298560] Epoch[35] Batch[250] avg_epoch_loss=2.645786\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=250 train loss <loss>=2.95195431709\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:50 INFO 139866244298560] Epoch[35] Batch [250]#011Speed: 595.07 samples/sec#011loss=2.951954\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:51 INFO 139866244298560] Epoch[35] Batch[255] avg_epoch_loss=2.653647\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=255 train loss <loss>=3.0482776165\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:51 INFO 139866244298560] Epoch[35] Batch [255]#011Speed: 468.64 samples/sec#011loss=3.048278\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:51 INFO 139866244298560] Epoch[35] Batch[260] avg_epoch_loss=2.661348\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=260 train loss <loss>=3.05563898087\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:51 INFO 139866244298560] Epoch[35] Batch [260]#011Speed: 596.08 samples/sec#011loss=3.055639\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:52 INFO 139866244298560] Epoch[35] Batch[265] avg_epoch_loss=2.672857\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=265 train loss <loss>=3.27364292145\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:52 INFO 139866244298560] Epoch[35] Batch [265]#011Speed: 494.93 samples/sec#011loss=3.273643\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:53 INFO 139866244298560] Epoch[35] Batch[270] avg_epoch_loss=2.683100\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, batch=270 train loss <loss>=3.22804031372\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:53 INFO 139866244298560] Epoch[35] Batch [270]#011Speed: 582.02 samples/sec#011loss=3.228040\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:53 INFO 139866244298560] processed a total of 17361 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33143.491983413696, \"sum\": 33143.491983413696, \"min\": 33143.491983413696}}, \"EndTime\": 1599443153.273707, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443120.130137}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:53 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=523.811105907 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:53 INFO 139866244298560] #progress_metric: host=algo-1, completed 45 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=35, train loss <loss>=2.68858840141\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:53 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:53 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_40b0ee77-0b01-49e9-8444-7c2b460569c7-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.924070358276367, \"sum\": 17.924070358276367, \"min\": 17.924070358276367}}, \"EndTime\": 1599443153.292363, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443153.27379}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:53 INFO 139866244298560] Epoch[36] Batch[0] avg_epoch_loss=2.173348\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=0 train loss <loss>=2.17334794998\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:54 INFO 139866244298560] Epoch[36] Batch[5] avg_epoch_loss=2.160744\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=5 train loss <loss>=2.16074436903\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:54 INFO 139866244298560] Epoch[36] Batch [5]#011Speed: 595.53 samples/sec#011loss=2.160744\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:54 INFO 139866244298560] Epoch[36] Batch[10] avg_epoch_loss=2.124214\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=10 train loss <loss>=2.08037657738\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:54 INFO 139866244298560] Epoch[36] Batch [10]#011Speed: 468.96 samples/sec#011loss=2.080377\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:55 INFO 139866244298560] Epoch[36] Batch[15] avg_epoch_loss=2.279896\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=15 train loss <loss>=2.62239665985\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:55 INFO 139866244298560] Epoch[36] Batch [15]#011Speed: 589.87 samples/sec#011loss=2.622397\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:55 INFO 139866244298560] Epoch[36] Batch[20] avg_epoch_loss=2.407116\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=20 train loss <loss>=2.81422042847\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:55 INFO 139866244298560] Epoch[36] Batch [20]#011Speed: 478.75 samples/sec#011loss=2.814220\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:56 INFO 139866244298560] Epoch[36] Batch[25] avg_epoch_loss=2.488426\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=25 train loss <loss>=2.82992858887\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:56 INFO 139866244298560] Epoch[36] Batch [25]#011Speed: 589.77 samples/sec#011loss=2.829929\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:57 INFO 139866244298560] Epoch[36] Batch[30] avg_epoch_loss=2.494141\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=30 train loss <loss>=2.52385723591\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:57 INFO 139866244298560] Epoch[36] Batch [30]#011Speed: 445.20 samples/sec#011loss=2.523857\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:57 INFO 139866244298560] Epoch[36] Batch[35] avg_epoch_loss=2.500268\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=35 train loss <loss>=2.53825850487\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:57 INFO 139866244298560] Epoch[36] Batch [35]#011Speed: 592.87 samples/sec#011loss=2.538259\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:58 INFO 139866244298560] Epoch[36] Batch[40] avg_epoch_loss=2.515414\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=40 train loss <loss>=2.62446537018\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:58 INFO 139866244298560] Epoch[36] Batch [40]#011Speed: 478.08 samples/sec#011loss=2.624465\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:58 INFO 139866244298560] Epoch[36] Batch[45] avg_epoch_loss=2.518586\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=45 train loss <loss>=2.54459071159\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:58 INFO 139866244298560] Epoch[36] Batch [45]#011Speed: 596.69 samples/sec#011loss=2.544591\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:59 INFO 139866244298560] Epoch[36] Batch[50] avg_epoch_loss=2.512497\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=50 train loss <loss>=2.45647711754\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:45:59 INFO 139866244298560] Epoch[36] Batch [50]#011Speed: 474.49 samples/sec#011loss=2.456477\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:00 INFO 139866244298560] Epoch[36] Batch[55] avg_epoch_loss=2.491121\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=55 train loss <loss>=2.27309453487\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:00 INFO 139866244298560] Epoch[36] Batch [55]#011Speed: 589.65 samples/sec#011loss=2.273095\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:00 INFO 139866244298560] Epoch[36] Batch[60] avg_epoch_loss=2.483684\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=60 train loss <loss>=2.40038189888\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:00 INFO 139866244298560] Epoch[36] Batch [60]#011Speed: 477.19 samples/sec#011loss=2.400382\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:01 INFO 139866244298560] Epoch[36] Batch[65] avg_epoch_loss=2.498406\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=65 train loss <loss>=2.67801866531\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:01 INFO 139866244298560] Epoch[36] Batch [65]#011Speed: 568.72 samples/sec#011loss=2.678019\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:02 INFO 139866244298560] Epoch[36] Batch[70] avg_epoch_loss=2.529607\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=70 train loss <loss>=2.94145712852\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:02 INFO 139866244298560] Epoch[36] Batch [70]#011Speed: 420.71 samples/sec#011loss=2.941457\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:02 INFO 139866244298560] Epoch[36] Batch[75] avg_epoch_loss=2.556446\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=75 train loss <loss>=2.93755927086\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:02 INFO 139866244298560] Epoch[36] Batch [75]#011Speed: 586.03 samples/sec#011loss=2.937559\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:03 INFO 139866244298560] Epoch[36] Batch[80] avg_epoch_loss=2.594293\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=80 train loss <loss>=3.16957483292\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:03 INFO 139866244298560] Epoch[36] Batch [80]#011Speed: 476.16 samples/sec#011loss=3.169575\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:03 INFO 139866244298560] Epoch[36] Batch[85] avg_epoch_loss=2.630313\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=85 train loss <loss>=3.21382555962\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:03 INFO 139866244298560] Epoch[36] Batch [85]#011Speed: 593.69 samples/sec#011loss=3.213826\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:04 INFO 139866244298560] Epoch[36] Batch[90] avg_epoch_loss=2.639056\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=90 train loss <loss>=2.78944129944\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:04 INFO 139866244298560] Epoch[36] Batch [90]#011Speed: 470.41 samples/sec#011loss=2.789441\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:05 INFO 139866244298560] Epoch[36] Batch[95] avg_epoch_loss=2.652422\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=95 train loss <loss>=2.89568719864\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:05 INFO 139866244298560] Epoch[36] Batch [95]#011Speed: 592.43 samples/sec#011loss=2.895687\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:05 INFO 139866244298560] Epoch[36] Batch[100] avg_epoch_loss=2.631725\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=100 train loss <loss>=2.23434784412\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:05 INFO 139866244298560] Epoch[36] Batch [100]#011Speed: 477.05 samples/sec#011loss=2.234348\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:06 INFO 139866244298560] Epoch[36] Batch[105] avg_epoch_loss=2.628177\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=105 train loss <loss>=2.556503582\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:06 INFO 139866244298560] Epoch[36] Batch [105]#011Speed: 596.48 samples/sec#011loss=2.556504\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:07 INFO 139866244298560] Epoch[36] Batch[110] avg_epoch_loss=2.610997\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=110 train loss <loss>=2.24677758217\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:07 INFO 139866244298560] Epoch[36] Batch [110]#011Speed: 434.49 samples/sec#011loss=2.246778\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:07 INFO 139866244298560] Epoch[36] Batch[115] avg_epoch_loss=2.599766\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=115 train loss <loss>=2.35044641495\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:07 INFO 139866244298560] Epoch[36] Batch [115]#011Speed: 578.60 samples/sec#011loss=2.350446\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:08 INFO 139866244298560] Epoch[36] Batch[120] avg_epoch_loss=2.598934\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=120 train loss <loss>=2.57961893082\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:08 INFO 139866244298560] Epoch[36] Batch [120]#011Speed: 480.72 samples/sec#011loss=2.579619\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:08 INFO 139866244298560] Epoch[36] Batch[125] avg_epoch_loss=2.600792\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=125 train loss <loss>=2.64576282501\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:08 INFO 139866244298560] Epoch[36] Batch [125]#011Speed: 587.95 samples/sec#011loss=2.645763\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:09 INFO 139866244298560] Epoch[36] Batch[130] avg_epoch_loss=2.615952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=130 train loss <loss>=2.99799237251\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:09 INFO 139866244298560] Epoch[36] Batch [130]#011Speed: 464.60 samples/sec#011loss=2.997992\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:10 INFO 139866244298560] Epoch[36] Batch[135] avg_epoch_loss=2.633969\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=135 train loss <loss>=3.10599694252\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:10 INFO 139866244298560] Epoch[36] Batch [135]#011Speed: 595.16 samples/sec#011loss=3.105997\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:10 INFO 139866244298560] Epoch[36] Batch[140] avg_epoch_loss=2.642698\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=140 train loss <loss>=2.8801404953\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:10 INFO 139866244298560] Epoch[36] Batch [140]#011Speed: 475.42 samples/sec#011loss=2.880140\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:11 INFO 139866244298560] Epoch[36] Batch[145] avg_epoch_loss=2.646849\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=145 train loss <loss>=2.76389122009\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:11 INFO 139866244298560] Epoch[36] Batch [145]#011Speed: 473.53 samples/sec#011loss=2.763891\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:12 INFO 139866244298560] Epoch[36] Batch[150] avg_epoch_loss=2.636091\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=150 train loss <loss>=2.32196350098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:12 INFO 139866244298560] Epoch[36] Batch [150]#011Speed: 593.05 samples/sec#011loss=2.321964\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:12 INFO 139866244298560] Epoch[36] Batch[155] avg_epoch_loss=2.625946\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=155 train loss <loss>=2.31956832409\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:12 INFO 139866244298560] Epoch[36] Batch [155]#011Speed: 450.21 samples/sec#011loss=2.319568\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:13 INFO 139866244298560] Epoch[36] Batch[160] avg_epoch_loss=2.623006\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=160 train loss <loss>=2.53127002716\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:13 INFO 139866244298560] Epoch[36] Batch [160]#011Speed: 592.56 samples/sec#011loss=2.531270\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:13 INFO 139866244298560] Epoch[36] Batch[165] avg_epoch_loss=2.617261\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=165 train loss <loss>=2.43228151798\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:13 INFO 139866244298560] Epoch[36] Batch [165]#011Speed: 476.49 samples/sec#011loss=2.432282\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:14 INFO 139866244298560] Epoch[36] Batch[170] avg_epoch_loss=2.607255\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=170 train loss <loss>=2.27503752708\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:14 INFO 139866244298560] Epoch[36] Batch [170]#011Speed: 597.24 samples/sec#011loss=2.275038\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:15 INFO 139866244298560] Epoch[36] Batch[175] avg_epoch_loss=2.597661\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=175 train loss <loss>=2.2695630312\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:15 INFO 139866244298560] Epoch[36] Batch [175]#011Speed: 456.89 samples/sec#011loss=2.269563\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:15 INFO 139866244298560] Epoch[36] Batch[180] avg_epoch_loss=2.603160\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=180 train loss <loss>=2.79673366547\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:15 INFO 139866244298560] Epoch[36] Batch [180]#011Speed: 583.69 samples/sec#011loss=2.796734\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:16 INFO 139866244298560] Epoch[36] Batch[185] avg_epoch_loss=2.617198\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=185 train loss <loss>=3.12537765503\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:16 INFO 139866244298560] Epoch[36] Batch [185]#011Speed: 483.16 samples/sec#011loss=3.125378\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:16 INFO 139866244298560] Epoch[36] Batch[190] avg_epoch_loss=2.634103\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=190 train loss <loss>=3.26297121048\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:16 INFO 139866244298560] Epoch[36] Batch [190]#011Speed: 589.33 samples/sec#011loss=3.262971\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:17 INFO 139866244298560] Epoch[36] Batch[195] avg_epoch_loss=2.650821\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=195 train loss <loss>=3.28944225311\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:17 INFO 139866244298560] Epoch[36] Batch [195]#011Speed: 421.31 samples/sec#011loss=3.289442\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:18 INFO 139866244298560] Epoch[36] Batch[200] avg_epoch_loss=2.669207\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=200 train loss <loss>=3.38994326591\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:18 INFO 139866244298560] Epoch[36] Batch [200]#011Speed: 590.80 samples/sec#011loss=3.389943\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:18 INFO 139866244298560] Epoch[36] Batch[205] avg_epoch_loss=2.675587\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=205 train loss <loss>=2.93206686974\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:18 INFO 139866244298560] Epoch[36] Batch [205]#011Speed: 479.69 samples/sec#011loss=2.932067\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:19 INFO 139866244298560] Epoch[36] Batch[210] avg_epoch_loss=2.678820\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=210 train loss <loss>=2.81200790405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:19 INFO 139866244298560] Epoch[36] Batch [210]#011Speed: 593.14 samples/sec#011loss=2.812008\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:20 INFO 139866244298560] Epoch[36] Batch[215] avg_epoch_loss=2.673938\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=215 train loss <loss>=2.46791090965\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:20 INFO 139866244298560] Epoch[36] Batch [215]#011Speed: 466.01 samples/sec#011loss=2.467911\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:20 INFO 139866244298560] Epoch[36] Batch[220] avg_epoch_loss=2.664927\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=220 train loss <loss>=2.27564315796\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:20 INFO 139866244298560] Epoch[36] Batch [220]#011Speed: 585.29 samples/sec#011loss=2.275643\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:21 INFO 139866244298560] Epoch[36] Batch[225] avg_epoch_loss=2.665259\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=225 train loss <loss>=2.67996516228\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:21 INFO 139866244298560] Epoch[36] Batch [225]#011Speed: 461.63 samples/sec#011loss=2.679965\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:21 INFO 139866244298560] Epoch[36] Batch[230] avg_epoch_loss=2.661759\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=230 train loss <loss>=2.50352020264\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:21 INFO 139866244298560] Epoch[36] Batch [230]#011Speed: 594.59 samples/sec#011loss=2.503520\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:22 INFO 139866244298560] Epoch[36] Batch[235] avg_epoch_loss=2.662960\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=235 train loss <loss>=2.71844215393\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:22 INFO 139866244298560] Epoch[36] Batch [235]#011Speed: 434.06 samples/sec#011loss=2.718442\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:23 INFO 139866244298560] Epoch[36] Batch[240] avg_epoch_loss=2.664722\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=240 train loss <loss>=2.74790086746\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:23 INFO 139866244298560] Epoch[36] Batch [240]#011Speed: 595.90 samples/sec#011loss=2.747901\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:23 INFO 139866244298560] Epoch[36] Batch[245] avg_epoch_loss=2.682470\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=245 train loss <loss>=3.53791947365\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:23 INFO 139866244298560] Epoch[36] Batch [245]#011Speed: 476.38 samples/sec#011loss=3.537919\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:24 INFO 139866244298560] Epoch[36] Batch[250] avg_epoch_loss=2.695455\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=250 train loss <loss>=3.33433094025\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:24 INFO 139866244298560] Epoch[36] Batch [250]#011Speed: 592.82 samples/sec#011loss=3.334331\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:25 INFO 139866244298560] Epoch[36] Batch[255] avg_epoch_loss=2.701930\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=255 train loss <loss>=3.02695145607\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:25 INFO 139866244298560] Epoch[36] Batch [255]#011Speed: 476.60 samples/sec#011loss=3.026951\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:25 INFO 139866244298560] Epoch[36] Batch[260] avg_epoch_loss=2.714985\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=260 train loss <loss>=3.38340320587\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:25 INFO 139866244298560] Epoch[36] Batch [260]#011Speed: 581.22 samples/sec#011loss=3.383403\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:26 INFO 139866244298560] Epoch[36] Batch[265] avg_epoch_loss=2.717429\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=265 train loss <loss>=2.84501724243\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:26 INFO 139866244298560] Epoch[36] Batch [265]#011Speed: 484.65 samples/sec#011loss=2.845017\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:26 INFO 139866244298560] Epoch[36] Batch[270] avg_epoch_loss=2.712585\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, batch=270 train loss <loss>=2.45489492416\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:26 INFO 139866244298560] Epoch[36] Batch [270]#011Speed: 584.84 samples/sec#011loss=2.454895\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:26 INFO 139866244298560] processed a total of 17361 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33626.40905380249, \"sum\": 33626.40905380249, \"min\": 33626.40905380249}}, \"EndTime\": 1599443186.918928, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443153.292444}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:26 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=516.28906945 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:26 INFO 139866244298560] #progress_metric: host=algo-1, completed 46 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=36, train loss <loss>=2.70557226526\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:26 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:27 INFO 139866244298560] Epoch[37] Batch[0] avg_epoch_loss=2.424430\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=0 train loss <loss>=2.42442989349\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:27 INFO 139866244298560] Epoch[37] Batch[5] avg_epoch_loss=1.993556\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=5 train loss <loss>=1.99355640014\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:27 INFO 139866244298560] Epoch[37] Batch [5]#011Speed: 548.71 samples/sec#011loss=1.993556\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:28 INFO 139866244298560] Epoch[37] Batch[10] avg_epoch_loss=2.146734\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=10 train loss <loss>=2.33054637909\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:28 INFO 139866244298560] Epoch[37] Batch [10]#011Speed: 479.74 samples/sec#011loss=2.330546\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:28 INFO 139866244298560] Epoch[37] Batch[15] avg_epoch_loss=2.283573\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=15 train loss <loss>=2.58461828232\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:28 INFO 139866244298560] Epoch[37] Batch [15]#011Speed: 589.13 samples/sec#011loss=2.584618\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:29 INFO 139866244298560] Epoch[37] Batch[20] avg_epoch_loss=2.414315\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=20 train loss <loss>=2.83269176483\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:29 INFO 139866244298560] Epoch[37] Batch [20]#011Speed: 473.30 samples/sec#011loss=2.832692\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:30 INFO 139866244298560] Epoch[37] Batch[25] avg_epoch_loss=2.496449\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=25 train loss <loss>=2.84141058922\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:30 INFO 139866244298560] Epoch[37] Batch [25]#011Speed: 593.12 samples/sec#011loss=2.841411\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:30 INFO 139866244298560] Epoch[37] Batch[30] avg_epoch_loss=2.504971\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=30 train loss <loss>=2.5492857933\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:30 INFO 139866244298560] Epoch[37] Batch [30]#011Speed: 471.80 samples/sec#011loss=2.549286\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:31 INFO 139866244298560] Epoch[37] Batch[35] avg_epoch_loss=2.502081\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=35 train loss <loss>=2.48416032791\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:31 INFO 139866244298560] Epoch[37] Batch [35]#011Speed: 592.49 samples/sec#011loss=2.484160\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:32 INFO 139866244298560] Epoch[37] Batch[40] avg_epoch_loss=2.507201\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=40 train loss <loss>=2.54406676292\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:32 INFO 139866244298560] Epoch[37] Batch [40]#011Speed: 480.49 samples/sec#011loss=2.544067\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:32 INFO 139866244298560] Epoch[37] Batch[45] avg_epoch_loss=2.508344\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=45 train loss <loss>=2.51771802902\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:32 INFO 139866244298560] Epoch[37] Batch [45]#011Speed: 553.87 samples/sec#011loss=2.517718\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:33 INFO 139866244298560] Epoch[37] Batch[50] avg_epoch_loss=2.504836\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=50 train loss <loss>=2.47256059647\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:33 INFO 139866244298560] Epoch[37] Batch [50]#011Speed: 471.96 samples/sec#011loss=2.472561\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:33 INFO 139866244298560] Epoch[37] Batch[55] avg_epoch_loss=2.495670\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=55 train loss <loss>=2.40218248367\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:33 INFO 139866244298560] Epoch[37] Batch [55]#011Speed: 588.62 samples/sec#011loss=2.402182\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:34 INFO 139866244298560] Epoch[37] Batch[60] avg_epoch_loss=2.489431\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=60 train loss <loss>=2.41955513954\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:34 INFO 139866244298560] Epoch[37] Batch [60]#011Speed: 481.16 samples/sec#011loss=2.419555\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:35 INFO 139866244298560] Epoch[37] Batch[65] avg_epoch_loss=2.466970\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=65 train loss <loss>=2.19294028282\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:35 INFO 139866244298560] Epoch[37] Batch [65]#011Speed: 587.42 samples/sec#011loss=2.192940\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:35 INFO 139866244298560] Epoch[37] Batch[70] avg_epoch_loss=2.500124\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=70 train loss <loss>=2.93775992393\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:35 INFO 139866244298560] Epoch[37] Batch [70]#011Speed: 472.20 samples/sec#011loss=2.937760\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:36 INFO 139866244298560] Epoch[37] Batch[75] avg_epoch_loss=2.526061\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=75 train loss <loss>=2.89435720444\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:36 INFO 139866244298560] Epoch[37] Batch [75]#011Speed: 485.86 samples/sec#011loss=2.894357\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:36 INFO 139866244298560] Epoch[37] Batch[80] avg_epoch_loss=2.571400\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=80 train loss <loss>=3.26055846214\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:36 INFO 139866244298560] Epoch[37] Batch [80]#011Speed: 588.96 samples/sec#011loss=3.260558\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:37 INFO 139866244298560] Epoch[37] Batch[85] avg_epoch_loss=2.596615\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=85 train loss <loss>=3.00509352684\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:37 INFO 139866244298560] Epoch[37] Batch [85]#011Speed: 474.00 samples/sec#011loss=3.005094\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:38 INFO 139866244298560] Epoch[37] Batch[90] avg_epoch_loss=2.603091\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=90 train loss <loss>=2.71448426247\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:38 INFO 139866244298560] Epoch[37] Batch [90]#011Speed: 562.01 samples/sec#011loss=2.714484\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:38 INFO 139866244298560] Epoch[37] Batch[95] avg_epoch_loss=2.597529\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=95 train loss <loss>=2.4963013649\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:38 INFO 139866244298560] Epoch[37] Batch [95]#011Speed: 476.81 samples/sec#011loss=2.496301\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:39 INFO 139866244298560] Epoch[37] Batch[100] avg_epoch_loss=2.594439\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=100 train loss <loss>=2.53510460854\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:39 INFO 139866244298560] Epoch[37] Batch [100]#011Speed: 593.02 samples/sec#011loss=2.535105\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:40 INFO 139866244298560] Epoch[37] Batch[105] avg_epoch_loss=2.583481\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=105 train loss <loss>=2.3621257782\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:40 INFO 139866244298560] Epoch[37] Batch [105]#011Speed: 475.72 samples/sec#011loss=2.362126\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:40 INFO 139866244298560] Epoch[37] Batch[110] avg_epoch_loss=2.565183\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=110 train loss <loss>=2.17727930546\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:40 INFO 139866244298560] Epoch[37] Batch [110]#011Speed: 587.20 samples/sec#011loss=2.177279\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:41 INFO 139866244298560] Epoch[37] Batch[115] avg_epoch_loss=2.562859\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=115 train loss <loss>=2.51125597954\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:41 INFO 139866244298560] Epoch[37] Batch [115]#011Speed: 480.17 samples/sec#011loss=2.511256\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:41 INFO 139866244298560] Epoch[37] Batch[120] avg_epoch_loss=2.553771\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=120 train loss <loss>=2.3429330349\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:41 INFO 139866244298560] Epoch[37] Batch [120]#011Speed: 596.04 samples/sec#011loss=2.342933\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:42 INFO 139866244298560] Epoch[37] Batch[125] avg_epoch_loss=2.554570\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=125 train loss <loss>=2.57391533852\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:42 INFO 139866244298560] Epoch[37] Batch [125]#011Speed: 478.24 samples/sec#011loss=2.573915\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:43 INFO 139866244298560] Epoch[37] Batch[130] avg_epoch_loss=2.556806\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=130 train loss <loss>=2.61315531731\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:43 INFO 139866244298560] Epoch[37] Batch [130]#011Speed: 532.50 samples/sec#011loss=2.613155\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:43 INFO 139866244298560] Epoch[37] Batch[135] avg_epoch_loss=2.576420\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=135 train loss <loss>=3.09030475616\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:43 INFO 139866244298560] Epoch[37] Batch [135]#011Speed: 476.44 samples/sec#011loss=3.090305\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:44 INFO 139866244298560] Epoch[37] Batch[140] avg_epoch_loss=2.595804\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=140 train loss <loss>=3.12304468155\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:44 INFO 139866244298560] Epoch[37] Batch [140]#011Speed: 591.52 samples/sec#011loss=3.123045\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:44 INFO 139866244298560] Epoch[37] Batch[145] avg_epoch_loss=2.597860\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=145 train loss <loss>=2.65584168434\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:44 INFO 139866244298560] Epoch[37] Batch [145]#011Speed: 474.88 samples/sec#011loss=2.655842\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:45 INFO 139866244298560] Epoch[37] Batch[150] avg_epoch_loss=2.589933\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=150 train loss <loss>=2.35845246315\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:45 INFO 139866244298560] Epoch[37] Batch [150]#011Speed: 580.57 samples/sec#011loss=2.358452\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:46 INFO 139866244298560] Epoch[37] Batch[155] avg_epoch_loss=2.589287\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=155 train loss <loss>=2.56977190971\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:46 INFO 139866244298560] Epoch[37] Batch [155]#011Speed: 468.17 samples/sec#011loss=2.569772\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:46 INFO 139866244298560] Epoch[37] Batch[160] avg_epoch_loss=2.588371\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=160 train loss <loss>=2.55980286598\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:46 INFO 139866244298560] Epoch[37] Batch [160]#011Speed: 596.06 samples/sec#011loss=2.559803\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:47 INFO 139866244298560] Epoch[37] Batch[165] avg_epoch_loss=2.587085\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=165 train loss <loss>=2.5456890583\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:47 INFO 139866244298560] Epoch[37] Batch [165]#011Speed: 459.58 samples/sec#011loss=2.545689\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:48 INFO 139866244298560] Epoch[37] Batch[170] avg_epoch_loss=2.577463\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=170 train loss <loss>=2.25798208714\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:48 INFO 139866244298560] Epoch[37] Batch [170]#011Speed: 416.33 samples/sec#011loss=2.257982\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:48 INFO 139866244298560] Epoch[37] Batch[175] avg_epoch_loss=2.576553\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=175 train loss <loss>=2.54543147087\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:48 INFO 139866244298560] Epoch[37] Batch [175]#011Speed: 584.32 samples/sec#011loss=2.545431\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:49 INFO 139866244298560] Epoch[37] Batch[180] avg_epoch_loss=2.579513\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=180 train loss <loss>=2.68372688293\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:49 INFO 139866244298560] Epoch[37] Batch [180]#011Speed: 470.78 samples/sec#011loss=2.683727\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:50 INFO 139866244298560] Epoch[37] Batch[185] avg_epoch_loss=2.592094\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=185 train loss <loss>=3.04752717018\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:50 INFO 139866244298560] Epoch[37] Batch [185]#011Speed: 591.84 samples/sec#011loss=3.047527\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:50 INFO 139866244298560] Epoch[37] Batch[190] avg_epoch_loss=2.613676\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=190 train loss <loss>=3.41650524139\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:50 INFO 139866244298560] Epoch[37] Batch [190]#011Speed: 480.19 samples/sec#011loss=3.416505\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:51 INFO 139866244298560] Epoch[37] Batch[195] avg_epoch_loss=2.639918\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=195 train loss <loss>=3.6423763752\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:51 INFO 139866244298560] Epoch[37] Batch [195]#011Speed: 595.38 samples/sec#011loss=3.642376\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:51 INFO 139866244298560] Epoch[37] Batch[200] avg_epoch_loss=2.660365\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=200 train loss <loss>=3.46190099716\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:51 INFO 139866244298560] Epoch[37] Batch [200]#011Speed: 477.13 samples/sec#011loss=3.461901\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:52 INFO 139866244298560] Epoch[37] Batch[205] avg_epoch_loss=2.673020\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=205 train loss <loss>=3.18174161911\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:52 INFO 139866244298560] Epoch[37] Batch [205]#011Speed: 590.69 samples/sec#011loss=3.181742\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:53 INFO 139866244298560] Epoch[37] Batch[210] avg_epoch_loss=2.678790\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=210 train loss <loss>=2.91649894714\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:53 INFO 139866244298560] Epoch[37] Batch [210]#011Speed: 444.78 samples/sec#011loss=2.916499\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:53 INFO 139866244298560] Epoch[37] Batch[215] avg_epoch_loss=2.674783\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=215 train loss <loss>=2.50568413734\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:53 INFO 139866244298560] Epoch[37] Batch [215]#011Speed: 591.13 samples/sec#011loss=2.505684\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:54 INFO 139866244298560] Epoch[37] Batch[220] avg_epoch_loss=2.671251\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=220 train loss <loss>=2.51869158745\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:54 INFO 139866244298560] Epoch[37] Batch [220]#011Speed: 468.36 samples/sec#011loss=2.518692\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:54 INFO 139866244298560] Epoch[37] Batch[225] avg_epoch_loss=2.672842\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=225 train loss <loss>=2.74315829277\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:54 INFO 139866244298560] Epoch[37] Batch [225]#011Speed: 589.49 samples/sec#011loss=2.743158\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:55 INFO 139866244298560] Epoch[37] Batch[230] avg_epoch_loss=2.675580\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=230 train loss <loss>=2.79934434891\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:55 INFO 139866244298560] Epoch[37] Batch [230]#011Speed: 467.27 samples/sec#011loss=2.799344\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:56 INFO 139866244298560] Epoch[37] Batch[235] avg_epoch_loss=2.681768\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=235 train loss <loss>=2.96763854027\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:56 INFO 139866244298560] Epoch[37] Batch [235]#011Speed: 587.84 samples/sec#011loss=2.967639\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:56 INFO 139866244298560] Epoch[37] Batch[240] avg_epoch_loss=2.687075\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=240 train loss <loss>=2.93754997253\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:56 INFO 139866244298560] Epoch[37] Batch [240]#011Speed: 484.10 samples/sec#011loss=2.937550\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:57 INFO 139866244298560] Epoch[37] Batch[245] avg_epoch_loss=2.691156\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=245 train loss <loss>=2.88790535927\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:57 INFO 139866244298560] Epoch[37] Batch [245]#011Speed: 595.82 samples/sec#011loss=2.887905\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:58 INFO 139866244298560] Epoch[37] Batch[250] avg_epoch_loss=2.702972\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=250 train loss <loss>=3.28430094719\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:58 INFO 139866244298560] Epoch[37] Batch [250]#011Speed: 480.15 samples/sec#011loss=3.284301\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:58 INFO 139866244298560] Epoch[37] Batch[255] avg_epoch_loss=2.715237\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=255 train loss <loss>=3.33092503548\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:58 INFO 139866244298560] Epoch[37] Batch [255]#011Speed: 541.45 samples/sec#011loss=3.330925\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:59 INFO 139866244298560] Epoch[37] Batch[260] avg_epoch_loss=2.720122\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=260 train loss <loss>=2.97025823593\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:59 INFO 139866244298560] Epoch[37] Batch [260]#011Speed: 493.44 samples/sec#011loss=2.970258\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:59 INFO 139866244298560] Epoch[37] Batch[265] avg_epoch_loss=2.725204\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, batch=265 train loss <loss>=2.99047651291\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:59 INFO 139866244298560] Epoch[37] Batch [265]#011Speed: 592.57 samples/sec#011loss=2.990477\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:59 INFO 139866244298560] processed a total of 17039 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32969.63310241699, \"sum\": 32969.63310241699, \"min\": 32969.63310241699}}, \"EndTime\": 1599443219.889332, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443186.918995}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:59 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=516.80652491 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:59 INFO 139866244298560] #progress_metric: host=algo-1, completed 47 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=37, train loss <loss>=2.72952645146\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:46:59 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:00 INFO 139866244298560] Epoch[38] Batch[0] avg_epoch_loss=2.206056\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=0 train loss <loss>=2.20605611801\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:00 INFO 139866244298560] Epoch[38] Batch[5] avg_epoch_loss=2.159989\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=5 train loss <loss>=2.1599885424\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:00 INFO 139866244298560] Epoch[38] Batch [5]#011Speed: 587.36 samples/sec#011loss=2.159989\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:01 INFO 139866244298560] Epoch[38] Batch[10] avg_epoch_loss=2.185473\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=10 train loss <loss>=2.21605534554\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:01 INFO 139866244298560] Epoch[38] Batch [10]#011Speed: 460.65 samples/sec#011loss=2.216055\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:01 INFO 139866244298560] Epoch[38] Batch[15] avg_epoch_loss=2.384659\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=15 train loss <loss>=2.82286725044\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:01 INFO 139866244298560] Epoch[38] Batch [15]#011Speed: 591.95 samples/sec#011loss=2.822867\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:02 INFO 139866244298560] Epoch[38] Batch[20] avg_epoch_loss=2.473692\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=20 train loss <loss>=2.75859861374\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:02 INFO 139866244298560] Epoch[38] Batch [20]#011Speed: 477.22 samples/sec#011loss=2.758599\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:03 INFO 139866244298560] Epoch[38] Batch[25] avg_epoch_loss=2.513868\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=25 train loss <loss>=2.68260383606\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:03 INFO 139866244298560] Epoch[38] Batch [25]#011Speed: 592.90 samples/sec#011loss=2.682604\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:03 INFO 139866244298560] Epoch[38] Batch[30] avg_epoch_loss=2.479608\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=30 train loss <loss>=2.30145585537\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:03 INFO 139866244298560] Epoch[38] Batch [30]#011Speed: 446.02 samples/sec#011loss=2.301456\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:04 INFO 139866244298560] Epoch[38] Batch[35] avg_epoch_loss=2.460269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=35 train loss <loss>=2.34036927223\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:04 INFO 139866244298560] Epoch[38] Batch [35]#011Speed: 592.53 samples/sec#011loss=2.340369\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:05 INFO 139866244298560] Epoch[38] Batch[40] avg_epoch_loss=2.469976\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=40 train loss <loss>=2.53986525536\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:05 INFO 139866244298560] Epoch[38] Batch [40]#011Speed: 471.29 samples/sec#011loss=2.539865\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:05 INFO 139866244298560] Epoch[38] Batch[45] avg_epoch_loss=2.438073\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=45 train loss <loss>=2.17647278309\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:05 INFO 139866244298560] Epoch[38] Batch [45]#011Speed: 590.34 samples/sec#011loss=2.176473\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:06 INFO 139866244298560] Epoch[38] Batch[50] avg_epoch_loss=2.437906\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=50 train loss <loss>=2.43636484146\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:06 INFO 139866244298560] Epoch[38] Batch [50]#011Speed: 472.26 samples/sec#011loss=2.436365\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:06 INFO 139866244298560] Epoch[38] Batch[55] avg_epoch_loss=2.432546\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=55 train loss <loss>=2.37788076401\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:06 INFO 139866244298560] Epoch[38] Batch [55]#011Speed: 586.55 samples/sec#011loss=2.377881\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:07 INFO 139866244298560] Epoch[38] Batch[60] avg_epoch_loss=2.438565\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=60 train loss <loss>=2.50597319603\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:07 INFO 139866244298560] Epoch[38] Batch [60]#011Speed: 474.77 samples/sec#011loss=2.505973\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:08 INFO 139866244298560] Epoch[38] Batch[65] avg_epoch_loss=2.440321\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=65 train loss <loss>=2.46174931526\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:08 INFO 139866244298560] Epoch[38] Batch [65]#011Speed: 595.09 samples/sec#011loss=2.461749\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:08 INFO 139866244298560] Epoch[38] Batch[70] avg_epoch_loss=2.481967\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=70 train loss <loss>=3.03168792725\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:08 INFO 139866244298560] Epoch[38] Batch [70]#011Speed: 436.15 samples/sec#011loss=3.031688\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:09 INFO 139866244298560] Epoch[38] Batch[75] avg_epoch_loss=2.516332\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=75 train loss <loss>=3.0043179512\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:09 INFO 139866244298560] Epoch[38] Batch [75]#011Speed: 593.56 samples/sec#011loss=3.004318\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:09 INFO 139866244298560] Epoch[38] Batch[80] avg_epoch_loss=2.552041\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=80 train loss <loss>=3.09481139183\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:09 INFO 139866244298560] Epoch[38] Batch [80]#011Speed: 479.07 samples/sec#011loss=3.094811\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:10 INFO 139866244298560] Epoch[38] Batch[85] avg_epoch_loss=2.582378\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=85 train loss <loss>=3.07383980751\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:10 INFO 139866244298560] Epoch[38] Batch [85]#011Speed: 589.29 samples/sec#011loss=3.073840\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:11 INFO 139866244298560] Epoch[38] Batch[90] avg_epoch_loss=2.576218\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=90 train loss <loss>=2.47027411461\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:11 INFO 139866244298560] Epoch[38] Batch [90]#011Speed: 475.31 samples/sec#011loss=2.470274\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:11 INFO 139866244298560] Epoch[38] Batch[95] avg_epoch_loss=2.557259\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=95 train loss <loss>=2.21220793724\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:11 INFO 139866244298560] Epoch[38] Batch [95]#011Speed: 476.85 samples/sec#011loss=2.212208\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:12 INFO 139866244298560] Epoch[38] Batch[100] avg_epoch_loss=2.547443\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=100 train loss <loss>=2.3589723587\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:12 INFO 139866244298560] Epoch[38] Batch [100]#011Speed: 591.30 samples/sec#011loss=2.358972\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:13 INFO 139866244298560] Epoch[38] Batch[105] avg_epoch_loss=2.538608\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=105 train loss <loss>=2.36012535095\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:13 INFO 139866244298560] Epoch[38] Batch [105]#011Speed: 479.20 samples/sec#011loss=2.360125\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:13 INFO 139866244298560] Epoch[38] Batch[110] avg_epoch_loss=2.520639\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=110 train loss <loss>=2.13971102238\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:13 INFO 139866244298560] Epoch[38] Batch [110]#011Speed: 536.69 samples/sec#011loss=2.139711\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:14 INFO 139866244298560] Epoch[38] Batch[115] avg_epoch_loss=2.533004\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=115 train loss <loss>=2.80750727654\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:14 INFO 139866244298560] Epoch[38] Batch [115]#011Speed: 488.16 samples/sec#011loss=2.807507\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:14 INFO 139866244298560] Epoch[38] Batch[120] avg_epoch_loss=2.558818\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=120 train loss <loss>=3.15769681931\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:14 INFO 139866244298560] Epoch[38] Batch [120]#011Speed: 570.99 samples/sec#011loss=3.157697\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:15 INFO 139866244298560] Epoch[38] Batch[125] avg_epoch_loss=2.575658\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=125 train loss <loss>=2.98318634033\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:15 INFO 139866244298560] Epoch[38] Batch [125]#011Speed: 482.86 samples/sec#011loss=2.983186\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:16 INFO 139866244298560] Epoch[38] Batch[130] avg_epoch_loss=2.590965\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=130 train loss <loss>=2.9766933918\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:16 INFO 139866244298560] Epoch[38] Batch [130]#011Speed: 588.75 samples/sec#011loss=2.976693\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:16 INFO 139866244298560] Epoch[38] Batch[135] avg_epoch_loss=2.588066\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=135 train loss <loss>=2.51211605072\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:16 INFO 139866244298560] Epoch[38] Batch [135]#011Speed: 468.45 samples/sec#011loss=2.512116\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:17 INFO 139866244298560] Epoch[38] Batch[140] avg_epoch_loss=2.573905\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=140 train loss <loss>=2.18873295784\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:17 INFO 139866244298560] Epoch[38] Batch [140]#011Speed: 592.87 samples/sec#011loss=2.188733\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:18 INFO 139866244298560] Epoch[38] Batch[145] avg_epoch_loss=2.556313\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=145 train loss <loss>=2.06020245552\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:18 INFO 139866244298560] Epoch[38] Batch [145]#011Speed: 433.31 samples/sec#011loss=2.060202\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:18 INFO 139866244298560] Epoch[38] Batch[150] avg_epoch_loss=2.543993\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=150 train loss <loss>=2.18426029682\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:18 INFO 139866244298560] Epoch[38] Batch [150]#011Speed: 528.15 samples/sec#011loss=2.184260\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:19 INFO 139866244298560] Epoch[38] Batch[155] avg_epoch_loss=2.538637\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=155 train loss <loss>=2.3768860817\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:19 INFO 139866244298560] Epoch[38] Batch [155]#011Speed: 480.38 samples/sec#011loss=2.376886\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:20 INFO 139866244298560] Epoch[38] Batch[160] avg_epoch_loss=2.540040\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=160 train loss <loss>=2.58380241394\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:20 INFO 139866244298560] Epoch[38] Batch [160]#011Speed: 468.00 samples/sec#011loss=2.583802\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:20 INFO 139866244298560] Epoch[38] Batch[165] avg_epoch_loss=2.549455\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=165 train loss <loss>=2.8526222229\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:20 INFO 139866244298560] Epoch[38] Batch [165]#011Speed: 596.21 samples/sec#011loss=2.852622\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:21 INFO 139866244298560] Epoch[38] Batch[170] avg_epoch_loss=2.554795\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=170 train loss <loss>=2.73208322525\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:21 INFO 139866244298560] Epoch[38] Batch [170]#011Speed: 474.91 samples/sec#011loss=2.732083\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:21 INFO 139866244298560] Epoch[38] Batch[175] avg_epoch_loss=2.576811\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=175 train loss <loss>=3.32978153229\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:21 INFO 139866244298560] Epoch[38] Batch [175]#011Speed: 592.75 samples/sec#011loss=3.329782\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:22 INFO 139866244298560] Epoch[38] Batch[180] avg_epoch_loss=2.601691\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=180 train loss <loss>=3.47744603157\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:22 INFO 139866244298560] Epoch[38] Batch [180]#011Speed: 481.70 samples/sec#011loss=3.477446\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:22 INFO 139866244298560] Epoch[38] Batch[185] avg_epoch_loss=2.619866\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=185 train loss <loss>=3.27782101631\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:22 INFO 139866244298560] Epoch[38] Batch [185]#011Speed: 584.22 samples/sec#011loss=3.277821\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:23 INFO 139866244298560] Epoch[38] Batch[190] avg_epoch_loss=2.622225\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=190 train loss <loss>=2.70996341705\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:23 INFO 139866244298560] Epoch[38] Batch [190]#011Speed: 472.37 samples/sec#011loss=2.709963\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:24 INFO 139866244298560] Epoch[38] Batch[195] avg_epoch_loss=2.622680\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=195 train loss <loss>=2.6400642395\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:24 INFO 139866244298560] Epoch[38] Batch [195]#011Speed: 532.94 samples/sec#011loss=2.640064\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:24 INFO 139866244298560] Epoch[38] Batch[200] avg_epoch_loss=2.626555\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=200 train loss <loss>=2.77844099998\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:24 INFO 139866244298560] Epoch[38] Batch [200]#011Speed: 465.50 samples/sec#011loss=2.778441\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:25 INFO 139866244298560] Epoch[38] Batch[205] avg_epoch_loss=2.624269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=205 train loss <loss>=2.53240013123\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:25 INFO 139866244298560] Epoch[38] Batch [205]#011Speed: 593.30 samples/sec#011loss=2.532400\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:26 INFO 139866244298560] Epoch[38] Batch[210] avg_epoch_loss=2.622441\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=210 train loss <loss>=2.54710688591\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:26 INFO 139866244298560] Epoch[38] Batch [210]#011Speed: 470.08 samples/sec#011loss=2.547107\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:26 INFO 139866244298560] Epoch[38] Batch[215] avg_epoch_loss=2.615060\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=215 train loss <loss>=2.3035847187\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:26 INFO 139866244298560] Epoch[38] Batch [215]#011Speed: 593.69 samples/sec#011loss=2.303585\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:27 INFO 139866244298560] Epoch[38] Batch[220] avg_epoch_loss=2.619929\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=220 train loss <loss>=2.83028702736\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:27 INFO 139866244298560] Epoch[38] Batch [220]#011Speed: 481.19 samples/sec#011loss=2.830287\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:27 INFO 139866244298560] Epoch[38] Batch[225] avg_epoch_loss=2.627870\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=225 train loss <loss>=2.97886724472\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:27 INFO 139866244298560] Epoch[38] Batch [225]#011Speed: 584.51 samples/sec#011loss=2.978867\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:28 INFO 139866244298560] Epoch[38] Batch[230] avg_epoch_loss=2.648291\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=230 train loss <loss>=3.57132377625\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:28 INFO 139866244298560] Epoch[38] Batch [230]#011Speed: 481.39 samples/sec#011loss=3.571324\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:29 INFO 139866244298560] Epoch[38] Batch[235] avg_epoch_loss=2.664316\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=235 train loss <loss>=3.4046435833\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:29 INFO 139866244298560] Epoch[38] Batch [235]#011Speed: 532.08 samples/sec#011loss=3.404644\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:29 INFO 139866244298560] Epoch[38] Batch[240] avg_epoch_loss=2.680886\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=240 train loss <loss>=3.46298093796\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:29 INFO 139866244298560] Epoch[38] Batch [240]#011Speed: 472.71 samples/sec#011loss=3.462981\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:30 INFO 139866244298560] Epoch[38] Batch[245] avg_epoch_loss=2.696008\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=245 train loss <loss>=3.4249147892\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:30 INFO 139866244298560] Epoch[38] Batch [245]#011Speed: 595.38 samples/sec#011loss=3.424915\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:31 INFO 139866244298560] Epoch[38] Batch[250] avg_epoch_loss=2.691022\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=250 train loss <loss>=2.44568533897\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:31 INFO 139866244298560] Epoch[38] Batch [250]#011Speed: 475.08 samples/sec#011loss=2.445685\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:31 INFO 139866244298560] Epoch[38] Batch[255] avg_epoch_loss=2.689401\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=255 train loss <loss>=2.60802278519\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:31 INFO 139866244298560] Epoch[38] Batch [255]#011Speed: 480.02 samples/sec#011loss=2.608023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:32 INFO 139866244298560] Epoch[38] Batch[260] avg_epoch_loss=2.680376\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=260 train loss <loss>=2.21830558777\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:32 INFO 139866244298560] Epoch[38] Batch [260]#011Speed: 593.31 samples/sec#011loss=2.218306\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:32 INFO 139866244298560] Epoch[38] Batch[265] avg_epoch_loss=2.677495\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, batch=265 train loss <loss>=2.52710285187\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:32 INFO 139866244298560] Epoch[38] Batch [265]#011Speed: 555.91 samples/sec#011loss=2.527103\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:33 INFO 139866244298560] processed a total of 17137 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33188.99893760681, \"sum\": 33188.99893760681, \"min\": 33188.99893760681}}, \"EndTime\": 1599443253.079138, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443219.88942}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:33 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=516.343927996 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:33 INFO 139866244298560] #progress_metric: host=algo-1, completed 48 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=38, train loss <loss>=2.6874615599\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:33 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:33 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_0b62343c-7148-43af-9b3f-3e73276dc392-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 17.85111427307129, \"sum\": 17.85111427307129, \"min\": 17.85111427307129}}, \"EndTime\": 1599443253.097819, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443253.079202}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:33 INFO 139866244298560] Epoch[39] Batch[0] avg_epoch_loss=1.941303\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=0 train loss <loss>=1.94130289555\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:33 INFO 139866244298560] Epoch[39] Batch[5] avg_epoch_loss=2.169914\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=5 train loss <loss>=2.16991351048\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:33 INFO 139866244298560] Epoch[39] Batch [5]#011Speed: 569.40 samples/sec#011loss=2.169914\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:34 INFO 139866244298560] Epoch[39] Batch[10] avg_epoch_loss=2.254737\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=10 train loss <loss>=2.35652561188\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:34 INFO 139866244298560] Epoch[39] Batch [10]#011Speed: 456.22 samples/sec#011loss=2.356526\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:35 INFO 139866244298560] Epoch[39] Batch[15] avg_epoch_loss=2.397916\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=15 train loss <loss>=2.71290955544\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:35 INFO 139866244298560] Epoch[39] Batch [15]#011Speed: 583.43 samples/sec#011loss=2.712910\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:35 INFO 139866244298560] Epoch[39] Batch[20] avg_epoch_loss=2.466480\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=20 train loss <loss>=2.68588342667\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:35 INFO 139866244298560] Epoch[39] Batch [20]#011Speed: 478.45 samples/sec#011loss=2.685883\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:36 INFO 139866244298560] Epoch[39] Batch[25] avg_epoch_loss=2.498659\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=25 train loss <loss>=2.63381319046\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:36 INFO 139866244298560] Epoch[39] Batch [25]#011Speed: 580.66 samples/sec#011loss=2.633813\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:37 INFO 139866244298560] Epoch[39] Batch[30] avg_epoch_loss=2.518818\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=30 train loss <loss>=2.62364296913\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:37 INFO 139866244298560] Epoch[39] Batch [30]#011Speed: 473.54 samples/sec#011loss=2.623643\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:37 INFO 139866244298560] Epoch[39] Batch[35] avg_epoch_loss=2.493321\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=35 train loss <loss>=2.33524122238\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:37 INFO 139866244298560] Epoch[39] Batch [35]#011Speed: 584.90 samples/sec#011loss=2.335241\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:38 INFO 139866244298560] Epoch[39] Batch[40] avg_epoch_loss=2.487554\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=40 train loss <loss>=2.44602923393\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:38 INFO 139866244298560] Epoch[39] Batch [40]#011Speed: 476.14 samples/sec#011loss=2.446029\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:38 INFO 139866244298560] Epoch[39] Batch[45] avg_epoch_loss=2.470276\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=45 train loss <loss>=2.3285949707\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:38 INFO 139866244298560] Epoch[39] Batch [45]#011Speed: 598.00 samples/sec#011loss=2.328595\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:39 INFO 139866244298560] Epoch[39] Batch[50] avg_epoch_loss=2.466869\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=50 train loss <loss>=2.43552536964\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:39 INFO 139866244298560] Epoch[39] Batch [50]#011Speed: 373.99 samples/sec#011loss=2.435525\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:40 INFO 139866244298560] Epoch[39] Batch[55] avg_epoch_loss=2.442447\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=55 train loss <loss>=2.19334700108\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:40 INFO 139866244298560] Epoch[39] Batch [55]#011Speed: 585.27 samples/sec#011loss=2.193347\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:40 INFO 139866244298560] Epoch[39] Batch[60] avg_epoch_loss=2.464709\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=60 train loss <loss>=2.71403880119\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:40 INFO 139866244298560] Epoch[39] Batch [60]#011Speed: 476.58 samples/sec#011loss=2.714039\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:41 INFO 139866244298560] Epoch[39] Batch[65] avg_epoch_loss=2.467863\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=65 train loss <loss>=2.50634851456\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:41 INFO 139866244298560] Epoch[39] Batch [65]#011Speed: 591.27 samples/sec#011loss=2.506349\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:42 INFO 139866244298560] Epoch[39] Batch[70] avg_epoch_loss=2.511788\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=70 train loss <loss>=3.091588974\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:42 INFO 139866244298560] Epoch[39] Batch [70]#011Speed: 479.91 samples/sec#011loss=3.091589\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:42 INFO 139866244298560] Epoch[39] Batch[75] avg_epoch_loss=2.559835\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=75 train loss <loss>=3.24210162163\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:42 INFO 139866244298560] Epoch[39] Batch [75]#011Speed: 591.11 samples/sec#011loss=3.242102\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:43 INFO 139866244298560] Epoch[39] Batch[80] avg_epoch_loss=2.580238\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=80 train loss <loss>=2.89037237167\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:43 INFO 139866244298560] Epoch[39] Batch [80]#011Speed: 479.08 samples/sec#011loss=2.890372\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:43 INFO 139866244298560] Epoch[39] Batch[85] avg_epoch_loss=2.600631\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=85 train loss <loss>=2.93099021912\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:43 INFO 139866244298560] Epoch[39] Batch [85]#011Speed: 473.88 samples/sec#011loss=2.930990\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:44 INFO 139866244298560] Epoch[39] Batch[90] avg_epoch_loss=2.605966\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=90 train loss <loss>=2.6977350235\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:44 INFO 139866244298560] Epoch[39] Batch [90]#011Speed: 542.23 samples/sec#011loss=2.697735\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:45 INFO 139866244298560] Epoch[39] Batch[95] avg_epoch_loss=2.602267\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=95 train loss <loss>=2.53493642807\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:45 INFO 139866244298560] Epoch[39] Batch [95]#011Speed: 472.14 samples/sec#011loss=2.534936\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:45 INFO 139866244298560] Epoch[39] Batch[100] avg_epoch_loss=2.592713\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=100 train loss <loss>=2.40927181244\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:45 INFO 139866244298560] Epoch[39] Batch [100]#011Speed: 593.23 samples/sec#011loss=2.409272\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:46 INFO 139866244298560] Epoch[39] Batch[105] avg_epoch_loss=2.584054\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=105 train loss <loss>=2.40916075706\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:46 INFO 139866244298560] Epoch[39] Batch [105]#011Speed: 476.20 samples/sec#011loss=2.409161\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:46 INFO 139866244298560] Epoch[39] Batch[110] avg_epoch_loss=2.566221\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=110 train loss <loss>=2.18814229965\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:46 INFO 139866244298560] Epoch[39] Batch [110]#011Speed: 592.36 samples/sec#011loss=2.188142\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:47 INFO 139866244298560] Epoch[39] Batch[115] avg_epoch_loss=2.551498\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=115 train loss <loss>=2.2246537447\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:47 INFO 139866244298560] Epoch[39] Batch [115]#011Speed: 486.88 samples/sec#011loss=2.224654\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:48 INFO 139866244298560] Epoch[39] Batch[120] avg_epoch_loss=2.545993\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=120 train loss <loss>=2.41828660965\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:48 INFO 139866244298560] Epoch[39] Batch [120]#011Speed: 537.89 samples/sec#011loss=2.418287\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:48 INFO 139866244298560] Epoch[39] Batch[125] avg_epoch_loss=2.560259\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=125 train loss <loss>=2.90548706055\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:48 INFO 139866244298560] Epoch[39] Batch [125]#011Speed: 469.41 samples/sec#011loss=2.905487\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:49 INFO 139866244298560] Epoch[39] Batch[130] avg_epoch_loss=2.576504\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=130 train loss <loss>=2.98587088585\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:49 INFO 139866244298560] Epoch[39] Batch [130]#011Speed: 544.45 samples/sec#011loss=2.985871\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:50 INFO 139866244298560] Epoch[39] Batch[135] avg_epoch_loss=2.591231\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=135 train loss <loss>=2.9770919323\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:50 INFO 139866244298560] Epoch[39] Batch [135]#011Speed: 468.58 samples/sec#011loss=2.977092\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:50 INFO 139866244298560] Epoch[39] Batch[140] avg_epoch_loss=2.599600\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=140 train loss <loss>=2.82723760605\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:50 INFO 139866244298560] Epoch[39] Batch [140]#011Speed: 590.43 samples/sec#011loss=2.827238\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:51 INFO 139866244298560] Epoch[39] Batch[145] avg_epoch_loss=2.583175\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=145 train loss <loss>=2.11998260021\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:51 INFO 139866244298560] Epoch[39] Batch [145]#011Speed: 471.88 samples/sec#011loss=2.119983\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:51 INFO 139866244298560] Epoch[39] Batch[150] avg_epoch_loss=2.573771\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=150 train loss <loss>=2.2991661787\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:51 INFO 139866244298560] Epoch[39] Batch [150]#011Speed: 583.16 samples/sec#011loss=2.299166\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:52 INFO 139866244298560] Epoch[39] Batch[155] avg_epoch_loss=2.565850\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=155 train loss <loss>=2.32665467262\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:52 INFO 139866244298560] Epoch[39] Batch [155]#011Speed: 468.47 samples/sec#011loss=2.326655\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:53 INFO 139866244298560] Epoch[39] Batch[160] avg_epoch_loss=2.565614\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=160 train loss <loss>=2.55822873116\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:53 INFO 139866244298560] Epoch[39] Batch [160]#011Speed: 579.42 samples/sec#011loss=2.558229\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:53 INFO 139866244298560] Epoch[39] Batch[165] avg_epoch_loss=2.563702\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=165 train loss <loss>=2.50215196609\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:53 INFO 139866244298560] Epoch[39] Batch [165]#011Speed: 474.24 samples/sec#011loss=2.502152\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:54 INFO 139866244298560] Epoch[39] Batch[170] avg_epoch_loss=2.553958\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=170 train loss <loss>=2.23045229912\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:54 INFO 139866244298560] Epoch[39] Batch [170]#011Speed: 540.20 samples/sec#011loss=2.230452\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:55 INFO 139866244298560] Epoch[39] Batch[175] avg_epoch_loss=2.558838\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=175 train loss <loss>=2.72572846413\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:55 INFO 139866244298560] Epoch[39] Batch [175]#011Speed: 439.89 samples/sec#011loss=2.725728\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:55 INFO 139866244298560] Epoch[39] Batch[180] avg_epoch_loss=2.566239\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=180 train loss <loss>=2.82676119804\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:55 INFO 139866244298560] Epoch[39] Batch [180]#011Speed: 593.52 samples/sec#011loss=2.826761\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:56 INFO 139866244298560] Epoch[39] Batch[185] avg_epoch_loss=2.577205\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=185 train loss <loss>=2.97417120934\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:56 INFO 139866244298560] Epoch[39] Batch [185]#011Speed: 470.33 samples/sec#011loss=2.974171\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:56 INFO 139866244298560] Epoch[39] Batch[190] avg_epoch_loss=2.589126\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=190 train loss <loss>=3.03261003494\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:56 INFO 139866244298560] Epoch[39] Batch [190]#011Speed: 586.26 samples/sec#011loss=3.032610\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:57 INFO 139866244298560] Epoch[39] Batch[195] avg_epoch_loss=2.609345\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=195 train loss <loss>=3.38170337677\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:57 INFO 139866244298560] Epoch[39] Batch [195]#011Speed: 480.31 samples/sec#011loss=3.381703\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:58 INFO 139866244298560] Epoch[39] Batch[200] avg_epoch_loss=2.630164\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=200 train loss <loss>=3.44626951218\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:58 INFO 139866244298560] Epoch[39] Batch [200]#011Speed: 588.78 samples/sec#011loss=3.446270\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:58 INFO 139866244298560] Epoch[39] Batch[205] avg_epoch_loss=2.645966\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=205 train loss <loss>=3.28120126724\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:58 INFO 139866244298560] Epoch[39] Batch [205]#011Speed: 482.13 samples/sec#011loss=3.281201\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:59 INFO 139866244298560] Epoch[39] Batch[210] avg_epoch_loss=2.657456\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=210 train loss <loss>=3.13082437515\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:47:59 INFO 139866244298560] Epoch[39] Batch [210]#011Speed: 483.81 samples/sec#011loss=3.130824\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:00 INFO 139866244298560] Epoch[39] Batch[215] avg_epoch_loss=2.646407\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=215 train loss <loss>=2.18015358448\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:00 INFO 139866244298560] Epoch[39] Batch [215]#011Speed: 544.32 samples/sec#011loss=2.180154\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:00 INFO 139866244298560] Epoch[39] Batch[220] avg_epoch_loss=2.643027\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=220 train loss <loss>=2.4970041275\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:00 INFO 139866244298560] Epoch[39] Batch [220]#011Speed: 475.26 samples/sec#011loss=2.497004\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:01 INFO 139866244298560] Epoch[39] Batch[225] avg_epoch_loss=2.637666\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=225 train loss <loss>=2.40070738792\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:01 INFO 139866244298560] Epoch[39] Batch [225]#011Speed: 586.56 samples/sec#011loss=2.400707\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:02 INFO 139866244298560] Epoch[39] Batch[230] avg_epoch_loss=2.641421\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=230 train loss <loss>=2.8111392498\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:02 INFO 139866244298560] Epoch[39] Batch [230]#011Speed: 452.45 samples/sec#011loss=2.811139\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:02 INFO 139866244298560] Epoch[39] Batch[235] avg_epoch_loss=2.644593\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=235 train loss <loss>=2.79116449356\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:02 INFO 139866244298560] Epoch[39] Batch [235]#011Speed: 588.44 samples/sec#011loss=2.791164\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:03 INFO 139866244298560] Epoch[39] Batch[240] avg_epoch_loss=2.646925\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=240 train loss <loss>=2.75697278976\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:03 INFO 139866244298560] Epoch[39] Batch [240]#011Speed: 475.47 samples/sec#011loss=2.756973\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:03 INFO 139866244298560] Epoch[39] Batch[245] avg_epoch_loss=2.655224\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=245 train loss <loss>=3.05526437759\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:03 INFO 139866244298560] Epoch[39] Batch [245]#011Speed: 593.24 samples/sec#011loss=3.055264\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:04 INFO 139866244298560] Epoch[39] Batch[250] avg_epoch_loss=2.660403\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=250 train loss <loss>=2.91517210007\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:04 INFO 139866244298560] Epoch[39] Batch [250]#011Speed: 470.63 samples/sec#011loss=2.915172\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:05 INFO 139866244298560] Epoch[39] Batch[255] avg_epoch_loss=2.672244\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=255 train loss <loss>=3.26668543816\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:05 INFO 139866244298560] Epoch[39] Batch [255]#011Speed: 540.29 samples/sec#011loss=3.266685\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:05 INFO 139866244298560] Epoch[39] Batch[260] avg_epoch_loss=2.682729\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=260 train loss <loss>=3.21956534386\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:05 INFO 139866244298560] Epoch[39] Batch [260]#011Speed: 491.94 samples/sec#011loss=3.219565\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:06 INFO 139866244298560] Epoch[39] Batch[265] avg_epoch_loss=2.686364\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, batch=265 train loss <loss>=2.8761162281\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:06 INFO 139866244298560] Epoch[39] Batch [265]#011Speed: 581.71 samples/sec#011loss=2.876116\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:06 INFO 139866244298560] processed a total of 17126 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33366.84799194336, \"sum\": 33366.84799194336, \"min\": 33366.84799194336}}, \"EndTime\": 1599443286.46482, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443253.097882}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:06 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=513.261945265 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:06 INFO 139866244298560] #progress_metric: host=algo-1, completed 50 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=39, train loss <loss>=2.69090356578\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:06 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:06 INFO 139866244298560] Epoch[40] Batch[0] avg_epoch_loss=2.001999\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=0 train loss <loss>=2.00199866295\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:07 INFO 139866244298560] Epoch[40] Batch[5] avg_epoch_loss=2.085070\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=5 train loss <loss>=2.08506973584\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:07 INFO 139866244298560] Epoch[40] Batch [5]#011Speed: 586.59 samples/sec#011loss=2.085070\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:07 INFO 139866244298560] Epoch[40] Batch[10] avg_epoch_loss=2.164097\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=10 train loss <loss>=2.25892968178\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:07 INFO 139866244298560] Epoch[40] Batch [10]#011Speed: 470.85 samples/sec#011loss=2.258930\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:08 INFO 139866244298560] Epoch[40] Batch[15] avg_epoch_loss=2.349542\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=15 train loss <loss>=2.75752091408\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:08 INFO 139866244298560] Epoch[40] Batch [15]#011Speed: 589.66 samples/sec#011loss=2.757521\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:09 INFO 139866244298560] Epoch[40] Batch[20] avg_epoch_loss=2.477806\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=20 train loss <loss>=2.88825154305\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:09 INFO 139866244298560] Epoch[40] Batch [20]#011Speed: 482.56 samples/sec#011loss=2.888252\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:09 INFO 139866244298560] Epoch[40] Batch[25] avg_epoch_loss=2.550610\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=25 train loss <loss>=2.85638818741\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:09 INFO 139866244298560] Epoch[40] Batch [25]#011Speed: 587.90 samples/sec#011loss=2.856388\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:10 INFO 139866244298560] Epoch[40] Batch[30] avg_epoch_loss=2.530660\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=30 train loss <loss>=2.42691502571\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:10 INFO 139866244298560] Epoch[40] Batch [30]#011Speed: 443.58 samples/sec#011loss=2.426915\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:10 INFO 139866244298560] Epoch[40] Batch[35] avg_epoch_loss=2.513241\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=35 train loss <loss>=2.40524859428\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:10 INFO 139866244298560] Epoch[40] Batch [35]#011Speed: 595.75 samples/sec#011loss=2.405249\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:11 INFO 139866244298560] Epoch[40] Batch[40] avg_epoch_loss=2.495184\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=40 train loss <loss>=2.36517019272\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:11 INFO 139866244298560] Epoch[40] Batch [40]#011Speed: 477.92 samples/sec#011loss=2.365170\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:12 INFO 139866244298560] Epoch[40] Batch[45] avg_epoch_loss=2.466750\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=45 train loss <loss>=2.23359234333\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:12 INFO 139866244298560] Epoch[40] Batch [45]#011Speed: 483.15 samples/sec#011loss=2.233592\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:12 INFO 139866244298560] Epoch[40] Batch[50] avg_epoch_loss=2.458556\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=50 train loss <loss>=2.38317456245\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:12 INFO 139866244298560] Epoch[40] Batch [50]#011Speed: 595.02 samples/sec#011loss=2.383175\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:13 INFO 139866244298560] Epoch[40] Batch[55] avg_epoch_loss=2.457749\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=55 train loss <loss>=2.44951667786\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:13 INFO 139866244298560] Epoch[40] Batch [55]#011Speed: 466.16 samples/sec#011loss=2.449517\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:14 INFO 139866244298560] Epoch[40] Batch[60] avg_epoch_loss=2.481684\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=60 train loss <loss>=2.74975209236\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:14 INFO 139866244298560] Epoch[40] Batch [60]#011Speed: 591.65 samples/sec#011loss=2.749752\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:14 INFO 139866244298560] Epoch[40] Batch[65] avg_epoch_loss=2.534184\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=65 train loss <loss>=3.17468323708\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:14 INFO 139866244298560] Epoch[40] Batch [65]#011Speed: 478.43 samples/sec#011loss=3.174683\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:15 INFO 139866244298560] Epoch[40] Batch[70] avg_epoch_loss=2.575635\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=70 train loss <loss>=3.12279362679\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:15 INFO 139866244298560] Epoch[40] Batch [70]#011Speed: 539.28 samples/sec#011loss=3.122794\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:15 INFO 139866244298560] Epoch[40] Batch[75] avg_epoch_loss=2.628536\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=75 train loss <loss>=3.37971940041\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:15 INFO 139866244298560] Epoch[40] Batch [75]#011Speed: 476.23 samples/sec#011loss=3.379719\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:16 INFO 139866244298560] Epoch[40] Batch[80] avg_epoch_loss=2.655662\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=80 train loss <loss>=3.0679877758\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:16 INFO 139866244298560] Epoch[40] Batch [80]#011Speed: 582.44 samples/sec#011loss=3.067988\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:17 INFO 139866244298560] Epoch[40] Batch[85] avg_epoch_loss=2.674718\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=85 train loss <loss>=2.98342504501\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:17 INFO 139866244298560] Epoch[40] Batch [85]#011Speed: 475.26 samples/sec#011loss=2.983425\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:17 INFO 139866244298560] Epoch[40] Batch[90] avg_epoch_loss=2.660580\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=90 train loss <loss>=2.41739788055\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:17 INFO 139866244298560] Epoch[40] Batch [90]#011Speed: 593.28 samples/sec#011loss=2.417398\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:18 INFO 139866244298560] Epoch[40] Batch[95] avg_epoch_loss=2.648402\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=95 train loss <loss>=2.42676358223\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:18 INFO 139866244298560] Epoch[40] Batch [95]#011Speed: 435.03 samples/sec#011loss=2.426764\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:19 INFO 139866244298560] Epoch[40] Batch[100] avg_epoch_loss=2.633517\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=100 train loss <loss>=2.34773185253\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:19 INFO 139866244298560] Epoch[40] Batch [100]#011Speed: 594.78 samples/sec#011loss=2.347732\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:19 INFO 139866244298560] Epoch[40] Batch[105] avg_epoch_loss=2.619853\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=105 train loss <loss>=2.34383625984\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:19 INFO 139866244298560] Epoch[40] Batch [105]#011Speed: 477.89 samples/sec#011loss=2.343836\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:20 INFO 139866244298560] Epoch[40] Batch[110] avg_epoch_loss=2.610560\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=110 train loss <loss>=2.41354045868\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:20 INFO 139866244298560] Epoch[40] Batch [110]#011Speed: 533.73 samples/sec#011loss=2.413540\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:20 INFO 139866244298560] Epoch[40] Batch[115] avg_epoch_loss=2.619686\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=115 train loss <loss>=2.82229795456\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:20 INFO 139866244298560] Epoch[40] Batch [115]#011Speed: 487.91 samples/sec#011loss=2.822298\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:21 INFO 139866244298560] Epoch[40] Batch[120] avg_epoch_loss=2.632210\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=120 train loss <loss>=2.92275366783\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:21 INFO 139866244298560] Epoch[40] Batch [120]#011Speed: 585.36 samples/sec#011loss=2.922754\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:22 INFO 139866244298560] Epoch[40] Batch[125] avg_epoch_loss=2.651147\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=125 train loss <loss>=3.10943183899\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:22 INFO 139866244298560] Epoch[40] Batch [125]#011Speed: 483.43 samples/sec#011loss=3.109432\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:22 INFO 139866244298560] Epoch[40] Batch[130] avg_epoch_loss=2.659898\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=130 train loss <loss>=2.88041014671\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:22 INFO 139866244298560] Epoch[40] Batch [130]#011Speed: 475.51 samples/sec#011loss=2.880410\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:23 INFO 139866244298560] Epoch[40] Batch[135] avg_epoch_loss=2.652049\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=135 train loss <loss>=2.44642977715\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:23 INFO 139866244298560] Epoch[40] Batch [135]#011Speed: 590.85 samples/sec#011loss=2.446430\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:24 INFO 139866244298560] Epoch[40] Batch[140] avg_epoch_loss=2.638708\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=140 train loss <loss>=2.275816679\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:24 INFO 139866244298560] Epoch[40] Batch [140]#011Speed: 478.10 samples/sec#011loss=2.275817\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:24 INFO 139866244298560] Epoch[40] Batch[145] avg_epoch_loss=2.623993\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=145 train loss <loss>=2.20903773308\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:24 INFO 139866244298560] Epoch[40] Batch [145]#011Speed: 590.27 samples/sec#011loss=2.209038\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:25 INFO 139866244298560] Epoch[40] Batch[150] avg_epoch_loss=2.613246\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=150 train loss <loss>=2.29943442345\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:25 INFO 139866244298560] Epoch[40] Batch [150]#011Speed: 449.33 samples/sec#011loss=2.299434\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:25 INFO 139866244298560] Epoch[40] Batch[155] avg_epoch_loss=2.606392\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=155 train loss <loss>=2.39939723015\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:25 INFO 139866244298560] Epoch[40] Batch [155]#011Speed: 593.25 samples/sec#011loss=2.399397\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:26 INFO 139866244298560] Epoch[40] Batch[160] avg_epoch_loss=2.603034\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=160 train loss <loss>=2.49825863838\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:26 INFO 139866244298560] Epoch[40] Batch [160]#011Speed: 476.38 samples/sec#011loss=2.498259\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:27 INFO 139866244298560] Epoch[40] Batch[165] avg_epoch_loss=2.602764\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=165 train loss <loss>=2.5940867424\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:27 INFO 139866244298560] Epoch[40] Batch [165]#011Speed: 591.16 samples/sec#011loss=2.594087\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:27 INFO 139866244298560] Epoch[40] Batch[170] avg_epoch_loss=2.615386\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=170 train loss <loss>=3.03443217278\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:27 INFO 139866244298560] Epoch[40] Batch [170]#011Speed: 475.56 samples/sec#011loss=3.034432\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:28 INFO 139866244298560] Epoch[40] Batch[175] avg_epoch_loss=2.635427\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=175 train loss <loss>=3.32082099915\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:28 INFO 139866244298560] Epoch[40] Batch [175]#011Speed: 592.72 samples/sec#011loss=3.320821\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:28 INFO 139866244298560] Epoch[40] Batch[180] avg_epoch_loss=2.655217\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=180 train loss <loss>=3.35183467865\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:28 INFO 139866244298560] Epoch[40] Batch [180]#011Speed: 481.87 samples/sec#011loss=3.351835\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:29 INFO 139866244298560] Epoch[40] Batch[185] avg_epoch_loss=2.669662\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=185 train loss <loss>=3.19256820679\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:29 INFO 139866244298560] Epoch[40] Batch [185]#011Speed: 592.44 samples/sec#011loss=3.192568\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:30 INFO 139866244298560] Epoch[40] Batch[190] avg_epoch_loss=2.668409\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=190 train loss <loss>=2.62178337574\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:30 INFO 139866244298560] Epoch[40] Batch [190]#011Speed: 479.97 samples/sec#011loss=2.621783\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:30 INFO 139866244298560] Epoch[40] Batch[195] avg_epoch_loss=2.667594\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=195 train loss <loss>=2.63645596504\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:30 INFO 139866244298560] Epoch[40] Batch [195]#011Speed: 546.50 samples/sec#011loss=2.636456\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:31 INFO 139866244298560] Epoch[40] Batch[200] avg_epoch_loss=2.668712\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=200 train loss <loss>=2.71253705025\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:31 INFO 139866244298560] Epoch[40] Batch [200]#011Speed: 472.48 samples/sec#011loss=2.712537\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:31 INFO 139866244298560] Epoch[40] Batch[205] avg_epoch_loss=2.665985\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=205 train loss <loss>=2.55635719299\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:31 INFO 139866244298560] Epoch[40] Batch [205]#011Speed: 591.13 samples/sec#011loss=2.556357\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:32 INFO 139866244298560] Epoch[40] Batch[210] avg_epoch_loss=2.659946\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=210 train loss <loss>=2.411140728\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:32 INFO 139866244298560] Epoch[40] Batch [210]#011Speed: 478.75 samples/sec#011loss=2.411141\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:33 INFO 139866244298560] Epoch[40] Batch[215] avg_epoch_loss=2.656434\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=215 train loss <loss>=2.50825443268\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:33 INFO 139866244298560] Epoch[40] Batch [215]#011Speed: 591.87 samples/sec#011loss=2.508254\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:33 INFO 139866244298560] Epoch[40] Batch[220] avg_epoch_loss=2.656987\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=220 train loss <loss>=2.68087921143\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:33 INFO 139866244298560] Epoch[40] Batch [220]#011Speed: 474.07 samples/sec#011loss=2.680879\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:34 INFO 139866244298560] Epoch[40] Batch[225] avg_epoch_loss=2.656828\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=225 train loss <loss>=2.64979314804\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:34 INFO 139866244298560] Epoch[40] Batch [225]#011Speed: 593.66 samples/sec#011loss=2.649793\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:35 INFO 139866244298560] Epoch[40] Batch[230] avg_epoch_loss=2.670586\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=230 train loss <loss>=3.29243550301\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:35 INFO 139866244298560] Epoch[40] Batch [230]#011Speed: 475.85 samples/sec#011loss=3.292436\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:35 INFO 139866244298560] Epoch[40] Batch[235] avg_epoch_loss=2.680097\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=235 train loss <loss>=3.11949372292\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:35 INFO 139866244298560] Epoch[40] Batch [235]#011Speed: 503.19 samples/sec#011loss=3.119494\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:36 INFO 139866244298560] Epoch[40] Batch[240] avg_epoch_loss=2.696728\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=240 train loss <loss>=3.48174939156\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:36 INFO 139866244298560] Epoch[40] Batch [240]#011Speed: 470.33 samples/sec#011loss=3.481749\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:37 INFO 139866244298560] Epoch[40] Batch[245] avg_epoch_loss=2.711514\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=245 train loss <loss>=3.42418942451\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:37 INFO 139866244298560] Epoch[40] Batch [245]#011Speed: 484.10 samples/sec#011loss=3.424189\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:37 INFO 139866244298560] Epoch[40] Batch[250] avg_epoch_loss=2.715850\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=250 train loss <loss>=2.92919068336\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:37 INFO 139866244298560] Epoch[40] Batch [250]#011Speed: 583.32 samples/sec#011loss=2.929191\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:38 INFO 139866244298560] Epoch[40] Batch[255] avg_epoch_loss=2.713788\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=255 train loss <loss>=2.61023182869\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:38 INFO 139866244298560] Epoch[40] Batch [255]#011Speed: 478.82 samples/sec#011loss=2.610232\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:38 INFO 139866244298560] Epoch[40] Batch[260] avg_epoch_loss=2.706018\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=260 train loss <loss>=2.30819010735\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:38 INFO 139866244298560] Epoch[40] Batch [260]#011Speed: 590.23 samples/sec#011loss=2.308190\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:39 INFO 139866244298560] Epoch[40] Batch[265] avg_epoch_loss=2.711502\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, batch=265 train loss <loss>=2.9978085041\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:39 INFO 139866244298560] Epoch[40] Batch [265]#011Speed: 574.43 samples/sec#011loss=2.997809\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:39 INFO 139866244298560] processed a total of 16998 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32857.4800491333, \"sum\": 32857.4800491333, \"min\": 32857.4800491333}}, \"EndTime\": 1599443319.322798, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443286.464886}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:39 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=517.323143812 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:39 INFO 139866244298560] #progress_metric: host=algo-1, completed 51 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=40, train loss <loss>=2.71150232661\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:39 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:39 INFO 139866244298560] Epoch[41] Batch[0] avg_epoch_loss=2.183041\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=0 train loss <loss>=2.1830406189\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:40 INFO 139866244298560] Epoch[41] Batch[5] avg_epoch_loss=2.065912\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=5 train loss <loss>=2.06591163079\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:40 INFO 139866244298560] Epoch[41] Batch [5]#011Speed: 591.17 samples/sec#011loss=2.065912\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:40 INFO 139866244298560] Epoch[41] Batch[10] avg_epoch_loss=2.136332\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=10 train loss <loss>=2.22083668709\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:40 INFO 139866244298560] Epoch[41] Batch [10]#011Speed: 436.63 samples/sec#011loss=2.220837\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:41 INFO 139866244298560] Epoch[41] Batch[15] avg_epoch_loss=2.236523\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=15 train loss <loss>=2.45694284439\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:41 INFO 139866244298560] Epoch[41] Batch [15]#011Speed: 589.28 samples/sec#011loss=2.456943\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:42 INFO 139866244298560] Epoch[41] Batch[20] avg_epoch_loss=2.363154\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=20 train loss <loss>=2.76837515831\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:42 INFO 139866244298560] Epoch[41] Batch [20]#011Speed: 479.77 samples/sec#011loss=2.768375\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:42 INFO 139866244298560] Epoch[41] Batch[25] avg_epoch_loss=2.458326\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=25 train loss <loss>=2.85804829597\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:42 INFO 139866244298560] Epoch[41] Batch [25]#011Speed: 594.75 samples/sec#011loss=2.858048\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:43 INFO 139866244298560] Epoch[41] Batch[30] avg_epoch_loss=2.491130\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=30 train loss <loss>=2.66170902252\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:43 INFO 139866244298560] Epoch[41] Batch [30]#011Speed: 480.09 samples/sec#011loss=2.661709\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:43 INFO 139866244298560] Epoch[41] Batch[35] avg_epoch_loss=2.471859\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=35 train loss <loss>=2.35237669945\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:43 INFO 139866244298560] Epoch[41] Batch [35]#011Speed: 595.61 samples/sec#011loss=2.352377\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:44 INFO 139866244298560] Epoch[41] Batch[40] avg_epoch_loss=2.444849\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=40 train loss <loss>=2.25038053989\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:44 INFO 139866244298560] Epoch[41] Batch [40]#011Speed: 477.03 samples/sec#011loss=2.250381\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:45 INFO 139866244298560] Epoch[41] Batch[45] avg_epoch_loss=2.445545\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=45 train loss <loss>=2.45125427246\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:45 INFO 139866244298560] Epoch[41] Batch [45]#011Speed: 591.31 samples/sec#011loss=2.451254\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:45 INFO 139866244298560] Epoch[41] Batch[50] avg_epoch_loss=2.441080\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=50 train loss <loss>=2.39999480247\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:45 INFO 139866244298560] Epoch[41] Batch [50]#011Speed: 441.45 samples/sec#011loss=2.399995\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:46 INFO 139866244298560] Epoch[41] Batch[55] avg_epoch_loss=2.415272\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=55 train loss <loss>=2.15203433037\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:46 INFO 139866244298560] Epoch[41] Batch [55]#011Speed: 568.34 samples/sec#011loss=2.152034\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:46 INFO 139866244298560] Epoch[41] Batch[60] avg_epoch_loss=2.445793\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=60 train loss <loss>=2.78762278557\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:46 INFO 139866244298560] Epoch[41] Batch [60]#011Speed: 483.05 samples/sec#011loss=2.787623\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:47 INFO 139866244298560] Epoch[41] Batch[65] avg_epoch_loss=2.499490\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=65 train loss <loss>=3.15459804535\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:47 INFO 139866244298560] Epoch[41] Batch [65]#011Speed: 478.21 samples/sec#011loss=3.154598\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:48 INFO 139866244298560] Epoch[41] Batch[70] avg_epoch_loss=2.566370\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=70 train loss <loss>=3.44919018745\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:48 INFO 139866244298560] Epoch[41] Batch [70]#011Speed: 588.40 samples/sec#011loss=3.449190\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:48 INFO 139866244298560] Epoch[41] Batch[75] avg_epoch_loss=2.606787\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=75 train loss <loss>=3.18069834709\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:48 INFO 139866244298560] Epoch[41] Batch [75]#011Speed: 450.18 samples/sec#011loss=3.180698\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:49 INFO 139866244298560] Epoch[41] Batch[80] avg_epoch_loss=2.614088\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=80 train loss <loss>=2.72506155968\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:49 INFO 139866244298560] Epoch[41] Batch [80]#011Speed: 595.07 samples/sec#011loss=2.725062\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:50 INFO 139866244298560] Epoch[41] Batch[85] avg_epoch_loss=2.620233\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=85 train loss <loss>=2.71978530884\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:50 INFO 139866244298560] Epoch[41] Batch [85]#011Speed: 461.22 samples/sec#011loss=2.719785\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:50 INFO 139866244298560] Epoch[41] Batch[90] avg_epoch_loss=2.624478\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=90 train loss <loss>=2.69749536514\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:50 INFO 139866244298560] Epoch[41] Batch [90]#011Speed: 591.29 samples/sec#011loss=2.697495\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:51 INFO 139866244298560] Epoch[41] Batch[95] avg_epoch_loss=2.610187\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=95 train loss <loss>=2.3500954628\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:51 INFO 139866244298560] Epoch[41] Batch [95]#011Speed: 439.06 samples/sec#011loss=2.350095\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:51 INFO 139866244298560] Epoch[41] Batch[100] avg_epoch_loss=2.607540\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=100 train loss <loss>=2.55670685768\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:51 INFO 139866244298560] Epoch[41] Batch [100]#011Speed: 588.27 samples/sec#011loss=2.556707\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:52 INFO 139866244298560] Epoch[41] Batch[105] avg_epoch_loss=2.604858\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=105 train loss <loss>=2.55068144798\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:52 INFO 139866244298560] Epoch[41] Batch [105]#011Speed: 479.21 samples/sec#011loss=2.550681\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:53 INFO 139866244298560] Epoch[41] Batch[110] avg_epoch_loss=2.601379\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=110 train loss <loss>=2.5276321888\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:53 INFO 139866244298560] Epoch[41] Batch [110]#011Speed: 589.66 samples/sec#011loss=2.527632\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:53 INFO 139866244298560] Epoch[41] Batch[115] avg_epoch_loss=2.600226\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=115 train loss <loss>=2.57463240623\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:53 INFO 139866244298560] Epoch[41] Batch [115]#011Speed: 473.38 samples/sec#011loss=2.574632\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:54 INFO 139866244298560] Epoch[41] Batch[120] avg_epoch_loss=2.609488\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=120 train loss <loss>=2.82437086105\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:54 INFO 139866244298560] Epoch[41] Batch [120]#011Speed: 589.18 samples/sec#011loss=2.824371\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:55 INFO 139866244298560] Epoch[41] Batch[125] avg_epoch_loss=2.619470\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=125 train loss <loss>=2.86103653908\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:55 INFO 139866244298560] Epoch[41] Batch [125]#011Speed: 475.04 samples/sec#011loss=2.861037\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:55 INFO 139866244298560] Epoch[41] Batch[130] avg_epoch_loss=2.628074\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=130 train loss <loss>=2.84488224983\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:55 INFO 139866244298560] Epoch[41] Batch [130]#011Speed: 586.92 samples/sec#011loss=2.844882\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:56 INFO 139866244298560] Epoch[41] Batch[135] avg_epoch_loss=2.632847\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=135 train loss <loss>=2.75789656639\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:56 INFO 139866244298560] Epoch[41] Batch [135]#011Speed: 435.92 samples/sec#011loss=2.757897\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:56 INFO 139866244298560] Epoch[41] Batch[140] avg_epoch_loss=2.633534\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=140 train loss <loss>=2.6522149086\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:56 INFO 139866244298560] Epoch[41] Batch [140]#011Speed: 592.78 samples/sec#011loss=2.652215\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:57 INFO 139866244298560] Epoch[41] Batch[145] avg_epoch_loss=2.627680\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=145 train loss <loss>=2.46259632111\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:57 INFO 139866244298560] Epoch[41] Batch [145]#011Speed: 455.03 samples/sec#011loss=2.462596\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:58 INFO 139866244298560] Epoch[41] Batch[150] avg_epoch_loss=2.618399\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=150 train loss <loss>=2.34740138054\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:58 INFO 139866244298560] Epoch[41] Batch [150]#011Speed: 594.88 samples/sec#011loss=2.347401\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:58 INFO 139866244298560] Epoch[41] Batch[155] avg_epoch_loss=2.620569\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=155 train loss <loss>=2.68611731529\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:58 INFO 139866244298560] Epoch[41] Batch [155]#011Speed: 472.02 samples/sec#011loss=2.686117\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:59 INFO 139866244298560] Epoch[41] Batch[160] avg_epoch_loss=2.622778\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=160 train loss <loss>=2.6916946888\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:48:59 INFO 139866244298560] Epoch[41] Batch [160]#011Speed: 593.74 samples/sec#011loss=2.691695\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:00 INFO 139866244298560] Epoch[41] Batch[165] avg_epoch_loss=2.611591\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=165 train loss <loss>=2.25136322975\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:00 INFO 139866244298560] Epoch[41] Batch [165]#011Speed: 463.78 samples/sec#011loss=2.251363\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:00 INFO 139866244298560] Epoch[41] Batch[170] avg_epoch_loss=2.606108\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=170 train loss <loss>=2.42408075333\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:00 INFO 139866244298560] Epoch[41] Batch [170]#011Speed: 587.90 samples/sec#011loss=2.424081\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:01 INFO 139866244298560] Epoch[41] Batch[175] avg_epoch_loss=2.615165\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=175 train loss <loss>=2.92491574287\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:01 INFO 139866244298560] Epoch[41] Batch [175]#011Speed: 450.41 samples/sec#011loss=2.924916\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:01 INFO 139866244298560] Epoch[41] Batch[180] avg_epoch_loss=2.622868\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=180 train loss <loss>=2.89400625229\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:01 INFO 139866244298560] Epoch[41] Batch [180]#011Speed: 566.00 samples/sec#011loss=2.894006\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:02 INFO 139866244298560] Epoch[41] Batch[185] avg_epoch_loss=2.641926\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=185 train loss <loss>=3.33182902336\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:02 INFO 139866244298560] Epoch[41] Batch [185]#011Speed: 470.71 samples/sec#011loss=3.331829\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:03 INFO 139866244298560] Epoch[41] Batch[190] avg_epoch_loss=2.656833\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=190 train loss <loss>=3.21135778427\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:03 INFO 139866244298560] Epoch[41] Batch [190]#011Speed: 590.46 samples/sec#011loss=3.211358\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:03 INFO 139866244298560] Epoch[41] Batch[195] avg_epoch_loss=2.667637\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=195 train loss <loss>=3.08034148216\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:03 INFO 139866244298560] Epoch[41] Batch [195]#011Speed: 482.68 samples/sec#011loss=3.080341\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:04 INFO 139866244298560] Epoch[41] Batch[200] avg_epoch_loss=2.683771\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=200 train loss <loss>=3.31625990868\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:04 INFO 139866244298560] Epoch[41] Batch [200]#011Speed: 480.63 samples/sec#011loss=3.316260\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:04 INFO 139866244298560] Epoch[41] Batch[205] avg_epoch_loss=2.682270\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=205 train loss <loss>=2.62189512253\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:04 INFO 139866244298560] Epoch[41] Batch [205]#011Speed: 592.75 samples/sec#011loss=2.621895\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:05 INFO 139866244298560] Epoch[41] Batch[210] avg_epoch_loss=2.679197\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=210 train loss <loss>=2.55262084007\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:05 INFO 139866244298560] Epoch[41] Batch [210]#011Speed: 474.63 samples/sec#011loss=2.552621\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:06 INFO 139866244298560] Epoch[41] Batch[215] avg_epoch_loss=2.670056\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=215 train loss <loss>=2.28430323601\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:06 INFO 139866244298560] Epoch[41] Batch [215]#011Speed: 587.15 samples/sec#011loss=2.284303\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:06 INFO 139866244298560] Epoch[41] Batch[220] avg_epoch_loss=2.667340\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=220 train loss <loss>=2.54998736382\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:06 INFO 139866244298560] Epoch[41] Batch [220]#011Speed: 447.78 samples/sec#011loss=2.549987\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:07 INFO 139866244298560] Epoch[41] Batch[225] avg_epoch_loss=2.662648\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=225 train loss <loss>=2.45528063774\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:07 INFO 139866244298560] Epoch[41] Batch [225]#011Speed: 583.01 samples/sec#011loss=2.455281\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:08 INFO 139866244298560] Epoch[41] Batch[230] avg_epoch_loss=2.668666\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=230 train loss <loss>=2.94066905975\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:08 INFO 139866244298560] Epoch[41] Batch [230]#011Speed: 484.38 samples/sec#011loss=2.940669\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:08 INFO 139866244298560] Epoch[41] Batch[235] avg_epoch_loss=2.683425\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=235 train loss <loss>=3.36531243324\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:08 INFO 139866244298560] Epoch[41] Batch [235]#011Speed: 589.85 samples/sec#011loss=3.365312\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:09 INFO 139866244298560] Epoch[41] Batch[240] avg_epoch_loss=2.694265\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=240 train loss <loss>=3.20590758324\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:09 INFO 139866244298560] Epoch[41] Batch [240]#011Speed: 481.35 samples/sec#011loss=3.205908\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:09 INFO 139866244298560] Epoch[41] Batch[245] avg_epoch_loss=2.705658\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=245 train loss <loss>=3.25478334427\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:09 INFO 139866244298560] Epoch[41] Batch [245]#011Speed: 591.24 samples/sec#011loss=3.254783\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:10 INFO 139866244298560] Epoch[41] Batch[250] avg_epoch_loss=2.712090\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=250 train loss <loss>=3.02853565216\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:10 INFO 139866244298560] Epoch[41] Batch [250]#011Speed: 480.29 samples/sec#011loss=3.028536\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:11 INFO 139866244298560] Epoch[41] Batch[255] avg_epoch_loss=2.715850\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=255 train loss <loss>=2.90462284088\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:11 INFO 139866244298560] Epoch[41] Batch [255]#011Speed: 592.53 samples/sec#011loss=2.904623\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:11 INFO 139866244298560] Epoch[41] Batch[260] avg_epoch_loss=2.710143\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=260 train loss <loss>=2.41793823242\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:11 INFO 139866244298560] Epoch[41] Batch [260]#011Speed: 454.23 samples/sec#011loss=2.417938\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:12 INFO 139866244298560] Epoch[41] Batch[265] avg_epoch_loss=2.706759\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, batch=265 train loss <loss>=2.53010997772\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:12 INFO 139866244298560] Epoch[41] Batch [265]#011Speed: 592.82 samples/sec#011loss=2.530110\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:12 INFO 139866244298560] processed a total of 17208 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33318.44520568848, \"sum\": 33318.44520568848, \"min\": 33318.44520568848}}, \"EndTime\": 1599443352.641971, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443319.322886}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:12 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=516.46756665 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:12 INFO 139866244298560] #progress_metric: host=algo-1, completed 52 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=41, train loss <loss>=2.72208463924\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:12 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:12 INFO 139866244298560] Epoch[42] Batch[0] avg_epoch_loss=2.469313\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=0 train loss <loss>=2.4693133831\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:13 INFO 139866244298560] Epoch[42] Batch[5] avg_epoch_loss=2.141391\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=5 train loss <loss>=2.14139129718\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:13 INFO 139866244298560] Epoch[42] Batch [5]#011Speed: 596.50 samples/sec#011loss=2.141391\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:14 INFO 139866244298560] Epoch[42] Batch[10] avg_epoch_loss=2.212121\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=10 train loss <loss>=2.29699654579\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:14 INFO 139866244298560] Epoch[42] Batch [10]#011Speed: 475.26 samples/sec#011loss=2.296997\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:14 INFO 139866244298560] Epoch[42] Batch[15] avg_epoch_loss=2.358874\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=15 train loss <loss>=2.68172917366\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:14 INFO 139866244298560] Epoch[42] Batch [15]#011Speed: 582.12 samples/sec#011loss=2.681729\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:15 INFO 139866244298560] Epoch[42] Batch[20] avg_epoch_loss=2.465823\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=20 train loss <loss>=2.80806150436\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:15 INFO 139866244298560] Epoch[42] Batch [20]#011Speed: 477.15 samples/sec#011loss=2.808062\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:15 INFO 139866244298560] Epoch[42] Batch[25] avg_epoch_loss=2.535189\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=25 train loss <loss>=2.82652668953\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:15 INFO 139866244298560] Epoch[42] Batch [25]#011Speed: 597.34 samples/sec#011loss=2.826527\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:16 INFO 139866244298560] Epoch[42] Batch[30] avg_epoch_loss=2.507319\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=30 train loss <loss>=2.36239566803\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:16 INFO 139866244298560] Epoch[42] Batch [30]#011Speed: 443.03 samples/sec#011loss=2.362396\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:17 INFO 139866244298560] Epoch[42] Batch[35] avg_epoch_loss=2.472208\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=35 train loss <loss>=2.2545156002\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:17 INFO 139866244298560] Epoch[42] Batch [35]#011Speed: 594.54 samples/sec#011loss=2.254516\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:17 INFO 139866244298560] Epoch[42] Batch[40] avg_epoch_loss=2.484836\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=40 train loss <loss>=2.57576112747\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:17 INFO 139866244298560] Epoch[42] Batch [40]#011Speed: 467.16 samples/sec#011loss=2.575761\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:18 INFO 139866244298560] Epoch[42] Batch[45] avg_epoch_loss=2.459818\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=45 train loss <loss>=2.25466828346\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:18 INFO 139866244298560] Epoch[42] Batch [45]#011Speed: 590.31 samples/sec#011loss=2.254668\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:19 INFO 139866244298560] Epoch[42] Batch[50] avg_epoch_loss=2.438963\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=50 train loss <loss>=2.24710292816\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:19 INFO 139866244298560] Epoch[42] Batch [50]#011Speed: 436.42 samples/sec#011loss=2.247103\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:19 INFO 139866244298560] Epoch[42] Batch[55] avg_epoch_loss=2.418315\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=55 train loss <loss>=2.20770430565\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:19 INFO 139866244298560] Epoch[42] Batch [55]#011Speed: 591.32 samples/sec#011loss=2.207704\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:20 INFO 139866244298560] Epoch[42] Batch[60] avg_epoch_loss=2.431245\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=60 train loss <loss>=2.5760614872\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:20 INFO 139866244298560] Epoch[42] Batch [60]#011Speed: 478.99 samples/sec#011loss=2.576061\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:20 INFO 139866244298560] Epoch[42] Batch[65] avg_epoch_loss=2.457616\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=65 train loss <loss>=2.77934041023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:20 INFO 139866244298560] Epoch[42] Batch [65]#011Speed: 485.91 samples/sec#011loss=2.779340\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:21 INFO 139866244298560] Epoch[42] Batch[70] avg_epoch_loss=2.528478\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=70 train loss <loss>=3.46384725571\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:21 INFO 139866244298560] Epoch[42] Batch [70]#011Speed: 589.69 samples/sec#011loss=3.463847\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:22 INFO 139866244298560] Epoch[42] Batch[75] avg_epoch_loss=2.581327\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=75 train loss <loss>=3.33179535866\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:22 INFO 139866244298560] Epoch[42] Batch [75]#011Speed: 435.92 samples/sec#011loss=3.331795\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:22 INFO 139866244298560] Epoch[42] Batch[80] avg_epoch_loss=2.620960\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=80 train loss <loss>=3.2233704567\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:22 INFO 139866244298560] Epoch[42] Batch [80]#011Speed: 592.07 samples/sec#011loss=3.223370\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:23 INFO 139866244298560] Epoch[42] Batch[85] avg_epoch_loss=2.620487\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=85 train loss <loss>=2.61283078194\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:23 INFO 139866244298560] Epoch[42] Batch [85]#011Speed: 468.85 samples/sec#011loss=2.612831\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:23 INFO 139866244298560] Epoch[42] Batch[90] avg_epoch_loss=2.612460\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=90 train loss <loss>=2.47439069748\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:23 INFO 139866244298560] Epoch[42] Batch [90]#011Speed: 582.40 samples/sec#011loss=2.474391\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:24 INFO 139866244298560] Epoch[42] Batch[95] avg_epoch_loss=2.615155\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=95 train loss <loss>=2.66421408653\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:24 INFO 139866244298560] Epoch[42] Batch [95]#011Speed: 472.02 samples/sec#011loss=2.664214\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:25 INFO 139866244298560] Epoch[42] Batch[100] avg_epoch_loss=2.611230\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=100 train loss <loss>=2.53586530685\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:25 INFO 139866244298560] Epoch[42] Batch [100]#011Speed: 531.57 samples/sec#011loss=2.535865\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:25 INFO 139866244298560] Epoch[42] Batch[105] avg_epoch_loss=2.589439\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=105 train loss <loss>=2.14925105572\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:25 INFO 139866244298560] Epoch[42] Batch [105]#011Speed: 478.89 samples/sec#011loss=2.149251\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:26 INFO 139866244298560] Epoch[42] Batch[110] avg_epoch_loss=2.586109\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=110 train loss <loss>=2.51553149223\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:26 INFO 139866244298560] Epoch[42] Batch [110]#011Speed: 587.77 samples/sec#011loss=2.515531\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:27 INFO 139866244298560] Epoch[42] Batch[115] avg_epoch_loss=2.587200\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=115 train loss <loss>=2.61139950752\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:27 INFO 139866244298560] Epoch[42] Batch [115]#011Speed: 445.17 samples/sec#011loss=2.611400\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:27 INFO 139866244298560] Epoch[42] Batch[120] avg_epoch_loss=2.595845\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=120 train loss <loss>=2.79640889168\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:27 INFO 139866244298560] Epoch[42] Batch [120]#011Speed: 586.96 samples/sec#011loss=2.796409\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:28 INFO 139866244298560] Epoch[42] Batch[125] avg_epoch_loss=2.609609\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=125 train loss <loss>=2.94271469116\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:28 INFO 139866244298560] Epoch[42] Batch [125]#011Speed: 482.28 samples/sec#011loss=2.942715\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:28 INFO 139866244298560] Epoch[42] Batch[130] avg_epoch_loss=2.631202\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=130 train loss <loss>=3.17533540726\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:28 INFO 139866244298560] Epoch[42] Batch [130]#011Speed: 592.12 samples/sec#011loss=3.175335\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:29 INFO 139866244298560] Epoch[42] Batch[135] avg_epoch_loss=2.631775\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=135 train loss <loss>=2.64679985046\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:29 INFO 139866244298560] Epoch[42] Batch [135]#011Speed: 477.25 samples/sec#011loss=2.646800\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:30 INFO 139866244298560] Epoch[42] Batch[140] avg_epoch_loss=2.635983\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=140 train loss <loss>=2.75042004585\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:30 INFO 139866244298560] Epoch[42] Batch [140]#011Speed: 578.86 samples/sec#011loss=2.750420\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:30 INFO 139866244298560] Epoch[42] Batch[145] avg_epoch_loss=2.615378\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=145 train loss <loss>=2.03433690071\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:30 INFO 139866244298560] Epoch[42] Batch [145]#011Speed: 474.36 samples/sec#011loss=2.034337\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:31 INFO 139866244298560] Epoch[42] Batch[150] avg_epoch_loss=2.596424\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=150 train loss <loss>=2.04296767712\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:31 INFO 139866244298560] Epoch[42] Batch [150]#011Speed: 591.79 samples/sec#011loss=2.042968\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:32 INFO 139866244298560] Epoch[42] Batch[155] avg_epoch_loss=2.598635\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=155 train loss <loss>=2.66541261673\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:32 INFO 139866244298560] Epoch[42] Batch [155]#011Speed: 441.33 samples/sec#011loss=2.665413\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:32 INFO 139866244298560] Epoch[42] Batch[160] avg_epoch_loss=2.595654\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=160 train loss <loss>=2.50264844894\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:32 INFO 139866244298560] Epoch[42] Batch [160]#011Speed: 473.31 samples/sec#011loss=2.502648\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:33 INFO 139866244298560] Epoch[42] Batch[165] avg_epoch_loss=2.585299\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=165 train loss <loss>=2.25186383724\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:33 INFO 139866244298560] Epoch[42] Batch [165]#011Speed: 595.90 samples/sec#011loss=2.251864\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:33 INFO 139866244298560] Epoch[42] Batch[170] avg_epoch_loss=2.595277\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=170 train loss <loss>=2.92655229568\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:33 INFO 139866244298560] Epoch[42] Batch [170]#011Speed: 481.40 samples/sec#011loss=2.926552\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:34 INFO 139866244298560] Epoch[42] Batch[175] avg_epoch_loss=2.611807\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=175 train loss <loss>=3.17711310387\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:34 INFO 139866244298560] Epoch[42] Batch [175]#011Speed: 590.05 samples/sec#011loss=3.177113\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:35 INFO 139866244298560] Epoch[42] Batch[180] avg_epoch_loss=2.626858\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=180 train loss <loss>=3.1566634655\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:35 INFO 139866244298560] Epoch[42] Batch [180]#011Speed: 478.77 samples/sec#011loss=3.156663\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:35 INFO 139866244298560] Epoch[42] Batch[185] avg_epoch_loss=2.648233\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=185 train loss <loss>=3.42199258804\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:35 INFO 139866244298560] Epoch[42] Batch [185]#011Speed: 586.13 samples/sec#011loss=3.421993\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:36 INFO 139866244298560] Epoch[42] Batch[190] avg_epoch_loss=2.668294\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=190 train loss <loss>=3.41456842422\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:36 INFO 139866244298560] Epoch[42] Batch [190]#011Speed: 476.88 samples/sec#011loss=3.414568\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:36 INFO 139866244298560] Epoch[42] Batch[195] avg_epoch_loss=2.678400\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=195 train loss <loss>=3.06444220543\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:36 INFO 139866244298560] Epoch[42] Batch [195]#011Speed: 569.52 samples/sec#011loss=3.064442\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:37 INFO 139866244298560] Epoch[42] Batch[200] avg_epoch_loss=2.683883\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=200 train loss <loss>=2.89882092476\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:37 INFO 139866244298560] Epoch[42] Batch [200]#011Speed: 445.30 samples/sec#011loss=2.898821\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:38 INFO 139866244298560] Epoch[42] Batch[205] avg_epoch_loss=2.686437\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=205 train loss <loss>=2.78910942078\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:38 INFO 139866244298560] Epoch[42] Batch [205]#011Speed: 595.04 samples/sec#011loss=2.789109\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:38 INFO 139866244298560] Epoch[42] Batch[210] avg_epoch_loss=2.683261\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=210 train loss <loss>=2.55241451263\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:38 INFO 139866244298560] Epoch[42] Batch [210]#011Speed: 475.84 samples/sec#011loss=2.552415\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:39 INFO 139866244298560] Epoch[42] Batch[215] avg_epoch_loss=2.676996\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=215 train loss <loss>=2.4125934124\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:39 INFO 139866244298560] Epoch[42] Batch [215]#011Speed: 592.71 samples/sec#011loss=2.412593\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:40 INFO 139866244298560] Epoch[42] Batch[220] avg_epoch_loss=2.675653\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=220 train loss <loss>=2.61767611504\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:40 INFO 139866244298560] Epoch[42] Batch [220]#011Speed: 476.87 samples/sec#011loss=2.617676\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:40 INFO 139866244298560] Epoch[42] Batch[225] avg_epoch_loss=2.671443\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=225 train loss <loss>=2.48532752991\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:40 INFO 139866244298560] Epoch[42] Batch [225]#011Speed: 575.00 samples/sec#011loss=2.485328\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:41 INFO 139866244298560] Epoch[42] Batch[230] avg_epoch_loss=2.671934\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=230 train loss <loss>=2.69412279129\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:41 INFO 139866244298560] Epoch[42] Batch [230]#011Speed: 483.62 samples/sec#011loss=2.694123\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:41 INFO 139866244298560] Epoch[42] Batch[235] avg_epoch_loss=2.679206\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=235 train loss <loss>=3.01520819664\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:41 INFO 139866244298560] Epoch[42] Batch [235]#011Speed: 592.39 samples/sec#011loss=3.015208\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:42 INFO 139866244298560] Epoch[42] Batch[240] avg_epoch_loss=2.697183\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=240 train loss <loss>=3.54569773674\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:42 INFO 139866244298560] Epoch[42] Batch [240]#011Speed: 436.20 samples/sec#011loss=3.545698\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:43 INFO 139866244298560] Epoch[42] Batch[245] avg_epoch_loss=2.716153\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=245 train loss <loss>=3.63047318459\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:43 INFO 139866244298560] Epoch[42] Batch [245]#011Speed: 592.27 samples/sec#011loss=3.630473\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:43 INFO 139866244298560] Epoch[42] Batch[250] avg_epoch_loss=2.718790\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=250 train loss <loss>=2.84852876663\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:43 INFO 139866244298560] Epoch[42] Batch [250]#011Speed: 480.15 samples/sec#011loss=2.848529\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:44 INFO 139866244298560] Epoch[42] Batch[255] avg_epoch_loss=2.717850\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=255 train loss <loss>=2.67068486214\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:44 INFO 139866244298560] Epoch[42] Batch [255]#011Speed: 476.31 samples/sec#011loss=2.670685\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:45 INFO 139866244298560] Epoch[42] Batch[260] avg_epoch_loss=2.713098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=260 train loss <loss>=2.46980438232\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:45 INFO 139866244298560] Epoch[42] Batch [260]#011Speed: 593.55 samples/sec#011loss=2.469804\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:45 INFO 139866244298560] Epoch[42] Batch[265] avg_epoch_loss=2.719876\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, batch=265 train loss <loss>=3.07367401123\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:45 INFO 139866244298560] Epoch[42] Batch [265]#011Speed: 562.55 samples/sec#011loss=3.073674\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:45 INFO 139866244298560] processed a total of 17053 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33075.91915130615, \"sum\": 33075.91915130615, \"min\": 33075.91915130615}}, \"EndTime\": 1599443385.718779, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443352.642103}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:45 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=515.568987107 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:45 INFO 139866244298560] #progress_metric: host=algo-1, completed 53 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=42, train loss <loss>=2.72396728519\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:45 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:45 INFO 139866244298560] Epoch[43] Batch[0] avg_epoch_loss=2.150084\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=0 train loss <loss>=2.15008425713\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:46 INFO 139866244298560] Epoch[43] Batch[5] avg_epoch_loss=2.029286\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=5 train loss <loss>=2.02928556999\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:46 INFO 139866244298560] Epoch[43] Batch [5]#011Speed: 590.24 samples/sec#011loss=2.029286\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:47 INFO 139866244298560] Epoch[43] Batch[10] avg_epoch_loss=2.136215\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=10 train loss <loss>=2.264529562\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:47 INFO 139866244298560] Epoch[43] Batch [10]#011Speed: 474.30 samples/sec#011loss=2.264530\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:47 INFO 139866244298560] Epoch[43] Batch[15] avg_epoch_loss=2.313371\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=15 train loss <loss>=2.70311632156\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:47 INFO 139866244298560] Epoch[43] Batch [15]#011Speed: 546.02 samples/sec#011loss=2.703116\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:48 INFO 139866244298560] Epoch[43] Batch[20] avg_epoch_loss=2.365283\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=20 train loss <loss>=2.53140087128\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:48 INFO 139866244298560] Epoch[43] Batch [20]#011Speed: 470.85 samples/sec#011loss=2.531401\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:49 INFO 139866244298560] Epoch[43] Batch[25] avg_epoch_loss=2.438843\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=25 train loss <loss>=2.74779529572\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:49 INFO 139866244298560] Epoch[43] Batch [25]#011Speed: 531.03 samples/sec#011loss=2.747795\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:49 INFO 139866244298560] Epoch[43] Batch[30] avg_epoch_loss=2.450715\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=30 train loss <loss>=2.51244587898\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:49 INFO 139866244298560] Epoch[43] Batch [30]#011Speed: 476.42 samples/sec#011loss=2.512446\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:50 INFO 139866244298560] Epoch[43] Batch[35] avg_epoch_loss=2.433470\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=35 train loss <loss>=2.32655282021\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:50 INFO 139866244298560] Epoch[43] Batch [35]#011Speed: 593.38 samples/sec#011loss=2.326553\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:50 INFO 139866244298560] Epoch[43] Batch[40] avg_epoch_loss=2.438742\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=40 train loss <loss>=2.47669997215\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:50 INFO 139866244298560] Epoch[43] Batch [40]#011Speed: 451.57 samples/sec#011loss=2.476700\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:51 INFO 139866244298560] Epoch[43] Batch[45] avg_epoch_loss=2.452095\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=45 train loss <loss>=2.56158647537\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:51 INFO 139866244298560] Epoch[43] Batch [45]#011Speed: 594.77 samples/sec#011loss=2.561586\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:52 INFO 139866244298560] Epoch[43] Batch[50] avg_epoch_loss=2.435213\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=50 train loss <loss>=2.27990760803\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:52 INFO 139866244298560] Epoch[43] Batch [50]#011Speed: 477.17 samples/sec#011loss=2.279908\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:52 INFO 139866244298560] Epoch[43] Batch[55] avg_epoch_loss=2.425611\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=55 train loss <loss>=2.32766671181\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:52 INFO 139866244298560] Epoch[43] Batch [55]#011Speed: 527.71 samples/sec#011loss=2.327667\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:53 INFO 139866244298560] Epoch[43] Batch[60] avg_epoch_loss=2.438457\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=60 train loss <loss>=2.58233046532\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:53 INFO 139866244298560] Epoch[43] Batch [60]#011Speed: 474.23 samples/sec#011loss=2.582330\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:54 INFO 139866244298560] Epoch[43] Batch[65] avg_epoch_loss=2.436923\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=65 train loss <loss>=2.41820874214\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:54 INFO 139866244298560] Epoch[43] Batch [65]#011Speed: 596.04 samples/sec#011loss=2.418209\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:54 INFO 139866244298560] Epoch[43] Batch[70] avg_epoch_loss=2.484976\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=70 train loss <loss>=3.11927108765\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:54 INFO 139866244298560] Epoch[43] Batch [70]#011Speed: 476.52 samples/sec#011loss=3.119271\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:55 INFO 139866244298560] Epoch[43] Batch[75] avg_epoch_loss=2.519150\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=75 train loss <loss>=3.00441827774\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:55 INFO 139866244298560] Epoch[43] Batch [75]#011Speed: 595.35 samples/sec#011loss=3.004418\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:55 INFO 139866244298560] Epoch[43] Batch[80] avg_epoch_loss=2.554364\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=80 train loss <loss>=3.0896212101\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:55 INFO 139866244298560] Epoch[43] Batch [80]#011Speed: 473.72 samples/sec#011loss=3.089621\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:56 INFO 139866244298560] Epoch[43] Batch[85] avg_epoch_loss=2.589702\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=85 train loss <loss>=3.16217417717\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:56 INFO 139866244298560] Epoch[43] Batch [85]#011Speed: 592.79 samples/sec#011loss=3.162174\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:57 INFO 139866244298560] Epoch[43] Batch[90] avg_epoch_loss=2.606234\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=90 train loss <loss>=2.89059081078\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:57 INFO 139866244298560] Epoch[43] Batch [90]#011Speed: 470.82 samples/sec#011loss=2.890591\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:57 INFO 139866244298560] Epoch[43] Batch[95] avg_epoch_loss=2.618048\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=95 train loss <loss>=2.83305468559\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:57 INFO 139866244298560] Epoch[43] Batch [95]#011Speed: 594.77 samples/sec#011loss=2.833055\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:58 INFO 139866244298560] Epoch[43] Batch[100] avg_epoch_loss=2.619344\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=100 train loss <loss>=2.64423370361\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:58 INFO 139866244298560] Epoch[43] Batch [100]#011Speed: 480.87 samples/sec#011loss=2.644234\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:58 INFO 139866244298560] Epoch[43] Batch[105] avg_epoch_loss=2.606593\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=105 train loss <loss>=2.3490228653\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:58 INFO 139866244298560] Epoch[43] Batch [105]#011Speed: 585.18 samples/sec#011loss=2.349023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:59 INFO 139866244298560] Epoch[43] Batch[110] avg_epoch_loss=2.586525\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=110 train loss <loss>=2.16108767986\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:49:59 INFO 139866244298560] Epoch[43] Batch [110]#011Speed: 477.93 samples/sec#011loss=2.161088\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:00 INFO 139866244298560] Epoch[43] Batch[115] avg_epoch_loss=2.564066\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=115 train loss <loss>=2.06546933651\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:00 INFO 139866244298560] Epoch[43] Batch [115]#011Speed: 593.76 samples/sec#011loss=2.065469\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:00 INFO 139866244298560] Epoch[43] Batch[120] avg_epoch_loss=2.550779\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=120 train loss <loss>=2.24252614975\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:00 INFO 139866244298560] Epoch[43] Batch [120]#011Speed: 474.96 samples/sec#011loss=2.242526\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:01 INFO 139866244298560] Epoch[43] Batch[125] avg_epoch_loss=2.546176\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=125 train loss <loss>=2.43479299545\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:01 INFO 139866244298560] Epoch[43] Batch [125]#011Speed: 597.79 samples/sec#011loss=2.434793\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:01 INFO 139866244298560] Epoch[43] Batch[130] avg_epoch_loss=2.557333\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=130 train loss <loss>=2.83847227097\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:01 INFO 139866244298560] Epoch[43] Batch [130]#011Speed: 456.29 samples/sec#011loss=2.838472\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:02 INFO 139866244298560] Epoch[43] Batch[135] avg_epoch_loss=2.566525\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=135 train loss <loss>=2.80736336708\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:02 INFO 139866244298560] Epoch[43] Batch [135]#011Speed: 589.60 samples/sec#011loss=2.807363\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:03 INFO 139866244298560] Epoch[43] Batch[140] avg_epoch_loss=2.578061\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=140 train loss <loss>=2.89182605743\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:03 INFO 139866244298560] Epoch[43] Batch [140]#011Speed: 476.42 samples/sec#011loss=2.891826\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:03 INFO 139866244298560] Epoch[43] Batch[145] avg_epoch_loss=2.587431\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=145 train loss <loss>=2.85169157982\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:03 INFO 139866244298560] Epoch[43] Batch [145]#011Speed: 474.23 samples/sec#011loss=2.851692\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:04 INFO 139866244298560] Epoch[43] Batch[150] avg_epoch_loss=2.581407\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=150 train loss <loss>=2.40548563004\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:04 INFO 139866244298560] Epoch[43] Batch [150]#011Speed: 593.23 samples/sec#011loss=2.405486\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:05 INFO 139866244298560] Epoch[43] Batch[155] avg_epoch_loss=2.582735\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=155 train loss <loss>=2.6228474617\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:05 INFO 139866244298560] Epoch[43] Batch [155]#011Speed: 472.35 samples/sec#011loss=2.622847\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:05 INFO 139866244298560] Epoch[43] Batch[160] avg_epoch_loss=2.588407\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=160 train loss <loss>=2.7653755188\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:05 INFO 139866244298560] Epoch[43] Batch [160]#011Speed: 586.86 samples/sec#011loss=2.765376\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:06 INFO 139866244298560] Epoch[43] Batch[165] avg_epoch_loss=2.586747\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=165 train loss <loss>=2.53329291344\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:06 INFO 139866244298560] Epoch[43] Batch [165]#011Speed: 481.06 samples/sec#011loss=2.533293\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:06 INFO 139866244298560] Epoch[43] Batch[170] avg_epoch_loss=2.582119\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=170 train loss <loss>=2.42845263481\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:06 INFO 139866244298560] Epoch[43] Batch [170]#011Speed: 587.81 samples/sec#011loss=2.428453\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:07 INFO 139866244298560] Epoch[43] Batch[175] avg_epoch_loss=2.581843\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=175 train loss <loss>=2.57242488861\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:07 INFO 139866244298560] Epoch[43] Batch [175]#011Speed: 474.50 samples/sec#011loss=2.572425\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:08 INFO 139866244298560] Epoch[43] Batch[180] avg_epoch_loss=2.574728\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=180 train loss <loss>=2.32428765297\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:08 INFO 139866244298560] Epoch[43] Batch [180]#011Speed: 583.76 samples/sec#011loss=2.324288\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:08 INFO 139866244298560] Epoch[43] Batch[185] avg_epoch_loss=2.585159\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=185 train loss <loss>=2.96276021004\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:08 INFO 139866244298560] Epoch[43] Batch [185]#011Speed: 477.59 samples/sec#011loss=2.962760\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:09 INFO 139866244298560] Epoch[43] Batch[190] avg_epoch_loss=2.596063\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=190 train loss <loss>=3.00168843269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:09 INFO 139866244298560] Epoch[43] Batch [190]#011Speed: 592.01 samples/sec#011loss=3.001688\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:09 INFO 139866244298560] Epoch[43] Batch[195] avg_epoch_loss=2.618993\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=195 train loss <loss>=3.49489531517\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:09 INFO 139866244298560] Epoch[43] Batch [195]#011Speed: 481.74 samples/sec#011loss=3.494895\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:10 INFO 139866244298560] Epoch[43] Batch[200] avg_epoch_loss=2.639555\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=200 train loss <loss>=3.44561767578\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:10 INFO 139866244298560] Epoch[43] Batch [200]#011Speed: 587.84 samples/sec#011loss=3.445618\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:11 INFO 139866244298560] Epoch[43] Batch[205] avg_epoch_loss=2.651285\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=205 train loss <loss>=3.12279601097\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:11 INFO 139866244298560] Epoch[43] Batch [205]#011Speed: 484.08 samples/sec#011loss=3.122796\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:11 INFO 139866244298560] Epoch[43] Batch[210] avg_epoch_loss=2.663726\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=210 train loss <loss>=3.17632780075\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:11 INFO 139866244298560] Epoch[43] Batch [210]#011Speed: 591.28 samples/sec#011loss=3.176328\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:12 INFO 139866244298560] Epoch[43] Batch[215] avg_epoch_loss=2.656106\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=215 train loss <loss>=2.33452851772\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:12 INFO 139866244298560] Epoch[43] Batch [215]#011Speed: 474.45 samples/sec#011loss=2.334529\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:12 INFO 139866244298560] Epoch[43] Batch[220] avg_epoch_loss=2.653225\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=220 train loss <loss>=2.52878379822\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:12 INFO 139866244298560] Epoch[43] Batch [220]#011Speed: 592.92 samples/sec#011loss=2.528784\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:13 INFO 139866244298560] Epoch[43] Batch[225] avg_epoch_loss=2.651800\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=225 train loss <loss>=2.58881793022\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:13 INFO 139866244298560] Epoch[43] Batch [225]#011Speed: 481.32 samples/sec#011loss=2.588818\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:14 INFO 139866244298560] Epoch[43] Batch[230] avg_epoch_loss=2.645104\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=230 train loss <loss>=2.34240984917\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:14 INFO 139866244298560] Epoch[43] Batch [230]#011Speed: 481.05 samples/sec#011loss=2.342410\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:14 INFO 139866244298560] Epoch[43] Batch[235] avg_epoch_loss=2.649036\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=235 train loss <loss>=2.8306889534\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:14 INFO 139866244298560] Epoch[43] Batch [235]#011Speed: 588.77 samples/sec#011loss=2.830689\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:15 INFO 139866244298560] Epoch[43] Batch[240] avg_epoch_loss=2.650961\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=240 train loss <loss>=2.74182801247\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:15 INFO 139866244298560] Epoch[43] Batch [240]#011Speed: 473.21 samples/sec#011loss=2.741828\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:15 INFO 139866244298560] Epoch[43] Batch[245] avg_epoch_loss=2.663112\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=245 train loss <loss>=3.24880065918\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:15 INFO 139866244298560] Epoch[43] Batch [245]#011Speed: 590.10 samples/sec#011loss=3.248801\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:16 INFO 139866244298560] Epoch[43] Batch[250] avg_epoch_loss=2.675213\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=250 train loss <loss>=3.27058796883\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:16 INFO 139866244298560] Epoch[43] Batch [250]#011Speed: 476.46 samples/sec#011loss=3.270588\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:17 INFO 139866244298560] Epoch[43] Batch[255] avg_epoch_loss=2.693799\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=255 train loss <loss>=3.62680635452\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:17 INFO 139866244298560] Epoch[43] Batch [255]#011Speed: 592.21 samples/sec#011loss=3.626806\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:17 INFO 139866244298560] Epoch[43] Batch[260] avg_epoch_loss=2.702339\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=260 train loss <loss>=3.13957867622\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:17 INFO 139866244298560] Epoch[43] Batch [260]#011Speed: 478.75 samples/sec#011loss=3.139579\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:18 INFO 139866244298560] Epoch[43] Batch[265] avg_epoch_loss=2.700096\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, batch=265 train loss <loss>=2.58304777145\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:18 INFO 139866244298560] Epoch[43] Batch [265]#011Speed: 596.31 samples/sec#011loss=2.583048\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:18 INFO 139866244298560] processed a total of 17186 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33017.327070236206, \"sum\": 33017.327070236206, \"min\": 33017.327070236206}}, \"EndTime\": 1599443418.736872, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443385.718868}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:18 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=520.512636529 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:18 INFO 139866244298560] #progress_metric: host=algo-1, completed 55 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=43, train loss <loss>=2.70169504779\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:18 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:19 INFO 139866244298560] Epoch[44] Batch[0] avg_epoch_loss=2.348860\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=0 train loss <loss>=2.34885954857\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:19 INFO 139866244298560] Epoch[44] Batch[5] avg_epoch_loss=2.178180\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=5 train loss <loss>=2.17818015814\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:19 INFO 139866244298560] Epoch[44] Batch [5]#011Speed: 587.83 samples/sec#011loss=2.178180\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:20 INFO 139866244298560] Epoch[44] Batch[10] avg_epoch_loss=2.262994\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=10 train loss <loss>=2.3647714138\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:20 INFO 139866244298560] Epoch[44] Batch [10]#011Speed: 470.38 samples/sec#011loss=2.364771\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:20 INFO 139866244298560] Epoch[44] Batch[15] avg_epoch_loss=2.362683\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=15 train loss <loss>=2.58199911118\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:20 INFO 139866244298560] Epoch[44] Batch [15]#011Speed: 570.76 samples/sec#011loss=2.581999\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:21 INFO 139866244298560] Epoch[44] Batch[20] avg_epoch_loss=2.441296\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=20 train loss <loss>=2.69285502434\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:21 INFO 139866244298560] Epoch[44] Batch [20]#011Speed: 474.38 samples/sec#011loss=2.692855\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:22 INFO 139866244298560] Epoch[44] Batch[25] avg_epoch_loss=2.517921\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=25 train loss <loss>=2.83974556923\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:22 INFO 139866244298560] Epoch[44] Batch [25]#011Speed: 590.00 samples/sec#011loss=2.839746\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:22 INFO 139866244298560] Epoch[44] Batch[30] avg_epoch_loss=2.517027\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=30 train loss <loss>=2.51238226891\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:22 INFO 139866244298560] Epoch[44] Batch [30]#011Speed: 471.01 samples/sec#011loss=2.512382\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:23 INFO 139866244298560] Epoch[44] Batch[35] avg_epoch_loss=2.530913\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=35 train loss <loss>=2.6170068264\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:23 INFO 139866244298560] Epoch[44] Batch [35]#011Speed: 592.95 samples/sec#011loss=2.617007\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:23 INFO 139866244298560] Epoch[44] Batch[40] avg_epoch_loss=2.530371\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=40 train loss <loss>=2.52646269798\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:23 INFO 139866244298560] Epoch[44] Batch [40]#011Speed: 478.10 samples/sec#011loss=2.526463\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:24 INFO 139866244298560] Epoch[44] Batch[45] avg_epoch_loss=2.515035\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=45 train loss <loss>=2.38927876949\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:24 INFO 139866244298560] Epoch[44] Batch [45]#011Speed: 592.19 samples/sec#011loss=2.389279\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:25 INFO 139866244298560] Epoch[44] Batch[50] avg_epoch_loss=2.513435\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=50 train loss <loss>=2.49872341156\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:25 INFO 139866244298560] Epoch[44] Batch [50]#011Speed: 469.52 samples/sec#011loss=2.498723\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:25 INFO 139866244298560] Epoch[44] Batch[55] avg_epoch_loss=2.504493\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=55 train loss <loss>=2.41327791214\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:25 INFO 139866244298560] Epoch[44] Batch [55]#011Speed: 583.67 samples/sec#011loss=2.413278\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:26 INFO 139866244298560] Epoch[44] Batch[60] avg_epoch_loss=2.516983\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=60 train loss <loss>=2.65687761307\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:26 INFO 139866244298560] Epoch[44] Batch [60]#011Speed: 474.04 samples/sec#011loss=2.656878\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:26 INFO 139866244298560] Epoch[44] Batch[65] avg_epoch_loss=2.528536\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=65 train loss <loss>=2.66947937012\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:26 INFO 139866244298560] Epoch[44] Batch [65]#011Speed: 592.02 samples/sec#011loss=2.669479\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:27 INFO 139866244298560] Epoch[44] Batch[70] avg_epoch_loss=2.536926\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=70 train loss <loss>=2.64767179489\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:27 INFO 139866244298560] Epoch[44] Batch [70]#011Speed: 478.44 samples/sec#011loss=2.647672\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:28 INFO 139866244298560] Epoch[44] Batch[75] avg_epoch_loss=2.540796\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=75 train loss <loss>=2.59575247765\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:28 INFO 139866244298560] Epoch[44] Batch [75]#011Speed: 596.06 samples/sec#011loss=2.595752\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:28 INFO 139866244298560] Epoch[44] Batch[80] avg_epoch_loss=2.582881\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=80 train loss <loss>=3.2225774765\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:28 INFO 139866244298560] Epoch[44] Batch [80]#011Speed: 484.43 samples/sec#011loss=3.222577\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:29 INFO 139866244298560] Epoch[44] Batch[85] avg_epoch_loss=2.617075\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=85 train loss <loss>=3.17100815773\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:29 INFO 139866244298560] Epoch[44] Batch [85]#011Speed: 591.93 samples/sec#011loss=3.171008\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:30 INFO 139866244298560] Epoch[44] Batch[90] avg_epoch_loss=2.637088\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=90 train loss <loss>=2.98131308556\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:30 INFO 139866244298560] Epoch[44] Batch [90]#011Speed: 465.30 samples/sec#011loss=2.981313\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:30 INFO 139866244298560] Epoch[44] Batch[95] avg_epoch_loss=2.651453\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=95 train loss <loss>=2.91290211678\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:30 INFO 139866244298560] Epoch[44] Batch [95]#011Speed: 471.10 samples/sec#011loss=2.912902\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:31 INFO 139866244298560] Epoch[44] Batch[100] avg_epoch_loss=2.641692\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=100 train loss <loss>=2.45428204536\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:31 INFO 139866244298560] Epoch[44] Batch [100]#011Speed: 594.90 samples/sec#011loss=2.454282\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:31 INFO 139866244298560] Epoch[44] Batch[105] avg_epoch_loss=2.628180\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=105 train loss <loss>=2.3552423954\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:31 INFO 139866244298560] Epoch[44] Batch [105]#011Speed: 474.12 samples/sec#011loss=2.355242\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:32 INFO 139866244298560] Epoch[44] Batch[110] avg_epoch_loss=2.616880\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=110 train loss <loss>=2.37730412483\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:32 INFO 139866244298560] Epoch[44] Batch [110]#011Speed: 589.10 samples/sec#011loss=2.377304\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:33 INFO 139866244298560] Epoch[44] Batch[115] avg_epoch_loss=2.597641\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=115 train loss <loss>=2.17054622173\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:33 INFO 139866244298560] Epoch[44] Batch [115]#011Speed: 479.25 samples/sec#011loss=2.170546\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:33 INFO 139866244298560] Epoch[44] Batch[120] avg_epoch_loss=2.588065\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=120 train loss <loss>=2.36590371132\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:33 INFO 139866244298560] Epoch[44] Batch [120]#011Speed: 595.00 samples/sec#011loss=2.365904\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:34 INFO 139866244298560] Epoch[44] Batch[125] avg_epoch_loss=2.575219\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=125 train loss <loss>=2.26432719231\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:34 INFO 139866244298560] Epoch[44] Batch [125]#011Speed: 482.89 samples/sec#011loss=2.264327\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:34 INFO 139866244298560] Epoch[44] Batch[130] avg_epoch_loss=2.566394\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=130 train loss <loss>=2.34400696754\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:34 INFO 139866244298560] Epoch[44] Batch [130]#011Speed: 590.82 samples/sec#011loss=2.344007\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:35 INFO 139866244298560] Epoch[44] Batch[135] avg_epoch_loss=2.565589\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=135 train loss <loss>=2.54450926781\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:35 INFO 139866244298560] Epoch[44] Batch [135]#011Speed: 469.43 samples/sec#011loss=2.544509\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:36 INFO 139866244298560] Epoch[44] Batch[140] avg_epoch_loss=2.582703\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=140 train loss <loss>=3.0482085228\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:36 INFO 139866244298560] Epoch[44] Batch [140]#011Speed: 583.52 samples/sec#011loss=3.048209\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:36 INFO 139866244298560] Epoch[44] Batch[145] avg_epoch_loss=2.601093\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=145 train loss <loss>=3.1196928978\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:36 INFO 139866244298560] Epoch[44] Batch [145]#011Speed: 475.48 samples/sec#011loss=3.119693\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:37 INFO 139866244298560] Epoch[44] Batch[150] avg_epoch_loss=2.606830\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=150 train loss <loss>=2.77433481216\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:37 INFO 139866244298560] Epoch[44] Batch [150]#011Speed: 573.26 samples/sec#011loss=2.774335\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:38 INFO 139866244298560] Epoch[44] Batch[155] avg_epoch_loss=2.611064\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=155 train loss <loss>=2.73893022537\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:38 INFO 139866244298560] Epoch[44] Batch [155]#011Speed: 472.45 samples/sec#011loss=2.738930\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:38 INFO 139866244298560] Epoch[44] Batch[160] avg_epoch_loss=2.614178\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=160 train loss <loss>=2.71133265495\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:38 INFO 139866244298560] Epoch[44] Batch [160]#011Speed: 588.49 samples/sec#011loss=2.711333\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:39 INFO 139866244298560] Epoch[44] Batch[165] avg_epoch_loss=2.609263\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=165 train loss <loss>=2.45100369453\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:39 INFO 139866244298560] Epoch[44] Batch [165]#011Speed: 470.21 samples/sec#011loss=2.451004\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:39 INFO 139866244298560] Epoch[44] Batch[170] avg_epoch_loss=2.597968\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=170 train loss <loss>=2.22296395302\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:39 INFO 139866244298560] Epoch[44] Batch [170]#011Speed: 593.35 samples/sec#011loss=2.222964\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:40 INFO 139866244298560] Epoch[44] Batch[175] avg_epoch_loss=2.592505\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=175 train loss <loss>=2.40567231178\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:40 INFO 139866244298560] Epoch[44] Batch [175]#011Speed: 474.07 samples/sec#011loss=2.405672\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:40 INFO 139866244298560] Epoch[44] Batch[180] avg_epoch_loss=2.594724\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=180 train loss <loss>=2.67286329269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:40 INFO 139866244298560] Epoch[44] Batch [180]#011Speed: 589.46 samples/sec#011loss=2.672863\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:41 INFO 139866244298560] Epoch[44] Batch[185] avg_epoch_loss=2.595759\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=185 train loss <loss>=2.63320150375\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:41 INFO 139866244298560] Epoch[44] Batch [185]#011Speed: 482.51 samples/sec#011loss=2.633202\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:42 INFO 139866244298560] Epoch[44] Batch[190] avg_epoch_loss=2.597108\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=190 train loss <loss>=2.64730086327\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:42 INFO 139866244298560] Epoch[44] Batch [190]#011Speed: 597.72 samples/sec#011loss=2.647301\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:42 INFO 139866244298560] Epoch[44] Batch[195] avg_epoch_loss=2.620155\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=195 train loss <loss>=3.50054016113\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:42 INFO 139866244298560] Epoch[44] Batch [195]#011Speed: 482.56 samples/sec#011loss=3.500540\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:43 INFO 139866244298560] Epoch[44] Batch[200] avg_epoch_loss=2.640322\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=200 train loss <loss>=3.43087720871\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:43 INFO 139866244298560] Epoch[44] Batch [200]#011Speed: 596.82 samples/sec#011loss=3.430877\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:44 INFO 139866244298560] Epoch[44] Batch[205] avg_epoch_loss=2.652179\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=205 train loss <loss>=3.12882328033\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:44 INFO 139866244298560] Epoch[44] Batch [205]#011Speed: 476.24 samples/sec#011loss=3.128823\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:44 INFO 139866244298560] Epoch[44] Batch[210] avg_epoch_loss=2.667214\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=210 train loss <loss>=3.28666887283\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:44 INFO 139866244298560] Epoch[44] Batch [210]#011Speed: 585.62 samples/sec#011loss=3.286669\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:45 INFO 139866244298560] Epoch[44] Batch[215] avg_epoch_loss=2.664457\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=215 train loss <loss>=2.54812510014\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:45 INFO 139866244298560] Epoch[44] Batch [215]#011Speed: 479.89 samples/sec#011loss=2.548125\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:45 INFO 139866244298560] Epoch[44] Batch[220] avg_epoch_loss=2.660412\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=220 train loss <loss>=2.48563599586\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:45 INFO 139866244298560] Epoch[44] Batch [220]#011Speed: 585.09 samples/sec#011loss=2.485636\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:46 INFO 139866244298560] Epoch[44] Batch[225] avg_epoch_loss=2.666034\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=225 train loss <loss>=2.91453852654\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:46 INFO 139866244298560] Epoch[44] Batch [225]#011Speed: 479.74 samples/sec#011loss=2.914539\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:47 INFO 139866244298560] Epoch[44] Batch[230] avg_epoch_loss=2.663856\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=230 train loss <loss>=2.56540474892\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:47 INFO 139866244298560] Epoch[44] Batch [230]#011Speed: 593.26 samples/sec#011loss=2.565405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:47 INFO 139866244298560] Epoch[44] Batch[235] avg_epoch_loss=2.663002\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=235 train loss <loss>=2.62355065346\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:47 INFO 139866244298560] Epoch[44] Batch [235]#011Speed: 473.56 samples/sec#011loss=2.623551\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:48 INFO 139866244298560] Epoch[44] Batch[240] avg_epoch_loss=2.658884\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=240 train loss <loss>=2.46450490952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:48 INFO 139866244298560] Epoch[44] Batch [240]#011Speed: 588.99 samples/sec#011loss=2.464505\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:48 INFO 139866244298560] Epoch[44] Batch[245] avg_epoch_loss=2.662624\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=245 train loss <loss>=2.84289984703\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:48 INFO 139866244298560] Epoch[44] Batch [245]#011Speed: 477.35 samples/sec#011loss=2.842900\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:49 INFO 139866244298560] Epoch[44] Batch[250] avg_epoch_loss=2.669833\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=250 train loss <loss>=3.02450098991\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:49 INFO 139866244298560] Epoch[44] Batch [250]#011Speed: 439.83 samples/sec#011loss=3.024501\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:50 INFO 139866244298560] Epoch[44] Batch[255] avg_epoch_loss=2.682139\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=255 train loss <loss>=3.29993476868\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:50 INFO 139866244298560] Epoch[44] Batch [255]#011Speed: 588.14 samples/sec#011loss=3.299935\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:50 INFO 139866244298560] Epoch[44] Batch[260] avg_epoch_loss=2.692551\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=260 train loss <loss>=3.22564659119\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:50 INFO 139866244298560] Epoch[44] Batch [260]#011Speed: 489.81 samples/sec#011loss=3.225647\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:51 INFO 139866244298560] Epoch[44] Batch[265] avg_epoch_loss=2.697851\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, batch=265 train loss <loss>=2.97450299263\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:51 INFO 139866244298560] Epoch[44] Batch [265]#011Speed: 596.85 samples/sec#011loss=2.974503\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:51 INFO 139866244298560] processed a total of 17123 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32859.57098007202, \"sum\": 32859.57098007202, \"min\": 32859.57098007202}}, \"EndTime\": 1599443451.597126, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443418.736935}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:51 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=521.094402367 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:51 INFO 139866244298560] #progress_metric: host=algo-1, completed 56 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=44, train loss <loss>=2.70408094908\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:51 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:51 INFO 139866244298560] Epoch[45] Batch[0] avg_epoch_loss=1.904219\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=0 train loss <loss>=1.90421891212\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:52 INFO 139866244298560] Epoch[45] Batch[5] avg_epoch_loss=1.936559\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=5 train loss <loss>=1.93655922016\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:52 INFO 139866244298560] Epoch[45] Batch [5]#011Speed: 586.69 samples/sec#011loss=1.936559\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:53 INFO 139866244298560] Epoch[45] Batch[10] avg_epoch_loss=1.970899\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=10 train loss <loss>=2.01210718155\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:53 INFO 139866244298560] Epoch[45] Batch [10]#011Speed: 472.51 samples/sec#011loss=2.012107\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:53 INFO 139866244298560] Epoch[45] Batch[15] avg_epoch_loss=2.164351\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=15 train loss <loss>=2.58994603157\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:53 INFO 139866244298560] Epoch[45] Batch [15]#011Speed: 595.96 samples/sec#011loss=2.589946\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:54 INFO 139866244298560] Epoch[45] Batch[20] avg_epoch_loss=2.310509\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=20 train loss <loss>=2.77821211815\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:54 INFO 139866244298560] Epoch[45] Batch [20]#011Speed: 469.77 samples/sec#011loss=2.778212\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:54 INFO 139866244298560] Epoch[45] Batch[25] avg_epoch_loss=2.407392\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=25 train loss <loss>=2.81430010796\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:54 INFO 139866244298560] Epoch[45] Batch [25]#011Speed: 584.76 samples/sec#011loss=2.814300\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:55 INFO 139866244298560] Epoch[45] Batch[30] avg_epoch_loss=2.409041\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=30 train loss <loss>=2.41761541367\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:55 INFO 139866244298560] Epoch[45] Batch [30]#011Speed: 477.58 samples/sec#011loss=2.417615\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:56 INFO 139866244298560] Epoch[45] Batch[35] avg_epoch_loss=2.412951\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=35 train loss <loss>=2.43719420433\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:56 INFO 139866244298560] Epoch[45] Batch [35]#011Speed: 582.88 samples/sec#011loss=2.437194\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:56 INFO 139866244298560] Epoch[45] Batch[40] avg_epoch_loss=2.410981\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=40 train loss <loss>=2.39679741859\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:56 INFO 139866244298560] Epoch[45] Batch [40]#011Speed: 480.71 samples/sec#011loss=2.396797\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:57 INFO 139866244298560] Epoch[45] Batch[45] avg_epoch_loss=2.406833\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=45 train loss <loss>=2.37282378674\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:57 INFO 139866244298560] Epoch[45] Batch [45]#011Speed: 589.81 samples/sec#011loss=2.372824\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:57 INFO 139866244298560] Epoch[45] Batch[50] avg_epoch_loss=2.389673\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=50 train loss <loss>=2.23179302216\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:57 INFO 139866244298560] Epoch[45] Batch [50]#011Speed: 451.03 samples/sec#011loss=2.231793\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:58 INFO 139866244298560] Epoch[45] Batch[55] avg_epoch_loss=2.388595\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=55 train loss <loss>=2.37760710716\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:58 INFO 139866244298560] Epoch[45] Batch [55]#011Speed: 596.69 samples/sec#011loss=2.377607\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:59 INFO 139866244298560] Epoch[45] Batch[60] avg_epoch_loss=2.409953\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=60 train loss <loss>=2.64916176796\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:59 INFO 139866244298560] Epoch[45] Batch [60]#011Speed: 486.06 samples/sec#011loss=2.649162\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:59 INFO 139866244298560] Epoch[45] Batch[65] avg_epoch_loss=2.455061\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=65 train loss <loss>=3.00536956787\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:50:59 INFO 139866244298560] Epoch[45] Batch [65]#011Speed: 478.19 samples/sec#011loss=3.005370\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:00 INFO 139866244298560] Epoch[45] Batch[70] avg_epoch_loss=2.523608\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=70 train loss <loss>=3.42843232155\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:00 INFO 139866244298560] Epoch[45] Batch [70]#011Speed: 591.56 samples/sec#011loss=3.428432\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:01 INFO 139866244298560] Epoch[45] Batch[75] avg_epoch_loss=2.582468\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=75 train loss <loss>=3.41828670502\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:01 INFO 139866244298560] Epoch[45] Batch [75]#011Speed: 474.61 samples/sec#011loss=3.418287\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:01 INFO 139866244298560] Epoch[45] Batch[80] avg_epoch_loss=2.597046\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=80 train loss <loss>=2.81862974167\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:01 INFO 139866244298560] Epoch[45] Batch [80]#011Speed: 572.43 samples/sec#011loss=2.818630\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:02 INFO 139866244298560] Epoch[45] Batch[85] avg_epoch_loss=2.598340\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=85 train loss <loss>=2.61930522919\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:02 INFO 139866244298560] Epoch[45] Batch [85]#011Speed: 465.46 samples/sec#011loss=2.619305\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:02 INFO 139866244298560] Epoch[45] Batch[90] avg_epoch_loss=2.586044\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=90 train loss <loss>=2.37455248833\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:02 INFO 139866244298560] Epoch[45] Batch [90]#011Speed: 586.98 samples/sec#011loss=2.374552\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:03 INFO 139866244298560] Epoch[45] Batch[95] avg_epoch_loss=2.578929\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=95 train loss <loss>=2.44942913055\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:03 INFO 139866244298560] Epoch[45] Batch [95]#011Speed: 450.23 samples/sec#011loss=2.449429\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:04 INFO 139866244298560] Epoch[45] Batch[100] avg_epoch_loss=2.562899\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=100 train loss <loss>=2.25512776375\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:04 INFO 139866244298560] Epoch[45] Batch [100]#011Speed: 590.52 samples/sec#011loss=2.255128\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:04 INFO 139866244298560] Epoch[45] Batch[105] avg_epoch_loss=2.558254\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=105 train loss <loss>=2.46442799568\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:04 INFO 139866244298560] Epoch[45] Batch [105]#011Speed: 458.44 samples/sec#011loss=2.464428\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:05 INFO 139866244298560] Epoch[45] Batch[110] avg_epoch_loss=2.538803\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=110 train loss <loss>=2.12644512653\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:05 INFO 139866244298560] Epoch[45] Batch [110]#011Speed: 590.42 samples/sec#011loss=2.126445\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:06 INFO 139866244298560] Epoch[45] Batch[115] avg_epoch_loss=2.544587\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=115 train loss <loss>=2.67297580242\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:06 INFO 139866244298560] Epoch[45] Batch [115]#011Speed: 479.45 samples/sec#011loss=2.672976\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:06 INFO 139866244298560] Epoch[45] Batch[120] avg_epoch_loss=2.564515\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=120 train loss <loss>=3.02684965134\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:06 INFO 139866244298560] Epoch[45] Batch [120]#011Speed: 595.19 samples/sec#011loss=3.026850\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:07 INFO 139866244298560] Epoch[45] Batch[125] avg_epoch_loss=2.589138\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=125 train loss <loss>=3.18502864838\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:07 INFO 139866244298560] Epoch[45] Batch [125]#011Speed: 477.70 samples/sec#011loss=3.185029\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:07 INFO 139866244298560] Epoch[45] Batch[130] avg_epoch_loss=2.610245\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=130 train loss <loss>=3.14213666916\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:07 INFO 139866244298560] Epoch[45] Batch [130]#011Speed: 572.99 samples/sec#011loss=3.142137\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:08 INFO 139866244298560] Epoch[45] Batch[135] avg_epoch_loss=2.610772\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=135 train loss <loss>=2.62457618713\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:08 INFO 139866244298560] Epoch[45] Batch [135]#011Speed: 443.70 samples/sec#011loss=2.624576\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:09 INFO 139866244298560] Epoch[45] Batch[140] avg_epoch_loss=2.601019\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=140 train loss <loss>=2.33574101925\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:09 INFO 139866244298560] Epoch[45] Batch [140]#011Speed: 586.51 samples/sec#011loss=2.335741\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:09 INFO 139866244298560] Epoch[45] Batch[145] avg_epoch_loss=2.579180\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=145 train loss <loss>=1.96332030296\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:09 INFO 139866244298560] Epoch[45] Batch [145]#011Speed: 473.76 samples/sec#011loss=1.963320\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:10 INFO 139866244298560] Epoch[45] Batch[150] avg_epoch_loss=2.571054\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=150 train loss <loss>=2.33376891613\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:10 INFO 139866244298560] Epoch[45] Batch [150]#011Speed: 474.78 samples/sec#011loss=2.333769\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:10 INFO 139866244298560] Epoch[45] Batch[155] avg_epoch_loss=2.571209\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=155 train loss <loss>=2.5759036541\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:10 INFO 139866244298560] Epoch[45] Batch [155]#011Speed: 584.76 samples/sec#011loss=2.575904\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:11 INFO 139866244298560] Epoch[45] Batch[160] avg_epoch_loss=2.564856\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=160 train loss <loss>=2.36661739349\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:11 INFO 139866244298560] Epoch[45] Batch [160]#011Speed: 473.34 samples/sec#011loss=2.366617\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:12 INFO 139866244298560] Epoch[45] Batch[165] avg_epoch_loss=2.563004\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=165 train loss <loss>=2.50337362289\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:12 INFO 139866244298560] Epoch[45] Batch [165]#011Speed: 595.27 samples/sec#011loss=2.503374\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:12 INFO 139866244298560] Epoch[45] Batch[170] avg_epoch_loss=2.566642\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=170 train loss <loss>=2.68741607666\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:12 INFO 139866244298560] Epoch[45] Batch [170]#011Speed: 466.11 samples/sec#011loss=2.687416\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:13 INFO 139866244298560] Epoch[45] Batch[175] avg_epoch_loss=2.574808\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=175 train loss <loss>=2.85409436226\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:13 INFO 139866244298560] Epoch[45] Batch [175]#011Speed: 548.49 samples/sec#011loss=2.854094\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:14 INFO 139866244298560] Epoch[45] Batch[180] avg_epoch_loss=2.590641\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=180 train loss <loss>=3.14797053337\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:14 INFO 139866244298560] Epoch[45] Batch [180]#011Speed: 482.34 samples/sec#011loss=3.147971\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:14 INFO 139866244298560] Epoch[45] Batch[185] avg_epoch_loss=2.613091\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=185 train loss <loss>=3.42577438354\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:14 INFO 139866244298560] Epoch[45] Batch [185]#011Speed: 585.90 samples/sec#011loss=3.425774\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:15 INFO 139866244298560] Epoch[45] Batch[190] avg_epoch_loss=2.627711\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=190 train loss <loss>=3.17159676552\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:15 INFO 139866244298560] Epoch[45] Batch [190]#011Speed: 476.68 samples/sec#011loss=3.171597\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:15 INFO 139866244298560] Epoch[45] Batch[195] avg_epoch_loss=2.629241\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=195 train loss <loss>=2.68765830994\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:15 INFO 139866244298560] Epoch[45] Batch [195]#011Speed: 589.09 samples/sec#011loss=2.687658\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:16 INFO 139866244298560] Epoch[45] Batch[200] avg_epoch_loss=2.629447\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=200 train loss <loss>=2.63751964569\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:16 INFO 139866244298560] Epoch[45] Batch [200]#011Speed: 477.48 samples/sec#011loss=2.637520\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:17 INFO 139866244298560] Epoch[45] Batch[205] avg_epoch_loss=2.626916\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=205 train loss <loss>=2.52519311905\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:17 INFO 139866244298560] Epoch[45] Batch [205]#011Speed: 589.05 samples/sec#011loss=2.525193\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:17 INFO 139866244298560] Epoch[45] Batch[210] avg_epoch_loss=2.623829\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=210 train loss <loss>=2.49661831856\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:17 INFO 139866244298560] Epoch[45] Batch [210]#011Speed: 471.88 samples/sec#011loss=2.496618\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:18 INFO 139866244298560] Epoch[45] Batch[215] avg_epoch_loss=2.620196\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=215 train loss <loss>=2.46688432693\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:18 INFO 139866244298560] Epoch[45] Batch [215]#011Speed: 560.23 samples/sec#011loss=2.466884\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:18 INFO 139866244298560] Epoch[45] Batch[220] avg_epoch_loss=2.622409\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=220 train loss <loss>=2.71804270744\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:18 INFO 139866244298560] Epoch[45] Batch [220]#011Speed: 469.75 samples/sec#011loss=2.718043\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:19 INFO 139866244298560] Epoch[45] Batch[225] avg_epoch_loss=2.627222\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=225 train loss <loss>=2.83994531631\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:19 INFO 139866244298560] Epoch[45] Batch [225]#011Speed: 529.74 samples/sec#011loss=2.839945\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:20 INFO 139866244298560] Epoch[45] Batch[230] avg_epoch_loss=2.636623\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=230 train loss <loss>=3.06154713631\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:20 INFO 139866244298560] Epoch[45] Batch [230]#011Speed: 473.02 samples/sec#011loss=3.061547\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:20 INFO 139866244298560] Epoch[45] Batch[235] avg_epoch_loss=2.652689\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=235 train loss <loss>=3.39493103027\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:20 INFO 139866244298560] Epoch[45] Batch [235]#011Speed: 590.04 samples/sec#011loss=3.394931\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:21 INFO 139866244298560] Epoch[45] Batch[240] avg_epoch_loss=2.665637\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=240 train loss <loss>=3.2767765522\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:21 INFO 139866244298560] Epoch[45] Batch [240]#011Speed: 479.64 samples/sec#011loss=3.276777\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:22 INFO 139866244298560] Epoch[45] Batch[245] avg_epoch_loss=2.681506\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=245 train loss <loss>=3.44642066956\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:22 INFO 139866244298560] Epoch[45] Batch [245]#011Speed: 587.00 samples/sec#011loss=3.446421\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:22 INFO 139866244298560] Epoch[45] Batch[250] avg_epoch_loss=2.680591\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=250 train loss <loss>=2.63555374146\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:22 INFO 139866244298560] Epoch[45] Batch [250]#011Speed: 470.85 samples/sec#011loss=2.635554\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:23 INFO 139866244298560] Epoch[45] Batch[255] avg_epoch_loss=2.673348\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=255 train loss <loss>=2.30974984169\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:23 INFO 139866244298560] Epoch[45] Batch [255]#011Speed: 591.14 samples/sec#011loss=2.309750\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:23 INFO 139866244298560] Epoch[45] Batch[260] avg_epoch_loss=2.667357\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=260 train loss <loss>=2.36059184074\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:23 INFO 139866244298560] Epoch[45] Batch [260]#011Speed: 444.65 samples/sec#011loss=2.360592\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:24 INFO 139866244298560] Epoch[45] Batch[265] avg_epoch_loss=2.662958\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, batch=265 train loss <loss>=2.43335590363\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:24 INFO 139866244298560] Epoch[45] Batch [265]#011Speed: 587.62 samples/sec#011loss=2.433356\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:24 INFO 139866244298560] processed a total of 17248 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33393.03994178772, \"sum\": 33393.03994178772, \"min\": 33393.03994178772}}, \"EndTime\": 1599443484.99075, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443451.59721}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:24 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=516.513377633 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:24 INFO 139866244298560] #progress_metric: host=algo-1, completed 57 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=45, train loss <loss>=2.67900572441\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:24 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:25 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_4ed3d88a-ddf5-4a25-b0b0-819674004d5c-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 22.161006927490234, \"sum\": 22.161006927490234, \"min\": 22.161006927490234}}, \"EndTime\": 1599443485.013658, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443484.990811}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:25 INFO 139866244298560] Epoch[46] Batch[0] avg_epoch_loss=2.285454\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=0 train loss <loss>=2.28545427322\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:25 INFO 139866244298560] Epoch[46] Batch[5] avg_epoch_loss=1.954301\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=5 train loss <loss>=1.95430056254\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:25 INFO 139866244298560] Epoch[46] Batch [5]#011Speed: 587.25 samples/sec#011loss=1.954301\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:26 INFO 139866244298560] Epoch[46] Batch[10] avg_epoch_loss=2.129603\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=10 train loss <loss>=2.33996589184\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:26 INFO 139866244298560] Epoch[46] Batch [10]#011Speed: 478.30 samples/sec#011loss=2.339966\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:27 INFO 139866244298560] Epoch[46] Batch[15] avg_epoch_loss=2.326280\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=15 train loss <loss>=2.75896821022\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:27 INFO 139866244298560] Epoch[46] Batch [15]#011Speed: 592.16 samples/sec#011loss=2.758968\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:27 INFO 139866244298560] Epoch[46] Batch[20] avg_epoch_loss=2.422548\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=20 train loss <loss>=2.73060512543\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:27 INFO 139866244298560] Epoch[46] Batch [20]#011Speed: 472.08 samples/sec#011loss=2.730605\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:28 INFO 139866244298560] Epoch[46] Batch[25] avg_epoch_loss=2.481530\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=25 train loss <loss>=2.72925543785\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:28 INFO 139866244298560] Epoch[46] Batch [25]#011Speed: 594.22 samples/sec#011loss=2.729255\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:28 INFO 139866244298560] Epoch[46] Batch[30] avg_epoch_loss=2.470868\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=30 train loss <loss>=2.41542358398\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:28 INFO 139866244298560] Epoch[46] Batch [30]#011Speed: 453.95 samples/sec#011loss=2.415424\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:29 INFO 139866244298560] Epoch[46] Batch[35] avg_epoch_loss=2.444643\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=35 train loss <loss>=2.28205041885\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:29 INFO 139866244298560] Epoch[46] Batch [35]#011Speed: 585.56 samples/sec#011loss=2.282050\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:30 INFO 139866244298560] Epoch[46] Batch[40] avg_epoch_loss=2.451087\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=40 train loss <loss>=2.49748344421\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:30 INFO 139866244298560] Epoch[46] Batch [40]#011Speed: 475.20 samples/sec#011loss=2.497483\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:30 INFO 139866244298560] Epoch[46] Batch[45] avg_epoch_loss=2.433796\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=45 train loss <loss>=2.29201180935\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:30 INFO 139866244298560] Epoch[46] Batch [45]#011Speed: 587.80 samples/sec#011loss=2.292012\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:31 INFO 139866244298560] Epoch[46] Batch[50] avg_epoch_loss=2.423498\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=50 train loss <loss>=2.32875487804\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:31 INFO 139866244298560] Epoch[46] Batch [50]#011Speed: 471.76 samples/sec#011loss=2.328755\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:31 INFO 139866244298560] Epoch[46] Batch[55] avg_epoch_loss=2.418151\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=55 train loss <loss>=2.36361646652\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:31 INFO 139866244298560] Epoch[46] Batch [55]#011Speed: 591.83 samples/sec#011loss=2.363616\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:32 INFO 139866244298560] Epoch[46] Batch[60] avg_epoch_loss=2.462256\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=60 train loss <loss>=2.9562309742\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:32 INFO 139866244298560] Epoch[46] Batch [60]#011Speed: 476.98 samples/sec#011loss=2.956231\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:33 INFO 139866244298560] Epoch[46] Batch[65] avg_epoch_loss=2.507782\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=65 train loss <loss>=3.06319689751\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:33 INFO 139866244298560] Epoch[46] Batch [65]#011Speed: 593.80 samples/sec#011loss=3.063197\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:33 INFO 139866244298560] Epoch[46] Batch[70] avg_epoch_loss=2.555102\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=70 train loss <loss>=3.17972183228\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:33 INFO 139866244298560] Epoch[46] Batch [70]#011Speed: 454.93 samples/sec#011loss=3.179722\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:34 INFO 139866244298560] Epoch[46] Batch[75] avg_epoch_loss=2.592949\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=75 train loss <loss>=3.1303838253\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:34 INFO 139866244298560] Epoch[46] Batch [75]#011Speed: 587.78 samples/sec#011loss=3.130384\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:35 INFO 139866244298560] Epoch[46] Batch[80] avg_epoch_loss=2.599374\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=80 train loss <loss>=2.69703588486\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:35 INFO 139866244298560] Epoch[46] Batch [80]#011Speed: 480.72 samples/sec#011loss=2.697036\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:35 INFO 139866244298560] Epoch[46] Batch[85] avg_epoch_loss=2.612917\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=85 train loss <loss>=2.83230819702\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:35 INFO 139866244298560] Epoch[46] Batch [85]#011Speed: 591.48 samples/sec#011loss=2.832308\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:36 INFO 139866244298560] Epoch[46] Batch[90] avg_epoch_loss=2.609612\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=90 train loss <loss>=2.5527633667\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:36 INFO 139866244298560] Epoch[46] Batch [90]#011Speed: 467.56 samples/sec#011loss=2.552763\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:36 INFO 139866244298560] Epoch[46] Batch[95] avg_epoch_loss=2.609462\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=95 train loss <loss>=2.60674300194\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:36 INFO 139866244298560] Epoch[46] Batch [95]#011Speed: 591.78 samples/sec#011loss=2.606743\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:37 INFO 139866244298560] Epoch[46] Batch[100] avg_epoch_loss=2.599888\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=100 train loss <loss>=2.41604852676\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:37 INFO 139866244298560] Epoch[46] Batch [100]#011Speed: 473.28 samples/sec#011loss=2.416049\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:38 INFO 139866244298560] Epoch[46] Batch[105] avg_epoch_loss=2.587797\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=105 train loss <loss>=2.3435781002\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:38 INFO 139866244298560] Epoch[46] Batch [105]#011Speed: 584.95 samples/sec#011loss=2.343578\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:38 INFO 139866244298560] Epoch[46] Batch[110] avg_epoch_loss=2.584209\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=110 train loss <loss>=2.50812902451\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:38 INFO 139866244298560] Epoch[46] Batch [110]#011Speed: 446.20 samples/sec#011loss=2.508129\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:39 INFO 139866244298560] Epoch[46] Batch[115] avg_epoch_loss=2.581395\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=115 train loss <loss>=2.51892676353\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:39 INFO 139866244298560] Epoch[46] Batch [115]#011Speed: 595.32 samples/sec#011loss=2.518927\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:39 INFO 139866244298560] Epoch[46] Batch[120] avg_epoch_loss=2.593554\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=120 train loss <loss>=2.87565617561\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:39 INFO 139866244298560] Epoch[46] Batch [120]#011Speed: 483.58 samples/sec#011loss=2.875656\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:40 INFO 139866244298560] Epoch[46] Batch[125] avg_epoch_loss=2.602201\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=125 train loss <loss>=2.81144728661\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:40 INFO 139866244298560] Epoch[46] Batch [125]#011Speed: 474.80 samples/sec#011loss=2.811447\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:41 INFO 139866244298560] Epoch[46] Batch[130] avg_epoch_loss=2.621636\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=130 train loss <loss>=3.11139011383\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:41 INFO 139866244298560] Epoch[46] Batch [130]#011Speed: 582.63 samples/sec#011loss=3.111390\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:41 INFO 139866244298560] Epoch[46] Batch[135] avg_epoch_loss=2.630757\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=135 train loss <loss>=2.86974406242\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:41 INFO 139866244298560] Epoch[46] Batch [135]#011Speed: 478.24 samples/sec#011loss=2.869744\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:42 INFO 139866244298560] Epoch[46] Batch[140] avg_epoch_loss=2.624780\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=140 train loss <loss>=2.46218338013\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:42 INFO 139866244298560] Epoch[46] Batch [140]#011Speed: 591.96 samples/sec#011loss=2.462183\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:43 INFO 139866244298560] Epoch[46] Batch[145] avg_epoch_loss=2.614882\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=145 train loss <loss>=2.33576731682\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:43 INFO 139866244298560] Epoch[46] Batch [145]#011Speed: 473.19 samples/sec#011loss=2.335767\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:43 INFO 139866244298560] Epoch[46] Batch[150] avg_epoch_loss=2.596968\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=150 train loss <loss>=2.07387280464\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:43 INFO 139866244298560] Epoch[46] Batch [150]#011Speed: 595.75 samples/sec#011loss=2.073873\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:44 INFO 139866244298560] Epoch[46] Batch[155] avg_epoch_loss=2.594818\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=155 train loss <loss>=2.52989301682\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:44 INFO 139866244298560] Epoch[46] Batch [155]#011Speed: 443.56 samples/sec#011loss=2.529893\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:44 INFO 139866244298560] Epoch[46] Batch[160] avg_epoch_loss=2.590823\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=160 train loss <loss>=2.46618962288\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:44 INFO 139866244298560] Epoch[46] Batch [160]#011Speed: 585.53 samples/sec#011loss=2.466190\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:45 INFO 139866244298560] Epoch[46] Batch[165] avg_epoch_loss=2.580182\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=165 train loss <loss>=2.23754713535\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:45 INFO 139866244298560] Epoch[46] Batch [165]#011Speed: 464.03 samples/sec#011loss=2.237547\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:46 INFO 139866244298560] Epoch[46] Batch[170] avg_epoch_loss=2.570614\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=170 train loss <loss>=2.25293514729\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:46 INFO 139866244298560] Epoch[46] Batch [170]#011Speed: 584.81 samples/sec#011loss=2.252935\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:46 INFO 139866244298560] Epoch[46] Batch[175] avg_epoch_loss=2.568006\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=175 train loss <loss>=2.47882595062\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:46 INFO 139866244298560] Epoch[46] Batch [175]#011Speed: 475.77 samples/sec#011loss=2.478826\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:47 INFO 139866244298560] Epoch[46] Batch[180] avg_epoch_loss=2.574973\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=180 train loss <loss>=2.82019443512\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:47 INFO 139866244298560] Epoch[46] Batch [180]#011Speed: 589.08 samples/sec#011loss=2.820194\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:47 INFO 139866244298560] Epoch[46] Batch[185] avg_epoch_loss=2.595396\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=185 train loss <loss>=3.33473639488\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:47 INFO 139866244298560] Epoch[46] Batch [185]#011Speed: 482.49 samples/sec#011loss=3.334736\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:48 INFO 139866244298560] Epoch[46] Batch[190] avg_epoch_loss=2.613207\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=190 train loss <loss>=3.27574682236\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:48 INFO 139866244298560] Epoch[46] Batch [190]#011Speed: 597.55 samples/sec#011loss=3.275747\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:49 INFO 139866244298560] Epoch[46] Batch[195] avg_epoch_loss=2.628970\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=195 train loss <loss>=3.23112068176\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:49 INFO 139866244298560] Epoch[46] Batch [195]#011Speed: 431.23 samples/sec#011loss=3.231121\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:49 INFO 139866244298560] Epoch[46] Batch[200] avg_epoch_loss=2.643739\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=200 train loss <loss>=3.22269706726\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:49 INFO 139866244298560] Epoch[46] Batch [200]#011Speed: 445.73 samples/sec#011loss=3.222697\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:50 INFO 139866244298560] Epoch[46] Batch[205] avg_epoch_loss=2.643965\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=205 train loss <loss>=2.65306119919\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:50 INFO 139866244298560] Epoch[46] Batch [205]#011Speed: 582.08 samples/sec#011loss=2.653061\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:51 INFO 139866244298560] Epoch[46] Batch[210] avg_epoch_loss=2.647784\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=210 train loss <loss>=2.80513334274\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:51 INFO 139866244298560] Epoch[46] Batch [210]#011Speed: 471.53 samples/sec#011loss=2.805133\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:51 INFO 139866244298560] Epoch[46] Batch[215] avg_epoch_loss=2.641746\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=215 train loss <loss>=2.38691363335\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:51 INFO 139866244298560] Epoch[46] Batch [215]#011Speed: 589.72 samples/sec#011loss=2.386914\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:52 INFO 139866244298560] Epoch[46] Batch[220] avg_epoch_loss=2.638494\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=220 train loss <loss>=2.49802947044\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:52 INFO 139866244298560] Epoch[46] Batch [220]#011Speed: 482.33 samples/sec#011loss=2.498029\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:52 INFO 139866244298560] Epoch[46] Batch[225] avg_epoch_loss=2.636419\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=225 train loss <loss>=2.54469094276\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:52 INFO 139866244298560] Epoch[46] Batch [225]#011Speed: 578.79 samples/sec#011loss=2.544691\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:53 INFO 139866244298560] Epoch[46] Batch[230] avg_epoch_loss=2.646292\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=230 train loss <loss>=3.09253239632\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:53 INFO 139866244298560] Epoch[46] Batch [230]#011Speed: 480.71 samples/sec#011loss=3.092532\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:54 INFO 139866244298560] Epoch[46] Batch[235] avg_epoch_loss=2.666612\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=235 train loss <loss>=3.60539979935\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:54 INFO 139866244298560] Epoch[46] Batch [235]#011Speed: 535.95 samples/sec#011loss=3.605400\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:54 INFO 139866244298560] Epoch[46] Batch[240] avg_epoch_loss=2.682544\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=240 train loss <loss>=3.43456625938\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:54 INFO 139866244298560] Epoch[46] Batch [240]#011Speed: 470.00 samples/sec#011loss=3.434566\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:55 INFO 139866244298560] Epoch[46] Batch[245] avg_epoch_loss=2.691550\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=245 train loss <loss>=3.12560157776\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:55 INFO 139866244298560] Epoch[46] Batch [245]#011Speed: 587.17 samples/sec#011loss=3.125602\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:56 INFO 139866244298560] Epoch[46] Batch[250] avg_epoch_loss=2.695989\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=250 train loss <loss>=2.91439948082\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:56 INFO 139866244298560] Epoch[46] Batch [250]#011Speed: 469.32 samples/sec#011loss=2.914399\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:56 INFO 139866244298560] Epoch[46] Batch[255] avg_epoch_loss=2.697729\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=255 train loss <loss>=2.78507184982\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:56 INFO 139866244298560] Epoch[46] Batch [255]#011Speed: 583.30 samples/sec#011loss=2.785072\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:57 INFO 139866244298560] Epoch[46] Batch[260] avg_epoch_loss=2.691914\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=260 train loss <loss>=2.39419035912\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:57 INFO 139866244298560] Epoch[46] Batch [260]#011Speed: 481.54 samples/sec#011loss=2.394190\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:57 INFO 139866244298560] Epoch[46] Batch[265] avg_epoch_loss=2.686291\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, batch=265 train loss <loss>=2.39276356697\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:57 INFO 139866244298560] Epoch[46] Batch [265]#011Speed: 594.53 samples/sec#011loss=2.392764\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:58 INFO 139866244298560] processed a total of 17238 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33333.36400985718, \"sum\": 33333.36400985718, \"min\": 33333.36400985718}}, \"EndTime\": 1599443518.347181, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443485.013738}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:58 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=517.137693146 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:58 INFO 139866244298560] #progress_metric: host=algo-1, completed 58 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=46, train loss <loss>=2.70212586942\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:58 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:58 INFO 139866244298560] Epoch[47] Batch[0] avg_epoch_loss=2.041685\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=0 train loss <loss>=2.04168486595\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:59 INFO 139866244298560] Epoch[47] Batch[5] avg_epoch_loss=2.070346\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=5 train loss <loss>=2.07034591834\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:59 INFO 139866244298560] Epoch[47] Batch [5]#011Speed: 554.16 samples/sec#011loss=2.070346\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:59 INFO 139866244298560] Epoch[47] Batch[10] avg_epoch_loss=2.125293\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=10 train loss <loss>=2.19122955799\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:51:59 INFO 139866244298560] Epoch[47] Batch [10]#011Speed: 449.94 samples/sec#011loss=2.191230\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:00 INFO 139866244298560] Epoch[47] Batch[15] avg_epoch_loss=2.326144\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=15 train loss <loss>=2.76801457405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:00 INFO 139866244298560] Epoch[47] Batch [15]#011Speed: 589.80 samples/sec#011loss=2.768015\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:01 INFO 139866244298560] Epoch[47] Batch[20] avg_epoch_loss=2.442197\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=20 train loss <loss>=2.81356816292\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:01 INFO 139866244298560] Epoch[47] Batch [20]#011Speed: 459.49 samples/sec#011loss=2.813568\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:01 INFO 139866244298560] Epoch[47] Batch[25] avg_epoch_loss=2.475164\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=25 train loss <loss>=2.6136259079\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:01 INFO 139866244298560] Epoch[47] Batch [25]#011Speed: 565.95 samples/sec#011loss=2.613626\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:02 INFO 139866244298560] Epoch[47] Batch[30] avg_epoch_loss=2.497699\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=30 train loss <loss>=2.61487751007\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:02 INFO 139866244298560] Epoch[47] Batch [30]#011Speed: 472.92 samples/sec#011loss=2.614878\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:02 INFO 139866244298560] Epoch[47] Batch[35] avg_epoch_loss=2.518772\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=35 train loss <loss>=2.64942574501\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:02 INFO 139866244298560] Epoch[47] Batch [35]#011Speed: 583.40 samples/sec#011loss=2.649426\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:03 INFO 139866244298560] Epoch[47] Batch[40] avg_epoch_loss=2.522036\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=40 train loss <loss>=2.54554176331\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:03 INFO 139866244298560] Epoch[47] Batch [40]#011Speed: 486.09 samples/sec#011loss=2.545542\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:04 INFO 139866244298560] Epoch[47] Batch[45] avg_epoch_loss=2.489625\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=45 train loss <loss>=2.22385253906\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:04 INFO 139866244298560] Epoch[47] Batch [45]#011Speed: 592.65 samples/sec#011loss=2.223853\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:04 INFO 139866244298560] Epoch[47] Batch[50] avg_epoch_loss=2.477556\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=50 train loss <loss>=2.36651763916\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:04 INFO 139866244298560] Epoch[47] Batch [50]#011Speed: 438.68 samples/sec#011loss=2.366518\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:05 INFO 139866244298560] Epoch[47] Batch[55] avg_epoch_loss=2.446315\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=55 train loss <loss>=2.1276558876\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:05 INFO 139866244298560] Epoch[47] Batch [55]#011Speed: 584.28 samples/sec#011loss=2.127656\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:06 INFO 139866244298560] Epoch[47] Batch[60] avg_epoch_loss=2.445160\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=60 train loss <loss>=2.43222613335\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:06 INFO 139866244298560] Epoch[47] Batch [60]#011Speed: 473.45 samples/sec#011loss=2.432226\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:06 INFO 139866244298560] Epoch[47] Batch[65] avg_epoch_loss=2.470671\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=65 train loss <loss>=2.7819065094\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:06 INFO 139866244298560] Epoch[47] Batch [65]#011Speed: 589.21 samples/sec#011loss=2.781907\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:07 INFO 139866244298560] Epoch[47] Batch[70] avg_epoch_loss=2.497185\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=70 train loss <loss>=2.84716405869\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:07 INFO 139866244298560] Epoch[47] Batch [70]#011Speed: 478.69 samples/sec#011loss=2.847164\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:07 INFO 139866244298560] Epoch[47] Batch[75] avg_epoch_loss=2.550803\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=75 train loss <loss>=3.31218709946\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:07 INFO 139866244298560] Epoch[47] Batch [75]#011Speed: 589.12 samples/sec#011loss=3.312187\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:08 INFO 139866244298560] Epoch[47] Batch[80] avg_epoch_loss=2.586046\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=80 train loss <loss>=3.12173199654\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:08 INFO 139866244298560] Epoch[47] Batch [80]#011Speed: 475.31 samples/sec#011loss=3.121732\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:09 INFO 139866244298560] Epoch[47] Batch[85] avg_epoch_loss=2.619201\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=85 train loss <loss>=3.1563170433\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:09 INFO 139866244298560] Epoch[47] Batch [85]#011Speed: 597.01 samples/sec#011loss=3.156317\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:09 INFO 139866244298560] Epoch[47] Batch[90] avg_epoch_loss=2.616507\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=90 train loss <loss>=2.57016816139\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:09 INFO 139866244298560] Epoch[47] Batch [90]#011Speed: 434.93 samples/sec#011loss=2.570168\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:10 INFO 139866244298560] Epoch[47] Batch[95] avg_epoch_loss=2.611999\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=95 train loss <loss>=2.52995448112\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:10 INFO 139866244298560] Epoch[47] Batch [95]#011Speed: 591.04 samples/sec#011loss=2.529954\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:11 INFO 139866244298560] Epoch[47] Batch[100] avg_epoch_loss=2.606526\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=100 train loss <loss>=2.50144143105\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:11 INFO 139866244298560] Epoch[47] Batch [100]#011Speed: 467.20 samples/sec#011loss=2.501441\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:11 INFO 139866244298560] Epoch[47] Batch[105] avg_epoch_loss=2.604961\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=105 train loss <loss>=2.57335095406\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:11 INFO 139866244298560] Epoch[47] Batch [105]#011Speed: 594.99 samples/sec#011loss=2.573351\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:12 INFO 139866244298560] Epoch[47] Batch[110] avg_epoch_loss=2.596884\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=110 train loss <loss>=2.42566027641\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:12 INFO 139866244298560] Epoch[47] Batch [110]#011Speed: 479.18 samples/sec#011loss=2.425660\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:12 INFO 139866244298560] Epoch[47] Batch[115] avg_epoch_loss=2.580183\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=115 train loss <loss>=2.2094022274\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:12 INFO 139866244298560] Epoch[47] Batch [115]#011Speed: 586.03 samples/sec#011loss=2.209402\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:13 INFO 139866244298560] Epoch[47] Batch[120] avg_epoch_loss=2.572995\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=120 train loss <loss>=2.40625462532\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:13 INFO 139866244298560] Epoch[47] Batch [120]#011Speed: 476.34 samples/sec#011loss=2.406255\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:13 INFO 139866244298560] Epoch[47] Batch[125] avg_epoch_loss=2.570813\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=125 train loss <loss>=2.51798601151\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:13 INFO 139866244298560] Epoch[47] Batch [125]#011Speed: 590.97 samples/sec#011loss=2.517986\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:14 INFO 139866244298560] Epoch[47] Batch[130] avg_epoch_loss=2.581850\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=130 train loss <loss>=2.86000123024\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:14 INFO 139866244298560] Epoch[47] Batch [130]#011Speed: 433.07 samples/sec#011loss=2.860001\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:15 INFO 139866244298560] Epoch[47] Batch[135] avg_epoch_loss=2.591874\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=135 train loss <loss>=2.85449371338\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:15 INFO 139866244298560] Epoch[47] Batch [135]#011Speed: 549.14 samples/sec#011loss=2.854494\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:15 INFO 139866244298560] Epoch[47] Batch[140] avg_epoch_loss=2.599110\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=140 train loss <loss>=2.79593644142\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:15 INFO 139866244298560] Epoch[47] Batch [140]#011Speed: 469.14 samples/sec#011loss=2.795936\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:16 INFO 139866244298560] Epoch[47] Batch[145] avg_epoch_loss=2.607021\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=145 train loss <loss>=2.83011512756\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:16 INFO 139866244298560] Epoch[47] Batch [145]#011Speed: 482.35 samples/sec#011loss=2.830115\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:17 INFO 139866244298560] Epoch[47] Batch[150] avg_epoch_loss=2.601377\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=150 train loss <loss>=2.4365650177\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:17 INFO 139866244298560] Epoch[47] Batch [150]#011Speed: 588.89 samples/sec#011loss=2.436565\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:17 INFO 139866244298560] Epoch[47] Batch[155] avg_epoch_loss=2.599485\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=155 train loss <loss>=2.54234662056\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:17 INFO 139866244298560] Epoch[47] Batch [155]#011Speed: 478.36 samples/sec#011loss=2.542347\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:18 INFO 139866244298560] Epoch[47] Batch[160] avg_epoch_loss=2.600437\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=160 train loss <loss>=2.6301504612\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:18 INFO 139866244298560] Epoch[47] Batch [160]#011Speed: 590.93 samples/sec#011loss=2.630150\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:19 INFO 139866244298560] Epoch[47] Batch[165] avg_epoch_loss=2.595315\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=165 train loss <loss>=2.430372715\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:19 INFO 139866244298560] Epoch[47] Batch [165]#011Speed: 479.58 samples/sec#011loss=2.430373\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:19 INFO 139866244298560] Epoch[47] Batch[170] avg_epoch_loss=2.587722\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=170 train loss <loss>=2.33562402725\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:19 INFO 139866244298560] Epoch[47] Batch [170]#011Speed: 571.90 samples/sec#011loss=2.335624\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:20 INFO 139866244298560] Epoch[47] Batch[175] avg_epoch_loss=2.585345\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=175 train loss <loss>=2.50406718254\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:20 INFO 139866244298560] Epoch[47] Batch [175]#011Speed: 404.26 samples/sec#011loss=2.504067\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:20 INFO 139866244298560] Epoch[47] Batch[180] avg_epoch_loss=2.587164\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=180 train loss <loss>=2.65120196342\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:20 INFO 139866244298560] Epoch[47] Batch [180]#011Speed: 584.32 samples/sec#011loss=2.651202\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:21 INFO 139866244298560] Epoch[47] Batch[185] avg_epoch_loss=2.602532\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=185 train loss <loss>=3.15882749557\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:21 INFO 139866244298560] Epoch[47] Batch [185]#011Speed: 481.03 samples/sec#011loss=3.158827\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:22 INFO 139866244298560] Epoch[47] Batch[190] avg_epoch_loss=2.621769\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=190 train loss <loss>=3.33738913536\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:22 INFO 139866244298560] Epoch[47] Batch [190]#011Speed: 596.04 samples/sec#011loss=3.337389\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:22 INFO 139866244298560] Epoch[47] Batch[195] avg_epoch_loss=2.636632\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=195 train loss <loss>=3.20441484451\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:22 INFO 139866244298560] Epoch[47] Batch [195]#011Speed: 472.07 samples/sec#011loss=3.204415\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:23 INFO 139866244298560] Epoch[47] Batch[200] avg_epoch_loss=2.656420\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=200 train loss <loss>=3.43211460114\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:23 INFO 139866244298560] Epoch[47] Batch [200]#011Speed: 577.55 samples/sec#011loss=3.432115\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:24 INFO 139866244298560] Epoch[47] Batch[205] avg_epoch_loss=2.663290\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=205 train loss <loss>=2.93943753242\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:24 INFO 139866244298560] Epoch[47] Batch [205]#011Speed: 422.69 samples/sec#011loss=2.939438\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:24 INFO 139866244298560] Epoch[47] Batch[210] avg_epoch_loss=2.671458\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=210 train loss <loss>=3.00800452232\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:24 INFO 139866244298560] Epoch[47] Batch [210]#011Speed: 595.21 samples/sec#011loss=3.008005\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:25 INFO 139866244298560] Epoch[47] Batch[215] avg_epoch_loss=2.663074\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=215 train loss <loss>=2.30927093029\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:25 INFO 139866244298560] Epoch[47] Batch [215]#011Speed: 416.33 samples/sec#011loss=2.309271\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:25 INFO 139866244298560] Epoch[47] Batch[220] avg_epoch_loss=2.656149\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=220 train loss <loss>=2.35698070526\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:25 INFO 139866244298560] Epoch[47] Batch [220]#011Speed: 588.10 samples/sec#011loss=2.356981\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:26 INFO 139866244298560] Epoch[47] Batch[225] avg_epoch_loss=2.647625\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=225 train loss <loss>=2.27088017464\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:26 INFO 139866244298560] Epoch[47] Batch [225]#011Speed: 470.19 samples/sec#011loss=2.270880\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:27 INFO 139866244298560] Epoch[47] Batch[230] avg_epoch_loss=2.646728\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=230 train loss <loss>=2.60615649223\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:27 INFO 139866244298560] Epoch[47] Batch [230]#011Speed: 588.94 samples/sec#011loss=2.606156\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:27 INFO 139866244298560] Epoch[47] Batch[235] avg_epoch_loss=2.649354\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=235 train loss <loss>=2.7706946373\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:27 INFO 139866244298560] Epoch[47] Batch [235]#011Speed: 472.41 samples/sec#011loss=2.770695\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:28 INFO 139866244298560] Epoch[47] Batch[240] avg_epoch_loss=2.653406\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=240 train loss <loss>=2.8446413517\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:28 INFO 139866244298560] Epoch[47] Batch [240]#011Speed: 484.06 samples/sec#011loss=2.844641\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:29 INFO 139866244298560] Epoch[47] Batch[245] avg_epoch_loss=2.663400\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=245 train loss <loss>=3.14512004852\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:29 INFO 139866244298560] Epoch[47] Batch [245]#011Speed: 592.59 samples/sec#011loss=3.145120\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:29 INFO 139866244298560] Epoch[47] Batch[250] avg_epoch_loss=2.676549\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=250 train loss <loss>=3.32345333099\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:29 INFO 139866244298560] Epoch[47] Batch [250]#011Speed: 474.02 samples/sec#011loss=3.323453\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:30 INFO 139866244298560] Epoch[47] Batch[255] avg_epoch_loss=2.683015\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=255 train loss <loss>=3.00763931274\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:30 INFO 139866244298560] Epoch[47] Batch [255]#011Speed: 536.79 samples/sec#011loss=3.007639\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:31 INFO 139866244298560] Epoch[47] Batch[260] avg_epoch_loss=2.693264\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=260 train loss <loss>=3.21801791191\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:31 INFO 139866244298560] Epoch[47] Batch [260]#011Speed: 474.36 samples/sec#011loss=3.218018\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:31 INFO 139866244298560] Epoch[47] Batch[265] avg_epoch_loss=2.691838\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, batch=265 train loss <loss>=2.61737093925\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:31 INFO 139866244298560] Epoch[47] Batch [265]#011Speed: 590.18 samples/sec#011loss=2.617371\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:32 INFO 139866244298560] processed a total of 17249 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33702.598094940186, \"sum\": 33702.598094940186, \"min\": 33702.598094940186}}, \"EndTime\": 1599443552.050516, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443518.347261}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:32 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=511.798697937 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:32 INFO 139866244298560] #progress_metric: host=algo-1, completed 60 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=47, train loss <loss>=2.68467520034\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:32 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:32 INFO 139866244298560] Epoch[48] Batch[0] avg_epoch_loss=2.465899\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=0 train loss <loss>=2.46589851379\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:32 INFO 139866244298560] Epoch[48] Batch[5] avg_epoch_loss=2.135341\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=5 train loss <loss>=2.13534092903\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:32 INFO 139866244298560] Epoch[48] Batch [5]#011Speed: 589.30 samples/sec#011loss=2.135341\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:33 INFO 139866244298560] Epoch[48] Batch[10] avg_epoch_loss=2.265879\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=10 train loss <loss>=2.42252554893\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:33 INFO 139866244298560] Epoch[48] Batch [10]#011Speed: 471.82 samples/sec#011loss=2.422526\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:34 INFO 139866244298560] Epoch[48] Batch[15] avg_epoch_loss=2.361480\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=15 train loss <loss>=2.57180128098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:34 INFO 139866244298560] Epoch[48] Batch [15]#011Speed: 592.00 samples/sec#011loss=2.571801\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:34 INFO 139866244298560] Epoch[48] Batch[20] avg_epoch_loss=2.480469\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=20 train loss <loss>=2.86123571396\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:34 INFO 139866244298560] Epoch[48] Batch [20]#011Speed: 475.77 samples/sec#011loss=2.861236\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:35 INFO 139866244298560] Epoch[48] Batch[25] avg_epoch_loss=2.578238\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=25 train loss <loss>=2.98886394501\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:35 INFO 139866244298560] Epoch[48] Batch [25]#011Speed: 543.50 samples/sec#011loss=2.988864\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:36 INFO 139866244298560] Epoch[48] Batch[30] avg_epoch_loss=2.587453\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=30 train loss <loss>=2.63537397385\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:36 INFO 139866244298560] Epoch[48] Batch [30]#011Speed: 460.72 samples/sec#011loss=2.635374\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:36 INFO 139866244298560] Epoch[48] Batch[35] avg_epoch_loss=2.590123\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=35 train loss <loss>=2.60667471886\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:36 INFO 139866244298560] Epoch[48] Batch [35]#011Speed: 587.88 samples/sec#011loss=2.606675\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:37 INFO 139866244298560] Epoch[48] Batch[40] avg_epoch_loss=2.578498\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=40 train loss <loss>=2.49479932785\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:37 INFO 139866244298560] Epoch[48] Batch [40]#011Speed: 475.89 samples/sec#011loss=2.494799\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:37 INFO 139866244298560] Epoch[48] Batch[45] avg_epoch_loss=2.574509\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=45 train loss <loss>=2.54179706573\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:37 INFO 139866244298560] Epoch[48] Batch [45]#011Speed: 589.70 samples/sec#011loss=2.541797\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:38 INFO 139866244298560] Epoch[48] Batch[50] avg_epoch_loss=2.541346\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=50 train loss <loss>=2.23625025749\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:38 INFO 139866244298560] Epoch[48] Batch [50]#011Speed: 469.77 samples/sec#011loss=2.236250\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:38 INFO 139866244298560] Epoch[48] Batch[55] avg_epoch_loss=2.525347\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=55 train loss <loss>=2.36215600967\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:38 INFO 139866244298560] Epoch[48] Batch [55]#011Speed: 596.03 samples/sec#011loss=2.362156\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:39 INFO 139866244298560] Epoch[48] Batch[60] avg_epoch_loss=2.526145\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=60 train loss <loss>=2.53507699966\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:39 INFO 139866244298560] Epoch[48] Batch [60]#011Speed: 475.48 samples/sec#011loss=2.535077\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:40 INFO 139866244298560] Epoch[48] Batch[65] avg_epoch_loss=2.509589\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=65 train loss <loss>=2.30760893822\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:40 INFO 139866244298560] Epoch[48] Batch [65]#011Speed: 585.27 samples/sec#011loss=2.307609\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:40 INFO 139866244298560] Epoch[48] Batch[70] avg_epoch_loss=2.525298\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=70 train loss <loss>=2.73265862465\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:40 INFO 139866244298560] Epoch[48] Batch [70]#011Speed: 438.11 samples/sec#011loss=2.732659\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:41 INFO 139866244298560] Epoch[48] Batch[75] avg_epoch_loss=2.536510\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=75 train loss <loss>=2.6957224369\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:41 INFO 139866244298560] Epoch[48] Batch [75]#011Speed: 589.99 samples/sec#011loss=2.695722\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:42 INFO 139866244298560] Epoch[48] Batch[80] avg_epoch_loss=2.579023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=80 train loss <loss>=3.22521672249\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:42 INFO 139866244298560] Epoch[48] Batch [80]#011Speed: 484.39 samples/sec#011loss=3.225217\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:42 INFO 139866244298560] Epoch[48] Batch[85] avg_epoch_loss=2.626150\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=85 train loss <loss>=3.3896021843\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:42 INFO 139866244298560] Epoch[48] Batch [85]#011Speed: 594.48 samples/sec#011loss=3.389602\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:43 INFO 139866244298560] Epoch[48] Batch[90] avg_epoch_loss=2.631024\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=90 train loss <loss>=2.71486177444\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:43 INFO 139866244298560] Epoch[48] Batch [90]#011Speed: 478.52 samples/sec#011loss=2.714862\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:43 INFO 139866244298560] Epoch[48] Batch[95] avg_epoch_loss=2.636732\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=95 train loss <loss>=2.74061422348\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:43 INFO 139866244298560] Epoch[48] Batch [95]#011Speed: 594.68 samples/sec#011loss=2.740614\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:44 INFO 139866244298560] Epoch[48] Batch[100] avg_epoch_loss=2.623515\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=100 train loss <loss>=2.36974596977\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:44 INFO 139866244298560] Epoch[48] Batch [100]#011Speed: 476.47 samples/sec#011loss=2.369746\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:45 INFO 139866244298560] Epoch[48] Batch[105] avg_epoch_loss=2.619165\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=105 train loss <loss>=2.53131046295\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:45 INFO 139866244298560] Epoch[48] Batch [105]#011Speed: 583.95 samples/sec#011loss=2.531310\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:45 INFO 139866244298560] Epoch[48] Batch[110] avg_epoch_loss=2.604965\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=110 train loss <loss>=2.30390779972\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:45 INFO 139866244298560] Epoch[48] Batch [110]#011Speed: 428.87 samples/sec#011loss=2.303908\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:46 INFO 139866244298560] Epoch[48] Batch[115] avg_epoch_loss=2.588102\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=115 train loss <loss>=2.21375570297\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:46 INFO 139866244298560] Epoch[48] Batch [115]#011Speed: 467.79 samples/sec#011loss=2.213756\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:47 INFO 139866244298560] Epoch[48] Batch[120] avg_epoch_loss=2.574242\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=120 train loss <loss>=2.25267736912\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:47 INFO 139866244298560] Epoch[48] Batch [120]#011Speed: 593.87 samples/sec#011loss=2.252677\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:47 INFO 139866244298560] Epoch[48] Batch[125] avg_epoch_loss=2.568190\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=125 train loss <loss>=2.42173829079\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:47 INFO 139866244298560] Epoch[48] Batch [125]#011Speed: 475.88 samples/sec#011loss=2.421738\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:48 INFO 139866244298560] Epoch[48] Batch[130] avg_epoch_loss=2.578977\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=130 train loss <loss>=2.85081238747\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:48 INFO 139866244298560] Epoch[48] Batch [130]#011Speed: 591.85 samples/sec#011loss=2.850812\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:48 INFO 139866244298560] Epoch[48] Batch[135] avg_epoch_loss=2.592370\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=135 train loss <loss>=2.94326443672\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:48 INFO 139866244298560] Epoch[48] Batch [135]#011Speed: 473.76 samples/sec#011loss=2.943264\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:49 INFO 139866244298560] Epoch[48] Batch[140] avg_epoch_loss=2.609341\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=140 train loss <loss>=3.07095460892\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:49 INFO 139866244298560] Epoch[48] Batch [140]#011Speed: 595.65 samples/sec#011loss=3.070955\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:50 INFO 139866244298560] Epoch[48] Batch[145] avg_epoch_loss=2.609890\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=145 train loss <loss>=2.62538223267\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:50 INFO 139866244298560] Epoch[48] Batch [145]#011Speed: 443.95 samples/sec#011loss=2.625382\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:50 INFO 139866244298560] Epoch[48] Batch[150] avg_epoch_loss=2.600943\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=150 train loss <loss>=2.33967113495\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:50 INFO 139866244298560] Epoch[48] Batch [150]#011Speed: 553.52 samples/sec#011loss=2.339671\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:51 INFO 139866244298560] Epoch[48] Batch[155] avg_epoch_loss=2.596844\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=155 train loss <loss>=2.47306451797\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:51 INFO 139866244298560] Epoch[48] Batch [155]#011Speed: 472.16 samples/sec#011loss=2.473065\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:52 INFO 139866244298560] Epoch[48] Batch[160] avg_epoch_loss=2.592940\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=160 train loss <loss>=2.47112960815\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:52 INFO 139866244298560] Epoch[48] Batch [160]#011Speed: 579.17 samples/sec#011loss=2.471130\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:52 INFO 139866244298560] Epoch[48] Batch[165] avg_epoch_loss=2.589628\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=165 train loss <loss>=2.48297138214\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:52 INFO 139866244298560] Epoch[48] Batch [165]#011Speed: 471.74 samples/sec#011loss=2.482971\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:53 INFO 139866244298560] Epoch[48] Batch[170] avg_epoch_loss=2.580618\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=170 train loss <loss>=2.28149602413\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:53 INFO 139866244298560] Epoch[48] Batch [170]#011Speed: 577.79 samples/sec#011loss=2.281496\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:53 INFO 139866244298560] Epoch[48] Batch[175] avg_epoch_loss=2.578570\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=175 train loss <loss>=2.508517313\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:53 INFO 139866244298560] Epoch[48] Batch [175]#011Speed: 472.39 samples/sec#011loss=2.508517\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:54 INFO 139866244298560] Epoch[48] Batch[180] avg_epoch_loss=2.577470\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=180 train loss <loss>=2.53877530098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:54 INFO 139866244298560] Epoch[48] Batch [180]#011Speed: 588.24 samples/sec#011loss=2.538775\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:55 INFO 139866244298560] Epoch[48] Batch[185] avg_epoch_loss=2.595824\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=185 train loss <loss>=3.26021723747\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:55 INFO 139866244298560] Epoch[48] Batch [185]#011Speed: 471.42 samples/sec#011loss=3.260217\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:55 INFO 139866244298560] Epoch[48] Batch[190] avg_epoch_loss=2.611334\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=190 train loss <loss>=3.18832707405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:55 INFO 139866244298560] Epoch[48] Batch [190]#011Speed: 592.46 samples/sec#011loss=3.188327\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:56 INFO 139866244298560] Epoch[48] Batch[195] avg_epoch_loss=2.636950\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=195 train loss <loss>=3.6154841423\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:56 INFO 139866244298560] Epoch[48] Batch [195]#011Speed: 459.19 samples/sec#011loss=3.615484\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:57 INFO 139866244298560] Epoch[48] Batch[200] avg_epoch_loss=2.655939\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=200 train loss <loss>=3.40028090477\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:57 INFO 139866244298560] Epoch[48] Batch [200]#011Speed: 475.99 samples/sec#011loss=3.400281\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:57 INFO 139866244298560] Epoch[48] Batch[205] avg_epoch_loss=2.667706\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=205 train loss <loss>=3.14074764252\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:57 INFO 139866244298560] Epoch[48] Batch [205]#011Speed: 592.60 samples/sec#011loss=3.140748\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:58 INFO 139866244298560] Epoch[48] Batch[210] avg_epoch_loss=2.669912\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=210 train loss <loss>=2.76079454422\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:58 INFO 139866244298560] Epoch[48] Batch [210]#011Speed: 477.80 samples/sec#011loss=2.760795\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:58 INFO 139866244298560] Epoch[48] Batch[215] avg_epoch_loss=2.659686\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=215 train loss <loss>=2.22817614079\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:58 INFO 139866244298560] Epoch[48] Batch [215]#011Speed: 595.09 samples/sec#011loss=2.228176\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:59 INFO 139866244298560] Epoch[48] Batch[220] avg_epoch_loss=2.647638\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=220 train loss <loss>=2.12712962627\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:52:59 INFO 139866244298560] Epoch[48] Batch [220]#011Speed: 464.45 samples/sec#011loss=2.127130\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:00 INFO 139866244298560] Epoch[48] Batch[225] avg_epoch_loss=2.649954\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=225 train loss <loss>=2.75235090256\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:00 INFO 139866244298560] Epoch[48] Batch [225]#011Speed: 590.63 samples/sec#011loss=2.752351\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:00 INFO 139866244298560] Epoch[48] Batch[230] avg_epoch_loss=2.653338\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=230 train loss <loss>=2.80629072189\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:00 INFO 139866244298560] Epoch[48] Batch [230]#011Speed: 478.35 samples/sec#011loss=2.806291\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:01 INFO 139866244298560] Epoch[48] Batch[235] avg_epoch_loss=2.655435\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=235 train loss <loss>=2.75231728554\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:01 INFO 139866244298560] Epoch[48] Batch [235]#011Speed: 535.34 samples/sec#011loss=2.752317\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:02 INFO 139866244298560] Epoch[48] Batch[240] avg_epoch_loss=2.670833\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=240 train loss <loss>=3.39761929512\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:02 INFO 139866244298560] Epoch[48] Batch [240]#011Speed: 455.30 samples/sec#011loss=3.397619\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:02 INFO 139866244298560] Epoch[48] Batch[245] avg_epoch_loss=2.685594\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=245 train loss <loss>=3.39704232216\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:02 INFO 139866244298560] Epoch[48] Batch [245]#011Speed: 584.08 samples/sec#011loss=3.397042\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:03 INFO 139866244298560] Epoch[48] Batch[250] avg_epoch_loss=2.698519\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=250 train loss <loss>=3.33445410728\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:03 INFO 139866244298560] Epoch[48] Batch [250]#011Speed: 475.79 samples/sec#011loss=3.334454\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:03 INFO 139866244298560] Epoch[48] Batch[255] avg_epoch_loss=2.703866\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=255 train loss <loss>=2.97230100632\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:03 INFO 139866244298560] Epoch[48] Batch [255]#011Speed: 592.37 samples/sec#011loss=2.972301\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:04 INFO 139866244298560] Epoch[48] Batch[260] avg_epoch_loss=2.702102\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=260 train loss <loss>=2.61176757812\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:04 INFO 139866244298560] Epoch[48] Batch [260]#011Speed: 480.47 samples/sec#011loss=2.611768\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:04 INFO 139866244298560] Epoch[48] Batch[265] avg_epoch_loss=2.697825\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, batch=265 train loss <loss>=2.47454881668\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:04 INFO 139866244298560] Epoch[48] Batch [265]#011Speed: 590.57 samples/sec#011loss=2.474549\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:05 INFO 139866244298560] processed a total of 17105 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33173.439025878906, \"sum\": 33173.439025878906, \"min\": 33173.439025878906}}, \"EndTime\": 1599443585.224697, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443552.050578}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:05 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=515.621508 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:05 INFO 139866244298560] #progress_metric: host=algo-1, completed 61 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=48, train loss <loss>=2.70342049803\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:05 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:05 INFO 139866244298560] Epoch[49] Batch[0] avg_epoch_loss=2.174293\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=0 train loss <loss>=2.17429327965\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:06 INFO 139866244298560] Epoch[49] Batch[5] avg_epoch_loss=2.057545\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=5 train loss <loss>=2.05754460891\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:06 INFO 139866244298560] Epoch[49] Batch [5]#011Speed: 591.45 samples/sec#011loss=2.057545\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:06 INFO 139866244298560] Epoch[49] Batch[10] avg_epoch_loss=2.151461\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=10 train loss <loss>=2.26416101456\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:06 INFO 139866244298560] Epoch[49] Batch [10]#011Speed: 432.61 samples/sec#011loss=2.264161\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:07 INFO 139866244298560] Epoch[49] Batch[15] avg_epoch_loss=2.350013\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=15 train loss <loss>=2.78682560921\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:07 INFO 139866244298560] Epoch[49] Batch [15]#011Speed: 581.58 samples/sec#011loss=2.786826\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:07 INFO 139866244298560] Epoch[49] Batch[20] avg_epoch_loss=2.427691\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=20 train loss <loss>=2.67626318932\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:07 INFO 139866244298560] Epoch[49] Batch [20]#011Speed: 468.78 samples/sec#011loss=2.676263\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:08 INFO 139866244298560] Epoch[49] Batch[25] avg_epoch_loss=2.523519\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=25 train loss <loss>=2.92599716187\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:08 INFO 139866244298560] Epoch[49] Batch [25]#011Speed: 586.17 samples/sec#011loss=2.925997\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:09 INFO 139866244298560] Epoch[49] Batch[30] avg_epoch_loss=2.554300\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=30 train loss <loss>=2.71435790062\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:09 INFO 139866244298560] Epoch[49] Batch [30]#011Speed: 479.50 samples/sec#011loss=2.714358\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:09 INFO 139866244298560] Epoch[49] Batch[35] avg_epoch_loss=2.551827\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=35 train loss <loss>=2.53649339676\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:09 INFO 139866244298560] Epoch[49] Batch [35]#011Speed: 594.09 samples/sec#011loss=2.536493\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:10 INFO 139866244298560] Epoch[49] Batch[40] avg_epoch_loss=2.542770\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=40 train loss <loss>=2.47755823135\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:10 INFO 139866244298560] Epoch[49] Batch [40]#011Speed: 459.82 samples/sec#011loss=2.477558\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:10 INFO 139866244298560] Epoch[49] Batch[45] avg_epoch_loss=2.549398\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=45 train loss <loss>=2.60375342369\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:10 INFO 139866244298560] Epoch[49] Batch [45]#011Speed: 593.49 samples/sec#011loss=2.603753\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:11 INFO 139866244298560] Epoch[49] Batch[50] avg_epoch_loss=2.549094\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=50 train loss <loss>=2.54629683495\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:11 INFO 139866244298560] Epoch[49] Batch [50]#011Speed: 433.46 samples/sec#011loss=2.546297\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:12 INFO 139866244298560] Epoch[49] Batch[55] avg_epoch_loss=2.532876\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=55 train loss <loss>=2.3674536705\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:12 INFO 139866244298560] Epoch[49] Batch [55]#011Speed: 587.35 samples/sec#011loss=2.367454\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:12 INFO 139866244298560] Epoch[49] Batch[60] avg_epoch_loss=2.540614\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=60 train loss <loss>=2.62727108002\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:12 INFO 139866244298560] Epoch[49] Batch [60]#011Speed: 480.31 samples/sec#011loss=2.627271\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:13 INFO 139866244298560] Epoch[49] Batch[65] avg_epoch_loss=2.539161\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=65 train loss <loss>=2.52144041061\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:13 INFO 139866244298560] Epoch[49] Batch [65]#011Speed: 585.18 samples/sec#011loss=2.521440\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:14 INFO 139866244298560] Epoch[49] Batch[70] avg_epoch_loss=2.586023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=70 train loss <loss>=3.20460243225\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:14 INFO 139866244298560] Epoch[49] Batch [70]#011Speed: 481.90 samples/sec#011loss=3.204602\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:14 INFO 139866244298560] Epoch[49] Batch[75] avg_epoch_loss=2.626436\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=75 train loss <loss>=3.20029973984\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:14 INFO 139866244298560] Epoch[49] Batch [75]#011Speed: 585.14 samples/sec#011loss=3.200300\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:15 INFO 139866244298560] Epoch[49] Batch[80] avg_epoch_loss=2.658149\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=80 train loss <loss>=3.14017982483\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:15 INFO 139866244298560] Epoch[49] Batch [80]#011Speed: 474.68 samples/sec#011loss=3.140180\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:15 INFO 139866244298560] Epoch[49] Batch[85] avg_epoch_loss=2.680266\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=85 train loss <loss>=3.03856596947\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:15 INFO 139866244298560] Epoch[49] Batch [85]#011Speed: 589.63 samples/sec#011loss=3.038566\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:16 INFO 139866244298560] Epoch[49] Batch[90] avg_epoch_loss=2.669552\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=90 train loss <loss>=2.48527617455\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:16 INFO 139866244298560] Epoch[49] Batch [90]#011Speed: 450.13 samples/sec#011loss=2.485276\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:17 INFO 139866244298560] Epoch[49] Batch[95] avg_epoch_loss=2.661405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=95 train loss <loss>=2.51312212944\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:17 INFO 139866244298560] Epoch[49] Batch [95]#011Speed: 586.34 samples/sec#011loss=2.513122\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:17 INFO 139866244298560] Epoch[49] Batch[100] avg_epoch_loss=2.646182\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=100 train loss <loss>=2.35390295982\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:17 INFO 139866244298560] Epoch[49] Batch [100]#011Speed: 466.60 samples/sec#011loss=2.353903\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:18 INFO 139866244298560] Epoch[49] Batch[105] avg_epoch_loss=2.641923\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=105 train loss <loss>=2.55589902401\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:18 INFO 139866244298560] Epoch[49] Batch [105]#011Speed: 481.17 samples/sec#011loss=2.555899\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:19 INFO 139866244298560] Epoch[49] Batch[110] avg_epoch_loss=2.630343\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=110 train loss <loss>=2.3848484993\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:19 INFO 139866244298560] Epoch[49] Batch [110]#011Speed: 594.18 samples/sec#011loss=2.384848\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:19 INFO 139866244298560] Epoch[49] Batch[115] avg_epoch_loss=2.615515\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=115 train loss <loss>=2.28632616997\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:19 INFO 139866244298560] Epoch[49] Batch [115]#011Speed: 396.61 samples/sec#011loss=2.286326\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:20 INFO 139866244298560] Epoch[49] Batch[120] avg_epoch_loss=2.624952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=120 train loss <loss>=2.84389162064\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:20 INFO 139866244298560] Epoch[49] Batch [120]#011Speed: 526.40 samples/sec#011loss=2.843892\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:21 INFO 139866244298560] Epoch[49] Batch[125] avg_epoch_loss=2.638832\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=125 train loss <loss>=2.97471766472\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:21 INFO 139866244298560] Epoch[49] Batch [125]#011Speed: 482.50 samples/sec#011loss=2.974718\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:21 INFO 139866244298560] Epoch[49] Batch[130] avg_epoch_loss=2.655537\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=130 train loss <loss>=3.07651023865\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:21 INFO 139866244298560] Epoch[49] Batch [130]#011Speed: 534.12 samples/sec#011loss=3.076510\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:22 INFO 139866244298560] Epoch[49] Batch[135] avg_epoch_loss=2.658500\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=135 train loss <loss>=2.73614177704\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:22 INFO 139866244298560] Epoch[49] Batch [135]#011Speed: 468.91 samples/sec#011loss=2.736142\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:22 INFO 139866244298560] Epoch[49] Batch[140] avg_epoch_loss=2.646721\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=140 train loss <loss>=2.32633242607\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:22 INFO 139866244298560] Epoch[49] Batch [140]#011Speed: 593.98 samples/sec#011loss=2.326332\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:23 INFO 139866244298560] Epoch[49] Batch[145] avg_epoch_loss=2.636710\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=145 train loss <loss>=2.3544044733\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:23 INFO 139866244298560] Epoch[49] Batch [145]#011Speed: 472.70 samples/sec#011loss=2.354404\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:24 INFO 139866244298560] Epoch[49] Batch[150] avg_epoch_loss=2.623013\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=150 train loss <loss>=2.22304742336\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:24 INFO 139866244298560] Epoch[49] Batch [150]#011Speed: 595.04 samples/sec#011loss=2.223047\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:24 INFO 139866244298560] Epoch[49] Batch[155] avg_epoch_loss=2.613834\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=155 train loss <loss>=2.33663554192\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:24 INFO 139866244298560] Epoch[49] Batch [155]#011Speed: 464.45 samples/sec#011loss=2.336636\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:25 INFO 139866244298560] Epoch[49] Batch[160] avg_epoch_loss=2.612310\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=160 train loss <loss>=2.56475374699\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:25 INFO 139866244298560] Epoch[49] Batch [160]#011Speed: 581.18 samples/sec#011loss=2.564754\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:26 INFO 139866244298560] Epoch[49] Batch[165] avg_epoch_loss=2.608936\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=165 train loss <loss>=2.50029444695\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:26 INFO 139866244298560] Epoch[49] Batch [165]#011Speed: 472.53 samples/sec#011loss=2.500294\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:26 INFO 139866244298560] Epoch[49] Batch[170] avg_epoch_loss=2.603158\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=170 train loss <loss>=2.41131381989\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:26 INFO 139866244298560] Epoch[49] Batch [170]#011Speed: 556.84 samples/sec#011loss=2.411314\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:27 INFO 139866244298560] Epoch[49] Batch[175] avg_epoch_loss=2.610776\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=175 train loss <loss>=2.87133545876\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:27 INFO 139866244298560] Epoch[49] Batch [175]#011Speed: 443.22 samples/sec#011loss=2.871335\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:27 INFO 139866244298560] Epoch[49] Batch[180] avg_epoch_loss=2.618396\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=180 train loss <loss>=2.88659768105\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:27 INFO 139866244298560] Epoch[49] Batch [180]#011Speed: 585.64 samples/sec#011loss=2.886598\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:28 INFO 139866244298560] Epoch[49] Batch[185] avg_epoch_loss=2.636167\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=185 train loss <loss>=3.27949571609\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:28 INFO 139866244298560] Epoch[49] Batch [185]#011Speed: 475.37 samples/sec#011loss=3.279496\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:29 INFO 139866244298560] Epoch[49] Batch[190] avg_epoch_loss=2.657671\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=190 train loss <loss>=3.45762753487\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:29 INFO 139866244298560] Epoch[49] Batch [190]#011Speed: 598.21 samples/sec#011loss=3.457628\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:29 INFO 139866244298560] Epoch[49] Batch[195] avg_epoch_loss=2.669016\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=195 train loss <loss>=3.10239081383\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:29 INFO 139866244298560] Epoch[49] Batch [195]#011Speed: 481.03 samples/sec#011loss=3.102391\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:30 INFO 139866244298560] Epoch[49] Batch[200] avg_epoch_loss=2.682452\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=200 train loss <loss>=3.20912408829\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:30 INFO 139866244298560] Epoch[49] Batch [200]#011Speed: 590.02 samples/sec#011loss=3.209124\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:31 INFO 139866244298560] Epoch[49] Batch[205] avg_epoch_loss=2.685290\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=205 train loss <loss>=2.7993803978\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:31 INFO 139866244298560] Epoch[49] Batch [205]#011Speed: 473.56 samples/sec#011loss=2.799380\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:31 INFO 139866244298560] Epoch[49] Batch[210] avg_epoch_loss=2.693620\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=210 train loss <loss>=3.0368244648\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:31 INFO 139866244298560] Epoch[49] Batch [210]#011Speed: 591.04 samples/sec#011loss=3.036824\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:32 INFO 139866244298560] Epoch[49] Batch[215] avg_epoch_loss=2.691153\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=215 train loss <loss>=2.58704562187\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:32 INFO 139866244298560] Epoch[49] Batch [215]#011Speed: 434.06 samples/sec#011loss=2.587046\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:32 INFO 139866244298560] Epoch[49] Batch[220] avg_epoch_loss=2.682470\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=220 train loss <loss>=2.30735590458\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:32 INFO 139866244298560] Epoch[49] Batch [220]#011Speed: 585.21 samples/sec#011loss=2.307356\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:33 INFO 139866244298560] Epoch[49] Batch[225] avg_epoch_loss=2.678775\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=225 train loss <loss>=2.51544919014\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:33 INFO 139866244298560] Epoch[49] Batch [225]#011Speed: 475.39 samples/sec#011loss=2.515449\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:34 INFO 139866244298560] Epoch[49] Batch[230] avg_epoch_loss=2.671988\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=230 train loss <loss>=2.36525025368\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:34 INFO 139866244298560] Epoch[49] Batch [230]#011Speed: 594.54 samples/sec#011loss=2.365250\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:34 INFO 139866244298560] Epoch[49] Batch[235] avg_epoch_loss=2.677307\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=235 train loss <loss>=2.92302904129\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:34 INFO 139866244298560] Epoch[49] Batch [235]#011Speed: 476.79 samples/sec#011loss=2.923029\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:35 INFO 139866244298560] Epoch[49] Batch[240] avg_epoch_loss=2.678930\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=240 train loss <loss>=2.75554227829\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:35 INFO 139866244298560] Epoch[49] Batch [240]#011Speed: 577.24 samples/sec#011loss=2.755542\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:35 INFO 139866244298560] Epoch[49] Batch[245] avg_epoch_loss=2.693459\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=245 train loss <loss>=3.39373159409\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:35 INFO 139866244298560] Epoch[49] Batch [245]#011Speed: 472.13 samples/sec#011loss=3.393732\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:36 INFO 139866244298560] Epoch[49] Batch[250] avg_epoch_loss=2.708940\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=250 train loss <loss>=3.47061219215\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:36 INFO 139866244298560] Epoch[49] Batch [250]#011Speed: 595.04 samples/sec#011loss=3.470612\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:37 INFO 139866244298560] Epoch[49] Batch[255] avg_epoch_loss=2.715893\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=255 train loss <loss>=3.06495656967\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:37 INFO 139866244298560] Epoch[49] Batch [255]#011Speed: 451.71 samples/sec#011loss=3.064957\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:37 INFO 139866244298560] Epoch[49] Batch[260] avg_epoch_loss=2.725179\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=260 train loss <loss>=3.20058321953\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:37 INFO 139866244298560] Epoch[49] Batch [260]#011Speed: 581.16 samples/sec#011loss=3.200583\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:38 INFO 139866244298560] Epoch[49] Batch[265] avg_epoch_loss=2.724083\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=265 train loss <loss>=2.66689186096\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:38 INFO 139866244298560] Epoch[49] Batch [265]#011Speed: 469.95 samples/sec#011loss=2.666892\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:38 INFO 139866244298560] Epoch[49] Batch[270] avg_epoch_loss=2.722619\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, batch=270 train loss <loss>=2.64474301338\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:38 INFO 139866244298560] Epoch[49] Batch [270]#011Speed: 591.22 samples/sec#011loss=2.644743\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:39 INFO 139866244298560] processed a total of 17357 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33865.10491371155, \"sum\": 33865.10491371155, \"min\": 33865.10491371155}}, \"EndTime\": 1599443619.090552, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443585.224778}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:39 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=512.53182525 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:39 INFO 139866244298560] #progress_metric: host=algo-1, completed 62 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=49, train loss <loss>=2.72842998101\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:39 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:39 INFO 139866244298560] Epoch[50] Batch[0] avg_epoch_loss=2.054877\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=0 train loss <loss>=2.05487728119\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:39 INFO 139866244298560] Epoch[50] Batch[5] avg_epoch_loss=2.170044\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=5 train loss <loss>=2.17004370689\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:39 INFO 139866244298560] Epoch[50] Batch [5]#011Speed: 591.95 samples/sec#011loss=2.170044\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:40 INFO 139866244298560] Epoch[50] Batch[10] avg_epoch_loss=2.220090\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=10 train loss <loss>=2.28014659882\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:40 INFO 139866244298560] Epoch[50] Batch [10]#011Speed: 473.38 samples/sec#011loss=2.280147\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:41 INFO 139866244298560] Epoch[50] Batch[15] avg_epoch_loss=2.377741\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=15 train loss <loss>=2.72457103729\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:41 INFO 139866244298560] Epoch[50] Batch [15]#011Speed: 592.44 samples/sec#011loss=2.724571\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:41 INFO 139866244298560] Epoch[50] Batch[20] avg_epoch_loss=2.461552\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=20 train loss <loss>=2.7297472477\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:41 INFO 139866244298560] Epoch[50] Batch [20]#011Speed: 476.42 samples/sec#011loss=2.729747\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:42 INFO 139866244298560] Epoch[50] Batch[25] avg_epoch_loss=2.552905\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=25 train loss <loss>=2.93658852577\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:42 INFO 139866244298560] Epoch[50] Batch [25]#011Speed: 544.32 samples/sec#011loss=2.936589\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:43 INFO 139866244298560] Epoch[50] Batch[30] avg_epoch_loss=2.534193\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=30 train loss <loss>=2.43688950539\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:43 INFO 139866244298560] Epoch[50] Batch [30]#011Speed: 467.28 samples/sec#011loss=2.436890\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:43 INFO 139866244298560] Epoch[50] Batch[35] avg_epoch_loss=2.503785\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=35 train loss <loss>=2.31525511742\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:43 INFO 139866244298560] Epoch[50] Batch [35]#011Speed: 585.83 samples/sec#011loss=2.315255\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:44 INFO 139866244298560] Epoch[50] Batch[40] avg_epoch_loss=2.491702\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=40 train loss <loss>=2.40470662117\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:44 INFO 139866244298560] Epoch[50] Batch [40]#011Speed: 479.32 samples/sec#011loss=2.404707\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:44 INFO 139866244298560] Epoch[50] Batch[45] avg_epoch_loss=2.499694\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=45 train loss <loss>=2.56523079872\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:44 INFO 139866244298560] Epoch[50] Batch [45]#011Speed: 588.81 samples/sec#011loss=2.565231\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:45 INFO 139866244298560] Epoch[50] Batch[50] avg_epoch_loss=2.488494\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=50 train loss <loss>=2.38545198441\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:45 INFO 139866244298560] Epoch[50] Batch [50]#011Speed: 469.19 samples/sec#011loss=2.385452\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:46 INFO 139866244298560] Epoch[50] Batch[55] avg_epoch_loss=2.485267\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=55 train loss <loss>=2.45235495567\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:46 INFO 139866244298560] Epoch[50] Batch [55]#011Speed: 590.05 samples/sec#011loss=2.452355\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:46 INFO 139866244298560] Epoch[50] Batch[60] avg_epoch_loss=2.472272\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=60 train loss <loss>=2.32672567368\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:46 INFO 139866244298560] Epoch[50] Batch [60]#011Speed: 481.27 samples/sec#011loss=2.326726\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:47 INFO 139866244298560] Epoch[50] Batch[65] avg_epoch_loss=2.480309\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=65 train loss <loss>=2.57835245132\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:47 INFO 139866244298560] Epoch[50] Batch [65]#011Speed: 418.79 samples/sec#011loss=2.578352\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:48 INFO 139866244298560] Epoch[50] Batch[70] avg_epoch_loss=2.507393\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=70 train loss <loss>=2.86490569115\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:48 INFO 139866244298560] Epoch[50] Batch [70]#011Speed: 584.41 samples/sec#011loss=2.864906\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:48 INFO 139866244298560] Epoch[50] Batch[75] avg_epoch_loss=2.543549\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=75 train loss <loss>=3.05696520805\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:48 INFO 139866244298560] Epoch[50] Batch [75]#011Speed: 477.82 samples/sec#011loss=3.056965\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:49 INFO 139866244298560] Epoch[50] Batch[80] avg_epoch_loss=2.578251\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=80 train loss <loss>=3.10571727753\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:49 INFO 139866244298560] Epoch[50] Batch [80]#011Speed: 592.90 samples/sec#011loss=3.105717\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:49 INFO 139866244298560] Epoch[50] Batch[85] avg_epoch_loss=2.592937\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=85 train loss <loss>=2.83085064888\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:49 INFO 139866244298560] Epoch[50] Batch [85]#011Speed: 477.58 samples/sec#011loss=2.830851\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:50 INFO 139866244298560] Epoch[50] Batch[90] avg_epoch_loss=2.599669\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=90 train loss <loss>=2.71546211243\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:50 INFO 139866244298560] Epoch[50] Batch [90]#011Speed: 533.87 samples/sec#011loss=2.715462\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:51 INFO 139866244298560] Epoch[50] Batch[95] avg_epoch_loss=2.596767\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=95 train loss <loss>=2.54395909309\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:51 INFO 139866244298560] Epoch[50] Batch [95]#011Speed: 477.64 samples/sec#011loss=2.543959\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:51 INFO 139866244298560] Epoch[50] Batch[100] avg_epoch_loss=2.587697\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=100 train loss <loss>=2.41355109215\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:51 INFO 139866244298560] Epoch[50] Batch [100]#011Speed: 594.08 samples/sec#011loss=2.413551\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:52 INFO 139866244298560] Epoch[50] Batch[105] avg_epoch_loss=2.573999\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=105 train loss <loss>=2.2973000288\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:52 INFO 139866244298560] Epoch[50] Batch [105]#011Speed: 425.55 samples/sec#011loss=2.297300\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:52 INFO 139866244298560] Epoch[50] Batch[110] avg_epoch_loss=2.547850\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=110 train loss <loss>=1.99348740578\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:52 INFO 139866244298560] Epoch[50] Batch [110]#011Speed: 585.99 samples/sec#011loss=1.993487\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:53 INFO 139866244298560] Epoch[50] Batch[115] avg_epoch_loss=2.538829\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=115 train loss <loss>=2.3385676384\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:53 INFO 139866244298560] Epoch[50] Batch [115]#011Speed: 466.07 samples/sec#011loss=2.338568\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:54 INFO 139866244298560] Epoch[50] Batch[120] avg_epoch_loss=2.536597\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=120 train loss <loss>=2.48480234146\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:54 INFO 139866244298560] Epoch[50] Batch [120]#011Speed: 596.18 samples/sec#011loss=2.484802\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:54 INFO 139866244298560] Epoch[50] Batch[125] avg_epoch_loss=2.555913\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=125 train loss <loss>=3.02336740494\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:54 INFO 139866244298560] Epoch[50] Batch [125]#011Speed: 479.57 samples/sec#011loss=3.023367\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:55 INFO 139866244298560] Epoch[50] Batch[130] avg_epoch_loss=2.569843\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=130 train loss <loss>=2.92087807655\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:55 INFO 139866244298560] Epoch[50] Batch [130]#011Speed: 583.40 samples/sec#011loss=2.920878\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:56 INFO 139866244298560] Epoch[50] Batch[135] avg_epoch_loss=2.580022\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=135 train loss <loss>=2.84671578407\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:56 INFO 139866244298560] Epoch[50] Batch [135]#011Speed: 468.62 samples/sec#011loss=2.846716\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:56 INFO 139866244298560] Epoch[50] Batch[140] avg_epoch_loss=2.589652\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=140 train loss <loss>=2.85158047676\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:56 INFO 139866244298560] Epoch[50] Batch [140]#011Speed: 478.76 samples/sec#011loss=2.851580\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:57 INFO 139866244298560] Epoch[50] Batch[145] avg_epoch_loss=2.581067\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=145 train loss <loss>=2.33896622658\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:57 INFO 139866244298560] Epoch[50] Batch [145]#011Speed: 596.11 samples/sec#011loss=2.338966\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:58 INFO 139866244298560] Epoch[50] Batch[150] avg_epoch_loss=2.570162\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=150 train loss <loss>=2.25173847675\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:58 INFO 139866244298560] Epoch[50] Batch [150]#011Speed: 438.90 samples/sec#011loss=2.251738\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:58 INFO 139866244298560] Epoch[50] Batch[155] avg_epoch_loss=2.565642\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=155 train loss <loss>=2.42915472984\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:58 INFO 139866244298560] Epoch[50] Batch [155]#011Speed: 571.76 samples/sec#011loss=2.429155\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:59 INFO 139866244298560] Epoch[50] Batch[160] avg_epoch_loss=2.555204\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=160 train loss <loss>=2.22954056263\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:59 INFO 139866244298560] Epoch[50] Batch [160]#011Speed: 472.25 samples/sec#011loss=2.229541\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:59 INFO 139866244298560] Epoch[50] Batch[165] avg_epoch_loss=2.543917\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=165 train loss <loss>=2.18047113419\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:53:59 INFO 139866244298560] Epoch[50] Batch [165]#011Speed: 593.33 samples/sec#011loss=2.180471\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:00 INFO 139866244298560] Epoch[50] Batch[170] avg_epoch_loss=2.539890\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=170 train loss <loss>=2.40619192123\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:00 INFO 139866244298560] Epoch[50] Batch [170]#011Speed: 475.74 samples/sec#011loss=2.406192\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:01 INFO 139866244298560] Epoch[50] Batch[175] avg_epoch_loss=2.544915\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=175 train loss <loss>=2.71676921844\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:01 INFO 139866244298560] Epoch[50] Batch [175]#011Speed: 583.73 samples/sec#011loss=2.716769\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:01 INFO 139866244298560] Epoch[50] Batch[180] avg_epoch_loss=2.557772\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=180 train loss <loss>=3.01034274101\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:01 INFO 139866244298560] Epoch[50] Batch [180]#011Speed: 455.82 samples/sec#011loss=3.010343\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:02 INFO 139866244298560] Epoch[50] Batch[185] avg_epoch_loss=2.575499\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=185 train loss <loss>=3.2172068119\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:02 INFO 139866244298560] Epoch[50] Batch [185]#011Speed: 589.77 samples/sec#011loss=3.217207\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:03 INFO 139866244298560] Epoch[50] Batch[190] avg_epoch_loss=2.595541\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=190 train loss <loss>=3.34110608101\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:03 INFO 139866244298560] Epoch[50] Batch [190]#011Speed: 441.68 samples/sec#011loss=3.341106\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:03 INFO 139866244298560] Epoch[50] Batch[195] avg_epoch_loss=2.618422\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=195 train loss <loss>=3.49246225357\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:03 INFO 139866244298560] Epoch[50] Batch [195]#011Speed: 588.56 samples/sec#011loss=3.492462\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:04 INFO 139866244298560] Epoch[50] Batch[200] avg_epoch_loss=2.635473\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=200 train loss <loss>=3.30388498306\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:04 INFO 139866244298560] Epoch[50] Batch [200]#011Speed: 473.54 samples/sec#011loss=3.303885\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:04 INFO 139866244298560] Epoch[50] Batch[205] avg_epoch_loss=2.641983\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=205 train loss <loss>=2.90366930962\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:04 INFO 139866244298560] Epoch[50] Batch [205]#011Speed: 586.61 samples/sec#011loss=2.903669\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:05 INFO 139866244298560] Epoch[50] Batch[210] avg_epoch_loss=2.645652\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=210 train loss <loss>=2.7968360424\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:05 INFO 139866244298560] Epoch[50] Batch [210]#011Speed: 472.35 samples/sec#011loss=2.796836\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:06 INFO 139866244298560] Epoch[50] Batch[215] avg_epoch_loss=2.643078\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=215 train loss <loss>=2.53444581032\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:06 INFO 139866244298560] Epoch[50] Batch [215]#011Speed: 587.73 samples/sec#011loss=2.534446\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:06 INFO 139866244298560] Epoch[50] Batch[220] avg_epoch_loss=2.636592\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=220 train loss <loss>=2.35639851093\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:06 INFO 139866244298560] Epoch[50] Batch [220]#011Speed: 473.94 samples/sec#011loss=2.356399\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:07 INFO 139866244298560] Epoch[50] Batch[225] avg_epoch_loss=2.634981\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=225 train loss <loss>=2.5637793541\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:07 INFO 139866244298560] Epoch[50] Batch [225]#011Speed: 591.68 samples/sec#011loss=2.563779\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:07 INFO 139866244298560] Epoch[50] Batch[230] avg_epoch_loss=2.629302\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=230 train loss <loss>=2.37260203362\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:07 INFO 139866244298560] Epoch[50] Batch [230]#011Speed: 441.94 samples/sec#011loss=2.372602\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:08 INFO 139866244298560] Epoch[50] Batch[235] avg_epoch_loss=2.631266\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=235 train loss <loss>=2.7220126152\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:08 INFO 139866244298560] Epoch[50] Batch [235]#011Speed: 581.22 samples/sec#011loss=2.722013\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:09 INFO 139866244298560] Epoch[50] Batch[240] avg_epoch_loss=2.638610\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=240 train loss <loss>=2.98524165154\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:09 INFO 139866244298560] Epoch[50] Batch [240]#011Speed: 480.23 samples/sec#011loss=2.985242\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:09 INFO 139866244298560] Epoch[50] Batch[245] avg_epoch_loss=2.654150\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=245 train loss <loss>=3.40316858292\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:09 INFO 139866244298560] Epoch[50] Batch [245]#011Speed: 588.13 samples/sec#011loss=3.403169\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:10 INFO 139866244298560] Epoch[50] Batch[250] avg_epoch_loss=2.662667\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=250 train loss <loss>=3.08168964386\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:10 INFO 139866244298560] Epoch[50] Batch [250]#011Speed: 475.61 samples/sec#011loss=3.081690\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:10 INFO 139866244298560] Epoch[50] Batch[255] avg_epoch_loss=2.670289\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=255 train loss <loss>=3.05292348862\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:10 INFO 139866244298560] Epoch[50] Batch [255]#011Speed: 583.34 samples/sec#011loss=3.052923\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:11 INFO 139866244298560] Epoch[50] Batch[260] avg_epoch_loss=2.674753\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=260 train loss <loss>=2.90331859589\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:11 INFO 139866244298560] Epoch[50] Batch [260]#011Speed: 484.07 samples/sec#011loss=2.903319\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:12 INFO 139866244298560] Epoch[50] Batch[265] avg_epoch_loss=2.674554\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, batch=265 train loss <loss>=2.6641520977\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:12 INFO 139866244298560] Epoch[50] Batch [265]#011Speed: 595.71 samples/sec#011loss=2.664152\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:12 INFO 139866244298560] processed a total of 17165 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33354.48384284973, \"sum\": 33354.48384284973, \"min\": 33354.48384284973}}, \"EndTime\": 1599443652.445577, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443619.090619}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:12 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=514.62111297 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:12 INFO 139866244298560] #progress_metric: host=algo-1, completed 63 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=50, train loss <loss>=2.66544584116\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:12 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:12 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_84b581cc-966a-4232-9bc3-84d1d0e83626-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.241167068481445, \"sum\": 18.241167068481445, \"min\": 18.241167068481445}}, \"EndTime\": 1599443652.464678, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443652.445665}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:12 INFO 139866244298560] Epoch[51] Batch[0] avg_epoch_loss=2.132293\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=0 train loss <loss>=2.13229298592\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:13 INFO 139866244298560] Epoch[51] Batch[5] avg_epoch_loss=2.005427\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=5 train loss <loss>=2.00542692343\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:13 INFO 139866244298560] Epoch[51] Batch [5]#011Speed: 574.19 samples/sec#011loss=2.005427\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:14 INFO 139866244298560] Epoch[51] Batch[10] avg_epoch_loss=2.088215\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=10 train loss <loss>=2.18756041527\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:14 INFO 139866244298560] Epoch[51] Batch [10]#011Speed: 471.02 samples/sec#011loss=2.187560\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:14 INFO 139866244298560] Epoch[51] Batch[15] avg_epoch_loss=2.237857\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=15 train loss <loss>=2.56706814766\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:14 INFO 139866244298560] Epoch[51] Batch [15]#011Speed: 584.10 samples/sec#011loss=2.567068\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:15 INFO 139866244298560] Epoch[51] Batch[20] avg_epoch_loss=2.295502\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=20 train loss <loss>=2.47996673584\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:15 INFO 139866244298560] Epoch[51] Batch [20]#011Speed: 478.94 samples/sec#011loss=2.479967\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:15 INFO 139866244298560] Epoch[51] Batch[25] avg_epoch_loss=2.398333\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=25 train loss <loss>=2.83022556305\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:15 INFO 139866244298560] Epoch[51] Batch [25]#011Speed: 584.60 samples/sec#011loss=2.830226\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:16 INFO 139866244298560] Epoch[51] Batch[30] avg_epoch_loss=2.456546\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=30 train loss <loss>=2.75925188065\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:16 INFO 139866244298560] Epoch[51] Batch [30]#011Speed: 485.32 samples/sec#011loss=2.759252\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:16 INFO 139866244298560] Epoch[51] Batch[35] avg_epoch_loss=2.442384\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=35 train loss <loss>=2.35458011627\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:16 INFO 139866244298560] Epoch[51] Batch [35]#011Speed: 592.07 samples/sec#011loss=2.354580\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:17 INFO 139866244298560] Epoch[51] Batch[40] avg_epoch_loss=2.462907\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=40 train loss <loss>=2.61067433357\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:17 INFO 139866244298560] Epoch[51] Batch [40]#011Speed: 477.90 samples/sec#011loss=2.610674\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:18 INFO 139866244298560] Epoch[51] Batch[45] avg_epoch_loss=2.467907\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=45 train loss <loss>=2.50890841484\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:18 INFO 139866244298560] Epoch[51] Batch [45]#011Speed: 538.28 samples/sec#011loss=2.508908\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:18 INFO 139866244298560] Epoch[51] Batch[50] avg_epoch_loss=2.455559\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=50 train loss <loss>=2.34195208549\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:18 INFO 139866244298560] Epoch[51] Batch [50]#011Speed: 476.07 samples/sec#011loss=2.341952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:19 INFO 139866244298560] Epoch[51] Batch[55] avg_epoch_loss=2.426421\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=55 train loss <loss>=2.12921557426\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:19 INFO 139866244298560] Epoch[51] Batch [55]#011Speed: 587.37 samples/sec#011loss=2.129216\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:20 INFO 139866244298560] Epoch[51] Batch[60] avg_epoch_loss=2.432558\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=60 train loss <loss>=2.50129566193\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:20 INFO 139866244298560] Epoch[51] Batch [60]#011Speed: 473.42 samples/sec#011loss=2.501296\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:20 INFO 139866244298560] Epoch[51] Batch[65] avg_epoch_loss=2.439869\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=65 train loss <loss>=2.52906169891\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:20 INFO 139866244298560] Epoch[51] Batch [65]#011Speed: 532.22 samples/sec#011loss=2.529062\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:21 INFO 139866244298560] Epoch[51] Batch[70] avg_epoch_loss=2.480654\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=70 train loss <loss>=3.0190076828\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:21 INFO 139866244298560] Epoch[51] Batch [70]#011Speed: 484.08 samples/sec#011loss=3.019008\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:21 INFO 139866244298560] Epoch[51] Batch[75] avg_epoch_loss=2.522990\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=75 train loss <loss>=3.12416343689\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:21 INFO 139866244298560] Epoch[51] Batch [75]#011Speed: 576.52 samples/sec#011loss=3.124163\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:22 INFO 139866244298560] Epoch[51] Batch[80] avg_epoch_loss=2.561509\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=80 train loss <loss>=3.14700927734\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:22 INFO 139866244298560] Epoch[51] Batch [80]#011Speed: 481.54 samples/sec#011loss=3.147009\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:23 INFO 139866244298560] Epoch[51] Batch[85] avg_epoch_loss=2.582829\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=85 train loss <loss>=2.92821202278\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:23 INFO 139866244298560] Epoch[51] Batch [85]#011Speed: 426.16 samples/sec#011loss=2.928212\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:23 INFO 139866244298560] Epoch[51] Batch[90] avg_epoch_loss=2.590165\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=90 train loss <loss>=2.71633224487\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:23 INFO 139866244298560] Epoch[51] Batch [90]#011Speed: 586.61 samples/sec#011loss=2.716332\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:24 INFO 139866244298560] Epoch[51] Batch[95] avg_epoch_loss=2.589877\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=95 train loss <loss>=2.58463158607\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:24 INFO 139866244298560] Epoch[51] Batch [95]#011Speed: 472.76 samples/sec#011loss=2.584632\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:25 INFO 139866244298560] Epoch[51] Batch[100] avg_epoch_loss=2.583028\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=100 train loss <loss>=2.45153899193\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:25 INFO 139866244298560] Epoch[51] Batch [100]#011Speed: 588.52 samples/sec#011loss=2.451539\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:25 INFO 139866244298560] Epoch[51] Batch[105] avg_epoch_loss=2.565624\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=105 train loss <loss>=2.214052248\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:25 INFO 139866244298560] Epoch[51] Batch [105]#011Speed: 468.24 samples/sec#011loss=2.214052\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:26 INFO 139866244298560] Epoch[51] Batch[110] avg_epoch_loss=2.553585\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=110 train loss <loss>=2.29836130142\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:26 INFO 139866244298560] Epoch[51] Batch [110]#011Speed: 594.46 samples/sec#011loss=2.298361\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:27 INFO 139866244298560] Epoch[51] Batch[115] avg_epoch_loss=2.537596\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=115 train loss <loss>=2.18263747692\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:27 INFO 139866244298560] Epoch[51] Batch [115]#011Speed: 476.43 samples/sec#011loss=2.182637\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:27 INFO 139866244298560] Epoch[51] Batch[120] avg_epoch_loss=2.540901\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=120 train loss <loss>=2.61758298874\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:27 INFO 139866244298560] Epoch[51] Batch [120]#011Speed: 581.65 samples/sec#011loss=2.617583\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:28 INFO 139866244298560] Epoch[51] Batch[125] avg_epoch_loss=2.548817\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=125 train loss <loss>=2.74038128853\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:28 INFO 139866244298560] Epoch[51] Batch [125]#011Speed: 445.69 samples/sec#011loss=2.740381\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:28 INFO 139866244298560] Epoch[51] Batch[130] avg_epoch_loss=2.555391\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=130 train loss <loss>=2.72107076645\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:28 INFO 139866244298560] Epoch[51] Batch [130]#011Speed: 553.71 samples/sec#011loss=2.721071\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:29 INFO 139866244298560] Epoch[51] Batch[135] avg_epoch_loss=2.570992\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=135 train loss <loss>=2.97972393036\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:29 INFO 139866244298560] Epoch[51] Batch [135]#011Speed: 461.66 samples/sec#011loss=2.979724\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:30 INFO 139866244298560] Epoch[51] Batch[140] avg_epoch_loss=2.583003\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=140 train loss <loss>=2.90970625877\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:30 INFO 139866244298560] Epoch[51] Batch [140]#011Speed: 593.21 samples/sec#011loss=2.909706\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:30 INFO 139866244298560] Epoch[51] Batch[145] avg_epoch_loss=2.584185\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=145 train loss <loss>=2.61752104759\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:30 INFO 139866244298560] Epoch[51] Batch [145]#011Speed: 475.85 samples/sec#011loss=2.617521\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:31 INFO 139866244298560] Epoch[51] Batch[150] avg_epoch_loss=2.569909\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=150 train loss <loss>=2.15304327011\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:31 INFO 139866244298560] Epoch[51] Batch [150]#011Speed: 595.77 samples/sec#011loss=2.153043\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:31 INFO 139866244298560] Epoch[51] Batch[155] avg_epoch_loss=2.564430\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=155 train loss <loss>=2.39895849228\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:31 INFO 139866244298560] Epoch[51] Batch [155]#011Speed: 477.66 samples/sec#011loss=2.398958\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:32 INFO 139866244298560] Epoch[51] Batch[160] avg_epoch_loss=2.558147\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=160 train loss <loss>=2.36212801933\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:32 INFO 139866244298560] Epoch[51] Batch [160]#011Speed: 592.61 samples/sec#011loss=2.362128\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:33 INFO 139866244298560] Epoch[51] Batch[165] avg_epoch_loss=2.560833\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=165 train loss <loss>=2.6473347187\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:33 INFO 139866244298560] Epoch[51] Batch [165]#011Speed: 473.88 samples/sec#011loss=2.647335\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:33 INFO 139866244298560] Epoch[51] Batch[170] avg_epoch_loss=2.555525\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=170 train loss <loss>=2.37928285599\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:33 INFO 139866244298560] Epoch[51] Batch [170]#011Speed: 543.71 samples/sec#011loss=2.379283\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:34 INFO 139866244298560] Epoch[51] Batch[175] avg_epoch_loss=2.563738\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=175 train loss <loss>=2.84463653564\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:34 INFO 139866244298560] Epoch[51] Batch [175]#011Speed: 472.29 samples/sec#011loss=2.844637\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:35 INFO 139866244298560] Epoch[51] Batch[180] avg_epoch_loss=2.569887\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=180 train loss <loss>=2.78632545471\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:35 INFO 139866244298560] Epoch[51] Batch [180]#011Speed: 472.15 samples/sec#011loss=2.786325\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:35 INFO 139866244298560] Epoch[51] Batch[185] avg_epoch_loss=2.592238\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=185 train loss <loss>=3.40134496689\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:35 INFO 139866244298560] Epoch[51] Batch [185]#011Speed: 590.04 samples/sec#011loss=3.401345\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:36 INFO 139866244298560] Epoch[51] Batch[190] avg_epoch_loss=2.611236\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=190 train loss <loss>=3.31795630455\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:36 INFO 139866244298560] Epoch[51] Batch [190]#011Speed: 477.65 samples/sec#011loss=3.317956\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:36 INFO 139866244298560] Epoch[51] Batch[195] avg_epoch_loss=2.623945\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=195 train loss <loss>=3.10942511559\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:36 INFO 139866244298560] Epoch[51] Batch [195]#011Speed: 577.28 samples/sec#011loss=3.109425\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:37 INFO 139866244298560] Epoch[51] Batch[200] avg_epoch_loss=2.637216\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=200 train loss <loss>=3.15745515823\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:37 INFO 139866244298560] Epoch[51] Batch [200]#011Speed: 468.71 samples/sec#011loss=3.157455\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:38 INFO 139866244298560] Epoch[51] Batch[205] avg_epoch_loss=2.642405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=205 train loss <loss>=2.8509762764\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:38 INFO 139866244298560] Epoch[51] Batch [205]#011Speed: 582.24 samples/sec#011loss=2.850976\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:38 INFO 139866244298560] Epoch[51] Batch[210] avg_epoch_loss=2.646419\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=210 train loss <loss>=2.81182966232\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:38 INFO 139866244298560] Epoch[51] Batch [210]#011Speed: 433.11 samples/sec#011loss=2.811830\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:39 INFO 139866244298560] Epoch[51] Batch[215] avg_epoch_loss=2.643688\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=215 train loss <loss>=2.52841324806\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:39 INFO 139866244298560] Epoch[51] Batch [215]#011Speed: 587.68 samples/sec#011loss=2.528413\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:40 INFO 139866244298560] Epoch[51] Batch[220] avg_epoch_loss=2.638754\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=220 train loss <loss>=2.42560591698\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:40 INFO 139866244298560] Epoch[51] Batch [220]#011Speed: 474.08 samples/sec#011loss=2.425606\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:40 INFO 139866244298560] Epoch[51] Batch[225] avg_epoch_loss=2.635250\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=225 train loss <loss>=2.48036141396\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:40 INFO 139866244298560] Epoch[51] Batch [225]#011Speed: 591.78 samples/sec#011loss=2.480361\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:41 INFO 139866244298560] Epoch[51] Batch[230] avg_epoch_loss=2.641040\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=230 train loss <loss>=2.90278644562\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:41 INFO 139866244298560] Epoch[51] Batch [230]#011Speed: 476.94 samples/sec#011loss=2.902786\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:41 INFO 139866244298560] Epoch[51] Batch[235] avg_epoch_loss=2.652518\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=235 train loss <loss>=3.18279776573\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:41 INFO 139866244298560] Epoch[51] Batch [235]#011Speed: 593.45 samples/sec#011loss=3.182798\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:42 INFO 139866244298560] Epoch[51] Batch[240] avg_epoch_loss=2.666840\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=240 train loss <loss>=3.34282960892\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:42 INFO 139866244298560] Epoch[51] Batch [240]#011Speed: 482.07 samples/sec#011loss=3.342830\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:43 INFO 139866244298560] Epoch[51] Batch[245] avg_epoch_loss=2.684538\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=245 train loss <loss>=3.53759260178\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:43 INFO 139866244298560] Epoch[51] Batch [245]#011Speed: 582.39 samples/sec#011loss=3.537593\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:43 INFO 139866244298560] Epoch[51] Batch[250] avg_epoch_loss=2.689753\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=250 train loss <loss>=2.94631175995\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:43 INFO 139866244298560] Epoch[51] Batch [250]#011Speed: 449.01 samples/sec#011loss=2.946312\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:44 INFO 139866244298560] Epoch[51] Batch[255] avg_epoch_loss=2.694469\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=255 train loss <loss>=2.9312335968\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:44 INFO 139866244298560] Epoch[51] Batch [255]#011Speed: 593.59 samples/sec#011loss=2.931234\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:45 INFO 139866244298560] Epoch[51] Batch[260] avg_epoch_loss=2.693573\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=260 train loss <loss>=2.64768152237\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:45 INFO 139866244298560] Epoch[51] Batch [260]#011Speed: 457.07 samples/sec#011loss=2.647682\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:45 INFO 139866244298560] Epoch[51] Batch[265] avg_epoch_loss=2.691575\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, batch=265 train loss <loss>=2.58728351593\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:45 INFO 139866244298560] Epoch[51] Batch [265]#011Speed: 581.82 samples/sec#011loss=2.587284\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:45 INFO 139866244298560] processed a total of 17024 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33096.920013427734, \"sum\": 33096.920013427734, \"min\": 33096.920013427734}}, \"EndTime\": 1599443685.56172, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443652.464739}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:45 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=514.366599776 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:45 INFO 139866244298560] #progress_metric: host=algo-1, completed 65 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=51, train loss <loss>=2.69157518256\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:45 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:45 INFO 139866244298560] Epoch[52] Batch[0] avg_epoch_loss=2.096085\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=0 train loss <loss>=2.09608483315\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:46 INFO 139866244298560] Epoch[52] Batch[5] avg_epoch_loss=2.198473\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=5 train loss <loss>=2.19847261906\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:46 INFO 139866244298560] Epoch[52] Batch [5]#011Speed: 589.12 samples/sec#011loss=2.198473\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:47 INFO 139866244298560] Epoch[52] Batch[10] avg_epoch_loss=2.231800\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=10 train loss <loss>=2.27179224491\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:47 INFO 139866244298560] Epoch[52] Batch [10]#011Speed: 474.70 samples/sec#011loss=2.271792\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:47 INFO 139866244298560] Epoch[52] Batch[15] avg_epoch_loss=2.351554\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=15 train loss <loss>=2.61501259804\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:47 INFO 139866244298560] Epoch[52] Batch [15]#011Speed: 586.91 samples/sec#011loss=2.615013\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:48 INFO 139866244298560] Epoch[52] Batch[20] avg_epoch_loss=2.452757\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=20 train loss <loss>=2.77660794258\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:48 INFO 139866244298560] Epoch[52] Batch [20]#011Speed: 474.96 samples/sec#011loss=2.776608\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:48 INFO 139866244298560] Epoch[52] Batch[25] avg_epoch_loss=2.510061\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=25 train loss <loss>=2.75073575974\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:48 INFO 139866244298560] Epoch[52] Batch [25]#011Speed: 524.79 samples/sec#011loss=2.750736\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:49 INFO 139866244298560] Epoch[52] Batch[30] avg_epoch_loss=2.521385\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=30 train loss <loss>=2.58026924133\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:49 INFO 139866244298560] Epoch[52] Batch [30]#011Speed: 472.88 samples/sec#011loss=2.580269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:50 INFO 139866244298560] Epoch[52] Batch[35] avg_epoch_loss=2.477089\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=35 train loss <loss>=2.20245769024\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:50 INFO 139866244298560] Epoch[52] Batch [35]#011Speed: 577.59 samples/sec#011loss=2.202458\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:50 INFO 139866244298560] Epoch[52] Batch[40] avg_epoch_loss=2.441692\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=40 train loss <loss>=2.18683483601\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:50 INFO 139866244298560] Epoch[52] Batch [40]#011Speed: 434.19 samples/sec#011loss=2.186835\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:51 INFO 139866244298560] Epoch[52] Batch[45] avg_epoch_loss=2.457537\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=45 train loss <loss>=2.58746037483\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:51 INFO 139866244298560] Epoch[52] Batch [45]#011Speed: 588.90 samples/sec#011loss=2.587460\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:52 INFO 139866244298560] Epoch[52] Batch[50] avg_epoch_loss=2.464256\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=50 train loss <loss>=2.52607226372\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:52 INFO 139866244298560] Epoch[52] Batch [50]#011Speed: 466.41 samples/sec#011loss=2.526072\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:52 INFO 139866244298560] Epoch[52] Batch[55] avg_epoch_loss=2.458678\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=55 train loss <loss>=2.40178771019\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:52 INFO 139866244298560] Epoch[52] Batch [55]#011Speed: 586.03 samples/sec#011loss=2.401788\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:53 INFO 139866244298560] Epoch[52] Batch[60] avg_epoch_loss=2.453748\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=60 train loss <loss>=2.39853219986\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:53 INFO 139866244298560] Epoch[52] Batch [60]#011Speed: 471.23 samples/sec#011loss=2.398532\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:53 INFO 139866244298560] Epoch[52] Batch[65] avg_epoch_loss=2.449333\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=65 train loss <loss>=2.39547028542\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:53 INFO 139866244298560] Epoch[52] Batch [65]#011Speed: 548.98 samples/sec#011loss=2.395470\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:54 INFO 139866244298560] Epoch[52] Batch[70] avg_epoch_loss=2.488008\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=70 train loss <loss>=2.99851846695\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:54 INFO 139866244298560] Epoch[52] Batch [70]#011Speed: 462.93 samples/sec#011loss=2.998518\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:55 INFO 139866244298560] Epoch[52] Batch[75] avg_epoch_loss=2.515289\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=75 train loss <loss>=2.90267252922\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:55 INFO 139866244298560] Epoch[52] Batch [75]#011Speed: 582.48 samples/sec#011loss=2.902673\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:55 INFO 139866244298560] Epoch[52] Batch[80] avg_epoch_loss=2.554058\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=80 train loss <loss>=3.14335579872\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:55 INFO 139866244298560] Epoch[52] Batch [80]#011Speed: 481.01 samples/sec#011loss=3.143356\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:56 INFO 139866244298560] Epoch[52] Batch[85] avg_epoch_loss=2.579781\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=85 train loss <loss>=2.99648375511\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:56 INFO 139866244298560] Epoch[52] Batch [85]#011Speed: 593.86 samples/sec#011loss=2.996484\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:57 INFO 139866244298560] Epoch[52] Batch[90] avg_epoch_loss=2.573247\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=90 train loss <loss>=2.460861063\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:57 INFO 139866244298560] Epoch[52] Batch [90]#011Speed: 470.17 samples/sec#011loss=2.460861\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:57 INFO 139866244298560] Epoch[52] Batch[95] avg_epoch_loss=2.576146\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=95 train loss <loss>=2.62890620232\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:57 INFO 139866244298560] Epoch[52] Batch [95]#011Speed: 593.38 samples/sec#011loss=2.628906\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:58 INFO 139866244298560] Epoch[52] Batch[100] avg_epoch_loss=2.572626\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=100 train loss <loss>=2.50505695343\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:58 INFO 139866244298560] Epoch[52] Batch [100]#011Speed: 473.83 samples/sec#011loss=2.505057\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:58 INFO 139866244298560] Epoch[52] Batch[105] avg_epoch_loss=2.571291\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=105 train loss <loss>=2.54431271553\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:58 INFO 139866244298560] Epoch[52] Batch [105]#011Speed: 470.33 samples/sec#011loss=2.544313\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:59 INFO 139866244298560] Epoch[52] Batch[110] avg_epoch_loss=2.567084\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=110 train loss <loss>=2.47790126801\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:54:59 INFO 139866244298560] Epoch[52] Batch [110]#011Speed: 595.81 samples/sec#011loss=2.477901\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:00 INFO 139866244298560] Epoch[52] Batch[115] avg_epoch_loss=2.557584\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=115 train loss <loss>=2.34668469429\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:00 INFO 139866244298560] Epoch[52] Batch [115]#011Speed: 467.59 samples/sec#011loss=2.346685\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:00 INFO 139866244298560] Epoch[52] Batch[120] avg_epoch_loss=2.549030\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=120 train loss <loss>=2.35057883263\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:00 INFO 139866244298560] Epoch[52] Batch [120]#011Speed: 589.02 samples/sec#011loss=2.350579\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:01 INFO 139866244298560] Epoch[52] Batch[125] avg_epoch_loss=2.542115\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=125 train loss <loss>=2.37476711273\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:01 INFO 139866244298560] Epoch[52] Batch [125]#011Speed: 478.34 samples/sec#011loss=2.374767\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:01 INFO 139866244298560] Epoch[52] Batch[130] avg_epoch_loss=2.550753\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=130 train loss <loss>=2.76842312813\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:01 INFO 139866244298560] Epoch[52] Batch [130]#011Speed: 564.94 samples/sec#011loss=2.768423\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:02 INFO 139866244298560] Epoch[52] Batch[135] avg_epoch_loss=2.560286\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=135 train loss <loss>=2.81005573273\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:02 INFO 139866244298560] Epoch[52] Batch [135]#011Speed: 462.89 samples/sec#011loss=2.810056\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:03 INFO 139866244298560] Epoch[52] Batch[140] avg_epoch_loss=2.570605\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=140 train loss <loss>=2.85128030777\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:03 INFO 139866244298560] Epoch[52] Batch [140]#011Speed: 578.84 samples/sec#011loss=2.851280\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:03 INFO 139866244298560] Epoch[52] Batch[145] avg_epoch_loss=2.576148\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=145 train loss <loss>=2.73247685432\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:03 INFO 139866244298560] Epoch[52] Batch [145]#011Speed: 475.78 samples/sec#011loss=2.732477\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:04 INFO 139866244298560] Epoch[52] Batch[150] avg_epoch_loss=2.586233\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=150 train loss <loss>=2.88070874214\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:04 INFO 139866244298560] Epoch[52] Batch [150]#011Speed: 592.54 samples/sec#011loss=2.880709\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:05 INFO 139866244298560] Epoch[52] Batch[155] avg_epoch_loss=2.580968\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=155 train loss <loss>=2.42195897102\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:05 INFO 139866244298560] Epoch[52] Batch [155]#011Speed: 472.22 samples/sec#011loss=2.421959\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:05 INFO 139866244298560] Epoch[52] Batch[160] avg_epoch_loss=2.583744\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=160 train loss <loss>=2.67036094666\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:05 INFO 139866244298560] Epoch[52] Batch [160]#011Speed: 591.07 samples/sec#011loss=2.670361\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:06 INFO 139866244298560] Epoch[52] Batch[165] avg_epoch_loss=2.578086\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=165 train loss <loss>=2.39587962627\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:06 INFO 139866244298560] Epoch[52] Batch [165]#011Speed: 467.24 samples/sec#011loss=2.395880\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:06 INFO 139866244298560] Epoch[52] Batch[170] avg_epoch_loss=2.573894\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=170 train loss <loss>=2.43473539352\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:06 INFO 139866244298560] Epoch[52] Batch [170]#011Speed: 589.02 samples/sec#011loss=2.434735\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:07 INFO 139866244298560] Epoch[52] Batch[175] avg_epoch_loss=2.570956\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=175 train loss <loss>=2.47047719955\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:07 INFO 139866244298560] Epoch[52] Batch [175]#011Speed: 470.44 samples/sec#011loss=2.470477\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:08 INFO 139866244298560] Epoch[52] Batch[180] avg_epoch_loss=2.572633\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=180 train loss <loss>=2.63165178299\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:08 INFO 139866244298560] Epoch[52] Batch [180]#011Speed: 565.53 samples/sec#011loss=2.631652\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:08 INFO 139866244298560] Epoch[52] Batch[185] avg_epoch_loss=2.576313\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=185 train loss <loss>=2.70951910019\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:08 INFO 139866244298560] Epoch[52] Batch [185]#011Speed: 484.36 samples/sec#011loss=2.709519\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:09 INFO 139866244298560] Epoch[52] Batch[190] avg_epoch_loss=2.583984\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=190 train loss <loss>=2.86937141418\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:09 INFO 139866244298560] Epoch[52] Batch [190]#011Speed: 597.03 samples/sec#011loss=2.869371\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:09 INFO 139866244298560] Epoch[52] Batch[195] avg_epoch_loss=2.594747\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=195 train loss <loss>=3.00589900017\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:09 INFO 139866244298560] Epoch[52] Batch [195]#011Speed: 477.87 samples/sec#011loss=3.005899\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:10 INFO 139866244298560] Epoch[52] Batch[200] avg_epoch_loss=2.619212\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=200 train loss <loss>=3.57821936607\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:10 INFO 139866244298560] Epoch[52] Batch [200]#011Speed: 587.66 samples/sec#011loss=3.578219\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:11 INFO 139866244298560] Epoch[52] Batch[205] avg_epoch_loss=2.631197\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=205 train loss <loss>=3.11301012039\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:11 INFO 139866244298560] Epoch[52] Batch [205]#011Speed: 481.75 samples/sec#011loss=3.113010\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:11 INFO 139866244298560] Epoch[52] Batch[210] avg_epoch_loss=2.643951\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=210 train loss <loss>=3.1694173336\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:11 INFO 139866244298560] Epoch[52] Batch [210]#011Speed: 592.71 samples/sec#011loss=3.169417\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:12 INFO 139866244298560] Epoch[52] Batch[215] avg_epoch_loss=2.640107\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=215 train loss <loss>=2.47787070274\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:12 INFO 139866244298560] Epoch[52] Batch [215]#011Speed: 473.12 samples/sec#011loss=2.477871\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:12 INFO 139866244298560] Epoch[52] Batch[220] avg_epoch_loss=2.638787\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=220 train loss <loss>=2.5817855835\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:12 INFO 139866244298560] Epoch[52] Batch [220]#011Speed: 587.34 samples/sec#011loss=2.581786\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:13 INFO 139866244298560] Epoch[52] Batch[225] avg_epoch_loss=2.634238\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=225 train loss <loss>=2.43314518929\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:13 INFO 139866244298560] Epoch[52] Batch [225]#011Speed: 481.04 samples/sec#011loss=2.433145\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:14 INFO 139866244298560] Epoch[52] Batch[230] avg_epoch_loss=2.634052\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=230 train loss <loss>=2.62567334175\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:14 INFO 139866244298560] Epoch[52] Batch [230]#011Speed: 592.85 samples/sec#011loss=2.625673\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:14 INFO 139866244298560] Epoch[52] Batch[235] avg_epoch_loss=2.631886\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=235 train loss <loss>=2.53180308342\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:14 INFO 139866244298560] Epoch[52] Batch [235]#011Speed: 468.99 samples/sec#011loss=2.531803\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:15 INFO 139866244298560] Epoch[52] Batch[240] avg_epoch_loss=2.629265\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=240 train loss <loss>=2.50555377007\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:15 INFO 139866244298560] Epoch[52] Batch [240]#011Speed: 481.79 samples/sec#011loss=2.505554\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:16 INFO 139866244298560] Epoch[52] Batch[245] avg_epoch_loss=2.644751\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=245 train loss <loss>=3.39116010666\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:16 INFO 139866244298560] Epoch[52] Batch [245]#011Speed: 573.82 samples/sec#011loss=3.391160\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:16 INFO 139866244298560] Epoch[52] Batch[250] avg_epoch_loss=2.657661\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=250 train loss <loss>=3.29282431602\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:16 INFO 139866244298560] Epoch[52] Batch [250]#011Speed: 484.08 samples/sec#011loss=3.292824\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:17 INFO 139866244298560] Epoch[52] Batch[255] avg_epoch_loss=2.669729\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=255 train loss <loss>=3.27557625771\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:17 INFO 139866244298560] Epoch[52] Batch [255]#011Speed: 589.66 samples/sec#011loss=3.275576\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:17 INFO 139866244298560] Epoch[52] Batch[260] avg_epoch_loss=2.669731\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=260 train loss <loss>=2.6698387146\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:17 INFO 139866244298560] Epoch[52] Batch [260]#011Speed: 480.19 samples/sec#011loss=2.669839\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:18 INFO 139866244298560] Epoch[52] Batch[265] avg_epoch_loss=2.667335\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, batch=265 train loss <loss>=2.54227223396\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:18 INFO 139866244298560] Epoch[52] Batch [265]#011Speed: 590.46 samples/sec#011loss=2.542272\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:18 INFO 139866244298560] processed a total of 17178 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33189.58806991577, \"sum\": 33189.58806991577, \"min\": 33189.58806991577}}, \"EndTime\": 1599443718.751972, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443685.561782}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:18 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=517.569866007 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:18 INFO 139866244298560] #progress_metric: host=algo-1, completed 66 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=52, train loss <loss>=2.6744414794\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:18 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:19 INFO 139866244298560] Epoch[53] Batch[0] avg_epoch_loss=2.036269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=0 train loss <loss>=2.03626942635\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:19 INFO 139866244298560] Epoch[53] Batch[5] avg_epoch_loss=2.086098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=5 train loss <loss>=2.0860978961\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:19 INFO 139866244298560] Epoch[53] Batch [5]#011Speed: 592.34 samples/sec#011loss=2.086098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:20 INFO 139866244298560] Epoch[53] Batch[10] avg_epoch_loss=2.082763\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=10 train loss <loss>=2.07876060009\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:20 INFO 139866244298560] Epoch[53] Batch [10]#011Speed: 463.19 samples/sec#011loss=2.078761\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:20 INFO 139866244298560] Epoch[53] Batch[15] avg_epoch_loss=2.233135\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=15 train loss <loss>=2.56395530701\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:20 INFO 139866244298560] Epoch[53] Batch [15]#011Speed: 576.98 samples/sec#011loss=2.563955\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:21 INFO 139866244298560] Epoch[53] Batch[20] avg_epoch_loss=2.354273\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=20 train loss <loss>=2.74191193581\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:21 INFO 139866244298560] Epoch[53] Batch [20]#011Speed: 449.50 samples/sec#011loss=2.741912\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:22 INFO 139866244298560] Epoch[53] Batch[25] avg_epoch_loss=2.461349\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=25 train loss <loss>=2.91107082367\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:22 INFO 139866244298560] Epoch[53] Batch [25]#011Speed: 590.99 samples/sec#011loss=2.911071\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:22 INFO 139866244298560] Epoch[53] Batch[30] avg_epoch_loss=2.475084\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=30 train loss <loss>=2.5465025425\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:22 INFO 139866244298560] Epoch[53] Batch [30]#011Speed: 471.07 samples/sec#011loss=2.546503\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:23 INFO 139866244298560] Epoch[53] Batch[35] avg_epoch_loss=2.492878\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=35 train loss <loss>=2.60320010185\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:23 INFO 139866244298560] Epoch[53] Batch [35]#011Speed: 585.13 samples/sec#011loss=2.603200\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:23 INFO 139866244298560] Epoch[53] Batch[40] avg_epoch_loss=2.501770\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=40 train loss <loss>=2.56579213142\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:23 INFO 139866244298560] Epoch[53] Batch [40]#011Speed: 475.43 samples/sec#011loss=2.565792\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:24 INFO 139866244298560] Epoch[53] Batch[45] avg_epoch_loss=2.485046\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=45 train loss <loss>=2.34791669846\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:24 INFO 139866244298560] Epoch[53] Batch [45]#011Speed: 593.96 samples/sec#011loss=2.347917\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:25 INFO 139866244298560] Epoch[53] Batch[50] avg_epoch_loss=2.494290\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=50 train loss <loss>=2.57933092117\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:25 INFO 139866244298560] Epoch[53] Batch [50]#011Speed: 466.23 samples/sec#011loss=2.579331\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:25 INFO 139866244298560] Epoch[53] Batch[55] avg_epoch_loss=2.484211\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=55 train loss <loss>=2.38140621185\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:25 INFO 139866244298560] Epoch[53] Batch [55]#011Speed: 588.45 samples/sec#011loss=2.381406\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:26 INFO 139866244298560] Epoch[53] Batch[60] avg_epoch_loss=2.470337\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=60 train loss <loss>=2.31494474411\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:26 INFO 139866244298560] Epoch[53] Batch [60]#011Speed: 481.77 samples/sec#011loss=2.314945\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:26 INFO 139866244298560] Epoch[53] Batch[65] avg_epoch_loss=2.458447\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=65 train loss <loss>=2.31339678764\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:26 INFO 139866244298560] Epoch[53] Batch [65]#011Speed: 594.23 samples/sec#011loss=2.313397\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:27 INFO 139866244298560] Epoch[53] Batch[70] avg_epoch_loss=2.455075\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=70 train loss <loss>=2.41055967808\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:27 INFO 139866244298560] Epoch[53] Batch [70]#011Speed: 481.51 samples/sec#011loss=2.410560\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:28 INFO 139866244298560] Epoch[53] Batch[75] avg_epoch_loss=2.480913\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=75 train loss <loss>=2.84780950546\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:28 INFO 139866244298560] Epoch[53] Batch [75]#011Speed: 586.09 samples/sec#011loss=2.847810\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:28 INFO 139866244298560] Epoch[53] Batch[80] avg_epoch_loss=2.520708\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=80 train loss <loss>=3.12559447289\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:28 INFO 139866244298560] Epoch[53] Batch [80]#011Speed: 479.19 samples/sec#011loss=3.125594\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:29 INFO 139866244298560] Epoch[53] Batch[85] avg_epoch_loss=2.567351\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=85 train loss <loss>=3.32297210693\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:29 INFO 139866244298560] Epoch[53] Batch [85]#011Speed: 592.02 samples/sec#011loss=3.322972\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:30 INFO 139866244298560] Epoch[53] Batch[90] avg_epoch_loss=2.581732\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=90 train loss <loss>=2.82907519341\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:30 INFO 139866244298560] Epoch[53] Batch [90]#011Speed: 478.80 samples/sec#011loss=2.829075\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:30 INFO 139866244298560] Epoch[53] Batch[95] avg_epoch_loss=2.580922\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=95 train loss <loss>=2.56618242264\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:30 INFO 139866244298560] Epoch[53] Batch [95]#011Speed: 478.45 samples/sec#011loss=2.566182\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:31 INFO 139866244298560] Epoch[53] Batch[100] avg_epoch_loss=2.565411\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=100 train loss <loss>=2.2676012516\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:31 INFO 139866244298560] Epoch[53] Batch [100]#011Speed: 584.72 samples/sec#011loss=2.267601\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:31 INFO 139866244298560] Epoch[53] Batch[105] avg_epoch_loss=2.549382\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=105 train loss <loss>=2.22560777664\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:31 INFO 139866244298560] Epoch[53] Batch [105]#011Speed: 477.97 samples/sec#011loss=2.225608\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:32 INFO 139866244298560] Epoch[53] Batch[110] avg_epoch_loss=2.536964\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=110 train loss <loss>=2.27369952202\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:32 INFO 139866244298560] Epoch[53] Batch [110]#011Speed: 590.50 samples/sec#011loss=2.273700\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:33 INFO 139866244298560] Epoch[53] Batch[115] avg_epoch_loss=2.529721\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=115 train loss <loss>=2.36891593933\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:33 INFO 139866244298560] Epoch[53] Batch [115]#011Speed: 472.38 samples/sec#011loss=2.368916\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:33 INFO 139866244298560] Epoch[53] Batch[120] avg_epoch_loss=2.529773\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=120 train loss <loss>=2.53098483086\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:33 INFO 139866244298560] Epoch[53] Batch [120]#011Speed: 594.86 samples/sec#011loss=2.530985\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:34 INFO 139866244298560] Epoch[53] Batch[125] avg_epoch_loss=2.540885\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=125 train loss <loss>=2.80978479385\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:34 INFO 139866244298560] Epoch[53] Batch [125]#011Speed: 472.62 samples/sec#011loss=2.809785\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:34 INFO 139866244298560] Epoch[53] Batch[130] avg_epoch_loss=2.551549\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=130 train loss <loss>=2.8202890873\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:34 INFO 139866244298560] Epoch[53] Batch [130]#011Speed: 590.85 samples/sec#011loss=2.820289\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:35 INFO 139866244298560] Epoch[53] Batch[135] avg_epoch_loss=2.568625\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=135 train loss <loss>=3.01601238251\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:35 INFO 139866244298560] Epoch[53] Batch [135]#011Speed: 470.01 samples/sec#011loss=3.016012\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:36 INFO 139866244298560] Epoch[53] Batch[140] avg_epoch_loss=2.580193\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=140 train loss <loss>=2.89485020638\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:36 INFO 139866244298560] Epoch[53] Batch [140]#011Speed: 588.12 samples/sec#011loss=2.894850\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:36 INFO 139866244298560] Epoch[53] Batch[145] avg_epoch_loss=2.574363\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=145 train loss <loss>=2.40995395184\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:36 INFO 139866244298560] Epoch[53] Batch [145]#011Speed: 483.70 samples/sec#011loss=2.409954\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:37 INFO 139866244298560] Epoch[53] Batch[150] avg_epoch_loss=2.566023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=150 train loss <loss>=2.32250065804\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:37 INFO 139866244298560] Epoch[53] Batch [150]#011Speed: 594.02 samples/sec#011loss=2.322501\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:37 INFO 139866244298560] Epoch[53] Batch[155] avg_epoch_loss=2.564700\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=155 train loss <loss>=2.52472681999\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:37 INFO 139866244298560] Epoch[53] Batch [155]#011Speed: 475.79 samples/sec#011loss=2.524727\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:38 INFO 139866244298560] Epoch[53] Batch[160] avg_epoch_loss=2.559272\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=160 train loss <loss>=2.38994150162\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:38 INFO 139866244298560] Epoch[53] Batch [160]#011Speed: 582.82 samples/sec#011loss=2.389942\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:39 INFO 139866244298560] Epoch[53] Batch[165] avg_epoch_loss=2.555050\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=165 train loss <loss>=2.41910686493\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:39 INFO 139866244298560] Epoch[53] Batch [165]#011Speed: 472.32 samples/sec#011loss=2.419107\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:39 INFO 139866244298560] Epoch[53] Batch[170] avg_epoch_loss=2.547598\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=170 train loss <loss>=2.30018894672\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:39 INFO 139866244298560] Epoch[53] Batch [170]#011Speed: 476.77 samples/sec#011loss=2.300189\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:40 INFO 139866244298560] Epoch[53] Batch[175] avg_epoch_loss=2.552655\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=175 train loss <loss>=2.72559151649\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:40 INFO 139866244298560] Epoch[53] Batch [175]#011Speed: 587.08 samples/sec#011loss=2.725592\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:41 INFO 139866244298560] Epoch[53] Batch[180] avg_epoch_loss=2.564056\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=180 train loss <loss>=2.96537909508\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:41 INFO 139866244298560] Epoch[53] Batch [180]#011Speed: 466.18 samples/sec#011loss=2.965379\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:41 INFO 139866244298560] Epoch[53] Batch[185] avg_epoch_loss=2.584432\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=185 train loss <loss>=3.32204451561\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:41 INFO 139866244298560] Epoch[53] Batch [185]#011Speed: 596.54 samples/sec#011loss=3.322045\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:42 INFO 139866244298560] Epoch[53] Batch[190] avg_epoch_loss=2.602783\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=190 train loss <loss>=3.28542904854\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:42 INFO 139866244298560] Epoch[53] Batch [190]#011Speed: 479.11 samples/sec#011loss=3.285429\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:42 INFO 139866244298560] Epoch[53] Batch[195] avg_epoch_loss=2.619571\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=195 train loss <loss>=3.26086363792\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:42 INFO 139866244298560] Epoch[53] Batch [195]#011Speed: 590.68 samples/sec#011loss=3.260864\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:43 INFO 139866244298560] Epoch[53] Batch[200] avg_epoch_loss=2.632135\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=200 train loss <loss>=3.12464160919\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:43 INFO 139866244298560] Epoch[53] Batch [200]#011Speed: 477.54 samples/sec#011loss=3.124642\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:44 INFO 139866244298560] Epoch[53] Batch[205] avg_epoch_loss=2.633239\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=205 train loss <loss>=2.67762746811\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:44 INFO 139866244298560] Epoch[53] Batch [205]#011Speed: 590.26 samples/sec#011loss=2.677627\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:44 INFO 139866244298560] Epoch[53] Batch[210] avg_epoch_loss=2.632034\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=210 train loss <loss>=2.58240470886\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:44 INFO 139866244298560] Epoch[53] Batch [210]#011Speed: 475.84 samples/sec#011loss=2.582405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:45 INFO 139866244298560] Epoch[53] Batch[215] avg_epoch_loss=2.631397\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=215 train loss <loss>=2.60449695587\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:45 INFO 139866244298560] Epoch[53] Batch [215]#011Speed: 589.44 samples/sec#011loss=2.604497\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:45 INFO 139866244298560] Epoch[53] Batch[220] avg_epoch_loss=2.625111\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=220 train loss <loss>=2.3535554409\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:45 INFO 139866244298560] Epoch[53] Batch [220]#011Speed: 470.21 samples/sec#011loss=2.353555\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:46 INFO 139866244298560] Epoch[53] Batch[225] avg_epoch_loss=2.625427\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=225 train loss <loss>=2.63941349983\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:46 INFO 139866244298560] Epoch[53] Batch [225]#011Speed: 592.48 samples/sec#011loss=2.639413\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:47 INFO 139866244298560] Epoch[53] Batch[230] avg_epoch_loss=2.626555\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=230 train loss <loss>=2.67752490044\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:47 INFO 139866244298560] Epoch[53] Batch [230]#011Speed: 484.10 samples/sec#011loss=2.677525\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:47 INFO 139866244298560] Epoch[53] Batch[235] avg_epoch_loss=2.636270\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=235 train loss <loss>=3.08509898186\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:47 INFO 139866244298560] Epoch[53] Batch [235]#011Speed: 593.66 samples/sec#011loss=3.085099\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:48 INFO 139866244298560] Epoch[53] Batch[240] avg_epoch_loss=2.646060\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=240 train loss <loss>=3.10815968513\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:48 INFO 139866244298560] Epoch[53] Batch [240]#011Speed: 477.05 samples/sec#011loss=3.108160\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:48 INFO 139866244298560] Epoch[53] Batch[245] avg_epoch_loss=2.660985\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=245 train loss <loss>=3.380377388\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:48 INFO 139866244298560] Epoch[53] Batch [245]#011Speed: 595.25 samples/sec#011loss=3.380377\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:49 INFO 139866244298560] Epoch[53] Batch[250] avg_epoch_loss=2.672452\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=250 train loss <loss>=3.23660535812\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:49 INFO 139866244298560] Epoch[53] Batch [250]#011Speed: 482.51 samples/sec#011loss=3.236605\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:50 INFO 139866244298560] Epoch[53] Batch[255] avg_epoch_loss=2.681757\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=255 train loss <loss>=3.1489051342\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:50 INFO 139866244298560] Epoch[53] Batch [255]#011Speed: 590.39 samples/sec#011loss=3.148905\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:50 INFO 139866244298560] Epoch[53] Batch[260] avg_epoch_loss=2.678652\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=260 train loss <loss>=2.519658041\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:50 INFO 139866244298560] Epoch[53] Batch [260]#011Speed: 469.86 samples/sec#011loss=2.519658\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:51 INFO 139866244298560] Epoch[53] Batch[265] avg_epoch_loss=2.676865\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, batch=265 train loss <loss>=2.58355484009\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:51 INFO 139866244298560] Epoch[53] Batch [265]#011Speed: 538.85 samples/sec#011loss=2.583555\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:51 INFO 139866244298560] processed a total of 17087 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32759.30905342102, \"sum\": 32759.30905342102, \"min\": 32759.30905342102}}, \"EndTime\": 1599443751.512065, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443718.752065}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:51 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=521.59036786 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:51 INFO 139866244298560] #progress_metric: host=algo-1, completed 67 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=53, train loss <loss>=2.6792887985\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:51 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:51 INFO 139866244298560] Epoch[54] Batch[0] avg_epoch_loss=2.380327\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=0 train loss <loss>=2.38032674789\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:52 INFO 139866244298560] Epoch[54] Batch[5] avg_epoch_loss=2.195967\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=5 train loss <loss>=2.19596676032\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:52 INFO 139866244298560] Epoch[54] Batch [5]#011Speed: 585.28 samples/sec#011loss=2.195967\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:52 INFO 139866244298560] Epoch[54] Batch[10] avg_epoch_loss=2.138593\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=10 train loss <loss>=2.06974408627\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:52 INFO 139866244298560] Epoch[54] Batch [10]#011Speed: 475.70 samples/sec#011loss=2.069744\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:53 INFO 139866244298560] Epoch[54] Batch[15] avg_epoch_loss=2.307435\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=15 train loss <loss>=2.67888817787\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:53 INFO 139866244298560] Epoch[54] Batch [15]#011Speed: 594.78 samples/sec#011loss=2.678888\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:54 INFO 139866244298560] Epoch[54] Batch[20] avg_epoch_loss=2.428617\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=20 train loss <loss>=2.81639914513\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:54 INFO 139866244298560] Epoch[54] Batch [20]#011Speed: 474.96 samples/sec#011loss=2.816399\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:54 INFO 139866244298560] Epoch[54] Batch[25] avg_epoch_loss=2.497755\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=25 train loss <loss>=2.78813576698\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:54 INFO 139866244298560] Epoch[54] Batch [25]#011Speed: 596.49 samples/sec#011loss=2.788136\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:55 INFO 139866244298560] Epoch[54] Batch[30] avg_epoch_loss=2.502187\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=30 train loss <loss>=2.52523226738\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:55 INFO 139866244298560] Epoch[54] Batch [30]#011Speed: 469.48 samples/sec#011loss=2.525232\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:55 INFO 139866244298560] Epoch[54] Batch[35] avg_epoch_loss=2.528766\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=35 train loss <loss>=2.6935564518\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:55 INFO 139866244298560] Epoch[54] Batch [35]#011Speed: 584.69 samples/sec#011loss=2.693556\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:56 INFO 139866244298560] Epoch[54] Batch[40] avg_epoch_loss=2.506488\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=40 train loss <loss>=2.34608201981\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:56 INFO 139866244298560] Epoch[54] Batch [40]#011Speed: 477.14 samples/sec#011loss=2.346082\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:57 INFO 139866244298560] Epoch[54] Batch[45] avg_epoch_loss=2.504873\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=45 train loss <loss>=2.49162902832\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:57 INFO 139866244298560] Epoch[54] Batch [45]#011Speed: 591.59 samples/sec#011loss=2.491629\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:57 INFO 139866244298560] Epoch[54] Batch[50] avg_epoch_loss=2.479930\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=50 train loss <loss>=2.2504588604\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:57 INFO 139866244298560] Epoch[54] Batch [50]#011Speed: 479.17 samples/sec#011loss=2.250459\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:58 INFO 139866244298560] Epoch[54] Batch[55] avg_epoch_loss=2.454130\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=55 train loss <loss>=2.19097545147\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:58 INFO 139866244298560] Epoch[54] Batch [55]#011Speed: 590.07 samples/sec#011loss=2.190975\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:59 INFO 139866244298560] Epoch[54] Batch[60] avg_epoch_loss=2.443586\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=60 train loss <loss>=2.32549042702\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:59 INFO 139866244298560] Epoch[54] Batch [60]#011Speed: 476.51 samples/sec#011loss=2.325490\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:59 INFO 139866244298560] Epoch[54] Batch[65] avg_epoch_loss=2.435186\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=65 train loss <loss>=2.33270578384\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:55:59 INFO 139866244298560] Epoch[54] Batch [65]#011Speed: 503.32 samples/sec#011loss=2.332706\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:00 INFO 139866244298560] Epoch[54] Batch[70] avg_epoch_loss=2.472810\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=70 train loss <loss>=2.96943907738\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:00 INFO 139866244298560] Epoch[54] Batch [70]#011Speed: 477.84 samples/sec#011loss=2.969439\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:01 INFO 139866244298560] Epoch[54] Batch[75] avg_epoch_loss=2.506631\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=75 train loss <loss>=2.98689050674\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:01 INFO 139866244298560] Epoch[54] Batch [75]#011Speed: 470.99 samples/sec#011loss=2.986891\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:01 INFO 139866244298560] Epoch[54] Batch[80] avg_epoch_loss=2.549636\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=80 train loss <loss>=3.20332126617\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:01 INFO 139866244298560] Epoch[54] Batch [80]#011Speed: 575.56 samples/sec#011loss=3.203321\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:02 INFO 139866244298560] Epoch[54] Batch[85] avg_epoch_loss=2.582813\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=85 train loss <loss>=3.12026867867\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:02 INFO 139866244298560] Epoch[54] Batch [85]#011Speed: 458.34 samples/sec#011loss=3.120269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:02 INFO 139866244298560] Epoch[54] Batch[90] avg_epoch_loss=2.586663\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=90 train loss <loss>=2.65288653374\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:02 INFO 139866244298560] Epoch[54] Batch [90]#011Speed: 583.17 samples/sec#011loss=2.652887\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:03 INFO 139866244298560] Epoch[54] Batch[95] avg_epoch_loss=2.586946\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=95 train loss <loss>=2.592100811\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:03 INFO 139866244298560] Epoch[54] Batch [95]#011Speed: 463.38 samples/sec#011loss=2.592101\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:04 INFO 139866244298560] Epoch[54] Batch[100] avg_epoch_loss=2.572945\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=100 train loss <loss>=2.30412313938\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:04 INFO 139866244298560] Epoch[54] Batch [100]#011Speed: 589.02 samples/sec#011loss=2.304123\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:04 INFO 139866244298560] Epoch[54] Batch[105] avg_epoch_loss=2.562522\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=105 train loss <loss>=2.35198488235\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:04 INFO 139866244298560] Epoch[54] Batch [105]#011Speed: 411.83 samples/sec#011loss=2.351985\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:05 INFO 139866244298560] Epoch[54] Batch[110] avg_epoch_loss=2.536424\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=110 train loss <loss>=1.98313846588\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:05 INFO 139866244298560] Epoch[54] Batch [110]#011Speed: 585.80 samples/sec#011loss=1.983138\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:06 INFO 139866244298560] Epoch[54] Batch[115] avg_epoch_loss=2.520081\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=115 train loss <loss>=2.15726852417\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:06 INFO 139866244298560] Epoch[54] Batch [115]#011Speed: 476.65 samples/sec#011loss=2.157269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:06 INFO 139866244298560] Epoch[54] Batch[120] avg_epoch_loss=2.513829\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=120 train loss <loss>=2.36879005432\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:06 INFO 139866244298560] Epoch[54] Batch [120]#011Speed: 532.37 samples/sec#011loss=2.368790\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:07 INFO 139866244298560] Epoch[54] Batch[125] avg_epoch_loss=2.517091\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=125 train loss <loss>=2.59602274895\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:07 INFO 139866244298560] Epoch[54] Batch [125]#011Speed: 333.82 samples/sec#011loss=2.596023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:08 INFO 139866244298560] Epoch[54] Batch[130] avg_epoch_loss=2.529639\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=130 train loss <loss>=2.84583711624\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:08 INFO 139866244298560] Epoch[54] Batch [130]#011Speed: 483.59 samples/sec#011loss=2.845837\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:08 INFO 139866244298560] Epoch[54] Batch[135] avg_epoch_loss=2.548610\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=135 train loss <loss>=3.045662117\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:08 INFO 139866244298560] Epoch[54] Batch [135]#011Speed: 483.60 samples/sec#011loss=3.045662\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:09 INFO 139866244298560] Epoch[54] Batch[140] avg_epoch_loss=2.566026\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=140 train loss <loss>=3.0397500515\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:09 INFO 139866244298560] Epoch[54] Batch [140]#011Speed: 596.51 samples/sec#011loss=3.039750\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:10 INFO 139866244298560] Epoch[54] Batch[145] avg_epoch_loss=2.551377\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=145 train loss <loss>=2.13826775551\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:10 INFO 139866244298560] Epoch[54] Batch [145]#011Speed: 435.55 samples/sec#011loss=2.138268\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:10 INFO 139866244298560] Epoch[54] Batch[150] avg_epoch_loss=2.539101\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=150 train loss <loss>=2.18062589169\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:10 INFO 139866244298560] Epoch[54] Batch [150]#011Speed: 586.81 samples/sec#011loss=2.180626\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:11 INFO 139866244298560] Epoch[54] Batch[155] avg_epoch_loss=2.545260\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=155 train loss <loss>=2.73129234314\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:11 INFO 139866244298560] Epoch[54] Batch [155]#011Speed: 469.29 samples/sec#011loss=2.731292\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:11 INFO 139866244298560] Epoch[54] Batch[160] avg_epoch_loss=2.545767\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=160 train loss <loss>=2.56157770157\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:11 INFO 139866244298560] Epoch[54] Batch [160]#011Speed: 591.05 samples/sec#011loss=2.561578\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:12 INFO 139866244298560] Epoch[54] Batch[165] avg_epoch_loss=2.545346\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=165 train loss <loss>=2.53178520203\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:12 INFO 139866244298560] Epoch[54] Batch [165]#011Speed: 465.78 samples/sec#011loss=2.531785\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:13 INFO 139866244298560] Epoch[54] Batch[170] avg_epoch_loss=2.541728\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=170 train loss <loss>=2.42160925865\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:13 INFO 139866244298560] Epoch[54] Batch [170]#011Speed: 593.92 samples/sec#011loss=2.421609\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:13 INFO 139866244298560] Epoch[54] Batch[175] avg_epoch_loss=2.545224\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=175 train loss <loss>=2.66477041245\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:13 INFO 139866244298560] Epoch[54] Batch [175]#011Speed: 476.52 samples/sec#011loss=2.664770\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:14 INFO 139866244298560] Epoch[54] Batch[180] avg_epoch_loss=2.548724\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=180 train loss <loss>=2.67193145752\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:14 INFO 139866244298560] Epoch[54] Batch [180]#011Speed: 591.14 samples/sec#011loss=2.671931\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:15 INFO 139866244298560] Epoch[54] Batch[185] avg_epoch_loss=2.568675\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=185 train loss <loss>=3.29089727402\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:15 INFO 139866244298560] Epoch[54] Batch [185]#011Speed: 424.00 samples/sec#011loss=3.290897\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:15 INFO 139866244298560] Epoch[54] Batch[190] avg_epoch_loss=2.585716\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=190 train loss <loss>=3.21964921951\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:15 INFO 139866244298560] Epoch[54] Batch [190]#011Speed: 584.16 samples/sec#011loss=3.219649\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:16 INFO 139866244298560] Epoch[54] Batch[195] avg_epoch_loss=2.603074\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=195 train loss <loss>=3.26615200043\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:16 INFO 139866244298560] Epoch[54] Batch [195]#011Speed: 473.60 samples/sec#011loss=3.266152\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:16 INFO 139866244298560] Epoch[54] Batch[200] avg_epoch_loss=2.621485\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=200 train loss <loss>=3.34319591522\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:16 INFO 139866244298560] Epoch[54] Batch [200]#011Speed: 590.51 samples/sec#011loss=3.343196\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:17 INFO 139866244298560] Epoch[54] Batch[205] avg_epoch_loss=2.629657\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=205 train loss <loss>=2.95815811157\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:17 INFO 139866244298560] Epoch[54] Batch [205]#011Speed: 472.12 samples/sec#011loss=2.958158\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:18 INFO 139866244298560] Epoch[54] Batch[210] avg_epoch_loss=2.629957\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=210 train loss <loss>=2.64233469963\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:18 INFO 139866244298560] Epoch[54] Batch [210]#011Speed: 589.67 samples/sec#011loss=2.642335\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:18 INFO 139866244298560] Epoch[54] Batch[215] avg_epoch_loss=2.624801\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=215 train loss <loss>=2.40721988678\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:18 INFO 139866244298560] Epoch[54] Batch [215]#011Speed: 473.16 samples/sec#011loss=2.407220\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:19 INFO 139866244298560] Epoch[54] Batch[220] avg_epoch_loss=2.624520\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=220 train loss <loss>=2.61236715317\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:19 INFO 139866244298560] Epoch[54] Batch [220]#011Speed: 594.49 samples/sec#011loss=2.612367\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:20 INFO 139866244298560] Epoch[54] Batch[225] avg_epoch_loss=2.618561\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=225 train loss <loss>=2.35518054962\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:20 INFO 139866244298560] Epoch[54] Batch [225]#011Speed: 474.77 samples/sec#011loss=2.355181\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:20 INFO 139866244298560] Epoch[54] Batch[230] avg_epoch_loss=2.617956\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=230 train loss <loss>=2.59058885574\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:20 INFO 139866244298560] Epoch[54] Batch [230]#011Speed: 539.88 samples/sec#011loss=2.590589\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:21 INFO 139866244298560] Epoch[54] Batch[235] avg_epoch_loss=2.620723\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=235 train loss <loss>=2.74857091904\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:21 INFO 139866244298560] Epoch[54] Batch [235]#011Speed: 440.07 samples/sec#011loss=2.748571\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:21 INFO 139866244298560] Epoch[54] Batch[240] avg_epoch_loss=2.624572\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=240 train loss <loss>=2.80625605583\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:21 INFO 139866244298560] Epoch[54] Batch [240]#011Speed: 588.79 samples/sec#011loss=2.806256\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:22 INFO 139866244298560] Epoch[54] Batch[245] avg_epoch_loss=2.634474\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=245 train loss <loss>=3.11175074577\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:22 INFO 139866244298560] Epoch[54] Batch [245]#011Speed: 473.60 samples/sec#011loss=3.111751\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:23 INFO 139866244298560] Epoch[54] Batch[250] avg_epoch_loss=2.647696\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=250 train loss <loss>=3.29823646545\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:23 INFO 139866244298560] Epoch[54] Batch [250]#011Speed: 475.88 samples/sec#011loss=3.298236\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:23 INFO 139866244298560] Epoch[54] Batch[255] avg_epoch_loss=2.661814\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=255 train loss <loss>=3.37053818703\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:23 INFO 139866244298560] Epoch[54] Batch [255]#011Speed: 594.95 samples/sec#011loss=3.370538\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:24 INFO 139866244298560] Epoch[54] Batch[260] avg_epoch_loss=2.668560\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=260 train loss <loss>=3.0139570713\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:24 INFO 139866244298560] Epoch[54] Batch [260]#011Speed: 487.10 samples/sec#011loss=3.013957\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:25 INFO 139866244298560] Epoch[54] Batch[265] avg_epoch_loss=2.668019\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, batch=265 train loss <loss>=2.63976078033\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:25 INFO 139866244298560] Epoch[54] Batch [265]#011Speed: 589.46 samples/sec#011loss=2.639761\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:25 INFO 139866244298560] processed a total of 17212 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33907.00578689575, \"sum\": 33907.00578689575, \"min\": 33907.00578689575}}, \"EndTime\": 1599443785.419614, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443751.512147}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:25 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=507.619046296 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:25 INFO 139866244298560] #progress_metric: host=algo-1, completed 68 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=54, train loss <loss>=2.67132845776\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:25 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:25 INFO 139866244298560] Epoch[55] Batch[0] avg_epoch_loss=2.368767\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=0 train loss <loss>=2.36876654625\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:26 INFO 139866244298560] Epoch[55] Batch[5] avg_epoch_loss=2.227795\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=5 train loss <loss>=2.22779460748\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:26 INFO 139866244298560] Epoch[55] Batch [5]#011Speed: 583.17 samples/sec#011loss=2.227795\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:26 INFO 139866244298560] Epoch[55] Batch[10] avg_epoch_loss=2.201436\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=10 train loss <loss>=2.16980597973\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:26 INFO 139866244298560] Epoch[55] Batch [10]#011Speed: 468.59 samples/sec#011loss=2.169806\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:27 INFO 139866244298560] Epoch[55] Batch[15] avg_epoch_loss=2.323464\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=15 train loss <loss>=2.59192533493\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:27 INFO 139866244298560] Epoch[55] Batch [15]#011Speed: 591.21 samples/sec#011loss=2.591925\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:28 INFO 139866244298560] Epoch[55] Batch[20] avg_epoch_loss=2.376973\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=20 train loss <loss>=2.54820132256\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:28 INFO 139866244298560] Epoch[55] Batch [20]#011Speed: 469.37 samples/sec#011loss=2.548201\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:28 INFO 139866244298560] Epoch[55] Batch[25] avg_epoch_loss=2.434634\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=25 train loss <loss>=2.6768102169\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:28 INFO 139866244298560] Epoch[55] Batch [25]#011Speed: 573.97 samples/sec#011loss=2.676810\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:29 INFO 139866244298560] Epoch[55] Batch[30] avg_epoch_loss=2.499050\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=30 train loss <loss>=2.83401079178\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:29 INFO 139866244298560] Epoch[55] Batch [30]#011Speed: 481.39 samples/sec#011loss=2.834011\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:29 INFO 139866244298560] Epoch[55] Batch[35] avg_epoch_loss=2.509434\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=35 train loss <loss>=2.57381806374\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:29 INFO 139866244298560] Epoch[55] Batch [35]#011Speed: 593.55 samples/sec#011loss=2.573818\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:30 INFO 139866244298560] Epoch[55] Batch[40] avg_epoch_loss=2.539607\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=40 train loss <loss>=2.75684924126\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:30 INFO 139866244298560] Epoch[55] Batch [40]#011Speed: 439.50 samples/sec#011loss=2.756849\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:31 INFO 139866244298560] Epoch[55] Batch[45] avg_epoch_loss=2.541048\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=45 train loss <loss>=2.55286784172\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:31 INFO 139866244298560] Epoch[55] Batch [45]#011Speed: 580.18 samples/sec#011loss=2.552868\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:31 INFO 139866244298560] Epoch[55] Batch[50] avg_epoch_loss=2.520987\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=50 train loss <loss>=2.33643016815\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:31 INFO 139866244298560] Epoch[55] Batch [50]#011Speed: 478.38 samples/sec#011loss=2.336430\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:32 INFO 139866244298560] Epoch[55] Batch[55] avg_epoch_loss=2.487384\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=55 train loss <loss>=2.1446249485\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:32 INFO 139866244298560] Epoch[55] Batch [55]#011Speed: 591.51 samples/sec#011loss=2.144625\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:33 INFO 139866244298560] Epoch[55] Batch[60] avg_epoch_loss=2.484129\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=60 train loss <loss>=2.44767508507\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:33 INFO 139866244298560] Epoch[55] Batch [60]#011Speed: 479.80 samples/sec#011loss=2.447675\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:33 INFO 139866244298560] Epoch[55] Batch[65] avg_epoch_loss=2.484470\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=65 train loss <loss>=2.48862667084\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:33 INFO 139866244298560] Epoch[55] Batch [65]#011Speed: 592.14 samples/sec#011loss=2.488627\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:34 INFO 139866244298560] Epoch[55] Batch[70] avg_epoch_loss=2.499662\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=70 train loss <loss>=2.70020673275\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:34 INFO 139866244298560] Epoch[55] Batch [70]#011Speed: 475.07 samples/sec#011loss=2.700207\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:34 INFO 139866244298560] Epoch[55] Batch[75] avg_epoch_loss=2.524425\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=75 train loss <loss>=2.87605524063\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:34 INFO 139866244298560] Epoch[55] Batch [75]#011Speed: 588.40 samples/sec#011loss=2.876055\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:35 INFO 139866244298560] Epoch[55] Batch[80] avg_epoch_loss=2.561030\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=80 train loss <loss>=3.11742024422\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:35 INFO 139866244298560] Epoch[55] Batch [80]#011Speed: 480.19 samples/sec#011loss=3.117420\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:36 INFO 139866244298560] Epoch[55] Batch[85] avg_epoch_loss=2.593891\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=85 train loss <loss>=3.12624340057\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:36 INFO 139866244298560] Epoch[55] Batch [85]#011Speed: 524.58 samples/sec#011loss=3.126243\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:36 INFO 139866244298560] Epoch[55] Batch[90] avg_epoch_loss=2.608079\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=90 train loss <loss>=2.852115345\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:36 INFO 139866244298560] Epoch[55] Batch [90]#011Speed: 462.52 samples/sec#011loss=2.852115\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:37 INFO 139866244298560] Epoch[55] Batch[95] avg_epoch_loss=2.617229\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=95 train loss <loss>=2.78376531601\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:37 INFO 139866244298560] Epoch[55] Batch [95]#011Speed: 591.19 samples/sec#011loss=2.783765\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:37 INFO 139866244298560] Epoch[55] Batch[100] avg_epoch_loss=2.607778\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=100 train loss <loss>=2.42630028725\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:37 INFO 139866244298560] Epoch[55] Batch [100]#011Speed: 478.94 samples/sec#011loss=2.426300\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:38 INFO 139866244298560] Epoch[55] Batch[105] avg_epoch_loss=2.593593\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=105 train loss <loss>=2.30705859661\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:38 INFO 139866244298560] Epoch[55] Batch [105]#011Speed: 586.80 samples/sec#011loss=2.307059\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:39 INFO 139866244298560] Epoch[55] Batch[110] avg_epoch_loss=2.585578\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=110 train loss <loss>=2.41566329002\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:39 INFO 139866244298560] Epoch[55] Batch [110]#011Speed: 475.31 samples/sec#011loss=2.415663\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:39 INFO 139866244298560] Epoch[55] Batch[115] avg_epoch_loss=2.575195\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=115 train loss <loss>=2.34469842911\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:39 INFO 139866244298560] Epoch[55] Batch [115]#011Speed: 593.76 samples/sec#011loss=2.344698\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:40 INFO 139866244298560] Epoch[55] Batch[120] avg_epoch_loss=2.565655\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=120 train loss <loss>=2.34432094097\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:40 INFO 139866244298560] Epoch[55] Batch [120]#011Speed: 459.21 samples/sec#011loss=2.344321\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:41 INFO 139866244298560] Epoch[55] Batch[125] avg_epoch_loss=2.563647\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=125 train loss <loss>=2.5150698185\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:41 INFO 139866244298560] Epoch[55] Batch [125]#011Speed: 531.27 samples/sec#011loss=2.515070\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:41 INFO 139866244298560] Epoch[55] Batch[130] avg_epoch_loss=2.558564\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=130 train loss <loss>=2.43046030998\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:41 INFO 139866244298560] Epoch[55] Batch [130]#011Speed: 477.07 samples/sec#011loss=2.430460\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:42 INFO 139866244298560] Epoch[55] Batch[135] avg_epoch_loss=2.558344\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=135 train loss <loss>=2.5525739193\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:42 INFO 139866244298560] Epoch[55] Batch [135]#011Speed: 477.96 samples/sec#011loss=2.552574\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:42 INFO 139866244298560] Epoch[55] Batch[140] avg_epoch_loss=2.576421\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=140 train loss <loss>=3.06813035011\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:42 INFO 139866244298560] Epoch[55] Batch [140]#011Speed: 587.92 samples/sec#011loss=3.068130\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:43 INFO 139866244298560] Epoch[55] Batch[145] avg_epoch_loss=2.583063\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=145 train loss <loss>=2.77035961151\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:43 INFO 139866244298560] Epoch[55] Batch [145]#011Speed: 482.17 samples/sec#011loss=2.770360\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:44 INFO 139866244298560] Epoch[55] Batch[150] avg_epoch_loss=2.590200\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=150 train loss <loss>=2.79860219955\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:44 INFO 139866244298560] Epoch[55] Batch [150]#011Speed: 591.18 samples/sec#011loss=2.798602\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:44 INFO 139866244298560] Epoch[55] Batch[155] avg_epoch_loss=2.588159\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=155 train loss <loss>=2.52652368546\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:44 INFO 139866244298560] Epoch[55] Batch [155]#011Speed: 469.52 samples/sec#011loss=2.526524\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:45 INFO 139866244298560] Epoch[55] Batch[160] avg_epoch_loss=2.583879\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=160 train loss <loss>=2.45033330917\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:45 INFO 139866244298560] Epoch[55] Batch [160]#011Speed: 590.18 samples/sec#011loss=2.450333\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:46 INFO 139866244298560] Epoch[55] Batch[165] avg_epoch_loss=2.578718\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=165 train loss <loss>=2.41254248619\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:46 INFO 139866244298560] Epoch[55] Batch [165]#011Speed: 437.12 samples/sec#011loss=2.412542\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:46 INFO 139866244298560] Epoch[55] Batch[170] avg_epoch_loss=2.570839\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=170 train loss <loss>=2.30924549103\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:46 INFO 139866244298560] Epoch[55] Batch [170]#011Speed: 589.87 samples/sec#011loss=2.309245\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:47 INFO 139866244298560] Epoch[55] Batch[175] avg_epoch_loss=2.570037\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=175 train loss <loss>=2.54259929657\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:47 INFO 139866244298560] Epoch[55] Batch [175]#011Speed: 474.89 samples/sec#011loss=2.542599\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:47 INFO 139866244298560] Epoch[55] Batch[180] avg_epoch_loss=2.569559\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=180 train loss <loss>=2.55275802612\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:47 INFO 139866244298560] Epoch[55] Batch [180]#011Speed: 592.05 samples/sec#011loss=2.552758\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:48 INFO 139866244298560] Epoch[55] Batch[185] avg_epoch_loss=2.591945\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=185 train loss <loss>=3.40229196548\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:48 INFO 139866244298560] Epoch[55] Batch [185]#011Speed: 481.89 samples/sec#011loss=3.402292\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:49 INFO 139866244298560] Epoch[55] Batch[190] avg_epoch_loss=2.612763\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=190 train loss <loss>=3.38721022606\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:49 INFO 139866244298560] Epoch[55] Batch [190]#011Speed: 492.10 samples/sec#011loss=3.387210\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:49 INFO 139866244298560] Epoch[55] Batch[195] avg_epoch_loss=2.622805\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=195 train loss <loss>=3.00642209053\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:49 INFO 139866244298560] Epoch[55] Batch [195]#011Speed: 595.53 samples/sec#011loss=3.006422\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:50 INFO 139866244298560] Epoch[55] Batch[200] avg_epoch_loss=2.633223\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=200 train loss <loss>=3.04157948494\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:50 INFO 139866244298560] Epoch[55] Batch [200]#011Speed: 475.28 samples/sec#011loss=3.041579\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:50 INFO 139866244298560] Epoch[55] Batch[205] avg_epoch_loss=2.635778\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=205 train loss <loss>=2.73852190971\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:50 INFO 139866244298560] Epoch[55] Batch [205]#011Speed: 595.37 samples/sec#011loss=2.738522\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:51 INFO 139866244298560] Epoch[55] Batch[210] avg_epoch_loss=2.632210\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=210 train loss <loss>=2.48519773483\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:51 INFO 139866244298560] Epoch[55] Batch [210]#011Speed: 405.55 samples/sec#011loss=2.485198\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:52 INFO 139866244298560] Epoch[55] Batch[215] avg_epoch_loss=2.627576\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=215 train loss <loss>=2.43201131821\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:52 INFO 139866244298560] Epoch[55] Batch [215]#011Speed: 585.81 samples/sec#011loss=2.432011\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:52 INFO 139866244298560] Epoch[55] Batch[220] avg_epoch_loss=2.621162\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=220 train loss <loss>=2.34408502579\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:52 INFO 139866244298560] Epoch[55] Batch [220]#011Speed: 470.01 samples/sec#011loss=2.344085\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:53 INFO 139866244298560] Epoch[55] Batch[225] avg_epoch_loss=2.624601\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=225 train loss <loss>=2.7766061306\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:53 INFO 139866244298560] Epoch[55] Batch [225]#011Speed: 579.13 samples/sec#011loss=2.776606\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:54 INFO 139866244298560] Epoch[55] Batch[230] avg_epoch_loss=2.636168\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=230 train loss <loss>=3.15899057388\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:54 INFO 139866244298560] Epoch[55] Batch [230]#011Speed: 487.70 samples/sec#011loss=3.158991\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:54 INFO 139866244298560] Epoch[55] Batch[235] avg_epoch_loss=2.647541\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=235 train loss <loss>=3.17297668457\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:54 INFO 139866244298560] Epoch[55] Batch [235]#011Speed: 592.02 samples/sec#011loss=3.172977\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:55 INFO 139866244298560] Epoch[55] Batch[240] avg_epoch_loss=2.665450\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=240 train loss <loss>=3.51072769165\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:55 INFO 139866244298560] Epoch[55] Batch [240]#011Speed: 476.81 samples/sec#011loss=3.510728\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:55 INFO 139866244298560] Epoch[55] Batch[245] avg_epoch_loss=2.683113\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=245 train loss <loss>=3.53449726105\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:55 INFO 139866244298560] Epoch[55] Batch [245]#011Speed: 595.70 samples/sec#011loss=3.534497\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:56 INFO 139866244298560] Epoch[55] Batch[250] avg_epoch_loss=2.687245\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=250 train loss <loss>=2.89053735733\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:56 INFO 139866244298560] Epoch[55] Batch [250]#011Speed: 413.31 samples/sec#011loss=2.890537\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:57 INFO 139866244298560] Epoch[55] Batch[255] avg_epoch_loss=2.686264\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=255 train loss <loss>=2.63702745438\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:57 INFO 139866244298560] Epoch[55] Batch [255]#011Speed: 590.56 samples/sec#011loss=2.637027\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:57 INFO 139866244298560] Epoch[55] Batch[260] avg_epoch_loss=2.684183\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=260 train loss <loss>=2.57761735916\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:57 INFO 139866244298560] Epoch[55] Batch [260]#011Speed: 471.96 samples/sec#011loss=2.577617\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:58 INFO 139866244298560] Epoch[55] Batch[265] avg_epoch_loss=2.686098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, batch=265 train loss <loss>=2.78608279228\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:58 INFO 139866244298560] Epoch[55] Batch [265]#011Speed: 569.20 samples/sec#011loss=2.786083\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:58 INFO 139866244298560] processed a total of 17089 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33245.118856430054, \"sum\": 33245.118856430054, \"min\": 33245.118856430054}}, \"EndTime\": 1599443818.665902, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443785.419884}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:58 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=514.028165215 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:58 INFO 139866244298560] #progress_metric: host=algo-1, completed 70 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=55, train loss <loss>=2.69618194584\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:58 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:58 INFO 139866244298560] Epoch[56] Batch[0] avg_epoch_loss=2.828512\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=0 train loss <loss>=2.82851195335\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:59 INFO 139866244298560] Epoch[56] Batch[5] avg_epoch_loss=2.164304\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=5 train loss <loss>=2.16430366039\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:56:59 INFO 139866244298560] Epoch[56] Batch [5]#011Speed: 596.07 samples/sec#011loss=2.164304\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:00 INFO 139866244298560] Epoch[56] Batch[10] avg_epoch_loss=2.152656\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=10 train loss <loss>=2.13867819309\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:00 INFO 139866244298560] Epoch[56] Batch [10]#011Speed: 471.22 samples/sec#011loss=2.138678\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:00 INFO 139866244298560] Epoch[56] Batch[15] avg_epoch_loss=2.266044\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=15 train loss <loss>=2.51549854279\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:00 INFO 139866244298560] Epoch[56] Batch [15]#011Speed: 591.37 samples/sec#011loss=2.515499\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:01 INFO 139866244298560] Epoch[56] Batch[20] avg_epoch_loss=2.360120\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=20 train loss <loss>=2.66116156578\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:01 INFO 139866244298560] Epoch[56] Batch [20]#011Speed: 435.57 samples/sec#011loss=2.661162\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:01 INFO 139866244298560] Epoch[56] Batch[25] avg_epoch_loss=2.430417\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=25 train loss <loss>=2.72566385269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:01 INFO 139866244298560] Epoch[56] Batch [25]#011Speed: 544.59 samples/sec#011loss=2.725664\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:02 INFO 139866244298560] Epoch[56] Batch[30] avg_epoch_loss=2.496560\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=30 train loss <loss>=2.84050636292\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:02 INFO 139866244298560] Epoch[56] Batch [30]#011Speed: 468.29 samples/sec#011loss=2.840506\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:03 INFO 139866244298560] Epoch[56] Batch[35] avg_epoch_loss=2.511233\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=35 train loss <loss>=2.60220594406\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:03 INFO 139866244298560] Epoch[56] Batch [35]#011Speed: 584.46 samples/sec#011loss=2.602206\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:03 INFO 139866244298560] Epoch[56] Batch[40] avg_epoch_loss=2.493691\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=40 train loss <loss>=2.36738591194\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:03 INFO 139866244298560] Epoch[56] Batch [40]#011Speed: 480.39 samples/sec#011loss=2.367386\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:04 INFO 139866244298560] Epoch[56] Batch[45] avg_epoch_loss=2.470460\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=45 train loss <loss>=2.27996480465\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:04 INFO 139866244298560] Epoch[56] Batch [45]#011Speed: 587.02 samples/sec#011loss=2.279965\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:05 INFO 139866244298560] Epoch[56] Batch[50] avg_epoch_loss=2.448308\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=50 train loss <loss>=2.24450864792\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:05 INFO 139866244298560] Epoch[56] Batch [50]#011Speed: 473.51 samples/sec#011loss=2.244509\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:05 INFO 139866244298560] Epoch[56] Batch[55] avg_epoch_loss=2.433097\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=55 train loss <loss>=2.27794733047\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:05 INFO 139866244298560] Epoch[56] Batch [55]#011Speed: 587.55 samples/sec#011loss=2.277947\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:06 INFO 139866244298560] Epoch[56] Batch[60] avg_epoch_loss=2.420138\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=60 train loss <loss>=2.27499990463\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:06 INFO 139866244298560] Epoch[56] Batch [60]#011Speed: 465.03 samples/sec#011loss=2.275000\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:06 INFO 139866244298560] Epoch[56] Batch[65] avg_epoch_loss=2.447247\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=65 train loss <loss>=2.77797541618\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:06 INFO 139866244298560] Epoch[56] Batch [65]#011Speed: 553.64 samples/sec#011loss=2.777975\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:07 INFO 139866244298560] Epoch[56] Batch[70] avg_epoch_loss=2.491101\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=70 train loss <loss>=3.06996870041\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:07 INFO 139866244298560] Epoch[56] Batch [70]#011Speed: 480.54 samples/sec#011loss=3.069969\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:08 INFO 139866244298560] Epoch[56] Batch[75] avg_epoch_loss=2.538468\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=75 train loss <loss>=3.21109142303\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:08 INFO 139866244298560] Epoch[56] Batch [75]#011Speed: 589.91 samples/sec#011loss=3.211091\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:08 INFO 139866244298560] Epoch[56] Batch[80] avg_epoch_loss=2.578494\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=80 train loss <loss>=3.1868748188\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:08 INFO 139866244298560] Epoch[56] Batch [80]#011Speed: 475.77 samples/sec#011loss=3.186875\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:09 INFO 139866244298560] Epoch[56] Batch[85] avg_epoch_loss=2.607978\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=85 train loss <loss>=3.08563017845\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:09 INFO 139866244298560] Epoch[56] Batch [85]#011Speed: 595.31 samples/sec#011loss=3.085630\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:10 INFO 139866244298560] Epoch[56] Batch[90] avg_epoch_loss=2.614445\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=90 train loss <loss>=2.72566709518\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:10 INFO 139866244298560] Epoch[56] Batch [90]#011Speed: 471.74 samples/sec#011loss=2.725667\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:10 INFO 139866244298560] Epoch[56] Batch[95] avg_epoch_loss=2.600090\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=95 train loss <loss>=2.33884334564\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:10 INFO 139866244298560] Epoch[56] Batch [95]#011Speed: 590.36 samples/sec#011loss=2.338843\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:11 INFO 139866244298560] Epoch[56] Batch[100] avg_epoch_loss=2.590790\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=100 train loss <loss>=2.41221547127\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:11 INFO 139866244298560] Epoch[56] Batch [100]#011Speed: 478.65 samples/sec#011loss=2.412215\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:11 INFO 139866244298560] Epoch[56] Batch[105] avg_epoch_loss=2.581073\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=105 train loss <loss>=2.38479881287\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:11 INFO 139866244298560] Epoch[56] Batch [105]#011Speed: 558.22 samples/sec#011loss=2.384799\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:12 INFO 139866244298560] Epoch[56] Batch[110] avg_epoch_loss=2.572037\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=110 train loss <loss>=2.38046755791\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:12 INFO 139866244298560] Epoch[56] Batch [110]#011Speed: 473.34 samples/sec#011loss=2.380468\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:13 INFO 139866244298560] Epoch[56] Batch[115] avg_epoch_loss=2.567457\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=115 train loss <loss>=2.46578650475\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:13 INFO 139866244298560] Epoch[56] Batch [115]#011Speed: 590.27 samples/sec#011loss=2.465787\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:13 INFO 139866244298560] Epoch[56] Batch[120] avg_epoch_loss=2.570262\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=120 train loss <loss>=2.63532891273\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:13 INFO 139866244298560] Epoch[56] Batch [120]#011Speed: 464.43 samples/sec#011loss=2.635329\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:14 INFO 139866244298560] Epoch[56] Batch[125] avg_epoch_loss=2.568961\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=125 train loss <loss>=2.53747506142\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:14 INFO 139866244298560] Epoch[56] Batch [125]#011Speed: 593.86 samples/sec#011loss=2.537475\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:14 INFO 139866244298560] Epoch[56] Batch[130] avg_epoch_loss=2.577849\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=130 train loss <loss>=2.80183873177\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:14 INFO 139866244298560] Epoch[56] Batch [130]#011Speed: 475.74 samples/sec#011loss=2.801839\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:15 INFO 139866244298560] Epoch[56] Batch[135] avg_epoch_loss=2.586157\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=135 train loss <loss>=2.80383152962\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:15 INFO 139866244298560] Epoch[56] Batch [135]#011Speed: 474.33 samples/sec#011loss=2.803832\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:16 INFO 139866244298560] Epoch[56] Batch[140] avg_epoch_loss=2.600666\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=140 train loss <loss>=2.9953148365\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:16 INFO 139866244298560] Epoch[56] Batch [140]#011Speed: 595.56 samples/sec#011loss=2.995315\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:16 INFO 139866244298560] Epoch[56] Batch[145] avg_epoch_loss=2.610960\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=145 train loss <loss>=2.90122513771\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:16 INFO 139866244298560] Epoch[56] Batch [145]#011Speed: 418.96 samples/sec#011loss=2.901225\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:17 INFO 139866244298560] Epoch[56] Batch[150] avg_epoch_loss=2.600718\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=150 train loss <loss>=2.30165464878\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:17 INFO 139866244298560] Epoch[56] Batch [150]#011Speed: 587.64 samples/sec#011loss=2.301655\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:18 INFO 139866244298560] Epoch[56] Batch[155] avg_epoch_loss=2.592474\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=155 train loss <loss>=2.34351010323\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:18 INFO 139866244298560] Epoch[56] Batch [155]#011Speed: 475.64 samples/sec#011loss=2.343510\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:18 INFO 139866244298560] Epoch[56] Batch[160] avg_epoch_loss=2.587675\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=160 train loss <loss>=2.43794574738\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:18 INFO 139866244298560] Epoch[56] Batch [160]#011Speed: 585.60 samples/sec#011loss=2.437946\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:19 INFO 139866244298560] Epoch[56] Batch[165] avg_epoch_loss=2.579109\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=165 train loss <loss>=2.30329663754\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:19 INFO 139866244298560] Epoch[56] Batch [165]#011Speed: 473.19 samples/sec#011loss=2.303297\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:19 INFO 139866244298560] Epoch[56] Batch[170] avg_epoch_loss=2.571390\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=170 train loss <loss>=2.31509823799\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:19 INFO 139866244298560] Epoch[56] Batch [170]#011Speed: 590.34 samples/sec#011loss=2.315098\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:20 INFO 139866244298560] Epoch[56] Batch[175] avg_epoch_loss=2.564678\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=175 train loss <loss>=2.33514709473\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:20 INFO 139866244298560] Epoch[56] Batch [175]#011Speed: 472.09 samples/sec#011loss=2.335147\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:21 INFO 139866244298560] Epoch[56] Batch[180] avg_epoch_loss=2.565782\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=180 train loss <loss>=2.60462560654\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:21 INFO 139866244298560] Epoch[56] Batch [180]#011Speed: 593.56 samples/sec#011loss=2.604626\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:21 INFO 139866244298560] Epoch[56] Batch[185] avg_epoch_loss=2.573405\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=185 train loss <loss>=2.8493622303\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:21 INFO 139866244298560] Epoch[56] Batch [185]#011Speed: 415.43 samples/sec#011loss=2.849362\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:22 INFO 139866244298560] Epoch[56] Batch[190] avg_epoch_loss=2.595638\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=190 train loss <loss>=3.42272043228\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:22 INFO 139866244298560] Epoch[56] Batch [190]#011Speed: 589.07 samples/sec#011loss=3.422720\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:23 INFO 139866244298560] Epoch[56] Batch[195] avg_epoch_loss=2.614775\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=195 train loss <loss>=3.34580149651\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:23 INFO 139866244298560] Epoch[56] Batch [195]#011Speed: 469.84 samples/sec#011loss=3.345801\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:23 INFO 139866244298560] Epoch[56] Batch[200] avg_epoch_loss=2.633752\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=200 train loss <loss>=3.37766051292\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:23 INFO 139866244298560] Epoch[56] Batch [200]#011Speed: 593.11 samples/sec#011loss=3.377661\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:24 INFO 139866244298560] Epoch[56] Batch[205] avg_epoch_loss=2.646736\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=205 train loss <loss>=3.16867833138\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:24 INFO 139866244298560] Epoch[56] Batch [205]#011Speed: 480.29 samples/sec#011loss=3.168678\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:24 INFO 139866244298560] Epoch[56] Batch[210] avg_epoch_loss=2.654166\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=210 train loss <loss>=2.96030497551\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:24 INFO 139866244298560] Epoch[56] Batch [210]#011Speed: 582.89 samples/sec#011loss=2.960305\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:25 INFO 139866244298560] Epoch[56] Batch[215] avg_epoch_loss=2.653815\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=215 train loss <loss>=2.63896579742\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:25 INFO 139866244298560] Epoch[56] Batch [215]#011Speed: 476.95 samples/sec#011loss=2.638966\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:26 INFO 139866244298560] Epoch[56] Batch[220] avg_epoch_loss=2.647521\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=220 train loss <loss>=2.37563376427\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:26 INFO 139866244298560] Epoch[56] Batch [220]#011Speed: 595.85 samples/sec#011loss=2.375634\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:26 INFO 139866244298560] Epoch[56] Batch[225] avg_epoch_loss=2.641537\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=225 train loss <loss>=2.37705135345\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:26 INFO 139866244298560] Epoch[56] Batch [225]#011Speed: 476.28 samples/sec#011loss=2.377051\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:27 INFO 139866244298560] Epoch[56] Batch[230] avg_epoch_loss=2.641300\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=230 train loss <loss>=2.63057765961\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:27 INFO 139866244298560] Epoch[56] Batch [230]#011Speed: 510.15 samples/sec#011loss=2.630578\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:28 INFO 139866244298560] Epoch[56] Batch[235] avg_epoch_loss=2.642292\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=235 train loss <loss>=2.68811650276\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:28 INFO 139866244298560] Epoch[56] Batch [235]#011Speed: 477.31 samples/sec#011loss=2.688117\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:28 INFO 139866244298560] Epoch[56] Batch[240] avg_epoch_loss=2.644761\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=240 train loss <loss>=2.76131644249\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:28 INFO 139866244298560] Epoch[56] Batch [240]#011Speed: 591.42 samples/sec#011loss=2.761316\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:29 INFO 139866244298560] Epoch[56] Batch[245] avg_epoch_loss=2.659567\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=245 train loss <loss>=3.37321529388\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:29 INFO 139866244298560] Epoch[56] Batch [245]#011Speed: 477.42 samples/sec#011loss=3.373215\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:29 INFO 139866244298560] Epoch[56] Batch[250] avg_epoch_loss=2.671208\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=250 train loss <loss>=3.24393754005\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:29 INFO 139866244298560] Epoch[56] Batch [250]#011Speed: 587.54 samples/sec#011loss=3.243938\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:30 INFO 139866244298560] Epoch[56] Batch[255] avg_epoch_loss=2.682134\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=255 train loss <loss>=3.23059802055\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:30 INFO 139866244298560] Epoch[56] Batch [255]#011Speed: 467.66 samples/sec#011loss=3.230598\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:31 INFO 139866244298560] Epoch[56] Batch[260] avg_epoch_loss=2.697403\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=260 train loss <loss>=3.47917819023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:31 INFO 139866244298560] Epoch[56] Batch [260]#011Speed: 595.27 samples/sec#011loss=3.479178\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:31 INFO 139866244298560] Epoch[56] Batch[265] avg_epoch_loss=2.697752\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=265 train loss <loss>=2.71597509384\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:31 INFO 139866244298560] Epoch[56] Batch [265]#011Speed: 485.20 samples/sec#011loss=2.715975\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:32 INFO 139866244298560] Epoch[56] Batch[270] avg_epoch_loss=2.699291\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, batch=270 train loss <loss>=2.7811961174\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:32 INFO 139866244298560] Epoch[56] Batch [270]#011Speed: 542.87 samples/sec#011loss=2.781196\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:32 INFO 139866244298560] processed a total of 17356 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33698.92382621765, \"sum\": 33698.92382621765, \"min\": 33698.92382621765}}, \"EndTime\": 1599443852.365545, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443818.66599}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:32 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=515.029068337 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:32 INFO 139866244298560] #progress_metric: host=algo-1, completed 71 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=56, train loss <loss>=2.69089917214\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:32 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:32 INFO 139866244298560] Epoch[57] Batch[0] avg_epoch_loss=2.462101\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=0 train loss <loss>=2.46210098267\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:33 INFO 139866244298560] Epoch[57] Batch[5] avg_epoch_loss=2.133380\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=5 train loss <loss>=2.13338011503\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:33 INFO 139866244298560] Epoch[57] Batch [5]#011Speed: 590.74 samples/sec#011loss=2.133380\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:33 INFO 139866244298560] Epoch[57] Batch[10] avg_epoch_loss=2.126044\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=10 train loss <loss>=2.11723957062\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:33 INFO 139866244298560] Epoch[57] Batch [10]#011Speed: 476.03 samples/sec#011loss=2.117240\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:34 INFO 139866244298560] Epoch[57] Batch[15] avg_epoch_loss=2.286954\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=15 train loss <loss>=2.64095573425\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:34 INFO 139866244298560] Epoch[57] Batch [15]#011Speed: 589.67 samples/sec#011loss=2.640956\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:35 INFO 139866244298560] Epoch[57] Batch[20] avg_epoch_loss=2.392353\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=20 train loss <loss>=2.729631567\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:35 INFO 139866244298560] Epoch[57] Batch [20]#011Speed: 481.37 samples/sec#011loss=2.729632\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:35 INFO 139866244298560] Epoch[57] Batch[25] avg_epoch_loss=2.449241\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=25 train loss <loss>=2.68817038536\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:35 INFO 139866244298560] Epoch[57] Batch [25]#011Speed: 584.26 samples/sec#011loss=2.688170\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:36 INFO 139866244298560] Epoch[57] Batch[30] avg_epoch_loss=2.469928\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=30 train loss <loss>=2.57750310898\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:36 INFO 139866244298560] Epoch[57] Batch [30]#011Speed: 483.69 samples/sec#011loss=2.577503\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:36 INFO 139866244298560] Epoch[57] Batch[35] avg_epoch_loss=2.450954\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=35 train loss <loss>=2.33330936432\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:36 INFO 139866244298560] Epoch[57] Batch [35]#011Speed: 594.21 samples/sec#011loss=2.333309\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:37 INFO 139866244298560] Epoch[57] Batch[40] avg_epoch_loss=2.452549\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=40 train loss <loss>=2.46403474808\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:37 INFO 139866244298560] Epoch[57] Batch [40]#011Speed: 420.40 samples/sec#011loss=2.464035\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:38 INFO 139866244298560] Epoch[57] Batch[45] avg_epoch_loss=2.443768\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=45 train loss <loss>=2.3717663765\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:38 INFO 139866244298560] Epoch[57] Batch [45]#011Speed: 587.25 samples/sec#011loss=2.371766\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:38 INFO 139866244298560] Epoch[57] Batch[50] avg_epoch_loss=2.424347\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=50 train loss <loss>=2.24567599297\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:38 INFO 139866244298560] Epoch[57] Batch [50]#011Speed: 480.73 samples/sec#011loss=2.245676\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:39 INFO 139866244298560] Epoch[57] Batch[55] avg_epoch_loss=2.397829\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=55 train loss <loss>=2.12734210491\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:39 INFO 139866244298560] Epoch[57] Batch [55]#011Speed: 482.09 samples/sec#011loss=2.127342\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:39 INFO 139866244298560] Epoch[57] Batch[60] avg_epoch_loss=2.417477\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=60 train loss <loss>=2.63752889633\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:39 INFO 139866244298560] Epoch[57] Batch [60]#011Speed: 596.15 samples/sec#011loss=2.637529\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:40 INFO 139866244298560] Epoch[57] Batch[65] avg_epoch_loss=2.456982\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=65 train loss <loss>=2.93895163536\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:40 INFO 139866244298560] Epoch[57] Batch [65]#011Speed: 479.56 samples/sec#011loss=2.938952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:41 INFO 139866244298560] Epoch[57] Batch[70] avg_epoch_loss=2.523191\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=70 train loss <loss>=3.39714593887\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:41 INFO 139866244298560] Epoch[57] Batch [70]#011Speed: 596.02 samples/sec#011loss=3.397146\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:41 INFO 139866244298560] Epoch[57] Batch[75] avg_epoch_loss=2.564110\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=75 train loss <loss>=3.14515838623\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:41 INFO 139866244298560] Epoch[57] Batch [75]#011Speed: 488.27 samples/sec#011loss=3.145158\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:42 INFO 139866244298560] Epoch[57] Batch[80] avg_epoch_loss=2.582289\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=80 train loss <loss>=2.85861907005\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:42 INFO 139866244298560] Epoch[57] Batch [80]#011Speed: 568.30 samples/sec#011loss=2.858619\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:43 INFO 139866244298560] Epoch[57] Batch[85] avg_epoch_loss=2.571922\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=85 train loss <loss>=2.4039760828\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:43 INFO 139866244298560] Epoch[57] Batch [85]#011Speed: 389.58 samples/sec#011loss=2.403976\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:43 INFO 139866244298560] Epoch[57] Batch[90] avg_epoch_loss=2.561734\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=90 train loss <loss>=2.38650054932\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:43 INFO 139866244298560] Epoch[57] Batch [90]#011Speed: 590.84 samples/sec#011loss=2.386501\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:44 INFO 139866244298560] Epoch[57] Batch[95] avg_epoch_loss=2.558345\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=95 train loss <loss>=2.49664907455\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:44 INFO 139866244298560] Epoch[57] Batch [95]#011Speed: 468.50 samples/sec#011loss=2.496649\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:44 INFO 139866244298560] Epoch[57] Batch[100] avg_epoch_loss=2.551934\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=100 train loss <loss>=2.42886164188\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:44 INFO 139866244298560] Epoch[57] Batch [100]#011Speed: 595.74 samples/sec#011loss=2.428862\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:45 INFO 139866244298560] Epoch[57] Batch[105] avg_epoch_loss=2.532840\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=105 train loss <loss>=2.14714217186\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:45 INFO 139866244298560] Epoch[57] Batch [105]#011Speed: 475.03 samples/sec#011loss=2.147142\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:46 INFO 139866244298560] Epoch[57] Batch[110] avg_epoch_loss=2.514951\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=110 train loss <loss>=2.13569850922\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:46 INFO 139866244298560] Epoch[57] Batch [110]#011Speed: 589.44 samples/sec#011loss=2.135699\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:46 INFO 139866244298560] Epoch[57] Batch[115] avg_epoch_loss=2.524670\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=115 train loss <loss>=2.7404381752\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:46 INFO 139866244298560] Epoch[57] Batch [115]#011Speed: 465.09 samples/sec#011loss=2.740438\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:47 INFO 139866244298560] Epoch[57] Batch[120] avg_epoch_loss=2.529803\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=120 train loss <loss>=2.64886689186\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:47 INFO 139866244298560] Epoch[57] Batch [120]#011Speed: 583.13 samples/sec#011loss=2.648867\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:48 INFO 139866244298560] Epoch[57] Batch[125] avg_epoch_loss=2.544894\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=125 train loss <loss>=2.91009745598\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:48 INFO 139866244298560] Epoch[57] Batch [125]#011Speed: 430.16 samples/sec#011loss=2.910097\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:48 INFO 139866244298560] Epoch[57] Batch[130] avg_epoch_loss=2.551408\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=130 train loss <loss>=2.71558251381\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:48 INFO 139866244298560] Epoch[57] Batch [130]#011Speed: 472.11 samples/sec#011loss=2.715583\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:49 INFO 139866244298560] Epoch[57] Batch[135] avg_epoch_loss=2.565248\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=135 train loss <loss>=2.92783193588\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:49 INFO 139866244298560] Epoch[57] Batch [135]#011Speed: 594.51 samples/sec#011loss=2.927832\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:50 INFO 139866244298560] Epoch[57] Batch[140] avg_epoch_loss=2.565510\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=140 train loss <loss>=2.57265639305\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:50 INFO 139866244298560] Epoch[57] Batch [140]#011Speed: 472.11 samples/sec#011loss=2.572656\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:50 INFO 139866244298560] Epoch[57] Batch[145] avg_epoch_loss=2.547307\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=145 train loss <loss>=2.03398759365\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:50 INFO 139866244298560] Epoch[57] Batch [145]#011Speed: 587.98 samples/sec#011loss=2.033988\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:51 INFO 139866244298560] Epoch[57] Batch[150] avg_epoch_loss=2.536702\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=150 train loss <loss>=2.22703082561\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:51 INFO 139866244298560] Epoch[57] Batch [150]#011Speed: 474.17 samples/sec#011loss=2.227031\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:51 INFO 139866244298560] Epoch[57] Batch[155] avg_epoch_loss=2.536154\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=155 train loss <loss>=2.51960325241\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:51 INFO 139866244298560] Epoch[57] Batch [155]#011Speed: 543.53 samples/sec#011loss=2.519603\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:52 INFO 139866244298560] Epoch[57] Batch[160] avg_epoch_loss=2.535082\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=160 train loss <loss>=2.50161819458\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:52 INFO 139866244298560] Epoch[57] Batch [160]#011Speed: 459.28 samples/sec#011loss=2.501618\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:53 INFO 139866244298560] Epoch[57] Batch[165] avg_epoch_loss=2.529823\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=165 train loss <loss>=2.36047878265\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:53 INFO 139866244298560] Epoch[57] Batch [165]#011Speed: 524.25 samples/sec#011loss=2.360479\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:53 INFO 139866244298560] Epoch[57] Batch[170] avg_epoch_loss=2.525014\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=170 train loss <loss>=2.36536426544\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:53 INFO 139866244298560] Epoch[57] Batch [170]#011Speed: 464.01 samples/sec#011loss=2.365364\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:54 INFO 139866244298560] Epoch[57] Batch[175] avg_epoch_loss=2.527575\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=175 train loss <loss>=2.61517410278\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:54 INFO 139866244298560] Epoch[57] Batch [175]#011Speed: 587.68 samples/sec#011loss=2.615174\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:55 INFO 139866244298560] Epoch[57] Batch[180] avg_epoch_loss=2.538263\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=180 train loss <loss>=2.91446681023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:55 INFO 139866244298560] Epoch[57] Batch [180]#011Speed: 473.93 samples/sec#011loss=2.914467\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:55 INFO 139866244298560] Epoch[57] Batch[185] avg_epoch_loss=2.554739\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=185 train loss <loss>=3.15118379593\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:55 INFO 139866244298560] Epoch[57] Batch [185]#011Speed: 580.35 samples/sec#011loss=3.151184\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:56 INFO 139866244298560] Epoch[57] Batch[190] avg_epoch_loss=2.573463\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=190 train loss <loss>=3.26999282837\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:56 INFO 139866244298560] Epoch[57] Batch [190]#011Speed: 480.54 samples/sec#011loss=3.269993\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:56 INFO 139866244298560] Epoch[57] Batch[195] avg_epoch_loss=2.596390\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=195 train loss <loss>=3.47220330238\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:56 INFO 139866244298560] Epoch[57] Batch [195]#011Speed: 589.42 samples/sec#011loss=3.472203\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:57 INFO 139866244298560] Epoch[57] Batch[200] avg_epoch_loss=2.606370\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=200 train loss <loss>=2.99758615494\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:57 INFO 139866244298560] Epoch[57] Batch [200]#011Speed: 485.89 samples/sec#011loss=2.997586\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:58 INFO 139866244298560] Epoch[57] Batch[205] avg_epoch_loss=2.614121\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=205 train loss <loss>=2.92571444511\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:58 INFO 139866244298560] Epoch[57] Batch [205]#011Speed: 564.38 samples/sec#011loss=2.925714\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:58 INFO 139866244298560] Epoch[57] Batch[210] avg_epoch_loss=2.608635\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=210 train loss <loss>=2.38261396885\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:58 INFO 139866244298560] Epoch[57] Batch [210]#011Speed: 414.58 samples/sec#011loss=2.382614\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:59 INFO 139866244298560] Epoch[57] Batch[215] avg_epoch_loss=2.604301\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=215 train loss <loss>=2.42140698433\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:57:59 INFO 139866244298560] Epoch[57] Batch [215]#011Speed: 593.71 samples/sec#011loss=2.421407\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:00 INFO 139866244298560] Epoch[57] Batch[220] avg_epoch_loss=2.601907\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=220 train loss <loss>=2.49845166206\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:00 INFO 139866244298560] Epoch[57] Batch [220]#011Speed: 477.13 samples/sec#011loss=2.498452\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:00 INFO 139866244298560] Epoch[57] Batch[225] avg_epoch_loss=2.595878\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=225 train loss <loss>=2.32943811417\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:00 INFO 139866244298560] Epoch[57] Batch [225]#011Speed: 585.22 samples/sec#011loss=2.329438\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:01 INFO 139866244298560] Epoch[57] Batch[230] avg_epoch_loss=2.595493\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=230 train loss <loss>=2.57804956436\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:01 INFO 139866244298560] Epoch[57] Batch [230]#011Speed: 477.41 samples/sec#011loss=2.578050\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:01 INFO 139866244298560] Epoch[57] Batch[235] avg_epoch_loss=2.601801\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=235 train loss <loss>=2.89325184822\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:01 INFO 139866244298560] Epoch[57] Batch [235]#011Speed: 588.79 samples/sec#011loss=2.893252\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:02 INFO 139866244298560] Epoch[57] Batch[240] avg_epoch_loss=2.617882\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=240 train loss <loss>=3.3768819809\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:02 INFO 139866244298560] Epoch[57] Batch [240]#011Speed: 464.79 samples/sec#011loss=3.376882\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:03 INFO 139866244298560] Epoch[57] Batch[245] avg_epoch_loss=2.637823\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=245 train loss <loss>=3.59900608063\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:03 INFO 139866244298560] Epoch[57] Batch [245]#011Speed: 583.85 samples/sec#011loss=3.599006\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:03 INFO 139866244298560] Epoch[57] Batch[250] avg_epoch_loss=2.649431\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=250 train loss <loss>=3.22055206299\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:03 INFO 139866244298560] Epoch[57] Batch [250]#011Speed: 442.27 samples/sec#011loss=3.220552\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:04 INFO 139866244298560] Epoch[57] Batch[255] avg_epoch_loss=2.657063\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=255 train loss <loss>=3.04018383026\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:04 INFO 139866244298560] Epoch[57] Batch [255]#011Speed: 477.02 samples/sec#011loss=3.040184\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:04 INFO 139866244298560] Epoch[57] Batch[260] avg_epoch_loss=2.656104\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=260 train loss <loss>=2.60701785088\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:04 INFO 139866244298560] Epoch[57] Batch [260]#011Speed: 594.58 samples/sec#011loss=2.607018\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:05 INFO 139866244298560] Epoch[57] Batch[265] avg_epoch_loss=2.663280\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, batch=265 train loss <loss>=3.03782801628\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:05 INFO 139866244298560] Epoch[57] Batch [265]#011Speed: 579.66 samples/sec#011loss=3.037828\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:05 INFO 139866244298560] processed a total of 16978 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33180.30095100403, \"sum\": 33180.30095100403, \"min\": 33180.30095100403}}, \"EndTime\": 1599443885.546668, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443852.36564}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:05 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=511.687591346 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:05 INFO 139866244298560] #progress_metric: host=algo-1, completed 72 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=57, train loss <loss>=2.66327963781\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:05 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:05 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_bd569a92-ed90-4622-8b90-4ac143836243-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.620967864990234, \"sum\": 18.620967864990234, \"min\": 18.620967864990234}}, \"EndTime\": 1599443885.565998, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443885.546732}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:05 INFO 139866244298560] Epoch[58] Batch[0] avg_epoch_loss=2.174721\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=0 train loss <loss>=2.17472076416\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:06 INFO 139866244298560] Epoch[58] Batch[5] avg_epoch_loss=2.215447\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=5 train loss <loss>=2.21544671059\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:06 INFO 139866244298560] Epoch[58] Batch [5]#011Speed: 599.74 samples/sec#011loss=2.215447\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:07 INFO 139866244298560] Epoch[58] Batch[10] avg_epoch_loss=2.213180\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=10 train loss <loss>=2.21046049595\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:07 INFO 139866244298560] Epoch[58] Batch [10]#011Speed: 473.58 samples/sec#011loss=2.210460\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:07 INFO 139866244298560] Epoch[58] Batch[15] avg_epoch_loss=2.336878\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=15 train loss <loss>=2.60901389122\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:07 INFO 139866244298560] Epoch[58] Batch [15]#011Speed: 583.57 samples/sec#011loss=2.609014\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:08 INFO 139866244298560] Epoch[58] Batch[20] avg_epoch_loss=2.416078\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=20 train loss <loss>=2.66951799393\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:08 INFO 139866244298560] Epoch[58] Batch [20]#011Speed: 472.42 samples/sec#011loss=2.669518\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:08 INFO 139866244298560] Epoch[58] Batch[25] avg_epoch_loss=2.484317\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=25 train loss <loss>=2.77091970444\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:08 INFO 139866244298560] Epoch[58] Batch [25]#011Speed: 534.64 samples/sec#011loss=2.770920\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:09 INFO 139866244298560] Epoch[58] Batch[30] avg_epoch_loss=2.527144\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=30 train loss <loss>=2.74984736443\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:09 INFO 139866244298560] Epoch[58] Batch [30]#011Speed: 472.91 samples/sec#011loss=2.749847\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:10 INFO 139866244298560] Epoch[58] Batch[35] avg_epoch_loss=2.513944\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=35 train loss <loss>=2.43209991455\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:10 INFO 139866244298560] Epoch[58] Batch [35]#011Speed: 593.79 samples/sec#011loss=2.432100\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:10 INFO 139866244298560] Epoch[58] Batch[40] avg_epoch_loss=2.543282\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=40 train loss <loss>=2.75452079773\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:10 INFO 139866244298560] Epoch[58] Batch [40]#011Speed: 477.71 samples/sec#011loss=2.754521\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:11 INFO 139866244298560] Epoch[58] Batch[45] avg_epoch_loss=2.526884\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=45 train loss <loss>=2.39241585732\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:11 INFO 139866244298560] Epoch[58] Batch [45]#011Speed: 589.32 samples/sec#011loss=2.392416\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:11 INFO 139866244298560] Epoch[58] Batch[50] avg_epoch_loss=2.503239\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=50 train loss <loss>=2.28570458889\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:11 INFO 139866244298560] Epoch[58] Batch [50]#011Speed: 482.06 samples/sec#011loss=2.285705\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:12 INFO 139866244298560] Epoch[58] Batch[55] avg_epoch_loss=2.469027\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=55 train loss <loss>=2.12006285191\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:12 INFO 139866244298560] Epoch[58] Batch [55]#011Speed: 587.29 samples/sec#011loss=2.120063\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:13 INFO 139866244298560] Epoch[58] Batch[60] avg_epoch_loss=2.486982\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=60 train loss <loss>=2.6880833149\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:13 INFO 139866244298560] Epoch[58] Batch [60]#011Speed: 480.48 samples/sec#011loss=2.688083\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:13 INFO 139866244298560] Epoch[58] Batch[65] avg_epoch_loss=2.522195\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=65 train loss <loss>=2.95179743767\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:13 INFO 139866244298560] Epoch[58] Batch [65]#011Speed: 421.09 samples/sec#011loss=2.951797\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:14 INFO 139866244298560] Epoch[58] Batch[70] avg_epoch_loss=2.585303\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=70 train loss <loss>=3.41832141876\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:14 INFO 139866244298560] Epoch[58] Batch [70]#011Speed: 590.04 samples/sec#011loss=3.418321\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:15 INFO 139866244298560] Epoch[58] Batch[75] avg_epoch_loss=2.613737\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=75 train loss <loss>=3.01750741005\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:15 INFO 139866244298560] Epoch[58] Batch [75]#011Speed: 481.72 samples/sec#011loss=3.017507\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:15 INFO 139866244298560] Epoch[58] Batch[80] avg_epoch_loss=2.629342\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=80 train loss <loss>=2.86652612686\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:15 INFO 139866244298560] Epoch[58] Batch [80]#011Speed: 586.19 samples/sec#011loss=2.866526\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:16 INFO 139866244298560] Epoch[58] Batch[85] avg_epoch_loss=2.630619\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=85 train loss <loss>=2.65131716728\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:16 INFO 139866244298560] Epoch[58] Batch [85]#011Speed: 473.67 samples/sec#011loss=2.651317\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:16 INFO 139866244298560] Epoch[58] Batch[90] avg_epoch_loss=2.630932\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=90 train loss <loss>=2.63630857468\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:16 INFO 139866244298560] Epoch[58] Batch [90]#011Speed: 594.97 samples/sec#011loss=2.636309\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:17 INFO 139866244298560] Epoch[58] Batch[95] avg_epoch_loss=2.615990\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=95 train loss <loss>=2.34405634403\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:17 INFO 139866244298560] Epoch[58] Batch [95]#011Speed: 479.26 samples/sec#011loss=2.344056\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:18 INFO 139866244298560] Epoch[58] Batch[100] avg_epoch_loss=2.602933\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=100 train loss <loss>=2.3522289753\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:18 INFO 139866244298560] Epoch[58] Batch [100]#011Speed: 587.49 samples/sec#011loss=2.352229\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:18 INFO 139866244298560] Epoch[58] Batch[105] avg_epoch_loss=2.591601\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=105 train loss <loss>=2.36270151138\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:18 INFO 139866244298560] Epoch[58] Batch [105]#011Speed: 465.03 samples/sec#011loss=2.362702\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:19 INFO 139866244298560] Epoch[58] Batch[110] avg_epoch_loss=2.577525\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=110 train loss <loss>=2.27909674644\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:19 INFO 139866244298560] Epoch[58] Batch [110]#011Speed: 548.86 samples/sec#011loss=2.279097\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:20 INFO 139866244298560] Epoch[58] Batch[115] avg_epoch_loss=2.583334\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=115 train loss <loss>=2.71230559349\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:20 INFO 139866244298560] Epoch[58] Batch [115]#011Speed: 480.39 samples/sec#011loss=2.712306\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:20 INFO 139866244298560] Epoch[58] Batch[120] avg_epoch_loss=2.600864\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=120 train loss <loss>=3.00755009651\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:20 INFO 139866244298560] Epoch[58] Batch [120]#011Speed: 588.40 samples/sec#011loss=3.007550\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:21 INFO 139866244298560] Epoch[58] Batch[125] avg_epoch_loss=2.618554\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=125 train loss <loss>=3.04665036201\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:21 INFO 139866244298560] Epoch[58] Batch [125]#011Speed: 479.35 samples/sec#011loss=3.046650\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:21 INFO 139866244298560] Epoch[58] Batch[130] avg_epoch_loss=2.634413\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=130 train loss <loss>=3.03407206535\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:21 INFO 139866244298560] Epoch[58] Batch [130]#011Speed: 593.87 samples/sec#011loss=3.034072\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:22 INFO 139866244298560] Epoch[58] Batch[135] avg_epoch_loss=2.629292\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=135 train loss <loss>=2.49512619972\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:22 INFO 139866244298560] Epoch[58] Batch [135]#011Speed: 434.17 samples/sec#011loss=2.495126\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:23 INFO 139866244298560] Epoch[58] Batch[140] avg_epoch_loss=2.618245\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=140 train loss <loss>=2.31776566505\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:23 INFO 139866244298560] Epoch[58] Batch [140]#011Speed: 586.91 samples/sec#011loss=2.317766\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:23 INFO 139866244298560] Epoch[58] Batch[145] avg_epoch_loss=2.598261\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=145 train loss <loss>=2.03471689224\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:23 INFO 139866244298560] Epoch[58] Batch [145]#011Speed: 477.26 samples/sec#011loss=2.034717\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:24 INFO 139866244298560] Epoch[58] Batch[150] avg_epoch_loss=2.588662\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=150 train loss <loss>=2.30834980011\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:24 INFO 139866244298560] Epoch[58] Batch [150]#011Speed: 438.76 samples/sec#011loss=2.308350\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:25 INFO 139866244298560] Epoch[58] Batch[155] avg_epoch_loss=2.589947\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=155 train loss <loss>=2.62876205444\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:25 INFO 139866244298560] Epoch[58] Batch [155]#011Speed: 584.13 samples/sec#011loss=2.628762\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:25 INFO 139866244298560] Epoch[58] Batch[160] avg_epoch_loss=2.580423\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=160 train loss <loss>=2.28326158524\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:25 INFO 139866244298560] Epoch[58] Batch [160]#011Speed: 463.78 samples/sec#011loss=2.283262\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:26 INFO 139866244298560] Epoch[58] Batch[165] avg_epoch_loss=2.576895\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=165 train loss <loss>=2.46332402229\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:26 INFO 139866244298560] Epoch[58] Batch [165]#011Speed: 591.94 samples/sec#011loss=2.463324\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:26 INFO 139866244298560] Epoch[58] Batch[170] avg_epoch_loss=2.586647\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=170 train loss <loss>=2.91041016579\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:26 INFO 139866244298560] Epoch[58] Batch [170]#011Speed: 478.28 samples/sec#011loss=2.910410\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:27 INFO 139866244298560] Epoch[58] Batch[175] avg_epoch_loss=2.604520\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=175 train loss <loss>=3.21575064659\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:27 INFO 139866244298560] Epoch[58] Batch [175]#011Speed: 596.63 samples/sec#011loss=3.215751\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:28 INFO 139866244298560] Epoch[58] Batch[180] avg_epoch_loss=2.617666\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=180 train loss <loss>=3.08041291237\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:28 INFO 139866244298560] Epoch[58] Batch [180]#011Speed: 466.34 samples/sec#011loss=3.080413\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:28 INFO 139866244298560] Epoch[58] Batch[185] avg_epoch_loss=2.632978\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=185 train loss <loss>=3.1872836113\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:28 INFO 139866244298560] Epoch[58] Batch [185]#011Speed: 583.53 samples/sec#011loss=3.187284\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:29 INFO 139866244298560] Epoch[58] Batch[190] avg_epoch_loss=2.644460\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=190 train loss <loss>=3.07157959938\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:29 INFO 139866244298560] Epoch[58] Batch [190]#011Speed: 413.21 samples/sec#011loss=3.071580\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:29 INFO 139866244298560] Epoch[58] Batch[195] avg_epoch_loss=2.645163\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=195 train loss <loss>=2.67202281952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:30 INFO 139866244298560] Epoch[58] Batch [195]#011Speed: 590.00 samples/sec#011loss=2.672023\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:30 INFO 139866244298560] Epoch[58] Batch[200] avg_epoch_loss=2.644934\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=200 train loss <loss>=2.63597145081\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:30 INFO 139866244298560] Epoch[58] Batch [200]#011Speed: 470.65 samples/sec#011loss=2.635971\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:31 INFO 139866244298560] Epoch[58] Batch[205] avg_epoch_loss=2.642242\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=205 train loss <loss>=2.5340133667\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:31 INFO 139866244298560] Epoch[58] Batch [205]#011Speed: 591.06 samples/sec#011loss=2.534013\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:31 INFO 139866244298560] Epoch[58] Batch[210] avg_epoch_loss=2.638472\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=210 train loss <loss>=2.48314418793\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:31 INFO 139866244298560] Epoch[58] Batch [210]#011Speed: 483.51 samples/sec#011loss=2.483144\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:32 INFO 139866244298560] Epoch[58] Batch[215] avg_epoch_loss=2.630545\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=215 train loss <loss>=2.29601182938\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:32 INFO 139866244298560] Epoch[58] Batch [215]#011Speed: 587.64 samples/sec#011loss=2.296012\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:33 INFO 139866244298560] Epoch[58] Batch[220] avg_epoch_loss=2.640418\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=220 train loss <loss>=3.06695461273\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:33 INFO 139866244298560] Epoch[58] Batch [220]#011Speed: 471.61 samples/sec#011loss=3.066955\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:33 INFO 139866244298560] Epoch[58] Batch[225] avg_epoch_loss=2.647115\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=225 train loss <loss>=2.9430914402\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:33 INFO 139866244298560] Epoch[58] Batch [225]#011Speed: 594.38 samples/sec#011loss=2.943091\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:34 INFO 139866244298560] Epoch[58] Batch[230] avg_epoch_loss=2.666121\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=230 train loss <loss>=3.52520155907\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:34 INFO 139866244298560] Epoch[58] Batch [230]#011Speed: 451.31 samples/sec#011loss=3.525202\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:35 INFO 139866244298560] Epoch[58] Batch[235] avg_epoch_loss=2.679672\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=235 train loss <loss>=3.30573773384\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:35 INFO 139866244298560] Epoch[58] Batch [235]#011Speed: 476.75 samples/sec#011loss=3.305738\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:35 INFO 139866244298560] Epoch[58] Batch[240] avg_epoch_loss=2.693287\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=240 train loss <loss>=3.33590126038\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:35 INFO 139866244298560] Epoch[58] Batch [240]#011Speed: 587.51 samples/sec#011loss=3.335901\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:36 INFO 139866244298560] Epoch[58] Batch[245] avg_epoch_loss=2.698917\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=245 train loss <loss>=2.9703104496\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:36 INFO 139866244298560] Epoch[58] Batch [245]#011Speed: 467.86 samples/sec#011loss=2.970310\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:36 INFO 139866244298560] Epoch[58] Batch[250] avg_epoch_loss=2.699473\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=250 train loss <loss>=2.7268228054\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:36 INFO 139866244298560] Epoch[58] Batch [250]#011Speed: 591.05 samples/sec#011loss=2.726823\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:37 INFO 139866244298560] Epoch[58] Batch[255] avg_epoch_loss=2.696246\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=255 train loss <loss>=2.53426403999\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:37 INFO 139866244298560] Epoch[58] Batch [255]#011Speed: 473.83 samples/sec#011loss=2.534264\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:38 INFO 139866244298560] Epoch[58] Batch[260] avg_epoch_loss=2.691754\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=260 train loss <loss>=2.46176629066\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:38 INFO 139866244298560] Epoch[58] Batch [260]#011Speed: 591.01 samples/sec#011loss=2.461766\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:38 INFO 139866244298560] Epoch[58] Batch[265] avg_epoch_loss=2.698211\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, batch=265 train loss <loss>=3.03526902199\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:38 INFO 139866244298560] Epoch[58] Batch [265]#011Speed: 552.12 samples/sec#011loss=3.035269\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:38 INFO 139866244298560] processed a total of 17116 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33241.53685569763, \"sum\": 33241.53685569763, \"min\": 33241.53685569763}}, \"EndTime\": 1599443918.807694, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443885.566078}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:38 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=514.895958238 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:38 INFO 139866244298560] #progress_metric: host=algo-1, completed 73 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=58, train loss <loss>=2.70732852149\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:38 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:39 INFO 139866244298560] Epoch[59] Batch[0] avg_epoch_loss=2.314917\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=0 train loss <loss>=2.31491732597\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:39 INFO 139866244298560] Epoch[59] Batch[5] avg_epoch_loss=2.135890\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=5 train loss <loss>=2.13588962952\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:39 INFO 139866244298560] Epoch[59] Batch [5]#011Speed: 505.01 samples/sec#011loss=2.135890\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:40 INFO 139866244298560] Epoch[59] Batch[10] avg_epoch_loss=2.130560\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=10 train loss <loss>=2.12416493893\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:40 INFO 139866244298560] Epoch[59] Batch [10]#011Speed: 473.20 samples/sec#011loss=2.124165\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:40 INFO 139866244298560] Epoch[59] Batch[15] avg_epoch_loss=2.280103\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=15 train loss <loss>=2.60909628868\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:40 INFO 139866244298560] Epoch[59] Batch [15]#011Speed: 586.18 samples/sec#011loss=2.609096\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:41 INFO 139866244298560] Epoch[59] Batch[20] avg_epoch_loss=2.345593\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=20 train loss <loss>=2.55516366959\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:41 INFO 139866244298560] Epoch[59] Batch [20]#011Speed: 472.45 samples/sec#011loss=2.555164\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:42 INFO 139866244298560] Epoch[59] Batch[25] avg_epoch_loss=2.403939\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=25 train loss <loss>=2.64899048805\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:42 INFO 139866244298560] Epoch[59] Batch [25]#011Speed: 593.29 samples/sec#011loss=2.648990\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:42 INFO 139866244298560] Epoch[59] Batch[30] avg_epoch_loss=2.446549\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=30 train loss <loss>=2.66812062263\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:42 INFO 139866244298560] Epoch[59] Batch [30]#011Speed: 470.89 samples/sec#011loss=2.668121\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:43 INFO 139866244298560] Epoch[59] Batch[35] avg_epoch_loss=2.478253\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=35 train loss <loss>=2.67481937408\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:43 INFO 139866244298560] Epoch[59] Batch [35]#011Speed: 575.44 samples/sec#011loss=2.674819\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:44 INFO 139866244298560] Epoch[59] Batch[40] avg_epoch_loss=2.490090\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=40 train loss <loss>=2.57531833649\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:44 INFO 139866244298560] Epoch[59] Batch [40]#011Speed: 476.36 samples/sec#011loss=2.575318\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:44 INFO 139866244298560] Epoch[59] Batch[45] avg_epoch_loss=2.488692\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=45 train loss <loss>=2.47722759247\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:44 INFO 139866244298560] Epoch[59] Batch [45]#011Speed: 531.33 samples/sec#011loss=2.477228\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:45 INFO 139866244298560] Epoch[59] Batch[50] avg_epoch_loss=2.468712\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=50 train loss <loss>=2.28489232063\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:45 INFO 139866244298560] Epoch[59] Batch [50]#011Speed: 476.56 samples/sec#011loss=2.284892\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:45 INFO 139866244298560] Epoch[59] Batch[55] avg_epoch_loss=2.457077\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=55 train loss <loss>=2.33840072155\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:45 INFO 139866244298560] Epoch[59] Batch [55]#011Speed: 581.36 samples/sec#011loss=2.338401\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:46 INFO 139866244298560] Epoch[59] Batch[60] avg_epoch_loss=2.444827\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=60 train loss <loss>=2.3076230526\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:46 INFO 139866244298560] Epoch[59] Batch [60]#011Speed: 480.69 samples/sec#011loss=2.307623\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:47 INFO 139866244298560] Epoch[59] Batch[65] avg_epoch_loss=2.450041\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=65 train loss <loss>=2.51365027428\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:47 INFO 139866244298560] Epoch[59] Batch [65]#011Speed: 594.42 samples/sec#011loss=2.513650\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:47 INFO 139866244298560] Epoch[59] Batch[70] avg_epoch_loss=2.460515\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=70 train loss <loss>=2.59877977371\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:47 INFO 139866244298560] Epoch[59] Batch [70]#011Speed: 477.12 samples/sec#011loss=2.598780\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:48 INFO 139866244298560] Epoch[59] Batch[75] avg_epoch_loss=2.493813\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=75 train loss <loss>=2.96664204597\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:48 INFO 139866244298560] Epoch[59] Batch [75]#011Speed: 589.66 samples/sec#011loss=2.966642\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:48 INFO 139866244298560] Epoch[59] Batch[80] avg_epoch_loss=2.527224\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=80 train loss <loss>=3.03507943153\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:48 INFO 139866244298560] Epoch[59] Batch [80]#011Speed: 481.44 samples/sec#011loss=3.035079\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:49 INFO 139866244298560] Epoch[59] Batch[85] avg_epoch_loss=2.565738\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=85 train loss <loss>=3.1896589756\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:49 INFO 139866244298560] Epoch[59] Batch [85]#011Speed: 570.01 samples/sec#011loss=3.189659\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:50 INFO 139866244298560] Epoch[59] Batch[90] avg_epoch_loss=2.584887\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=90 train loss <loss>=2.91425690651\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:50 INFO 139866244298560] Epoch[59] Batch [90]#011Speed: 430.51 samples/sec#011loss=2.914257\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:50 INFO 139866244298560] Epoch[59] Batch[95] avg_epoch_loss=2.580439\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=95 train loss <loss>=2.49948325157\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:50 INFO 139866244298560] Epoch[59] Batch [95]#011Speed: 584.94 samples/sec#011loss=2.499483\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:51 INFO 139866244298560] Epoch[59] Batch[100] avg_epoch_loss=2.576682\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=100 train loss <loss>=2.50453310013\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:51 INFO 139866244298560] Epoch[59] Batch [100]#011Speed: 475.96 samples/sec#011loss=2.504533\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:52 INFO 139866244298560] Epoch[59] Batch[105] avg_epoch_loss=2.569456\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=105 train loss <loss>=2.42350535393\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:52 INFO 139866244298560] Epoch[59] Batch [105]#011Speed: 596.01 samples/sec#011loss=2.423505\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:52 INFO 139866244298560] Epoch[59] Batch[110] avg_epoch_loss=2.562530\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=110 train loss <loss>=2.41569223404\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:52 INFO 139866244298560] Epoch[59] Batch [110]#011Speed: 429.37 samples/sec#011loss=2.415692\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:53 INFO 139866244298560] Epoch[59] Batch[115] avg_epoch_loss=2.546742\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=115 train loss <loss>=2.19624772072\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:53 INFO 139866244298560] Epoch[59] Batch [115]#011Speed: 584.88 samples/sec#011loss=2.196248\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:53 INFO 139866244298560] Epoch[59] Batch[120] avg_epoch_loss=2.537588\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=120 train loss <loss>=2.32520956993\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:53 INFO 139866244298560] Epoch[59] Batch [120]#011Speed: 473.82 samples/sec#011loss=2.325210\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:54 INFO 139866244298560] Epoch[59] Batch[125] avg_epoch_loss=2.534310\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=125 train loss <loss>=2.45497756004\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:54 INFO 139866244298560] Epoch[59] Batch [125]#011Speed: 594.35 samples/sec#011loss=2.454978\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:55 INFO 139866244298560] Epoch[59] Batch[130] avg_epoch_loss=2.545636\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=130 train loss <loss>=2.83105549812\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:55 INFO 139866244298560] Epoch[59] Batch [130]#011Speed: 436.73 samples/sec#011loss=2.831055\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:55 INFO 139866244298560] Epoch[59] Batch[135] avg_epoch_loss=2.557898\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=135 train loss <loss>=2.87916355133\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:55 INFO 139866244298560] Epoch[59] Batch [135]#011Speed: 574.41 samples/sec#011loss=2.879164\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:56 INFO 139866244298560] Epoch[59] Batch[140] avg_epoch_loss=2.564391\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=140 train loss <loss>=2.74099259377\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:56 INFO 139866244298560] Epoch[59] Batch [140]#011Speed: 477.64 samples/sec#011loss=2.740993\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:57 INFO 139866244298560] Epoch[59] Batch[145] avg_epoch_loss=2.572339\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=145 train loss <loss>=2.79649686813\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:57 INFO 139866244298560] Epoch[59] Batch [145]#011Speed: 591.50 samples/sec#011loss=2.796497\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:57 INFO 139866244298560] Epoch[59] Batch[150] avg_epoch_loss=2.556312\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=150 train loss <loss>=2.0883014679\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:57 INFO 139866244298560] Epoch[59] Batch [150]#011Speed: 472.21 samples/sec#011loss=2.088301\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:58 INFO 139866244298560] Epoch[59] Batch[155] avg_epoch_loss=2.545847\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=155 train loss <loss>=2.22981791496\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:58 INFO 139866244298560] Epoch[59] Batch [155]#011Speed: 580.93 samples/sec#011loss=2.229818\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:58 INFO 139866244298560] Epoch[59] Batch[160] avg_epoch_loss=2.543104\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=160 train loss <loss>=2.45753560066\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:58 INFO 139866244298560] Epoch[59] Batch [160]#011Speed: 473.62 samples/sec#011loss=2.457536\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:59 INFO 139866244298560] Epoch[59] Batch[165] avg_epoch_loss=2.540227\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=165 train loss <loss>=2.44758553505\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:58:59 INFO 139866244298560] Epoch[59] Batch [165]#011Speed: 593.39 samples/sec#011loss=2.447586\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:00 INFO 139866244298560] Epoch[59] Batch[170] avg_epoch_loss=2.534891\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=170 train loss <loss>=2.35770542622\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:00 INFO 139866244298560] Epoch[59] Batch [170]#011Speed: 407.16 samples/sec#011loss=2.357705\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:00 INFO 139866244298560] Epoch[59] Batch[175] avg_epoch_loss=2.531529\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=175 train loss <loss>=2.41657857895\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:00 INFO 139866244298560] Epoch[59] Batch [175]#011Speed: 581.53 samples/sec#011loss=2.416579\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:01 INFO 139866244298560] Epoch[59] Batch[180] avg_epoch_loss=2.539585\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=180 train loss <loss>=2.82314186096\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:01 INFO 139866244298560] Epoch[59] Batch [180]#011Speed: 473.33 samples/sec#011loss=2.823142\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:02 INFO 139866244298560] Epoch[59] Batch[185] avg_epoch_loss=2.545810\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=185 train loss <loss>=2.771139431\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:02 INFO 139866244298560] Epoch[59] Batch [185]#011Speed: 564.22 samples/sec#011loss=2.771139\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:02 INFO 139866244298560] Epoch[59] Batch[190] avg_epoch_loss=2.569154\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=190 train loss <loss>=3.43755812645\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:02 INFO 139866244298560] Epoch[59] Batch [190]#011Speed: 474.89 samples/sec#011loss=3.437558\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:03 INFO 139866244298560] Epoch[59] Batch[195] avg_epoch_loss=2.589209\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=195 train loss <loss>=3.35530581474\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:03 INFO 139866244298560] Epoch[59] Batch [195]#011Speed: 585.05 samples/sec#011loss=3.355306\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:03 INFO 139866244298560] Epoch[59] Batch[200] avg_epoch_loss=2.599111\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=200 train loss <loss>=2.98726687431\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:03 INFO 139866244298560] Epoch[59] Batch [200]#011Speed: 480.46 samples/sec#011loss=2.987267\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:04 INFO 139866244298560] Epoch[59] Batch[205] avg_epoch_loss=2.605586\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=205 train loss <loss>=2.86591219902\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:04 INFO 139866244298560] Epoch[59] Batch [205]#011Speed: 594.76 samples/sec#011loss=2.865912\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:05 INFO 139866244298560] Epoch[59] Batch[210] avg_epoch_loss=2.606876\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=210 train loss <loss>=2.66000361443\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:05 INFO 139866244298560] Epoch[59] Batch [210]#011Speed: 439.24 samples/sec#011loss=2.660004\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:05 INFO 139866244298560] Epoch[59] Batch[215] avg_epoch_loss=2.604377\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=215 train loss <loss>=2.49891748428\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:05 INFO 139866244298560] Epoch[59] Batch [215]#011Speed: 445.24 samples/sec#011loss=2.498917\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:06 INFO 139866244298560] Epoch[59] Batch[220] avg_epoch_loss=2.596810\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=220 train loss <loss>=2.26992745399\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:06 INFO 139866244298560] Epoch[59] Batch [220]#011Speed: 594.06 samples/sec#011loss=2.269927\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:07 INFO 139866244298560] Epoch[59] Batch[225] avg_epoch_loss=2.589237\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=225 train loss <loss>=2.25452213287\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:07 INFO 139866244298560] Epoch[59] Batch [225]#011Speed: 480.45 samples/sec#011loss=2.254522\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:07 INFO 139866244298560] Epoch[59] Batch[230] avg_epoch_loss=2.590072\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=230 train loss <loss>=2.62781801224\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:07 INFO 139866244298560] Epoch[59] Batch [230]#011Speed: 585.10 samples/sec#011loss=2.627818\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:08 INFO 139866244298560] Epoch[59] Batch[235] avg_epoch_loss=2.592873\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=235 train loss <loss>=2.72227840424\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:08 INFO 139866244298560] Epoch[59] Batch [235]#011Speed: 467.80 samples/sec#011loss=2.722278\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:08 INFO 139866244298560] Epoch[59] Batch[240] avg_epoch_loss=2.603712\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=240 train loss <loss>=3.11530075073\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:08 INFO 139866244298560] Epoch[59] Batch [240]#011Speed: 588.38 samples/sec#011loss=3.115301\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:09 INFO 139866244298560] Epoch[59] Batch[245] avg_epoch_loss=2.614501\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=245 train loss <loss>=3.134516716\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:09 INFO 139866244298560] Epoch[59] Batch [245]#011Speed: 484.95 samples/sec#011loss=3.134517\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:10 INFO 139866244298560] Epoch[59] Batch[250] avg_epoch_loss=2.630336\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=250 train loss <loss>=3.40941562653\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:10 INFO 139866244298560] Epoch[59] Batch [250]#011Speed: 590.61 samples/sec#011loss=3.409416\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:10 INFO 139866244298560] Epoch[59] Batch[255] avg_epoch_loss=2.643580\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=255 train loss <loss>=3.30845332146\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:10 INFO 139866244298560] Epoch[59] Batch [255]#011Speed: 411.61 samples/sec#011loss=3.308453\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:11 INFO 139866244298560] Epoch[59] Batch[260] avg_epoch_loss=2.648608\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=260 train loss <loss>=2.90605125427\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:11 INFO 139866244298560] Epoch[59] Batch [260]#011Speed: 591.18 samples/sec#011loss=2.906051\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:12 INFO 139866244298560] Epoch[59] Batch[265] avg_epoch_loss=2.646427\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=265 train loss <loss>=2.53252930641\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:12 INFO 139866244298560] Epoch[59] Batch [265]#011Speed: 478.57 samples/sec#011loss=2.532529\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:12 INFO 139866244298560] Epoch[59] Batch[270] avg_epoch_loss=2.642365\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, batch=270 train loss <loss>=2.42629857063\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:12 INFO 139866244298560] Epoch[59] Batch [270]#011Speed: 590.92 samples/sec#011loss=2.426299\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:12 INFO 139866244298560] processed a total of 17472 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 34045.04489898682, \"sum\": 34045.04489898682, \"min\": 34045.04489898682}}, \"EndTime\": 1599443952.853525, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443918.80777}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:12 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=513.200564255 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:12 INFO 139866244298560] #progress_metric: host=algo-1, completed 75 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=59, train loss <loss>=2.64734417353\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:12 INFO 139866244298560] best epoch loss so far\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:12 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/state_6ae55c3f-b95d-474a-8303-f7ee1bb337a9-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.serialize.time\": {\"count\": 1, \"max\": 18.053054809570312, \"sum\": 18.053054809570312, \"min\": 18.053054809570312}}, \"EndTime\": 1599443952.872319, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443952.853588}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:13 INFO 139866244298560] Epoch[60] Batch[0] avg_epoch_loss=2.216748\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=0 train loss <loss>=2.21674799919\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:13 INFO 139866244298560] Epoch[60] Batch[5] avg_epoch_loss=2.147584\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=5 train loss <loss>=2.14758386215\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:13 INFO 139866244298560] Epoch[60] Batch [5]#011Speed: 589.10 samples/sec#011loss=2.147584\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:14 INFO 139866244298560] Epoch[60] Batch[10] avg_epoch_loss=2.127937\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=10 train loss <loss>=2.10436134338\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:14 INFO 139866244298560] Epoch[60] Batch [10]#011Speed: 476.49 samples/sec#011loss=2.104361\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:14 INFO 139866244298560] Epoch[60] Batch[15] avg_epoch_loss=2.328311\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=15 train loss <loss>=2.76913294792\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:14 INFO 139866244298560] Epoch[60] Batch [15]#011Speed: 593.59 samples/sec#011loss=2.769133\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:15 INFO 139866244298560] Epoch[60] Batch[20] avg_epoch_loss=2.427979\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=20 train loss <loss>=2.74691872597\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:15 INFO 139866244298560] Epoch[60] Batch [20]#011Speed: 447.90 samples/sec#011loss=2.746919\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:16 INFO 139866244298560] Epoch[60] Batch[25] avg_epoch_loss=2.504876\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=25 train loss <loss>=2.82784337997\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:16 INFO 139866244298560] Epoch[60] Batch [25]#011Speed: 585.10 samples/sec#011loss=2.827843\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:16 INFO 139866244298560] Epoch[60] Batch[30] avg_epoch_loss=2.533325\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=30 train loss <loss>=2.68126044273\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:16 INFO 139866244298560] Epoch[60] Batch [30]#011Speed: 465.69 samples/sec#011loss=2.681260\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:17 INFO 139866244298560] Epoch[60] Batch[35] avg_epoch_loss=2.511036\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=35 train loss <loss>=2.37284355164\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:17 INFO 139866244298560] Epoch[60] Batch [35]#011Speed: 597.09 samples/sec#011loss=2.372844\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:18 INFO 139866244298560] Epoch[60] Batch[40] avg_epoch_loss=2.494466\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=40 train loss <loss>=2.375157094\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:18 INFO 139866244298560] Epoch[60] Batch [40]#011Speed: 478.19 samples/sec#011loss=2.375157\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:18 INFO 139866244298560] Epoch[60] Batch[45] avg_epoch_loss=2.451205\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=45 train loss <loss>=2.09647054672\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:18 INFO 139866244298560] Epoch[60] Batch [45]#011Speed: 590.71 samples/sec#011loss=2.096471\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:19 INFO 139866244298560] Epoch[60] Batch[50] avg_epoch_loss=2.425210\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=50 train loss <loss>=2.18605690002\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:19 INFO 139866244298560] Epoch[60] Batch [50]#011Speed: 481.70 samples/sec#011loss=2.186057\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:19 INFO 139866244298560] Epoch[60] Batch[55] avg_epoch_loss=2.419664\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=55 train loss <loss>=2.36308779716\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:19 INFO 139866244298560] Epoch[60] Batch [55]#011Speed: 596.52 samples/sec#011loss=2.363088\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:20 INFO 139866244298560] Epoch[60] Batch[60] avg_epoch_loss=2.434920\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=60 train loss <loss>=2.60579295158\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:20 INFO 139866244298560] Epoch[60] Batch [60]#011Speed: 480.81 samples/sec#011loss=2.605793\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:21 INFO 139866244298560] Epoch[60] Batch[65] avg_epoch_loss=2.447975\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=65 train loss <loss>=2.60724143982\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:21 INFO 139866244298560] Epoch[60] Batch [65]#011Speed: 531.37 samples/sec#011loss=2.607241\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:21 INFO 139866244298560] Epoch[60] Batch[70] avg_epoch_loss=2.478688\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=70 train loss <loss>=2.88410596848\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:21 INFO 139866244298560] Epoch[60] Batch [70]#011Speed: 475.34 samples/sec#011loss=2.884106\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:22 INFO 139866244298560] Epoch[60] Batch[75] avg_epoch_loss=2.529323\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=75 train loss <loss>=3.24833950996\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:22 INFO 139866244298560] Epoch[60] Batch [75]#011Speed: 593.67 samples/sec#011loss=3.248340\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:22 INFO 139866244298560] Epoch[60] Batch[80] avg_epoch_loss=2.558032\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=80 train loss <loss>=2.99439740181\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:22 INFO 139866244298560] Epoch[60] Batch [80]#011Speed: 434.94 samples/sec#011loss=2.994397\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:23 INFO 139866244298560] Epoch[60] Batch[85] avg_epoch_loss=2.587290\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=85 train loss <loss>=3.06127490997\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:23 INFO 139866244298560] Epoch[60] Batch [85]#011Speed: 591.26 samples/sec#011loss=3.061275\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:24 INFO 139866244298560] Epoch[60] Batch[90] avg_epoch_loss=2.581611\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=90 train loss <loss>=2.48394088745\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:24 INFO 139866244298560] Epoch[60] Batch [90]#011Speed: 471.89 samples/sec#011loss=2.483941\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:24 INFO 139866244298560] Epoch[60] Batch[95] avg_epoch_loss=2.565454\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=95 train loss <loss>=2.27139625549\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:24 INFO 139866244298560] Epoch[60] Batch [95]#011Speed: 594.38 samples/sec#011loss=2.271396\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:25 INFO 139866244298560] Epoch[60] Batch[100] avg_epoch_loss=2.554252\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=100 train loss <loss>=2.33916356564\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:25 INFO 139866244298560] Epoch[60] Batch [100]#011Speed: 468.53 samples/sec#011loss=2.339164\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:26 INFO 139866244298560] Epoch[60] Batch[105] avg_epoch_loss=2.550907\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=105 train loss <loss>=2.48334026337\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:26 INFO 139866244298560] Epoch[60] Batch [105]#011Speed: 547.19 samples/sec#011loss=2.483340\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:26 INFO 139866244298560] Epoch[60] Batch[110] avg_epoch_loss=2.542095\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=110 train loss <loss>=2.35529141426\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:26 INFO 139866244298560] Epoch[60] Batch [110]#011Speed: 474.66 samples/sec#011loss=2.355291\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:27 INFO 139866244298560] Epoch[60] Batch[115] avg_epoch_loss=2.533268\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=115 train loss <loss>=2.33730602264\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:27 INFO 139866244298560] Epoch[60] Batch [115]#011Speed: 596.68 samples/sec#011loss=2.337306\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:27 INFO 139866244298560] Epoch[60] Batch[120] avg_epoch_loss=2.531857\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=120 train loss <loss>=2.49910445213\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:27 INFO 139866244298560] Epoch[60] Batch [120]#011Speed: 469.62 samples/sec#011loss=2.499104\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:28 INFO 139866244298560] Epoch[60] Batch[125] avg_epoch_loss=2.526351\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=125 train loss <loss>=2.3931060791\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:28 INFO 139866244298560] Epoch[60] Batch [125]#011Speed: 591.58 samples/sec#011loss=2.393106\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:29 INFO 139866244298560] Epoch[60] Batch[130] avg_epoch_loss=2.543732\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=130 train loss <loss>=2.98173146248\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:29 INFO 139866244298560] Epoch[60] Batch [130]#011Speed: 479.43 samples/sec#011loss=2.981731\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:29 INFO 139866244298560] Epoch[60] Batch[135] avg_epoch_loss=2.557297\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=135 train loss <loss>=2.91270666122\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:29 INFO 139866244298560] Epoch[60] Batch [135]#011Speed: 484.91 samples/sec#011loss=2.912707\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:30 INFO 139866244298560] Epoch[60] Batch[140] avg_epoch_loss=2.569611\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=140 train loss <loss>=2.90454449654\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:30 INFO 139866244298560] Epoch[60] Batch [140]#011Speed: 580.15 samples/sec#011loss=2.904544\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:31 INFO 139866244298560] Epoch[60] Batch[145] avg_epoch_loss=2.564293\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=145 train loss <loss>=2.41433501244\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:31 INFO 139866244298560] Epoch[60] Batch [145]#011Speed: 439.03 samples/sec#011loss=2.414335\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:31 INFO 139866244298560] Epoch[60] Batch[150] avg_epoch_loss=2.554163\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=150 train loss <loss>=2.25838024616\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:31 INFO 139866244298560] Epoch[60] Batch [150]#011Speed: 594.22 samples/sec#011loss=2.258380\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:32 INFO 139866244298560] Epoch[60] Batch[155] avg_epoch_loss=2.549122\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=155 train loss <loss>=2.39686870575\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:32 INFO 139866244298560] Epoch[60] Batch [155]#011Speed: 480.16 samples/sec#011loss=2.396869\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:32 INFO 139866244298560] Epoch[60] Batch[160] avg_epoch_loss=2.543114\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=160 train loss <loss>=2.35568461418\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:32 INFO 139866244298560] Epoch[60] Batch [160]#011Speed: 588.27 samples/sec#011loss=2.355685\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:33 INFO 139866244298560] Epoch[60] Batch[165] avg_epoch_loss=2.534926\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=165 train loss <loss>=2.27126786709\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:33 INFO 139866244298560] Epoch[60] Batch [165]#011Speed: 474.15 samples/sec#011loss=2.271268\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:34 INFO 139866244298560] Epoch[60] Batch[170] avg_epoch_loss=2.534200\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=170 train loss <loss>=2.51009526253\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:34 INFO 139866244298560] Epoch[60] Batch [170]#011Speed: 588.98 samples/sec#011loss=2.510095\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:34 INFO 139866244298560] Epoch[60] Batch[175] avg_epoch_loss=2.549751\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=175 train loss <loss>=3.08158392906\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:34 INFO 139866244298560] Epoch[60] Batch [175]#011Speed: 470.68 samples/sec#011loss=3.081584\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:35 INFO 139866244298560] Epoch[60] Batch[180] avg_epoch_loss=2.559310\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=180 train loss <loss>=2.89578075409\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:35 INFO 139866244298560] Epoch[60] Batch [180]#011Speed: 586.55 samples/sec#011loss=2.895781\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:35 INFO 139866244298560] Epoch[60] Batch[185] avg_epoch_loss=2.585752\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=185 train loss <loss>=3.54297289848\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:35 INFO 139866244298560] Epoch[60] Batch [185]#011Speed: 440.63 samples/sec#011loss=3.542973\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:36 INFO 139866244298560] Epoch[60] Batch[190] avg_epoch_loss=2.608513\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=190 train loss <loss>=3.4552172184\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:36 INFO 139866244298560] Epoch[60] Batch [190]#011Speed: 576.40 samples/sec#011loss=3.455217\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:37 INFO 139866244298560] Epoch[60] Batch[195] avg_epoch_loss=2.627124\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=195 train loss <loss>=3.33805189133\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:37 INFO 139866244298560] Epoch[60] Batch [195]#011Speed: 476.98 samples/sec#011loss=3.338052\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:37 INFO 139866244298560] Epoch[60] Batch[200] avg_epoch_loss=2.639086\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=200 train loss <loss>=3.10801687241\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:37 INFO 139866244298560] Epoch[60] Batch [200]#011Speed: 593.52 samples/sec#011loss=3.108017\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:38 INFO 139866244298560] Epoch[60] Batch[205] avg_epoch_loss=2.640503\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=205 train loss <loss>=2.69747056961\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:38 INFO 139866244298560] Epoch[60] Batch [205]#011Speed: 459.11 samples/sec#011loss=2.697471\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:39 INFO 139866244298560] Epoch[60] Batch[210] avg_epoch_loss=2.641978\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=210 train loss <loss>=2.70273160934\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:39 INFO 139866244298560] Epoch[60] Batch [210]#011Speed: 474.53 samples/sec#011loss=2.702732\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:39 INFO 139866244298560] Epoch[60] Batch[215] avg_epoch_loss=2.633940\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=215 train loss <loss>=2.29474484921\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:39 INFO 139866244298560] Epoch[60] Batch [215]#011Speed: 592.59 samples/sec#011loss=2.294745\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:40 INFO 139866244298560] Epoch[60] Batch[220] avg_epoch_loss=2.631776\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=220 train loss <loss>=2.53827433586\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:40 INFO 139866244298560] Epoch[60] Batch [220]#011Speed: 474.46 samples/sec#011loss=2.538274\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:40 INFO 139866244298560] Epoch[60] Batch[225] avg_epoch_loss=2.628652\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=225 train loss <loss>=2.49057164192\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:40 INFO 139866244298560] Epoch[60] Batch [225]#011Speed: 591.65 samples/sec#011loss=2.490572\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:41 INFO 139866244298560] Epoch[60] Batch[230] avg_epoch_loss=2.628659\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=230 train loss <loss>=2.62898712158\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:41 INFO 139866244298560] Epoch[60] Batch [230]#011Speed: 442.39 samples/sec#011loss=2.628987\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:42 INFO 139866244298560] Epoch[60] Batch[235] avg_epoch_loss=2.634819\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=235 train loss <loss>=2.91941857338\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:42 INFO 139866244298560] Epoch[60] Batch [235]#011Speed: 589.80 samples/sec#011loss=2.919419\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:42 INFO 139866244298560] Epoch[60] Batch[240] avg_epoch_loss=2.647557\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=240 train loss <loss>=3.24878029823\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:42 INFO 139866244298560] Epoch[60] Batch [240]#011Speed: 473.88 samples/sec#011loss=3.248780\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:43 INFO 139866244298560] Epoch[60] Batch[245] avg_epoch_loss=2.663835\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=245 train loss <loss>=3.44844942093\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:43 INFO 139866244298560] Epoch[60] Batch [245]#011Speed: 589.35 samples/sec#011loss=3.448449\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:44 INFO 139866244298560] Epoch[60] Batch[250] avg_epoch_loss=2.674139\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=250 train loss <loss>=3.18107156754\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:44 INFO 139866244298560] Epoch[60] Batch [250]#011Speed: 477.87 samples/sec#011loss=3.181072\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:44 INFO 139866244298560] Epoch[60] Batch[255] avg_epoch_loss=2.681177\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=255 train loss <loss>=3.03446583748\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:44 INFO 139866244298560] Epoch[60] Batch [255]#011Speed: 589.53 samples/sec#011loss=3.034466\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:45 INFO 139866244298560] Epoch[60] Batch[260] avg_epoch_loss=2.682801\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=260 train loss <loss>=2.76597056389\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:45 INFO 139866244298560] Epoch[60] Batch [260]#011Speed: 472.60 samples/sec#011loss=2.765971\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:45 INFO 139866244298560] Epoch[60] Batch[265] avg_epoch_loss=2.677349\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, batch=265 train loss <loss>=2.39275484085\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:45 INFO 139866244298560] Epoch[60] Batch [265]#011Speed: 593.24 samples/sec#011loss=2.392755\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:46 INFO 139866244298560] processed a total of 17259 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33438.222885131836, \"sum\": 33438.222885131836, \"min\": 33438.222885131836}}, \"EndTime\": 1599443986.310663, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443952.87238}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:46 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=516.143517566 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:46 INFO 139866244298560] #progress_metric: host=algo-1, completed 76 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=60, train loss <loss>=2.68092023752\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:46 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:46 INFO 139866244298560] Epoch[61] Batch[0] avg_epoch_loss=2.237562\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=0 train loss <loss>=2.23756170273\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:47 INFO 139866244298560] Epoch[61] Batch[5] avg_epoch_loss=2.196125\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=5 train loss <loss>=2.19612510999\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:47 INFO 139866244298560] Epoch[61] Batch [5]#011Speed: 589.60 samples/sec#011loss=2.196125\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:47 INFO 139866244298560] Epoch[61] Batch[10] avg_epoch_loss=2.123267\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=10 train loss <loss>=2.0358379364\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:47 INFO 139866244298560] Epoch[61] Batch [10]#011Speed: 467.35 samples/sec#011loss=2.035838\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:48 INFO 139866244298560] Epoch[61] Batch[15] avg_epoch_loss=2.275300\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=15 train loss <loss>=2.60977311134\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:48 INFO 139866244298560] Epoch[61] Batch [15]#011Speed: 596.04 samples/sec#011loss=2.609773\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:49 INFO 139866244298560] Epoch[61] Batch[20] avg_epoch_loss=2.379861\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=20 train loss <loss>=2.71445407867\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:49 INFO 139866244298560] Epoch[61] Batch [20]#011Speed: 479.49 samples/sec#011loss=2.714454\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:49 INFO 139866244298560] Epoch[61] Batch[25] avg_epoch_loss=2.459920\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=25 train loss <loss>=2.79617023468\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:49 INFO 139866244298560] Epoch[61] Batch [25]#011Speed: 594.01 samples/sec#011loss=2.796170\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:50 INFO 139866244298560] Epoch[61] Batch[30] avg_epoch_loss=2.483237\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=30 train loss <loss>=2.60448665619\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:50 INFO 139866244298560] Epoch[61] Batch [30]#011Speed: 471.18 samples/sec#011loss=2.604487\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:50 INFO 139866244298560] Epoch[61] Batch[35] avg_epoch_loss=2.510058\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=35 train loss <loss>=2.6763481617\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:50 INFO 139866244298560] Epoch[61] Batch [35]#011Speed: 591.16 samples/sec#011loss=2.676348\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:51 INFO 139866244298560] Epoch[61] Batch[40] avg_epoch_loss=2.501397\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=40 train loss <loss>=2.43903260231\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:51 INFO 139866244298560] Epoch[61] Batch [40]#011Speed: 451.83 samples/sec#011loss=2.439033\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:52 INFO 139866244298560] Epoch[61] Batch[45] avg_epoch_loss=2.495403\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=45 train loss <loss>=2.44625282288\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:52 INFO 139866244298560] Epoch[61] Batch [45]#011Speed: 572.03 samples/sec#011loss=2.446253\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:52 INFO 139866244298560] Epoch[61] Batch[50] avg_epoch_loss=2.478982\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=50 train loss <loss>=2.3279074192\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:52 INFO 139866244298560] Epoch[61] Batch [50]#011Speed: 428.08 samples/sec#011loss=2.327907\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:53 INFO 139866244298560] Epoch[61] Batch[55] avg_epoch_loss=2.481119\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=55 train loss <loss>=2.50292363167\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:53 INFO 139866244298560] Epoch[61] Batch [55]#011Speed: 592.59 samples/sec#011loss=2.502924\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:54 INFO 139866244298560] Epoch[61] Batch[60] avg_epoch_loss=2.483056\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=60 train loss <loss>=2.50474796295\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:54 INFO 139866244298560] Epoch[61] Batch [60]#011Speed: 471.45 samples/sec#011loss=2.504748\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:54 INFO 139866244298560] Epoch[61] Batch[65] avg_epoch_loss=2.486827\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=65 train loss <loss>=2.53282966614\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:54 INFO 139866244298560] Epoch[61] Batch [65]#011Speed: 597.08 samples/sec#011loss=2.532830\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:55 INFO 139866244298560] Epoch[61] Batch[70] avg_epoch_loss=2.523864\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=70 train loss <loss>=3.01276111603\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:55 INFO 139866244298560] Epoch[61] Batch [70]#011Speed: 478.42 samples/sec#011loss=3.012761\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:55 INFO 139866244298560] Epoch[61] Batch[75] avg_epoch_loss=2.565800\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=75 train loss <loss>=3.16128811836\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:55 INFO 139866244298560] Epoch[61] Batch [75]#011Speed: 592.85 samples/sec#011loss=3.161288\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:56 INFO 139866244298560] Epoch[61] Batch[80] avg_epoch_loss=2.578355\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=80 train loss <loss>=2.76918778419\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:56 INFO 139866244298560] Epoch[61] Batch [80]#011Speed: 487.12 samples/sec#011loss=2.769188\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:57 INFO 139866244298560] Epoch[61] Batch[85] avg_epoch_loss=2.586085\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=85 train loss <loss>=2.71131157875\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:57 INFO 139866244298560] Epoch[61] Batch [85]#011Speed: 426.02 samples/sec#011loss=2.711312\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:57 INFO 139866244298560] Epoch[61] Batch[90] avg_epoch_loss=2.564775\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=90 train loss <loss>=2.19823403358\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:57 INFO 139866244298560] Epoch[61] Batch [90]#011Speed: 592.09 samples/sec#011loss=2.198234\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:58 INFO 139866244298560] Epoch[61] Batch[95] avg_epoch_loss=2.554906\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=95 train loss <loss>=2.37529244423\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:58 INFO 139866244298560] Epoch[61] Batch [95]#011Speed: 467.41 samples/sec#011loss=2.375292\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:59 INFO 139866244298560] Epoch[61] Batch[100] avg_epoch_loss=2.543353\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=100 train loss <loss>=2.32154574394\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:59 INFO 139866244298560] Epoch[61] Batch [100]#011Speed: 590.01 samples/sec#011loss=2.321546\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:59 INFO 139866244298560] Epoch[61] Batch[105] avg_epoch_loss=2.537900\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=105 train loss <loss>=2.42774207592\u001b[0m\n",
      "\u001b[34m[09/07/2020 01:59:59 INFO 139866244298560] Epoch[61] Batch [105]#011Speed: 480.64 samples/sec#011loss=2.427742\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:00 INFO 139866244298560] Epoch[61] Batch[110] avg_epoch_loss=2.521794\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=110 train loss <loss>=2.1803463459\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:00 INFO 139866244298560] Epoch[61] Batch [110]#011Speed: 586.68 samples/sec#011loss=2.180346\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:00 INFO 139866244298560] Epoch[61] Batch[115] avg_epoch_loss=2.524498\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=115 train loss <loss>=2.5845364809\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:00 INFO 139866244298560] Epoch[61] Batch [115]#011Speed: 474.61 samples/sec#011loss=2.584536\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:01 INFO 139866244298560] Epoch[61] Batch[120] avg_epoch_loss=2.540408\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=120 train loss <loss>=2.90950255394\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:01 INFO 139866244298560] Epoch[61] Batch [120]#011Speed: 564.36 samples/sec#011loss=2.909503\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:02 INFO 139866244298560] Epoch[61] Batch[125] avg_epoch_loss=2.564376\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=125 train loss <loss>=3.14441370964\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:02 INFO 139866244298560] Epoch[61] Batch [125]#011Speed: 478.87 samples/sec#011loss=3.144414\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:02 INFO 139866244298560] Epoch[61] Batch[130] avg_epoch_loss=2.584021\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=130 train loss <loss>=3.07908363342\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:02 INFO 139866244298560] Epoch[61] Batch [130]#011Speed: 590.05 samples/sec#011loss=3.079084\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:03 INFO 139866244298560] Epoch[61] Batch[135] avg_epoch_loss=2.571783\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=135 train loss <loss>=2.25113735199\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:03 INFO 139866244298560] Epoch[61] Batch [135]#011Speed: 469.42 samples/sec#011loss=2.251137\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:03 INFO 139866244298560] Epoch[61] Batch[140] avg_epoch_loss=2.563502\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=140 train loss <loss>=2.33827233315\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:03 INFO 139866244298560] Epoch[61] Batch [140]#011Speed: 586.39 samples/sec#011loss=2.338272\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:04 INFO 139866244298560] Epoch[61] Batch[145] avg_epoch_loss=2.549275\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=145 train loss <loss>=2.1480618\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:04 INFO 139866244298560] Epoch[61] Batch [145]#011Speed: 477.60 samples/sec#011loss=2.148062\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:05 INFO 139866244298560] Epoch[61] Batch[150] avg_epoch_loss=2.534497\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=150 train loss <loss>=2.1029910326\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:05 INFO 139866244298560] Epoch[61] Batch [150]#011Speed: 591.75 samples/sec#011loss=2.102991\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:05 INFO 139866244298560] Epoch[61] Batch[155] avg_epoch_loss=2.535055\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=155 train loss <loss>=2.5518805027\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:05 INFO 139866244298560] Epoch[61] Batch [155]#011Speed: 468.71 samples/sec#011loss=2.551881\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:06 INFO 139866244298560] Epoch[61] Batch[160] avg_epoch_loss=2.534509\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=160 train loss <loss>=2.51749458313\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:06 INFO 139866244298560] Epoch[61] Batch [160]#011Speed: 472.62 samples/sec#011loss=2.517495\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:07 INFO 139866244298560] Epoch[61] Batch[165] avg_epoch_loss=2.536298\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=165 train loss <loss>=2.59388852119\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:07 INFO 139866244298560] Epoch[61] Batch [165]#011Speed: 586.07 samples/sec#011loss=2.593889\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:07 INFO 139866244298560] Epoch[61] Batch[170] avg_epoch_loss=2.540572\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=170 train loss <loss>=2.68248510361\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:07 INFO 139866244298560] Epoch[61] Batch [170]#011Speed: 470.25 samples/sec#011loss=2.682485\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:08 INFO 139866244298560] Epoch[61] Batch[175] avg_epoch_loss=2.557647\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=175 train loss <loss>=3.14160442352\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:08 INFO 139866244298560] Epoch[61] Batch [175]#011Speed: 581.20 samples/sec#011loss=3.141604\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:08 INFO 139866244298560] Epoch[61] Batch[180] avg_epoch_loss=2.579994\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=180 train loss <loss>=3.36660404205\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:08 INFO 139866244298560] Epoch[61] Batch [180]#011Speed: 474.41 samples/sec#011loss=3.366604\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:09 INFO 139866244298560] Epoch[61] Batch[185] avg_epoch_loss=2.601819\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=185 train loss <loss>=3.39187755585\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:09 INFO 139866244298560] Epoch[61] Batch [185]#011Speed: 591.39 samples/sec#011loss=3.391878\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:10 INFO 139866244298560] Epoch[61] Batch[190] avg_epoch_loss=2.611600\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=190 train loss <loss>=2.97545247078\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:10 INFO 139866244298560] Epoch[61] Batch [190]#011Speed: 475.93 samples/sec#011loss=2.975452\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:10 INFO 139866244298560] Epoch[61] Batch[195] avg_epoch_loss=2.612391\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=195 train loss <loss>=2.64261779785\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:10 INFO 139866244298560] Epoch[61] Batch [195]#011Speed: 586.14 samples/sec#011loss=2.642618\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:11 INFO 139866244298560] Epoch[61] Batch[200] avg_epoch_loss=2.609084\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=200 train loss <loss>=2.47943634987\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:11 INFO 139866244298560] Epoch[61] Batch [200]#011Speed: 473.23 samples/sec#011loss=2.479436\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:11 INFO 139866244298560] Epoch[61] Batch[205] avg_epoch_loss=2.608465\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=205 train loss <loss>=2.58358974457\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:11 INFO 139866244298560] Epoch[61] Batch [205]#011Speed: 595.03 samples/sec#011loss=2.583590\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:12 INFO 139866244298560] Epoch[61] Batch[210] avg_epoch_loss=2.610153\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=210 train loss <loss>=2.67971315384\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:12 INFO 139866244298560] Epoch[61] Batch [210]#011Speed: 471.92 samples/sec#011loss=2.679713\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:13 INFO 139866244298560] Epoch[61] Batch[215] avg_epoch_loss=2.608668\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=215 train loss <loss>=2.54597563744\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:13 INFO 139866244298560] Epoch[61] Batch [215]#011Speed: 590.93 samples/sec#011loss=2.545976\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:13 INFO 139866244298560] Epoch[61] Batch[220] avg_epoch_loss=2.604019\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=220 train loss <loss>=2.40318961143\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:13 INFO 139866244298560] Epoch[61] Batch [220]#011Speed: 473.74 samples/sec#011loss=2.403190\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:14 INFO 139866244298560] Epoch[61] Batch[225] avg_epoch_loss=2.606377\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=225 train loss <loss>=2.71060709953\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:14 INFO 139866244298560] Epoch[61] Batch [225]#011Speed: 587.35 samples/sec#011loss=2.710607\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:15 INFO 139866244298560] Epoch[61] Batch[230] avg_epoch_loss=2.613024\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=230 train loss <loss>=2.91348900795\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:15 INFO 139866244298560] Epoch[61] Batch [230]#011Speed: 481.29 samples/sec#011loss=2.913489\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:15 INFO 139866244298560] Epoch[61] Batch[235] avg_epoch_loss=2.632325\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=235 train loss <loss>=3.52401223183\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:15 INFO 139866244298560] Epoch[61] Batch [235]#011Speed: 590.65 samples/sec#011loss=3.524012\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:16 INFO 139866244298560] Epoch[61] Batch[240] avg_epoch_loss=2.649638\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=240 train loss <loss>=3.46682786942\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:16 INFO 139866244298560] Epoch[61] Batch [240]#011Speed: 479.29 samples/sec#011loss=3.466828\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:16 INFO 139866244298560] Epoch[61] Batch[245] avg_epoch_loss=2.664089\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=245 train loss <loss>=3.36060347557\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:16 INFO 139866244298560] Epoch[61] Batch [245]#011Speed: 593.32 samples/sec#011loss=3.360603\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:17 INFO 139866244298560] Epoch[61] Batch[250] avg_epoch_loss=2.668664\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=250 train loss <loss>=2.89377055168\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:17 INFO 139866244298560] Epoch[61] Batch [250]#011Speed: 476.79 samples/sec#011loss=2.893771\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:18 INFO 139866244298560] Epoch[61] Batch[255] avg_epoch_loss=2.662112\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=255 train loss <loss>=2.33321137428\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:18 INFO 139866244298560] Epoch[61] Batch [255]#011Speed: 582.60 samples/sec#011loss=2.333211\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:18 INFO 139866244298560] Epoch[61] Batch[260] avg_epoch_loss=2.660962\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=260 train loss <loss>=2.60204296112\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:18 INFO 139866244298560] Epoch[61] Batch [260]#011Speed: 480.12 samples/sec#011loss=2.602043\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:19 INFO 139866244298560] Epoch[61] Batch[265] avg_epoch_loss=2.654031\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=265 train loss <loss>=2.2922326088\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:19 INFO 139866244298560] Epoch[61] Batch [265]#011Speed: 589.31 samples/sec#011loss=2.292233\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:19 INFO 139866244298560] Epoch[61] Batch[270] avg_epoch_loss=2.676155\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, batch=270 train loss <loss>=3.85319290161\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:19 INFO 139866244298560] Epoch[61] Batch [270]#011Speed: 562.00 samples/sec#011loss=3.853193\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:19 INFO 139866244298560] processed a total of 17282 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33478.70397567749, \"sum\": 33478.70397567749, \"min\": 33478.70397567749}}, \"EndTime\": 1599444019.790202, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599443986.310779}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:19 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=516.207163959 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:19 INFO 139866244298560] #progress_metric: host=algo-1, completed 77 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=61, train loss <loss>=2.67615538989\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:19 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:20 INFO 139866244298560] Epoch[62] Batch[0] avg_epoch_loss=2.107007\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=0 train loss <loss>=2.10700726509\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:20 INFO 139866244298560] Epoch[62] Batch[5] avg_epoch_loss=2.045854\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=5 train loss <loss>=2.04585419099\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:20 INFO 139866244298560] Epoch[62] Batch [5]#011Speed: 587.04 samples/sec#011loss=2.045854\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:21 INFO 139866244298560] Epoch[62] Batch[10] avg_epoch_loss=2.065113\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=10 train loss <loss>=2.08822426796\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:21 INFO 139866244298560] Epoch[62] Batch [10]#011Speed: 468.47 samples/sec#011loss=2.088224\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:21 INFO 139866244298560] Epoch[62] Batch[15] avg_epoch_loss=2.245694\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=15 train loss <loss>=2.6429713726\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:21 INFO 139866244298560] Epoch[62] Batch [15]#011Speed: 594.73 samples/sec#011loss=2.642971\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:22 INFO 139866244298560] Epoch[62] Batch[20] avg_epoch_loss=2.356184\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=20 train loss <loss>=2.70975418091\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:22 INFO 139866244298560] Epoch[62] Batch [20]#011Speed: 483.92 samples/sec#011loss=2.709754\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:23 INFO 139866244298560] Epoch[62] Batch[25] avg_epoch_loss=2.432216\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=25 train loss <loss>=2.75154967308\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:23 INFO 139866244298560] Epoch[62] Batch [25]#011Speed: 519.95 samples/sec#011loss=2.751550\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:23 INFO 139866244298560] Epoch[62] Batch[30] avg_epoch_loss=2.478910\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=30 train loss <loss>=2.72171683311\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:23 INFO 139866244298560] Epoch[62] Batch [30]#011Speed: 478.71 samples/sec#011loss=2.721717\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:24 INFO 139866244298560] Epoch[62] Batch[35] avg_epoch_loss=2.493935\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=35 train loss <loss>=2.58708944321\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:24 INFO 139866244298560] Epoch[62] Batch [35]#011Speed: 591.28 samples/sec#011loss=2.587089\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:24 INFO 139866244298560] Epoch[62] Batch[40] avg_epoch_loss=2.488784\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=40 train loss <loss>=2.45170025826\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:24 INFO 139866244298560] Epoch[62] Batch [40]#011Speed: 476.30 samples/sec#011loss=2.451700\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:25 INFO 139866244298560] Epoch[62] Batch[45] avg_epoch_loss=2.494082\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=45 train loss <loss>=2.53752131462\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:25 INFO 139866244298560] Epoch[62] Batch [45]#011Speed: 589.50 samples/sec#011loss=2.537521\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:26 INFO 139866244298560] Epoch[62] Batch[50] avg_epoch_loss=2.482715\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=50 train loss <loss>=2.37814393044\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:26 INFO 139866244298560] Epoch[62] Batch [50]#011Speed: 473.68 samples/sec#011loss=2.378144\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:26 INFO 139866244298560] Epoch[62] Batch[55] avg_epoch_loss=2.445180\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=55 train loss <loss>=2.06232304573\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:26 INFO 139866244298560] Epoch[62] Batch [55]#011Speed: 593.29 samples/sec#011loss=2.062323\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:27 INFO 139866244298560] Epoch[62] Batch[60] avg_epoch_loss=2.427542\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=60 train loss <loss>=2.2299888134\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:27 INFO 139866244298560] Epoch[62] Batch [60]#011Speed: 478.96 samples/sec#011loss=2.229989\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:27 INFO 139866244298560] Epoch[62] Batch[65] avg_epoch_loss=2.441043\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=65 train loss <loss>=2.60576562881\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:27 INFO 139866244298560] Epoch[62] Batch [65]#011Speed: 593.37 samples/sec#011loss=2.605766\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:28 INFO 139866244298560] Epoch[62] Batch[70] avg_epoch_loss=2.489226\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=70 train loss <loss>=3.12524161339\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:28 INFO 139866244298560] Epoch[62] Batch [70]#011Speed: 476.14 samples/sec#011loss=3.125242\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:29 INFO 139866244298560] Epoch[62] Batch[75] avg_epoch_loss=2.537007\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=75 train loss <loss>=3.21548657417\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:29 INFO 139866244298560] Epoch[62] Batch [75]#011Speed: 591.99 samples/sec#011loss=3.215487\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:29 INFO 139866244298560] Epoch[62] Batch[80] avg_epoch_loss=2.579141\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=80 train loss <loss>=3.21958255768\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:29 INFO 139866244298560] Epoch[62] Batch [80]#011Speed: 478.66 samples/sec#011loss=3.219583\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:30 INFO 139866244298560] Epoch[62] Batch[85] avg_epoch_loss=2.610946\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=85 train loss <loss>=3.12618031502\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:30 INFO 139866244298560] Epoch[62] Batch [85]#011Speed: 593.47 samples/sec#011loss=3.126180\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:31 INFO 139866244298560] Epoch[62] Batch[90] avg_epoch_loss=2.608886\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=90 train loss <loss>=2.57346339226\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:31 INFO 139866244298560] Epoch[62] Batch [90]#011Speed: 464.94 samples/sec#011loss=2.573463\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:31 INFO 139866244298560] Epoch[62] Batch[95] avg_epoch_loss=2.602644\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=95 train loss <loss>=2.4890381813\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:31 INFO 139866244298560] Epoch[62] Batch [95]#011Speed: 597.27 samples/sec#011loss=2.489038\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:32 INFO 139866244298560] Epoch[62] Batch[100] avg_epoch_loss=2.601980\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=100 train loss <loss>=2.58922324181\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:32 INFO 139866244298560] Epoch[62] Batch [100]#011Speed: 477.68 samples/sec#011loss=2.589223\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:32 INFO 139866244298560] Epoch[62] Batch[105] avg_epoch_loss=2.603977\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=105 train loss <loss>=2.64431977272\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:32 INFO 139866244298560] Epoch[62] Batch [105]#011Speed: 595.30 samples/sec#011loss=2.644320\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:33 INFO 139866244298560] Epoch[62] Batch[110] avg_epoch_loss=2.591369\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=110 train loss <loss>=2.32408704758\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:33 INFO 139866244298560] Epoch[62] Batch [110]#011Speed: 472.88 samples/sec#011loss=2.324087\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:34 INFO 139866244298560] Epoch[62] Batch[115] avg_epoch_loss=2.578810\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=115 train loss <loss>=2.29999341965\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:34 INFO 139866244298560] Epoch[62] Batch [115]#011Speed: 590.73 samples/sec#011loss=2.299993\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:34 INFO 139866244298560] Epoch[62] Batch[120] avg_epoch_loss=2.582640\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=120 train loss <loss>=2.6714963913\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:34 INFO 139866244298560] Epoch[62] Batch [120]#011Speed: 471.17 samples/sec#011loss=2.671496\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:35 INFO 139866244298560] Epoch[62] Batch[125] avg_epoch_loss=2.586766\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=125 train loss <loss>=2.68661727905\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:35 INFO 139866244298560] Epoch[62] Batch [125]#011Speed: 584.63 samples/sec#011loss=2.686617\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:35 INFO 139866244298560] Epoch[62] Batch[130] avg_epoch_loss=2.602159\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=130 train loss <loss>=2.99005441666\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:35 INFO 139866244298560] Epoch[62] Batch [130]#011Speed: 474.39 samples/sec#011loss=2.990054\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:36 INFO 139866244298560] Epoch[62] Batch[135] avg_epoch_loss=2.610484\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=135 train loss <loss>=2.82859520912\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:36 INFO 139866244298560] Epoch[62] Batch [135]#011Speed: 584.53 samples/sec#011loss=2.828595\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:37 INFO 139866244298560] Epoch[62] Batch[140] avg_epoch_loss=2.614289\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=140 train loss <loss>=2.71778540611\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:37 INFO 139866244298560] Epoch[62] Batch [140]#011Speed: 473.32 samples/sec#011loss=2.717785\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:37 INFO 139866244298560] Epoch[62] Batch[145] avg_epoch_loss=2.615356\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=145 train loss <loss>=2.64546995163\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:37 INFO 139866244298560] Epoch[62] Batch [145]#011Speed: 596.82 samples/sec#011loss=2.645470\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:38 INFO 139866244298560] Epoch[62] Batch[150] avg_epoch_loss=2.613754\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=150 train loss <loss>=2.56694846153\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:38 INFO 139866244298560] Epoch[62] Batch [150]#011Speed: 468.46 samples/sec#011loss=2.566948\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:39 INFO 139866244298560] Epoch[62] Batch[155] avg_epoch_loss=2.606397\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=155 train loss <loss>=2.38423810005\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:39 INFO 139866244298560] Epoch[62] Batch [155]#011Speed: 476.88 samples/sec#011loss=2.384238\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:39 INFO 139866244298560] Epoch[62] Batch[160] avg_epoch_loss=2.598135\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=160 train loss <loss>=2.34034199715\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:39 INFO 139866244298560] Epoch[62] Batch [160]#011Speed: 592.34 samples/sec#011loss=2.340342\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:40 INFO 139866244298560] Epoch[62] Batch[165] avg_epoch_loss=2.588772\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=165 train loss <loss>=2.28727827072\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:40 INFO 139866244298560] Epoch[62] Batch [165]#011Speed: 478.92 samples/sec#011loss=2.287278\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:40 INFO 139866244298560] Epoch[62] Batch[170] avg_epoch_loss=2.581781\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=170 train loss <loss>=2.34970378876\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:40 INFO 139866244298560] Epoch[62] Batch [170]#011Speed: 588.99 samples/sec#011loss=2.349704\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:41 INFO 139866244298560] Epoch[62] Batch[175] avg_epoch_loss=2.580020\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=175 train loss <loss>=2.51979112625\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:41 INFO 139866244298560] Epoch[62] Batch [175]#011Speed: 474.16 samples/sec#011loss=2.519791\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:41 INFO 139866244298560] Epoch[62] Batch[180] avg_epoch_loss=2.580465\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=180 train loss <loss>=2.59613881111\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:41 INFO 139866244298560] Epoch[62] Batch [180]#011Speed: 594.69 samples/sec#011loss=2.596139\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:42 INFO 139866244298560] Epoch[62] Batch[185] avg_epoch_loss=2.588853\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=185 train loss <loss>=2.89249105453\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:42 INFO 139866244298560] Epoch[62] Batch [185]#011Speed: 486.63 samples/sec#011loss=2.892491\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:43 INFO 139866244298560] Epoch[62] Batch[190] avg_epoch_loss=2.601959\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=190 train loss <loss>=3.08950095177\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:43 INFO 139866244298560] Epoch[62] Batch [190]#011Speed: 586.00 samples/sec#011loss=3.089501\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:43 INFO 139866244298560] Epoch[62] Batch[195] avg_epoch_loss=2.623552\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=195 train loss <loss>=3.44837999344\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:43 INFO 139866244298560] Epoch[62] Batch [195]#011Speed: 478.55 samples/sec#011loss=3.448380\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:44 INFO 139866244298560] Epoch[62] Batch[200] avg_epoch_loss=2.646124\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=200 train loss <loss>=3.53096241951\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:44 INFO 139866244298560] Epoch[62] Batch [200]#011Speed: 592.71 samples/sec#011loss=3.530962\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:45 INFO 139866244298560] Epoch[62] Batch[205] avg_epoch_loss=2.649003\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=205 train loss <loss>=2.76473608017\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:45 INFO 139866244298560] Epoch[62] Batch [205]#011Speed: 475.15 samples/sec#011loss=2.764736\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:45 INFO 139866244298560] Epoch[62] Batch[210] avg_epoch_loss=2.655224\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=210 train loss <loss>=2.91153116226\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:45 INFO 139866244298560] Epoch[62] Batch [210]#011Speed: 482.34 samples/sec#011loss=2.911531\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:46 INFO 139866244298560] Epoch[62] Batch[215] avg_epoch_loss=2.646626\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=215 train loss <loss>=2.28381314278\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:46 INFO 139866244298560] Epoch[62] Batch [215]#011Speed: 587.55 samples/sec#011loss=2.283813\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:46 INFO 139866244298560] Epoch[62] Batch[220] avg_epoch_loss=2.640066\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=220 train loss <loss>=2.35663490295\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:46 INFO 139866244298560] Epoch[62] Batch [220]#011Speed: 476.66 samples/sec#011loss=2.356635\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:47 INFO 139866244298560] Epoch[62] Batch[225] avg_epoch_loss=2.637199\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=225 train loss <loss>=2.51050481796\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:47 INFO 139866244298560] Epoch[62] Batch [225]#011Speed: 593.04 samples/sec#011loss=2.510505\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:48 INFO 139866244298560] Epoch[62] Batch[230] avg_epoch_loss=2.636459\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=230 train loss <loss>=2.60300989151\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:48 INFO 139866244298560] Epoch[62] Batch [230]#011Speed: 475.99 samples/sec#011loss=2.603010\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:48 INFO 139866244298560] Epoch[62] Batch[235] avg_epoch_loss=2.637975\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=235 train loss <loss>=2.70800232887\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:48 INFO 139866244298560] Epoch[62] Batch [235]#011Speed: 589.05 samples/sec#011loss=2.708002\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:49 INFO 139866244298560] Epoch[62] Batch[240] avg_epoch_loss=2.649905\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=240 train loss <loss>=3.21299271584\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:49 INFO 139866244298560] Epoch[62] Batch [240]#011Speed: 487.31 samples/sec#011loss=3.212993\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:49 INFO 139866244298560] Epoch[62] Batch[245] avg_epoch_loss=2.666698\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=245 train loss <loss>=3.4761534214\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:49 INFO 139866244298560] Epoch[62] Batch [245]#011Speed: 590.32 samples/sec#011loss=3.476153\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:50 INFO 139866244298560] Epoch[62] Batch[250] avg_epoch_loss=2.680830\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=250 train loss <loss>=3.37612185478\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:50 INFO 139866244298560] Epoch[62] Batch [250]#011Speed: 477.54 samples/sec#011loss=3.376122\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:51 INFO 139866244298560] Epoch[62] Batch[255] avg_epoch_loss=2.690405\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=255 train loss <loss>=3.17103881836\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:51 INFO 139866244298560] Epoch[62] Batch [255]#011Speed: 569.29 samples/sec#011loss=3.171039\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:51 INFO 139866244298560] Epoch[62] Batch[260] avg_epoch_loss=2.687640\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=260 train loss <loss>=2.54606261253\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:51 INFO 139866244298560] Epoch[62] Batch [260]#011Speed: 478.99 samples/sec#011loss=2.546063\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:52 INFO 139866244298560] Epoch[62] Batch[265] avg_epoch_loss=2.686745\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, batch=265 train loss <loss>=2.64004015923\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:52 INFO 139866244298560] Epoch[62] Batch [265]#011Speed: 593.19 samples/sec#011loss=2.640040\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:52 INFO 139866244298560] processed a total of 17072 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32667.137145996094, \"sum\": 32667.137145996094, \"min\": 32667.137145996094}}, \"EndTime\": 1599444052.457894, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599444019.790271}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:52 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=522.601743069 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:52 INFO 139866244298560] #progress_metric: host=algo-1, completed 78 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=62, train loss <loss>=2.68491172746\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:52 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:52 INFO 139866244298560] Epoch[63] Batch[0] avg_epoch_loss=2.259110\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=0 train loss <loss>=2.25910997391\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:53 INFO 139866244298560] Epoch[63] Batch[5] avg_epoch_loss=2.042087\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=5 train loss <loss>=2.04208689928\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:53 INFO 139866244298560] Epoch[63] Batch [5]#011Speed: 537.45 samples/sec#011loss=2.042087\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:53 INFO 139866244298560] Epoch[63] Batch[10] avg_epoch_loss=2.091424\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=10 train loss <loss>=2.15062770844\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:53 INFO 139866244298560] Epoch[63] Batch [10]#011Speed: 472.63 samples/sec#011loss=2.150628\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:54 INFO 139866244298560] Epoch[63] Batch[15] avg_epoch_loss=2.255610\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=15 train loss <loss>=2.61681990623\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:54 INFO 139866244298560] Epoch[63] Batch [15]#011Speed: 559.80 samples/sec#011loss=2.616820\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:55 INFO 139866244298560] Epoch[63] Batch[20] avg_epoch_loss=2.335937\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=20 train loss <loss>=2.5929828167\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:55 INFO 139866244298560] Epoch[63] Batch [20]#011Speed: 470.54 samples/sec#011loss=2.592983\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:55 INFO 139866244298560] Epoch[63] Batch[25] avg_epoch_loss=2.428902\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=25 train loss <loss>=2.81935725212\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:55 INFO 139866244298560] Epoch[63] Batch [25]#011Speed: 590.33 samples/sec#011loss=2.819357\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:56 INFO 139866244298560] Epoch[63] Batch[30] avg_epoch_loss=2.452111\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=30 train loss <loss>=2.57279620171\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:56 INFO 139866244298560] Epoch[63] Batch [30]#011Speed: 477.01 samples/sec#011loss=2.572796\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:56 INFO 139866244298560] Epoch[63] Batch[35] avg_epoch_loss=2.468100\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=35 train loss <loss>=2.56723031998\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:56 INFO 139866244298560] Epoch[63] Batch [35]#011Speed: 592.60 samples/sec#011loss=2.567230\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:57 INFO 139866244298560] Epoch[63] Batch[40] avg_epoch_loss=2.444315\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=40 train loss <loss>=2.27306642532\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:57 INFO 139866244298560] Epoch[63] Batch [40]#011Speed: 477.25 samples/sec#011loss=2.273066\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:58 INFO 139866244298560] Epoch[63] Batch[45] avg_epoch_loss=2.442643\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=45 train loss <loss>=2.42893223763\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:58 INFO 139866244298560] Epoch[63] Batch [45]#011Speed: 592.64 samples/sec#011loss=2.428932\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:58 INFO 139866244298560] Epoch[63] Batch[50] avg_epoch_loss=2.424737\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=50 train loss <loss>=2.25999617577\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:58 INFO 139866244298560] Epoch[63] Batch [50]#011Speed: 468.48 samples/sec#011loss=2.259996\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:59 INFO 139866244298560] Epoch[63] Batch[55] avg_epoch_loss=2.427870\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=55 train loss <loss>=2.45982813835\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:00:59 INFO 139866244298560] Epoch[63] Batch [55]#011Speed: 592.00 samples/sec#011loss=2.459828\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:00 INFO 139866244298560] Epoch[63] Batch[60] avg_epoch_loss=2.438369\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=60 train loss <loss>=2.55596380234\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:00 INFO 139866244298560] Epoch[63] Batch [60]#011Speed: 477.29 samples/sec#011loss=2.555964\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:00 INFO 139866244298560] Epoch[63] Batch[65] avg_epoch_loss=2.448704\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=65 train loss <loss>=2.5747923851\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:00 INFO 139866244298560] Epoch[63] Batch [65]#011Speed: 589.62 samples/sec#011loss=2.574792\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:01 INFO 139866244298560] Epoch[63] Batch[70] avg_epoch_loss=2.497313\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=70 train loss <loss>=3.13895301819\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:01 INFO 139866244298560] Epoch[63] Batch [70]#011Speed: 460.37 samples/sec#011loss=3.138953\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:01 INFO 139866244298560] Epoch[63] Batch[75] avg_epoch_loss=2.535803\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=75 train loss <loss>=3.08235702515\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:01 INFO 139866244298560] Epoch[63] Batch [75]#011Speed: 588.50 samples/sec#011loss=3.082357\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:02 INFO 139866244298560] Epoch[63] Batch[80] avg_epoch_loss=2.570337\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=80 train loss <loss>=3.09524898529\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:02 INFO 139866244298560] Epoch[63] Batch [80]#011Speed: 424.13 samples/sec#011loss=3.095249\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:03 INFO 139866244298560] Epoch[63] Batch[85] avg_epoch_loss=2.603900\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=85 train loss <loss>=3.14761514664\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:03 INFO 139866244298560] Epoch[63] Batch [85]#011Speed: 594.62 samples/sec#011loss=3.147615\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:03 INFO 139866244298560] Epoch[63] Batch[90] avg_epoch_loss=2.596603\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=90 train loss <loss>=2.47110800743\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:03 INFO 139866244298560] Epoch[63] Batch [90]#011Speed: 474.42 samples/sec#011loss=2.471108\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:04 INFO 139866244298560] Epoch[63] Batch[95] avg_epoch_loss=2.579808\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=95 train loss <loss>=2.27413954735\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:04 INFO 139866244298560] Epoch[63] Batch [95]#011Speed: 474.94 samples/sec#011loss=2.274140\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:05 INFO 139866244298560] Epoch[63] Batch[100] avg_epoch_loss=2.583288\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=100 train loss <loss>=2.65010757446\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:05 INFO 139866244298560] Epoch[63] Batch [100]#011Speed: 589.22 samples/sec#011loss=2.650108\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:05 INFO 139866244298560] Epoch[63] Batch[105] avg_epoch_loss=2.570510\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=105 train loss <loss>=2.31239209175\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:05 INFO 139866244298560] Epoch[63] Batch [105]#011Speed: 479.39 samples/sec#011loss=2.312392\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:06 INFO 139866244298560] Epoch[63] Batch[110] avg_epoch_loss=2.556262\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=110 train loss <loss>=2.25419359207\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:06 INFO 139866244298560] Epoch[63] Batch [110]#011Speed: 591.22 samples/sec#011loss=2.254194\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:06 INFO 139866244298560] Epoch[63] Batch[115] avg_epoch_loss=2.565809\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=115 train loss <loss>=2.77775249481\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:06 INFO 139866244298560] Epoch[63] Batch [115]#011Speed: 484.75 samples/sec#011loss=2.777752\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:07 INFO 139866244298560] Epoch[63] Batch[120] avg_epoch_loss=2.582353\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=120 train loss <loss>=2.96617560387\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:07 INFO 139866244298560] Epoch[63] Batch [120]#011Speed: 551.08 samples/sec#011loss=2.966176\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:08 INFO 139866244298560] Epoch[63] Batch[125] avg_epoch_loss=2.604510\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=125 train loss <loss>=3.14071440697\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:08 INFO 139866244298560] Epoch[63] Batch [125]#011Speed: 459.69 samples/sec#011loss=3.140714\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:08 INFO 139866244298560] Epoch[63] Batch[130] avg_epoch_loss=2.625901\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=130 train loss <loss>=3.1649392128\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:08 INFO 139866244298560] Epoch[63] Batch [130]#011Speed: 574.65 samples/sec#011loss=3.164939\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:09 INFO 139866244298560] Epoch[63] Batch[135] avg_epoch_loss=2.623904\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=135 train loss <loss>=2.57158241272\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:09 INFO 139866244298560] Epoch[63] Batch [135]#011Speed: 483.38 samples/sec#011loss=2.571582\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:10 INFO 139866244298560] Epoch[63] Batch[140] avg_epoch_loss=2.621444\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=140 train loss <loss>=2.55453920364\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:10 INFO 139866244298560] Epoch[63] Batch [140]#011Speed: 479.96 samples/sec#011loss=2.554539\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:10 INFO 139866244298560] Epoch[63] Batch[145] avg_epoch_loss=2.607092\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=145 train loss <loss>=2.20235929489\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:10 INFO 139866244298560] Epoch[63] Batch [145]#011Speed: 590.02 samples/sec#011loss=2.202359\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:11 INFO 139866244298560] Epoch[63] Batch[150] avg_epoch_loss=2.589403\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=150 train loss <loss>=2.0728918314\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:11 INFO 139866244298560] Epoch[63] Batch [150]#011Speed: 472.84 samples/sec#011loss=2.072892\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:11 INFO 139866244298560] Epoch[63] Batch[155] avg_epoch_loss=2.590471\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=155 train loss <loss>=2.62271738052\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:11 INFO 139866244298560] Epoch[63] Batch [155]#011Speed: 593.21 samples/sec#011loss=2.622717\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:12 INFO 139866244298560] Epoch[63] Batch[160] avg_epoch_loss=2.588004\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=160 train loss <loss>=2.51105093956\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:12 INFO 139866244298560] Epoch[63] Batch [160]#011Speed: 460.39 samples/sec#011loss=2.511051\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:13 INFO 139866244298560] Epoch[63] Batch[165] avg_epoch_loss=2.590406\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=165 train loss <loss>=2.66775841713\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:13 INFO 139866244298560] Epoch[63] Batch [165]#011Speed: 539.99 samples/sec#011loss=2.667758\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:13 INFO 139866244298560] Epoch[63] Batch[170] avg_epoch_loss=2.596721\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=170 train loss <loss>=2.80636954308\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:13 INFO 139866244298560] Epoch[63] Batch [170]#011Speed: 465.98 samples/sec#011loss=2.806370\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:14 INFO 139866244298560] Epoch[63] Batch[175] avg_epoch_loss=2.607887\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=175 train loss <loss>=2.98976416588\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:14 INFO 139866244298560] Epoch[63] Batch [175]#011Speed: 586.07 samples/sec#011loss=2.989764\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:15 INFO 139866244298560] Epoch[63] Batch[180] avg_epoch_loss=2.623187\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=180 train loss <loss>=3.16175637245\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:15 INFO 139866244298560] Epoch[63] Batch [180]#011Speed: 480.19 samples/sec#011loss=3.161756\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:15 INFO 139866244298560] Epoch[63] Batch[185] avg_epoch_loss=2.643146\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=185 train loss <loss>=3.36566300392\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:15 INFO 139866244298560] Epoch[63] Batch [185]#011Speed: 589.07 samples/sec#011loss=3.365663\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:16 INFO 139866244298560] Epoch[63] Batch[190] avg_epoch_loss=2.662293\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=190 train loss <loss>=3.37455277443\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:16 INFO 139866244298560] Epoch[63] Batch [190]#011Speed: 466.56 samples/sec#011loss=3.374553\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:16 INFO 139866244298560] Epoch[63] Batch[195] avg_epoch_loss=2.674674\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=195 train loss <loss>=3.1476102829\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:16 INFO 139866244298560] Epoch[63] Batch [195]#011Speed: 597.42 samples/sec#011loss=3.147610\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:17 INFO 139866244298560] Epoch[63] Batch[200] avg_epoch_loss=2.679773\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=200 train loss <loss>=2.87966814041\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:17 INFO 139866244298560] Epoch[63] Batch [200]#011Speed: 472.33 samples/sec#011loss=2.879668\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:18 INFO 139866244298560] Epoch[63] Batch[205] avg_epoch_loss=2.678867\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=205 train loss <loss>=2.64246220589\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:18 INFO 139866244298560] Epoch[63] Batch [205]#011Speed: 522.62 samples/sec#011loss=2.642462\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:18 INFO 139866244298560] Epoch[63] Batch[210] avg_epoch_loss=2.678703\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=210 train loss <loss>=2.67193317413\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:18 INFO 139866244298560] Epoch[63] Batch [210]#011Speed: 473.25 samples/sec#011loss=2.671933\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:19 INFO 139866244298560] Epoch[63] Batch[215] avg_epoch_loss=2.665805\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=215 train loss <loss>=2.1215105772\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:19 INFO 139866244298560] Epoch[63] Batch [215]#011Speed: 587.78 samples/sec#011loss=2.121511\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:19 INFO 139866244298560] Epoch[63] Batch[220] avg_epoch_loss=2.657440\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=220 train loss <loss>=2.29607434273\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:19 INFO 139866244298560] Epoch[63] Batch [220]#011Speed: 479.99 samples/sec#011loss=2.296074\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:20 INFO 139866244298560] Epoch[63] Batch[225] avg_epoch_loss=2.652500\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=225 train loss <loss>=2.4341448307\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:20 INFO 139866244298560] Epoch[63] Batch [225]#011Speed: 590.06 samples/sec#011loss=2.434145\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:21 INFO 139866244298560] Epoch[63] Batch[230] avg_epoch_loss=2.655738\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=230 train loss <loss>=2.80210154057\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:21 INFO 139866244298560] Epoch[63] Batch [230]#011Speed: 476.19 samples/sec#011loss=2.802102\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:21 INFO 139866244298560] Epoch[63] Batch[235] avg_epoch_loss=2.669343\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=235 train loss <loss>=3.29788269997\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:21 INFO 139866244298560] Epoch[63] Batch [235]#011Speed: 589.79 samples/sec#011loss=3.297883\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:22 INFO 139866244298560] Epoch[63] Batch[240] avg_epoch_loss=2.679228\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=240 train loss <loss>=3.14581279755\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:22 INFO 139866244298560] Epoch[63] Batch [240]#011Speed: 476.98 samples/sec#011loss=3.145813\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:22 INFO 139866244298560] Epoch[63] Batch[245] avg_epoch_loss=2.695541\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=245 train loss <loss>=3.48179411888\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:22 INFO 139866244298560] Epoch[63] Batch [245]#011Speed: 577.21 samples/sec#011loss=3.481794\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:23 INFO 139866244298560] Epoch[63] Batch[250] avg_epoch_loss=2.701394\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=250 train loss <loss>=2.98937883377\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:23 INFO 139866244298560] Epoch[63] Batch [250]#011Speed: 407.92 samples/sec#011loss=2.989379\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:24 INFO 139866244298560] Epoch[63] Batch[255] avg_epoch_loss=2.704978\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=255 train loss <loss>=2.88487687111\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:24 INFO 139866244298560] Epoch[63] Batch [255]#011Speed: 587.70 samples/sec#011loss=2.884877\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:24 INFO 139866244298560] Epoch[63] Batch[260] avg_epoch_loss=2.702449\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=260 train loss <loss>=2.57300519943\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:24 INFO 139866244298560] Epoch[63] Batch [260]#011Speed: 478.30 samples/sec#011loss=2.573005\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:25 INFO 139866244298560] Epoch[63] Batch[265] avg_epoch_loss=2.696486\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, batch=265 train loss <loss>=2.38521990776\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:25 INFO 139866244298560] Epoch[63] Batch [265]#011Speed: 581.52 samples/sec#011loss=2.385220\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:25 INFO 139866244298560] processed a total of 17235 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33503.698110580444, \"sum\": 33503.698110580444, \"min\": 33503.698110580444}}, \"EndTime\": 1599444085.962413, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599444052.458015}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:25 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=514.418492461 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:25 INFO 139866244298560] #progress_metric: host=algo-1, completed 80 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=63, train loss <loss>=2.70733857155\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:25 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:26 INFO 139866244298560] Epoch[64] Batch[0] avg_epoch_loss=2.199249\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=0 train loss <loss>=2.19924926758\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:26 INFO 139866244298560] Epoch[64] Batch[5] avg_epoch_loss=2.310287\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=5 train loss <loss>=2.31028747559\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:26 INFO 139866244298560] Epoch[64] Batch [5]#011Speed: 592.43 samples/sec#011loss=2.310287\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:27 INFO 139866244298560] Epoch[64] Batch[10] avg_epoch_loss=2.354702\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=10 train loss <loss>=2.40799951553\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:27 INFO 139866244298560] Epoch[64] Batch [10]#011Speed: 478.21 samples/sec#011loss=2.408000\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:27 INFO 139866244298560] Epoch[64] Batch[15] avg_epoch_loss=2.458039\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=15 train loss <loss>=2.68538184166\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:27 INFO 139866244298560] Epoch[64] Batch [15]#011Speed: 595.23 samples/sec#011loss=2.685382\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:28 INFO 139866244298560] Epoch[64] Batch[20] avg_epoch_loss=2.524216\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=20 train loss <loss>=2.73598270416\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:28 INFO 139866244298560] Epoch[64] Batch [20]#011Speed: 379.20 samples/sec#011loss=2.735983\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:29 INFO 139866244298560] Epoch[64] Batch[25] avg_epoch_loss=2.561635\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=25 train loss <loss>=2.71879496574\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:29 INFO 139866244298560] Epoch[64] Batch [25]#011Speed: 591.26 samples/sec#011loss=2.718795\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:30 INFO 139866244298560] Epoch[64] Batch[30] avg_epoch_loss=2.591992\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=30 train loss <loss>=2.74984521866\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:30 INFO 139866244298560] Epoch[64] Batch [30]#011Speed: 473.69 samples/sec#011loss=2.749845\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:30 INFO 139866244298560] Epoch[64] Batch[35] avg_epoch_loss=2.593760\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=35 train loss <loss>=2.60472326279\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:30 INFO 139866244298560] Epoch[64] Batch [35]#011Speed: 589.89 samples/sec#011loss=2.604723\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:31 INFO 139866244298560] Epoch[64] Batch[40] avg_epoch_loss=2.566214\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=40 train loss <loss>=2.36788172722\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:31 INFO 139866244298560] Epoch[64] Batch [40]#011Speed: 478.89 samples/sec#011loss=2.367882\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:31 INFO 139866244298560] Epoch[64] Batch[45] avg_epoch_loss=2.570306\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=45 train loss <loss>=2.60385742187\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:31 INFO 139866244298560] Epoch[64] Batch [45]#011Speed: 593.95 samples/sec#011loss=2.603857\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:32 INFO 139866244298560] Epoch[64] Batch[50] avg_epoch_loss=2.558082\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=50 train loss <loss>=2.44562492371\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:32 INFO 139866244298560] Epoch[64] Batch [50]#011Speed: 480.33 samples/sec#011loss=2.445625\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:32 INFO 139866244298560] Epoch[64] Batch[55] avg_epoch_loss=2.529716\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=55 train loss <loss>=2.24038336277\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:32 INFO 139866244298560] Epoch[64] Batch [55]#011Speed: 587.37 samples/sec#011loss=2.240383\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:33 INFO 139866244298560] Epoch[64] Batch[60] avg_epoch_loss=2.519951\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=60 train loss <loss>=2.41057658195\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:33 INFO 139866244298560] Epoch[64] Batch [60]#011Speed: 440.92 samples/sec#011loss=2.410577\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:34 INFO 139866244298560] Epoch[64] Batch[65] avg_epoch_loss=2.509723\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=65 train loss <loss>=2.38495211601\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:34 INFO 139866244298560] Epoch[64] Batch [65]#011Speed: 582.85 samples/sec#011loss=2.384952\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:34 INFO 139866244298560] Epoch[64] Batch[70] avg_epoch_loss=2.522178\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=70 train loss <loss>=2.6865760088\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:34 INFO 139866244298560] Epoch[64] Batch [70]#011Speed: 470.64 samples/sec#011loss=2.686576\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:35 INFO 139866244298560] Epoch[64] Batch[75] avg_epoch_loss=2.540472\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=75 train loss <loss>=2.8002518177\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:35 INFO 139866244298560] Epoch[64] Batch [75]#011Speed: 588.37 samples/sec#011loss=2.800252\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:36 INFO 139866244298560] Epoch[64] Batch[80] avg_epoch_loss=2.573914\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=80 train loss <loss>=3.08222718239\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:36 INFO 139866244298560] Epoch[64] Batch [80]#011Speed: 476.62 samples/sec#011loss=3.082227\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:36 INFO 139866244298560] Epoch[64] Batch[85] avg_epoch_loss=2.607787\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=85 train loss <loss>=3.15652952194\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:36 INFO 139866244298560] Epoch[64] Batch [85]#011Speed: 589.16 samples/sec#011loss=3.156530\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:37 INFO 139866244298560] Epoch[64] Batch[90] avg_epoch_loss=2.631976\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=90 train loss <loss>=3.04802851677\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:37 INFO 139866244298560] Epoch[64] Batch [90]#011Speed: 469.43 samples/sec#011loss=3.048029\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:37 INFO 139866244298560] Epoch[64] Batch[95] avg_epoch_loss=2.653605\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=95 train loss <loss>=3.04724793434\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:37 INFO 139866244298560] Epoch[64] Batch [95]#011Speed: 590.45 samples/sec#011loss=3.047248\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:38 INFO 139866244298560] Epoch[64] Batch[100] avg_epoch_loss=2.649024\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=100 train loss <loss>=2.56107330322\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:38 INFO 139866244298560] Epoch[64] Batch [100]#011Speed: 429.85 samples/sec#011loss=2.561073\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:39 INFO 139866244298560] Epoch[64] Batch[105] avg_epoch_loss=2.639417\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=105 train loss <loss>=2.4453666687\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:39 INFO 139866244298560] Epoch[64] Batch [105]#011Speed: 593.47 samples/sec#011loss=2.445367\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:39 INFO 139866244298560] Epoch[64] Batch[110] avg_epoch_loss=2.630431\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=110 train loss <loss>=2.43992094994\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:39 INFO 139866244298560] Epoch[64] Batch [110]#011Speed: 469.96 samples/sec#011loss=2.439921\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:40 INFO 139866244298560] Epoch[64] Batch[115] avg_epoch_loss=2.621043\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=115 train loss <loss>=2.41262397766\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:40 INFO 139866244298560] Epoch[64] Batch [115]#011Speed: 594.99 samples/sec#011loss=2.412624\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:41 INFO 139866244298560] Epoch[64] Batch[120] avg_epoch_loss=2.610423\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=120 train loss <loss>=2.36404006481\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:41 INFO 139866244298560] Epoch[64] Batch [120]#011Speed: 471.81 samples/sec#011loss=2.364040\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:41 INFO 139866244298560] Epoch[64] Batch[125] avg_epoch_loss=2.595238\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=125 train loss <loss>=2.22777318954\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:41 INFO 139866244298560] Epoch[64] Batch [125]#011Speed: 594.81 samples/sec#011loss=2.227773\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:42 INFO 139866244298560] Epoch[64] Batch[130] avg_epoch_loss=2.583141\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=130 train loss <loss>=2.27829051018\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:42 INFO 139866244298560] Epoch[64] Batch [130]#011Speed: 474.11 samples/sec#011loss=2.278291\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:42 INFO 139866244298560] Epoch[64] Batch[135] avg_epoch_loss=2.574018\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=135 train loss <loss>=2.33498892784\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:42 INFO 139866244298560] Epoch[64] Batch [135]#011Speed: 477.74 samples/sec#011loss=2.334989\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:43 INFO 139866244298560] Epoch[64] Batch[140] avg_epoch_loss=2.592085\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=140 train loss <loss>=3.08350725174\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:43 INFO 139866244298560] Epoch[64] Batch [140]#011Speed: 594.67 samples/sec#011loss=3.083507\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:44 INFO 139866244298560] Epoch[64] Batch[145] avg_epoch_loss=2.597962\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=145 train loss <loss>=2.76368708611\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:44 INFO 139866244298560] Epoch[64] Batch [145]#011Speed: 447.96 samples/sec#011loss=2.763687\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:44 INFO 139866244298560] Epoch[64] Batch[150] avg_epoch_loss=2.605740\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=150 train loss <loss>=2.83285999298\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:44 INFO 139866244298560] Epoch[64] Batch [150]#011Speed: 579.49 samples/sec#011loss=2.832860\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:45 INFO 139866244298560] Epoch[64] Batch[155] avg_epoch_loss=2.614500\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=155 train loss <loss>=2.87906265259\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:45 INFO 139866244298560] Epoch[64] Batch [155]#011Speed: 477.37 samples/sec#011loss=2.879063\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:46 INFO 139866244298560] Epoch[64] Batch[160] avg_epoch_loss=2.618197\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=160 train loss <loss>=2.73352375031\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:46 INFO 139866244298560] Epoch[64] Batch [160]#011Speed: 586.95 samples/sec#011loss=2.733524\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:46 INFO 139866244298560] Epoch[64] Batch[165] avg_epoch_loss=2.615179\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=165 train loss <loss>=2.51801438332\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:46 INFO 139866244298560] Epoch[64] Batch [165]#011Speed: 477.25 samples/sec#011loss=2.518014\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:47 INFO 139866244298560] Epoch[64] Batch[170] avg_epoch_loss=2.610303\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=170 train loss <loss>=2.4484102726\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:47 INFO 139866244298560] Epoch[64] Batch [170]#011Speed: 595.19 samples/sec#011loss=2.448410\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:47 INFO 139866244298560] Epoch[64] Batch[175] avg_epoch_loss=2.611142\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=175 train loss <loss>=2.63983426094\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:47 INFO 139866244298560] Epoch[64] Batch [175]#011Speed: 476.46 samples/sec#011loss=2.639834\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:48 INFO 139866244298560] Epoch[64] Batch[180] avg_epoch_loss=2.605606\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=180 train loss <loss>=2.4107562542\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:48 INFO 139866244298560] Epoch[64] Batch [180]#011Speed: 588.37 samples/sec#011loss=2.410756\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:49 INFO 139866244298560] Epoch[64] Batch[185] avg_epoch_loss=2.613246\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=185 train loss <loss>=2.88980541229\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:49 INFO 139866244298560] Epoch[64] Batch [185]#011Speed: 447.37 samples/sec#011loss=2.889805\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:49 INFO 139866244298560] Epoch[64] Batch[190] avg_epoch_loss=2.622184\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=190 train loss <loss>=2.95467734337\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:49 INFO 139866244298560] Epoch[64] Batch [190]#011Speed: 588.15 samples/sec#011loss=2.954677\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:50 INFO 139866244298560] Epoch[64] Batch[195] avg_epoch_loss=2.639202\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=195 train loss <loss>=3.28928022385\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:50 INFO 139866244298560] Epoch[64] Batch [195]#011Speed: 483.06 samples/sec#011loss=3.289280\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:51 INFO 139866244298560] Epoch[64] Batch[200] avg_epoch_loss=2.662361\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=200 train loss <loss>=3.57022132874\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:51 INFO 139866244298560] Epoch[64] Batch [200]#011Speed: 480.59 samples/sec#011loss=3.570221\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:51 INFO 139866244298560] Epoch[64] Batch[205] avg_epoch_loss=2.669311\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=205 train loss <loss>=2.94867930412\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:51 INFO 139866244298560] Epoch[64] Batch [205]#011Speed: 595.04 samples/sec#011loss=2.948679\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:52 INFO 139866244298560] Epoch[64] Batch[210] avg_epoch_loss=2.671262\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=210 train loss <loss>=2.75163536072\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:52 INFO 139866244298560] Epoch[64] Batch [210]#011Speed: 481.82 samples/sec#011loss=2.751635\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:52 INFO 139866244298560] Epoch[64] Batch[215] avg_epoch_loss=2.668987\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=215 train loss <loss>=2.57297945023\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:52 INFO 139866244298560] Epoch[64] Batch [215]#011Speed: 593.88 samples/sec#011loss=2.572979\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:53 INFO 139866244298560] Epoch[64] Batch[220] avg_epoch_loss=2.659748\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=220 train loss <loss>=2.26063961983\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:53 INFO 139866244298560] Epoch[64] Batch [220]#011Speed: 427.50 samples/sec#011loss=2.260640\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:54 INFO 139866244298560] Epoch[64] Batch[225] avg_epoch_loss=2.663196\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=225 train loss <loss>=2.81558046341\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:54 INFO 139866244298560] Epoch[64] Batch [225]#011Speed: 530.35 samples/sec#011loss=2.815580\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:54 INFO 139866244298560] Epoch[64] Batch[230] avg_epoch_loss=2.659631\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=230 train loss <loss>=2.49851894379\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:54 INFO 139866244298560] Epoch[64] Batch [230]#011Speed: 469.68 samples/sec#011loss=2.498519\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:55 INFO 139866244298560] Epoch[64] Batch[235] avg_epoch_loss=2.659434\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=235 train loss <loss>=2.65032191277\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:55 INFO 139866244298560] Epoch[64] Batch [235]#011Speed: 591.50 samples/sec#011loss=2.650322\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:56 INFO 139866244298560] Epoch[64] Batch[240] avg_epoch_loss=2.665594\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=240 train loss <loss>=2.95633583069\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:56 INFO 139866244298560] Epoch[64] Batch [240]#011Speed: 477.34 samples/sec#011loss=2.956336\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:56 INFO 139866244298560] Epoch[64] Batch[245] avg_epoch_loss=2.676040\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=245 train loss <loss>=3.17954349518\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:56 INFO 139866244298560] Epoch[64] Batch [245]#011Speed: 594.63 samples/sec#011loss=3.179543\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:57 INFO 139866244298560] Epoch[64] Batch[250] avg_epoch_loss=2.689853\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=250 train loss <loss>=3.36947836876\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:57 INFO 139866244298560] Epoch[64] Batch [250]#011Speed: 477.67 samples/sec#011loss=3.369478\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:57 INFO 139866244298560] Epoch[64] Batch[255] avg_epoch_loss=2.702802\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=255 train loss <loss>=3.3527973175\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:57 INFO 139866244298560] Epoch[64] Batch [255]#011Speed: 593.68 samples/sec#011loss=3.352797\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:58 INFO 139866244298560] Epoch[64] Batch[260] avg_epoch_loss=2.708833\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=260 train loss <loss>=3.01766037941\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:58 INFO 139866244298560] Epoch[64] Batch [260]#011Speed: 492.81 samples/sec#011loss=3.017660\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:58 INFO 139866244298560] Epoch[64] Batch[265] avg_epoch_loss=2.704465\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, batch=265 train loss <loss>=2.47643332481\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:58 INFO 139866244298560] Epoch[64] Batch [265]#011Speed: 581.19 samples/sec#011loss=2.476433\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:59 INFO 139866244298560] processed a total of 17040 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33152.95600891113, \"sum\": 33152.95600891113, \"min\": 33152.95600891113}}, \"EndTime\": 1599444119.116064, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599444085.962502}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:59 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=513.979454325 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:59 INFO 139866244298560] #progress_metric: host=algo-1, completed 81 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=64, train loss <loss>=2.70921389128\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:59 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:59 INFO 139866244298560] Epoch[65] Batch[0] avg_epoch_loss=2.064796\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:01:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=0 train loss <loss>=2.06479597092\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:00 INFO 139866244298560] Epoch[65] Batch[5] avg_epoch_loss=2.122539\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=5 train loss <loss>=2.12253860633\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:00 INFO 139866244298560] Epoch[65] Batch [5]#011Speed: 526.11 samples/sec#011loss=2.122539\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:00 INFO 139866244298560] Epoch[65] Batch[10] avg_epoch_loss=2.170039\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=10 train loss <loss>=2.22703857422\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:00 INFO 139866244298560] Epoch[65] Batch [10]#011Speed: 466.46 samples/sec#011loss=2.227039\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:01 INFO 139866244298560] Epoch[65] Batch[15] avg_epoch_loss=2.315842\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=15 train loss <loss>=2.63660860062\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:01 INFO 139866244298560] Epoch[65] Batch [15]#011Speed: 570.90 samples/sec#011loss=2.636609\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:02 INFO 139866244298560] Epoch[65] Batch[20] avg_epoch_loss=2.389430\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=20 train loss <loss>=2.62491111755\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:02 INFO 139866244298560] Epoch[65] Batch [20]#011Speed: 469.16 samples/sec#011loss=2.624911\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:02 INFO 139866244298560] Epoch[65] Batch[25] avg_epoch_loss=2.462188\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=25 train loss <loss>=2.76777129173\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:02 INFO 139866244298560] Epoch[65] Batch [25]#011Speed: 592.08 samples/sec#011loss=2.767771\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:03 INFO 139866244298560] Epoch[65] Batch[30] avg_epoch_loss=2.494294\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=30 train loss <loss>=2.66124458313\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:03 INFO 139866244298560] Epoch[65] Batch [30]#011Speed: 476.04 samples/sec#011loss=2.661245\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:03 INFO 139866244298560] Epoch[65] Batch[35] avg_epoch_loss=2.514956\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=35 train loss <loss>=2.64306182861\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:03 INFO 139866244298560] Epoch[65] Batch [35]#011Speed: 581.69 samples/sec#011loss=2.643062\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:04 INFO 139866244298560] Epoch[65] Batch[40] avg_epoch_loss=2.538284\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=40 train loss <loss>=2.70624837875\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:04 INFO 139866244298560] Epoch[65] Batch [40]#011Speed: 443.99 samples/sec#011loss=2.706248\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:05 INFO 139866244298560] Epoch[65] Batch[45] avg_epoch_loss=2.520796\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=45 train loss <loss>=2.37739157677\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:05 INFO 139866244298560] Epoch[65] Batch [45]#011Speed: 588.07 samples/sec#011loss=2.377392\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:05 INFO 139866244298560] Epoch[65] Batch[50] avg_epoch_loss=2.492611\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=50 train loss <loss>=2.23330779076\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:05 INFO 139866244298560] Epoch[65] Batch [50]#011Speed: 451.12 samples/sec#011loss=2.233308\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:06 INFO 139866244298560] Epoch[65] Batch[55] avg_epoch_loss=2.475318\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=55 train loss <loss>=2.29893212318\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:06 INFO 139866244298560] Epoch[65] Batch [55]#011Speed: 597.65 samples/sec#011loss=2.298932\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:07 INFO 139866244298560] Epoch[65] Batch[60] avg_epoch_loss=2.455957\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=60 train loss <loss>=2.23911669254\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:07 INFO 139866244298560] Epoch[65] Batch [60]#011Speed: 478.66 samples/sec#011loss=2.239117\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:07 INFO 139866244298560] Epoch[65] Batch[65] avg_epoch_loss=2.434085\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=65 train loss <loss>=2.16723761559\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:07 INFO 139866244298560] Epoch[65] Batch [65]#011Speed: 590.75 samples/sec#011loss=2.167238\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:08 INFO 139866244298560] Epoch[65] Batch[70] avg_epoch_loss=2.444572\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=70 train loss <loss>=2.58301296234\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:08 INFO 139866244298560] Epoch[65] Batch [70]#011Speed: 477.51 samples/sec#011loss=2.583013\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:08 INFO 139866244298560] Epoch[65] Batch[75] avg_epoch_loss=2.449986\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=75 train loss <loss>=2.52686185837\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:08 INFO 139866244298560] Epoch[65] Batch [75]#011Speed: 574.65 samples/sec#011loss=2.526862\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:09 INFO 139866244298560] Epoch[65] Batch[80] avg_epoch_loss=2.486242\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=80 train loss <loss>=3.03733687401\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:09 INFO 139866244298560] Epoch[65] Batch [80]#011Speed: 442.24 samples/sec#011loss=3.037337\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:10 INFO 139866244298560] Epoch[65] Batch[85] avg_epoch_loss=2.541128\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=85 train loss <loss>=3.43026499748\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:10 INFO 139866244298560] Epoch[65] Batch [85]#011Speed: 591.69 samples/sec#011loss=3.430265\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:10 INFO 139866244298560] Epoch[65] Batch[90] avg_epoch_loss=2.567772\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=90 train loss <loss>=3.02604851723\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:10 INFO 139866244298560] Epoch[65] Batch [90]#011Speed: 466.58 samples/sec#011loss=3.026049\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:11 INFO 139866244298560] Epoch[65] Batch[95] avg_epoch_loss=2.587757\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=95 train loss <loss>=2.95149073601\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:11 INFO 139866244298560] Epoch[65] Batch [95]#011Speed: 590.06 samples/sec#011loss=2.951491\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:11 INFO 139866244298560] Epoch[65] Batch[100] avg_epoch_loss=2.588612\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=100 train loss <loss>=2.60502471924\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:11 INFO 139866244298560] Epoch[65] Batch [100]#011Speed: 479.01 samples/sec#011loss=2.605025\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:12 INFO 139866244298560] Epoch[65] Batch[105] avg_epoch_loss=2.577600\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=105 train loss <loss>=2.35515966415\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:12 INFO 139866244298560] Epoch[65] Batch [105]#011Speed: 482.66 samples/sec#011loss=2.355160\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:13 INFO 139866244298560] Epoch[65] Batch[110] avg_epoch_loss=2.562596\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=110 train loss <loss>=2.24451367855\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:13 INFO 139866244298560] Epoch[65] Batch [110]#011Speed: 593.09 samples/sec#011loss=2.244514\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:13 INFO 139866244298560] Epoch[65] Batch[115] avg_epoch_loss=2.545999\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=115 train loss <loss>=2.17753648758\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:13 INFO 139866244298560] Epoch[65] Batch [115]#011Speed: 460.44 samples/sec#011loss=2.177536\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:14 INFO 139866244298560] Epoch[65] Batch[120] avg_epoch_loss=2.539115\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=120 train loss <loss>=2.37940807343\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:14 INFO 139866244298560] Epoch[65] Batch [120]#011Speed: 565.97 samples/sec#011loss=2.379408\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:15 INFO 139866244298560] Epoch[65] Batch[125] avg_epoch_loss=2.538457\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=125 train loss <loss>=2.52253527641\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:15 INFO 139866244298560] Epoch[65] Batch [125]#011Speed: 429.57 samples/sec#011loss=2.522535\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:15 INFO 139866244298560] Epoch[65] Batch[130] avg_epoch_loss=2.537102\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=130 train loss <loss>=2.50296163559\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:15 INFO 139866244298560] Epoch[65] Batch [130]#011Speed: 583.80 samples/sec#011loss=2.502962\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:16 INFO 139866244298560] Epoch[65] Batch[135] avg_epoch_loss=2.548173\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=135 train loss <loss>=2.83822832108\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:16 INFO 139866244298560] Epoch[65] Batch [135]#011Speed: 480.27 samples/sec#011loss=2.838228\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:16 INFO 139866244298560] Epoch[65] Batch[140] avg_epoch_loss=2.567263\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=140 train loss <loss>=3.08652720451\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:16 INFO 139866244298560] Epoch[65] Batch [140]#011Speed: 595.16 samples/sec#011loss=3.086527\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:17 INFO 139866244298560] Epoch[65] Batch[145] avg_epoch_loss=2.567821\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=145 train loss <loss>=2.58354697227\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:17 INFO 139866244298560] Epoch[65] Batch [145]#011Speed: 487.72 samples/sec#011loss=2.583547\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:18 INFO 139866244298560] Epoch[65] Batch[150] avg_epoch_loss=2.566061\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=150 train loss <loss>=2.51466221809\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:18 INFO 139866244298560] Epoch[65] Batch [150]#011Speed: 591.65 samples/sec#011loss=2.514662\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:18 INFO 139866244298560] Epoch[65] Batch[155] avg_epoch_loss=2.568385\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=155 train loss <loss>=2.6385705471\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:18 INFO 139866244298560] Epoch[65] Batch [155]#011Speed: 471.63 samples/sec#011loss=2.638571\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:19 INFO 139866244298560] Epoch[65] Batch[160] avg_epoch_loss=2.569490\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=160 train loss <loss>=2.60396170616\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:19 INFO 139866244298560] Epoch[65] Batch [160]#011Speed: 534.00 samples/sec#011loss=2.603962\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:20 INFO 139866244298560] Epoch[65] Batch[165] avg_epoch_loss=2.561122\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=165 train loss <loss>=2.29167985916\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:20 INFO 139866244298560] Epoch[65] Batch [165]#011Speed: 426.34 samples/sec#011loss=2.291680\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:20 INFO 139866244298560] Epoch[65] Batch[170] avg_epoch_loss=2.559487\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=170 train loss <loss>=2.5051990509\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:20 INFO 139866244298560] Epoch[65] Batch [170]#011Speed: 465.41 samples/sec#011loss=2.505199\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:21 INFO 139866244298560] Epoch[65] Batch[175] avg_epoch_loss=2.552826\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=175 train loss <loss>=2.32503712177\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:21 INFO 139866244298560] Epoch[65] Batch [175]#011Speed: 588.99 samples/sec#011loss=2.325037\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:22 INFO 139866244298560] Epoch[65] Batch[180] avg_epoch_loss=2.554620\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=180 train loss <loss>=2.61777062416\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:22 INFO 139866244298560] Epoch[65] Batch [180]#011Speed: 483.43 samples/sec#011loss=2.617771\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:22 INFO 139866244298560] Epoch[65] Batch[185] avg_epoch_loss=2.560762\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=185 train loss <loss>=2.78309121132\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:22 INFO 139866244298560] Epoch[65] Batch [185]#011Speed: 593.59 samples/sec#011loss=2.783091\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:23 INFO 139866244298560] Epoch[65] Batch[190] avg_epoch_loss=2.564933\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=190 train loss <loss>=2.72008218765\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:23 INFO 139866244298560] Epoch[65] Batch [190]#011Speed: 473.56 samples/sec#011loss=2.720082\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:23 INFO 139866244298560] Epoch[65] Batch[195] avg_epoch_loss=2.580644\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=195 train loss <loss>=3.18082165718\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:23 INFO 139866244298560] Epoch[65] Batch [195]#011Speed: 531.76 samples/sec#011loss=3.180822\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:24 INFO 139866244298560] Epoch[65] Batch[200] avg_epoch_loss=2.597850\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=200 train loss <loss>=3.27231278419\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:24 INFO 139866244298560] Epoch[65] Batch [200]#011Speed: 472.44 samples/sec#011loss=3.272313\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:25 INFO 139866244298560] Epoch[65] Batch[205] avg_epoch_loss=2.613976\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=205 train loss <loss>=3.26223125458\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:25 INFO 139866244298560] Epoch[65] Batch [205]#011Speed: 528.63 samples/sec#011loss=3.262231\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:25 INFO 139866244298560] Epoch[65] Batch[210] avg_epoch_loss=2.625220\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=210 train loss <loss>=3.08846912384\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:25 INFO 139866244298560] Epoch[65] Batch [210]#011Speed: 473.12 samples/sec#011loss=3.088469\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:26 INFO 139866244298560] Epoch[65] Batch[215] avg_epoch_loss=2.630101\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=215 train loss <loss>=2.83608555794\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:26 INFO 139866244298560] Epoch[65] Batch [215]#011Speed: 588.81 samples/sec#011loss=2.836086\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:27 INFO 139866244298560] Epoch[65] Batch[220] avg_epoch_loss=2.633664\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=220 train loss <loss>=2.78760795593\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:27 INFO 139866244298560] Epoch[65] Batch [220]#011Speed: 470.95 samples/sec#011loss=2.787608\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:27 INFO 139866244298560] Epoch[65] Batch[225] avg_epoch_loss=2.631901\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=225 train loss <loss>=2.55396966934\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:27 INFO 139866244298560] Epoch[65] Batch [225]#011Speed: 591.48 samples/sec#011loss=2.553970\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:28 INFO 139866244298560] Epoch[65] Batch[230] avg_epoch_loss=2.628748\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=230 train loss <loss>=2.48621854782\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:28 INFO 139866244298560] Epoch[65] Batch [230]#011Speed: 475.46 samples/sec#011loss=2.486219\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:28 INFO 139866244298560] Epoch[65] Batch[235] avg_epoch_loss=2.626852\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=235 train loss <loss>=2.53927128315\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:28 INFO 139866244298560] Epoch[65] Batch [235]#011Speed: 579.58 samples/sec#011loss=2.539271\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:29 INFO 139866244298560] Epoch[65] Batch[240] avg_epoch_loss=2.619889\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=240 train loss <loss>=2.29122638702\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:29 INFO 139866244298560] Epoch[65] Batch [240]#011Speed: 473.80 samples/sec#011loss=2.291226\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:30 INFO 139866244298560] Epoch[65] Batch[245] avg_epoch_loss=2.618178\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=245 train loss <loss>=2.53572974205\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:30 INFO 139866244298560] Epoch[65] Batch [245]#011Speed: 549.08 samples/sec#011loss=2.535730\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:30 INFO 139866244298560] Epoch[65] Batch[250] avg_epoch_loss=2.622872\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=250 train loss <loss>=2.85380311012\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:30 INFO 139866244298560] Epoch[65] Batch [250]#011Speed: 469.03 samples/sec#011loss=2.853803\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:31 INFO 139866244298560] Epoch[65] Batch[255] avg_epoch_loss=2.631304\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=255 train loss <loss>=3.05459041595\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:31 INFO 139866244298560] Epoch[65] Batch [255]#011Speed: 586.63 samples/sec#011loss=3.054590\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:31 INFO 139866244298560] Epoch[65] Batch[260] avg_epoch_loss=2.640177\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=260 train loss <loss>=3.0944981575\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:31 INFO 139866244298560] Epoch[65] Batch [260]#011Speed: 495.62 samples/sec#011loss=3.094498\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:32 INFO 139866244298560] Epoch[65] Batch[265] avg_epoch_loss=2.650723\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, batch=265 train loss <loss>=3.20118751526\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:32 INFO 139866244298560] Epoch[65] Batch [265]#011Speed: 591.56 samples/sec#011loss=3.201188\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:32 INFO 139866244298560] processed a total of 17135 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33567.739963531494, \"sum\": 33567.739963531494, \"min\": 33567.739963531494}}, \"EndTime\": 1599444152.686754, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599444119.116144}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:32 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=510.458865731 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:32 INFO 139866244298560] #progress_metric: host=algo-1, completed 82 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=65, train loss <loss>=2.65426383357\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:32 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:32 INFO 139866244298560] Epoch[66] Batch[0] avg_epoch_loss=1.959200\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=0 train loss <loss>=1.95920038223\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:33 INFO 139866244298560] Epoch[66] Batch[5] avg_epoch_loss=2.059443\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=5 train loss <loss>=2.05944273869\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:33 INFO 139866244298560] Epoch[66] Batch [5]#011Speed: 592.48 samples/sec#011loss=2.059443\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:34 INFO 139866244298560] Epoch[66] Batch[10] avg_epoch_loss=2.156158\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=10 train loss <loss>=2.27221565247\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:34 INFO 139866244298560] Epoch[66] Batch [10]#011Speed: 470.88 samples/sec#011loss=2.272216\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:34 INFO 139866244298560] Epoch[66] Batch[15] avg_epoch_loss=2.324832\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=15 train loss <loss>=2.69591703415\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:34 INFO 139866244298560] Epoch[66] Batch [15]#011Speed: 588.47 samples/sec#011loss=2.695917\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:35 INFO 139866244298560] Epoch[66] Batch[20] avg_epoch_loss=2.404339\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=20 train loss <loss>=2.65875854492\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:35 INFO 139866244298560] Epoch[66] Batch [20]#011Speed: 421.23 samples/sec#011loss=2.658759\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:36 INFO 139866244298560] Epoch[66] Batch[25] avg_epoch_loss=2.486902\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=25 train loss <loss>=2.83366632462\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:36 INFO 139866244298560] Epoch[66] Batch [25]#011Speed: 584.76 samples/sec#011loss=2.833666\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:36 INFO 139866244298560] Epoch[66] Batch[30] avg_epoch_loss=2.532932\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=30 train loss <loss>=2.77229251862\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:36 INFO 139866244298560] Epoch[66] Batch [30]#011Speed: 470.92 samples/sec#011loss=2.772293\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:37 INFO 139866244298560] Epoch[66] Batch[35] avg_epoch_loss=2.522685\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=35 train loss <loss>=2.45915369987\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:37 INFO 139866244298560] Epoch[66] Batch [35]#011Speed: 590.13 samples/sec#011loss=2.459154\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:37 INFO 139866244298560] Epoch[66] Batch[40] avg_epoch_loss=2.512361\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=40 train loss <loss>=2.43802647591\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:37 INFO 139866244298560] Epoch[66] Batch [40]#011Speed: 475.82 samples/sec#011loss=2.438026\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:38 INFO 139866244298560] Epoch[66] Batch[45] avg_epoch_loss=2.506841\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=45 train loss <loss>=2.46157922745\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:38 INFO 139866244298560] Epoch[66] Batch [45]#011Speed: 584.75 samples/sec#011loss=2.461579\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:39 INFO 139866244298560] Epoch[66] Batch[50] avg_epoch_loss=2.518992\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=50 train loss <loss>=2.63077874184\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:39 INFO 139866244298560] Epoch[66] Batch [50]#011Speed: 475.60 samples/sec#011loss=2.630779\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:39 INFO 139866244298560] Epoch[66] Batch[55] avg_epoch_loss=2.504536\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=55 train loss <loss>=2.35707843304\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:39 INFO 139866244298560] Epoch[66] Batch [55]#011Speed: 580.13 samples/sec#011loss=2.357078\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:40 INFO 139866244298560] Epoch[66] Batch[60] avg_epoch_loss=2.484168\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=60 train loss <loss>=2.25604858398\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:40 INFO 139866244298560] Epoch[66] Batch [60]#011Speed: 435.49 samples/sec#011loss=2.256049\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:40 INFO 139866244298560] Epoch[66] Batch[65] avg_epoch_loss=2.498467\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=65 train loss <loss>=2.67292070389\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:40 INFO 139866244298560] Epoch[66] Batch [65]#011Speed: 588.03 samples/sec#011loss=2.672921\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:41 INFO 139866244298560] Epoch[66] Batch[70] avg_epoch_loss=2.529091\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=70 train loss <loss>=2.93332700729\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:41 INFO 139866244298560] Epoch[66] Batch [70]#011Speed: 481.31 samples/sec#011loss=2.933327\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:42 INFO 139866244298560] Epoch[66] Batch[75] avg_epoch_loss=2.547660\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=75 train loss <loss>=2.81133389473\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:42 INFO 139866244298560] Epoch[66] Batch [75]#011Speed: 591.14 samples/sec#011loss=2.811334\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:42 INFO 139866244298560] Epoch[66] Batch[80] avg_epoch_loss=2.575452\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=80 train loss <loss>=2.99788899422\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:42 INFO 139866244298560] Epoch[66] Batch [80]#011Speed: 478.00 samples/sec#011loss=2.997889\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:43 INFO 139866244298560] Epoch[66] Batch[85] avg_epoch_loss=2.605002\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=85 train loss <loss>=3.0837117672\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:43 INFO 139866244298560] Epoch[66] Batch [85]#011Speed: 594.18 samples/sec#011loss=3.083712\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:44 INFO 139866244298560] Epoch[66] Batch[90] avg_epoch_loss=2.612515\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=90 train loss <loss>=2.74174876213\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:44 INFO 139866244298560] Epoch[66] Batch [90]#011Speed: 472.26 samples/sec#011loss=2.741749\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:44 INFO 139866244298560] Epoch[66] Batch[95] avg_epoch_loss=2.629519\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=95 train loss <loss>=2.93898310661\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:44 INFO 139866244298560] Epoch[66] Batch [95]#011Speed: 588.13 samples/sec#011loss=2.938983\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:45 INFO 139866244298560] Epoch[66] Batch[100] avg_epoch_loss=2.624319\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=100 train loss <loss>=2.52447977066\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:45 INFO 139866244298560] Epoch[66] Batch [100]#011Speed: 466.40 samples/sec#011loss=2.524480\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:45 INFO 139866244298560] Epoch[66] Batch[105] avg_epoch_loss=2.614591\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=105 train loss <loss>=2.4180970192\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:45 INFO 139866244298560] Epoch[66] Batch [105]#011Speed: 519.95 samples/sec#011loss=2.418097\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:46 INFO 139866244298560] Epoch[66] Batch[110] avg_epoch_loss=2.583525\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=110 train loss <loss>=1.92492794991\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:46 INFO 139866244298560] Epoch[66] Batch [110]#011Speed: 475.87 samples/sec#011loss=1.924928\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:47 INFO 139866244298560] Epoch[66] Batch[115] avg_epoch_loss=2.568273\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=115 train loss <loss>=2.22967772484\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:47 INFO 139866244298560] Epoch[66] Batch [115]#011Speed: 587.74 samples/sec#011loss=2.229678\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:47 INFO 139866244298560] Epoch[66] Batch[120] avg_epoch_loss=2.555952\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=120 train loss <loss>=2.27010116577\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:47 INFO 139866244298560] Epoch[66] Batch [120]#011Speed: 474.13 samples/sec#011loss=2.270101\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:48 INFO 139866244298560] Epoch[66] Batch[125] avg_epoch_loss=2.547235\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=125 train loss <loss>=2.33628268242\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:48 INFO 139866244298560] Epoch[66] Batch [125]#011Speed: 592.74 samples/sec#011loss=2.336283\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:49 INFO 139866244298560] Epoch[66] Batch[130] avg_epoch_loss=2.549210\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=130 train loss <loss>=2.59897904396\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:49 INFO 139866244298560] Epoch[66] Batch [130]#011Speed: 467.23 samples/sec#011loss=2.598979\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:49 INFO 139866244298560] Epoch[66] Batch[135] avg_epoch_loss=2.554326\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=135 train loss <loss>=2.68835425377\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:49 INFO 139866244298560] Epoch[66] Batch [135]#011Speed: 590.98 samples/sec#011loss=2.688354\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:50 INFO 139866244298560] Epoch[66] Batch[140] avg_epoch_loss=2.575123\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=140 train loss <loss>=3.14082050323\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:50 INFO 139866244298560] Epoch[66] Batch [140]#011Speed: 465.13 samples/sec#011loss=3.140821\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:50 INFO 139866244298560] Epoch[66] Batch[145] avg_epoch_loss=2.584744\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=145 train loss <loss>=2.8560526371\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:50 INFO 139866244298560] Epoch[66] Batch [145]#011Speed: 500.12 samples/sec#011loss=2.856053\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:51 INFO 139866244298560] Epoch[66] Batch[150] avg_epoch_loss=2.592576\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=150 train loss <loss>=2.82125601768\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:51 INFO 139866244298560] Epoch[66] Batch [150]#011Speed: 470.92 samples/sec#011loss=2.821256\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:52 INFO 139866244298560] Epoch[66] Batch[155] avg_epoch_loss=2.599780\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=155 train loss <loss>=2.81733579636\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:52 INFO 139866244298560] Epoch[66] Batch [155]#011Speed: 481.65 samples/sec#011loss=2.817336\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:52 INFO 139866244298560] Epoch[66] Batch[160] avg_epoch_loss=2.602186\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=160 train loss <loss>=2.67726254463\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:52 INFO 139866244298560] Epoch[66] Batch [160]#011Speed: 592.84 samples/sec#011loss=2.677263\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:53 INFO 139866244298560] Epoch[66] Batch[165] avg_epoch_loss=2.603915\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=165 train loss <loss>=2.65960111618\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:53 INFO 139866244298560] Epoch[66] Batch [165]#011Speed: 468.00 samples/sec#011loss=2.659601\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:54 INFO 139866244298560] Epoch[66] Batch[170] avg_epoch_loss=2.597170\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=170 train loss <loss>=2.373219347\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:54 INFO 139866244298560] Epoch[66] Batch [170]#011Speed: 518.80 samples/sec#011loss=2.373219\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:54 INFO 139866244298560] Epoch[66] Batch[175] avg_epoch_loss=2.594064\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=175 train loss <loss>=2.48784828186\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:54 INFO 139866244298560] Epoch[66] Batch [175]#011Speed: 464.74 samples/sec#011loss=2.487848\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:55 INFO 139866244298560] Epoch[66] Batch[180] avg_epoch_loss=2.598799\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=180 train loss <loss>=2.76546902657\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:55 INFO 139866244298560] Epoch[66] Batch [180]#011Speed: 586.80 samples/sec#011loss=2.765469\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:56 INFO 139866244298560] Epoch[66] Batch[185] avg_epoch_loss=2.597217\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=185 train loss <loss>=2.53994646072\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:56 INFO 139866244298560] Epoch[66] Batch [185]#011Speed: 427.96 samples/sec#011loss=2.539946\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:56 INFO 139866244298560] Epoch[66] Batch[190] avg_epoch_loss=2.597263\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=190 train loss <loss>=2.59896273613\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:56 INFO 139866244298560] Epoch[66] Batch [190]#011Speed: 596.14 samples/sec#011loss=2.598963\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:57 INFO 139866244298560] Epoch[66] Batch[195] avg_epoch_loss=2.601120\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=195 train loss <loss>=2.74846012592\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:57 INFO 139866244298560] Epoch[66] Batch [195]#011Speed: 483.02 samples/sec#011loss=2.748460\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:57 INFO 139866244298560] Epoch[66] Batch[200] avg_epoch_loss=2.617050\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=200 train loss <loss>=3.24153351784\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:57 INFO 139866244298560] Epoch[66] Batch [200]#011Speed: 592.11 samples/sec#011loss=3.241534\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:58 INFO 139866244298560] Epoch[66] Batch[205] avg_epoch_loss=2.624843\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=205 train loss <loss>=2.93810362816\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:58 INFO 139866244298560] Epoch[66] Batch [205]#011Speed: 476.30 samples/sec#011loss=2.938104\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:59 INFO 139866244298560] Epoch[66] Batch[210] avg_epoch_loss=2.638149\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=210 train loss <loss>=3.1863743782\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:59 INFO 139866244298560] Epoch[66] Batch [210]#011Speed: 587.53 samples/sec#011loss=3.186374\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:59 INFO 139866244298560] Epoch[66] Batch[215] avg_epoch_loss=2.643373\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=215 train loss <loss>=2.86380133629\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:02:59 INFO 139866244298560] Epoch[66] Batch [215]#011Speed: 487.25 samples/sec#011loss=2.863801\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:00 INFO 139866244298560] Epoch[66] Batch[220] avg_epoch_loss=2.648912\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=220 train loss <loss>=2.88821783066\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:00 INFO 139866244298560] Epoch[66] Batch [220]#011Speed: 586.64 samples/sec#011loss=2.888218\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:00 INFO 139866244298560] Epoch[66] Batch[225] avg_epoch_loss=2.649980\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=225 train loss <loss>=2.69717564583\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:00 INFO 139866244298560] Epoch[66] Batch [225]#011Speed: 449.94 samples/sec#011loss=2.697176\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:01 INFO 139866244298560] Epoch[66] Batch[230] avg_epoch_loss=2.647210\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=230 train loss <loss>=2.52199895382\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:01 INFO 139866244298560] Epoch[66] Batch [230]#011Speed: 557.48 samples/sec#011loss=2.521999\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:02 INFO 139866244298560] Epoch[66] Batch[235] avg_epoch_loss=2.648362\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=235 train loss <loss>=2.7015642643\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:02 INFO 139866244298560] Epoch[66] Batch [235]#011Speed: 469.79 samples/sec#011loss=2.701564\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:02 INFO 139866244298560] Epoch[66] Batch[240] avg_epoch_loss=2.642449\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=240 train loss <loss>=2.36338381767\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:02 INFO 139866244298560] Epoch[66] Batch [240]#011Speed: 589.38 samples/sec#011loss=2.363384\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:03 INFO 139866244298560] Epoch[66] Batch[245] avg_epoch_loss=2.646468\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=245 train loss <loss>=2.84017677307\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:03 INFO 139866244298560] Epoch[66] Batch [245]#011Speed: 482.25 samples/sec#011loss=2.840177\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:03 INFO 139866244298560] Epoch[66] Batch[250] avg_epoch_loss=2.648734\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=250 train loss <loss>=2.76020498276\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:03 INFO 139866244298560] Epoch[66] Batch [250]#011Speed: 586.69 samples/sec#011loss=2.760205\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:04 INFO 139866244298560] Epoch[66] Batch[255] avg_epoch_loss=2.654657\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=255 train loss <loss>=2.95199642181\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:04 INFO 139866244298560] Epoch[66] Batch [255]#011Speed: 472.58 samples/sec#011loss=2.951996\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:05 INFO 139866244298560] Epoch[66] Batch[260] avg_epoch_loss=2.661871\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=260 train loss <loss>=3.03122558594\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:05 INFO 139866244298560] Epoch[66] Batch [260]#011Speed: 589.34 samples/sec#011loss=3.031226\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:05 INFO 139866244298560] Epoch[66] Batch[265] avg_epoch_loss=2.666792\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=265 train loss <loss>=2.92367863655\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:05 INFO 139866244298560] Epoch[66] Batch [265]#011Speed: 484.26 samples/sec#011loss=2.923679\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:06 INFO 139866244298560] Epoch[66] Batch[270] avg_epoch_loss=2.675690\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, batch=270 train loss <loss>=3.14905138016\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:06 INFO 139866244298560] Epoch[66] Batch [270]#011Speed: 482.24 samples/sec#011loss=3.149051\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:06 INFO 139866244298560] processed a total of 17307 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33783.254861831665, \"sum\": 33783.254861831665, \"min\": 33783.254861831665}}, \"EndTime\": 1599444186.470779, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599444152.686814}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:06 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=512.293398374 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:06 INFO 139866244298560] #progress_metric: host=algo-1, completed 83 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=66, train loss <loss>=2.67568970694\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:06 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:06 INFO 139866244298560] Epoch[67] Batch[0] avg_epoch_loss=2.251102\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=0 train loss <loss>=2.25110197067\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:07 INFO 139866244298560] Epoch[67] Batch[5] avg_epoch_loss=1.997358\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=5 train loss <loss>=1.99735846122\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:07 INFO 139866244298560] Epoch[67] Batch [5]#011Speed: 588.40 samples/sec#011loss=1.997358\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:07 INFO 139866244298560] Epoch[67] Batch[10] avg_epoch_loss=2.227302\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=10 train loss <loss>=2.50323534012\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:07 INFO 139866244298560] Epoch[67] Batch [10]#011Speed: 474.68 samples/sec#011loss=2.503235\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:08 INFO 139866244298560] Epoch[67] Batch[15] avg_epoch_loss=2.352093\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=15 train loss <loss>=2.62663354874\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:08 INFO 139866244298560] Epoch[67] Batch [15]#011Speed: 594.36 samples/sec#011loss=2.626634\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:09 INFO 139866244298560] Epoch[67] Batch[20] avg_epoch_loss=2.438437\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=20 train loss <loss>=2.71473555565\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:09 INFO 139866244298560] Epoch[67] Batch [20]#011Speed: 464.75 samples/sec#011loss=2.714736\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:09 INFO 139866244298560] Epoch[67] Batch[25] avg_epoch_loss=2.480027\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=25 train loss <loss>=2.65470523834\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:09 INFO 139866244298560] Epoch[67] Batch [25]#011Speed: 589.62 samples/sec#011loss=2.654705\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:10 INFO 139866244298560] Epoch[67] Batch[30] avg_epoch_loss=2.478839\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=30 train loss <loss>=2.47266316414\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:10 INFO 139866244298560] Epoch[67] Batch [30]#011Speed: 475.48 samples/sec#011loss=2.472663\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:10 INFO 139866244298560] Epoch[67] Batch[35] avg_epoch_loss=2.440889\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=35 train loss <loss>=2.20559856892\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:10 INFO 139866244298560] Epoch[67] Batch [35]#011Speed: 589.30 samples/sec#011loss=2.205599\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:11 INFO 139866244298560] Epoch[67] Batch[40] avg_epoch_loss=2.437839\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=40 train loss <loss>=2.41588025093\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:11 INFO 139866244298560] Epoch[67] Batch [40]#011Speed: 450.72 samples/sec#011loss=2.415880\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:12 INFO 139866244298560] Epoch[67] Batch[45] avg_epoch_loss=2.446917\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=45 train loss <loss>=2.52135276794\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:12 INFO 139866244298560] Epoch[67] Batch [45]#011Speed: 590.47 samples/sec#011loss=2.521353\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:12 INFO 139866244298560] Epoch[67] Batch[50] avg_epoch_loss=2.451121\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=50 train loss <loss>=2.48979830742\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:12 INFO 139866244298560] Epoch[67] Batch [50]#011Speed: 479.26 samples/sec#011loss=2.489798\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:13 INFO 139866244298560] Epoch[67] Batch[55] avg_epoch_loss=2.438983\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=55 train loss <loss>=2.31518177986\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:13 INFO 139866244298560] Epoch[67] Batch [55]#011Speed: 599.65 samples/sec#011loss=2.315182\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:14 INFO 139866244298560] Epoch[67] Batch[60] avg_epoch_loss=2.443713\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=60 train loss <loss>=2.49667978287\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:14 INFO 139866244298560] Epoch[67] Batch [60]#011Speed: 467.40 samples/sec#011loss=2.496680\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:14 INFO 139866244298560] Epoch[67] Batch[65] avg_epoch_loss=2.448301\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=65 train loss <loss>=2.50428228378\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:14 INFO 139866244298560] Epoch[67] Batch [65]#011Speed: 593.38 samples/sec#011loss=2.504282\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:15 INFO 139866244298560] Epoch[67] Batch[70] avg_epoch_loss=2.496170\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=70 train loss <loss>=3.12804131508\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:15 INFO 139866244298560] Epoch[67] Batch [70]#011Speed: 473.16 samples/sec#011loss=3.128041\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:15 INFO 139866244298560] Epoch[67] Batch[75] avg_epoch_loss=2.543820\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=75 train loss <loss>=3.22044725418\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:15 INFO 139866244298560] Epoch[67] Batch [75]#011Speed: 474.17 samples/sec#011loss=3.220447\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:16 INFO 139866244298560] Epoch[67] Batch[80] avg_epoch_loss=2.571991\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=80 train loss <loss>=3.00018601418\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:16 INFO 139866244298560] Epoch[67] Batch [80]#011Speed: 517.60 samples/sec#011loss=3.000186\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:17 INFO 139866244298560] Epoch[67] Batch[85] avg_epoch_loss=2.595244\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=85 train loss <loss>=2.97194252014\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:17 INFO 139866244298560] Epoch[67] Batch [85]#011Speed: 462.86 samples/sec#011loss=2.971943\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:17 INFO 139866244298560] Epoch[67] Batch[90] avg_epoch_loss=2.586341\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=90 train loss <loss>=2.43320803642\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:17 INFO 139866244298560] Epoch[67] Batch [90]#011Speed: 588.83 samples/sec#011loss=2.433208\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:18 INFO 139866244298560] Epoch[67] Batch[95] avg_epoch_loss=2.580404\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=95 train loss <loss>=2.47235269547\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:18 INFO 139866244298560] Epoch[67] Batch [95]#011Speed: 475.13 samples/sec#011loss=2.472353\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:19 INFO 139866244298560] Epoch[67] Batch[100] avg_epoch_loss=2.582196\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=100 train loss <loss>=2.61660366058\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:19 INFO 139866244298560] Epoch[67] Batch [100]#011Speed: 588.11 samples/sec#011loss=2.616604\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:19 INFO 139866244298560] Epoch[67] Batch[105] avg_epoch_loss=2.566042\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=105 train loss <loss>=2.23973929882\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:19 INFO 139866244298560] Epoch[67] Batch [105]#011Speed: 475.17 samples/sec#011loss=2.239739\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:20 INFO 139866244298560] Epoch[67] Batch[110] avg_epoch_loss=2.549000\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=110 train loss <loss>=2.18771071434\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:20 INFO 139866244298560] Epoch[67] Batch [110]#011Speed: 592.74 samples/sec#011loss=2.187711\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:20 INFO 139866244298560] Epoch[67] Batch[115] avg_epoch_loss=2.545537\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=115 train loss <loss>=2.46865649223\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:20 INFO 139866244298560] Epoch[67] Batch [115]#011Speed: 483.70 samples/sec#011loss=2.468656\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:21 INFO 139866244298560] Epoch[67] Batch[120] avg_epoch_loss=2.549007\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=120 train loss <loss>=2.62949934006\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:21 INFO 139866244298560] Epoch[67] Batch [120]#011Speed: 533.91 samples/sec#011loss=2.629499\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:22 INFO 139866244298560] Epoch[67] Batch[125] avg_epoch_loss=2.567014\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=125 train loss <loss>=3.00278935432\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:22 INFO 139866244298560] Epoch[67] Batch [125]#011Speed: 481.17 samples/sec#011loss=3.002789\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:22 INFO 139866244298560] Epoch[67] Batch[130] avg_epoch_loss=2.578563\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=130 train loss <loss>=2.86959524155\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:22 INFO 139866244298560] Epoch[67] Batch [130]#011Speed: 586.01 samples/sec#011loss=2.869595\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:23 INFO 139866244298560] Epoch[67] Batch[135] avg_epoch_loss=2.579330\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=135 train loss <loss>=2.59942631721\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:23 INFO 139866244298560] Epoch[67] Batch [135]#011Speed: 476.93 samples/sec#011loss=2.599426\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:23 INFO 139866244298560] Epoch[67] Batch[140] avg_epoch_loss=2.573120\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=140 train loss <loss>=2.40420122147\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:23 INFO 139866244298560] Epoch[67] Batch [140]#011Speed: 580.37 samples/sec#011loss=2.404201\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:24 INFO 139866244298560] Epoch[67] Batch[145] avg_epoch_loss=2.555299\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=145 train loss <loss>=2.05274317265\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:24 INFO 139866244298560] Epoch[67] Batch [145]#011Speed: 440.68 samples/sec#011loss=2.052743\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:25 INFO 139866244298560] Epoch[67] Batch[150] avg_epoch_loss=2.543140\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=150 train loss <loss>=2.18812170029\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:25 INFO 139866244298560] Epoch[67] Batch [150]#011Speed: 478.35 samples/sec#011loss=2.188122\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:25 INFO 139866244298560] Epoch[67] Batch[155] avg_epoch_loss=2.537835\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=155 train loss <loss>=2.37759728432\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:25 INFO 139866244298560] Epoch[67] Batch [155]#011Speed: 583.40 samples/sec#011loss=2.377597\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:26 INFO 139866244298560] Epoch[67] Batch[160] avg_epoch_loss=2.536023\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=160 train loss <loss>=2.47951350212\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:26 INFO 139866244298560] Epoch[67] Batch [160]#011Speed: 446.03 samples/sec#011loss=2.479514\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:27 INFO 139866244298560] Epoch[67] Batch[165] avg_epoch_loss=2.541829\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=165 train loss <loss>=2.72876620293\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:27 INFO 139866244298560] Epoch[67] Batch [165]#011Speed: 592.08 samples/sec#011loss=2.728766\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:27 INFO 139866244298560] Epoch[67] Batch[170] avg_epoch_loss=2.545605\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=170 train loss <loss>=2.67095856667\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:27 INFO 139866244298560] Epoch[67] Batch [170]#011Speed: 471.88 samples/sec#011loss=2.670959\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:28 INFO 139866244298560] Epoch[67] Batch[175] avg_epoch_loss=2.560620\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=175 train loss <loss>=3.07414932251\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:28 INFO 139866244298560] Epoch[67] Batch [175]#011Speed: 595.77 samples/sec#011loss=3.074149\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:29 INFO 139866244298560] Epoch[67] Batch[180] avg_epoch_loss=2.579555\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=180 train loss <loss>=3.24605717659\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:29 INFO 139866244298560] Epoch[67] Batch [180]#011Speed: 480.13 samples/sec#011loss=3.246057\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:29 INFO 139866244298560] Epoch[67] Batch[185] avg_epoch_loss=2.594254\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=185 train loss <loss>=3.12634954453\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:29 INFO 139866244298560] Epoch[67] Batch [185]#011Speed: 594.51 samples/sec#011loss=3.126350\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:30 INFO 139866244298560] Epoch[67] Batch[190] avg_epoch_loss=2.596475\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=190 train loss <loss>=2.67909946442\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:30 INFO 139866244298560] Epoch[67] Batch [190]#011Speed: 480.69 samples/sec#011loss=2.679099\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:30 INFO 139866244298560] Epoch[67] Batch[195] avg_epoch_loss=2.595069\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=195 train loss <loss>=2.5413734436\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:30 INFO 139866244298560] Epoch[67] Batch [195]#011Speed: 579.35 samples/sec#011loss=2.541373\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:31 INFO 139866244298560] Epoch[67] Batch[200] avg_epoch_loss=2.596874\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=200 train loss <loss>=2.6676094532\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:31 INFO 139866244298560] Epoch[67] Batch [200]#011Speed: 451.96 samples/sec#011loss=2.667609\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:32 INFO 139866244298560] Epoch[67] Batch[205] avg_epoch_loss=2.598230\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=205 train loss <loss>=2.65277585983\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:32 INFO 139866244298560] Epoch[67] Batch [205]#011Speed: 543.92 samples/sec#011loss=2.652776\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:32 INFO 139866244298560] Epoch[67] Batch[210] avg_epoch_loss=2.593867\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=210 train loss <loss>=2.41411600113\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:32 INFO 139866244298560] Epoch[67] Batch [210]#011Speed: 473.61 samples/sec#011loss=2.414116\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:33 INFO 139866244298560] Epoch[67] Batch[215] avg_epoch_loss=2.589538\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=215 train loss <loss>=2.40684361458\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:33 INFO 139866244298560] Epoch[67] Batch [215]#011Speed: 592.65 samples/sec#011loss=2.406844\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:33 INFO 139866244298560] Epoch[67] Batch[220] avg_epoch_loss=2.600012\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=220 train loss <loss>=3.05247449875\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:33 INFO 139866244298560] Epoch[67] Batch [220]#011Speed: 473.66 samples/sec#011loss=3.052474\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:34 INFO 139866244298560] Epoch[67] Batch[225] avg_epoch_loss=2.603090\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=225 train loss <loss>=2.73912396431\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:34 INFO 139866244298560] Epoch[67] Batch [225]#011Speed: 589.40 samples/sec#011loss=2.739124\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:35 INFO 139866244298560] Epoch[67] Batch[230] avg_epoch_loss=2.622129\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=230 train loss <loss>=3.48272848129\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:35 INFO 139866244298560] Epoch[67] Batch [230]#011Speed: 472.44 samples/sec#011loss=3.482728\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:35 INFO 139866244298560] Epoch[67] Batch[235] avg_epoch_loss=2.637254\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=235 train loss <loss>=3.33601865768\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:35 INFO 139866244298560] Epoch[67] Batch [235]#011Speed: 477.21 samples/sec#011loss=3.336019\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:36 INFO 139866244298560] Epoch[67] Batch[240] avg_epoch_loss=2.651799\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=240 train loss <loss>=3.33829884529\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:36 INFO 139866244298560] Epoch[67] Batch [240]#011Speed: 595.41 samples/sec#011loss=3.338299\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:37 INFO 139866244298560] Epoch[67] Batch[245] avg_epoch_loss=2.666418\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=245 train loss <loss>=3.3710916996\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:37 INFO 139866244298560] Epoch[67] Batch [245]#011Speed: 425.02 samples/sec#011loss=3.371092\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:37 INFO 139866244298560] Epoch[67] Batch[250] avg_epoch_loss=2.665713\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=250 train loss <loss>=2.63102850914\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:37 INFO 139866244298560] Epoch[67] Batch [250]#011Speed: 593.08 samples/sec#011loss=2.631029\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:38 INFO 139866244298560] Epoch[67] Batch[255] avg_epoch_loss=2.666848\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=255 train loss <loss>=2.72380099297\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:38 INFO 139866244298560] Epoch[67] Batch [255]#011Speed: 476.92 samples/sec#011loss=2.723801\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:38 INFO 139866244298560] Epoch[67] Batch[260] avg_epoch_loss=2.662778\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=260 train loss <loss>=2.45437431335\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:38 INFO 139866244298560] Epoch[67] Batch [260]#011Speed: 586.42 samples/sec#011loss=2.454374\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:39 INFO 139866244298560] Epoch[67] Batch[265] avg_epoch_loss=2.663686\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, batch=265 train loss <loss>=2.71109790802\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:39 INFO 139866244298560] Epoch[67] Batch [265]#011Speed: 543.61 samples/sec#011loss=2.711098\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:39 INFO 139866244298560] processed a total of 17116 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33237.05196380615, \"sum\": 33237.05196380615, \"min\": 33237.05196380615}}, \"EndTime\": 1599444219.708473, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599444186.470845}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:39 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=514.965576602 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:39 INFO 139866244298560] #progress_metric: host=algo-1, completed 85 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=67, train loss <loss>=2.67429897678\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:39 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:39 INFO 139866244298560] Epoch[68] Batch[0] avg_epoch_loss=2.095951\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=0 train loss <loss>=2.09595131874\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:40 INFO 139866244298560] Epoch[68] Batch[5] avg_epoch_loss=2.204872\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=5 train loss <loss>=2.20487211148\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:40 INFO 139866244298560] Epoch[68] Batch [5]#011Speed: 590.98 samples/sec#011loss=2.204872\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:41 INFO 139866244298560] Epoch[68] Batch[10] avg_epoch_loss=2.199268\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=10 train loss <loss>=2.1925429821\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:41 INFO 139866244298560] Epoch[68] Batch [10]#011Speed: 467.75 samples/sec#011loss=2.192543\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:41 INFO 139866244298560] Epoch[68] Batch[15] avg_epoch_loss=2.313962\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=15 train loss <loss>=2.56628923416\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:41 INFO 139866244298560] Epoch[68] Batch [15]#011Speed: 594.04 samples/sec#011loss=2.566289\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:42 INFO 139866244298560] Epoch[68] Batch[20] avg_epoch_loss=2.388431\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=20 train loss <loss>=2.62673125267\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:42 INFO 139866244298560] Epoch[68] Batch [20]#011Speed: 428.15 samples/sec#011loss=2.626731\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:43 INFO 139866244298560] Epoch[68] Batch[25] avg_epoch_loss=2.464651\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=25 train loss <loss>=2.78477387428\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:43 INFO 139866244298560] Epoch[68] Batch [25]#011Speed: 590.52 samples/sec#011loss=2.784774\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:43 INFO 139866244298560] Epoch[68] Batch[30] avg_epoch_loss=2.501665\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=30 train loss <loss>=2.69414219856\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:43 INFO 139866244298560] Epoch[68] Batch [30]#011Speed: 479.80 samples/sec#011loss=2.694142\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:44 INFO 139866244298560] Epoch[68] Batch[35] avg_epoch_loss=2.469189\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=35 train loss <loss>=2.26783418655\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:44 INFO 139866244298560] Epoch[68] Batch [35]#011Speed: 582.60 samples/sec#011loss=2.267834\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:44 INFO 139866244298560] Epoch[68] Batch[40] avg_epoch_loss=2.500876\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=40 train loss <loss>=2.72902183533\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:44 INFO 139866244298560] Epoch[68] Batch [40]#011Speed: 472.70 samples/sec#011loss=2.729022\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:45 INFO 139866244298560] Epoch[68] Batch[45] avg_epoch_loss=2.497255\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=45 train loss <loss>=2.46756014824\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:45 INFO 139866244298560] Epoch[68] Batch [45]#011Speed: 593.13 samples/sec#011loss=2.467560\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:46 INFO 139866244298560] Epoch[68] Batch[50] avg_epoch_loss=2.492755\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=50 train loss <loss>=2.45135416985\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:46 INFO 139866244298560] Epoch[68] Batch [50]#011Speed: 469.09 samples/sec#011loss=2.451354\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:46 INFO 139866244298560] Epoch[68] Batch[55] avg_epoch_loss=2.474401\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=55 train loss <loss>=2.28719134331\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:46 INFO 139866244298560] Epoch[68] Batch [55]#011Speed: 594.18 samples/sec#011loss=2.287191\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:47 INFO 139866244298560] Epoch[68] Batch[60] avg_epoch_loss=2.456980\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=60 train loss <loss>=2.2618635416\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:47 INFO 139866244298560] Epoch[68] Batch [60]#011Speed: 437.31 samples/sec#011loss=2.261864\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:47 INFO 139866244298560] Epoch[68] Batch[65] avg_epoch_loss=2.466195\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:47 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=65 train loss <loss>=2.57861680984\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:47 INFO 139866244298560] Epoch[68] Batch [65]#011Speed: 590.95 samples/sec#011loss=2.578617\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:48 INFO 139866244298560] Epoch[68] Batch[70] avg_epoch_loss=2.481233\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:48 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=70 train loss <loss>=2.67973666191\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:48 INFO 139866244298560] Epoch[68] Batch [70]#011Speed: 480.48 samples/sec#011loss=2.679737\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:49 INFO 139866244298560] Epoch[68] Batch[75] avg_epoch_loss=2.486655\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=75 train loss <loss>=2.56364636421\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:49 INFO 139866244298560] Epoch[68] Batch [75]#011Speed: 593.56 samples/sec#011loss=2.563646\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:49 INFO 139866244298560] Epoch[68] Batch[80] avg_epoch_loss=2.525615\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:49 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=80 train loss <loss>=3.11781892776\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:49 INFO 139866244298560] Epoch[68] Batch [80]#011Speed: 476.23 samples/sec#011loss=3.117819\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:50 INFO 139866244298560] Epoch[68] Batch[85] avg_epoch_loss=2.564031\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:50 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=85 train loss <loss>=3.18636035919\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:50 INFO 139866244298560] Epoch[68] Batch [85]#011Speed: 593.66 samples/sec#011loss=3.186360\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:51 INFO 139866244298560] Epoch[68] Batch[90] avg_epoch_loss=2.582945\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=90 train loss <loss>=2.90827283859\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:51 INFO 139866244298560] Epoch[68] Batch [90]#011Speed: 466.87 samples/sec#011loss=2.908273\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:51 INFO 139866244298560] Epoch[68] Batch[95] avg_epoch_loss=2.597379\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:51 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=95 train loss <loss>=2.86008200645\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:51 INFO 139866244298560] Epoch[68] Batch [95]#011Speed: 591.14 samples/sec#011loss=2.860082\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:52 INFO 139866244298560] Epoch[68] Batch[100] avg_epoch_loss=2.587812\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=100 train loss <loss>=2.40412569046\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:52 INFO 139866244298560] Epoch[68] Batch [100]#011Speed: 448.12 samples/sec#011loss=2.404126\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:52 INFO 139866244298560] Epoch[68] Batch[105] avg_epoch_loss=2.582414\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:52 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=105 train loss <loss>=2.47335543633\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:52 INFO 139866244298560] Epoch[68] Batch [105]#011Speed: 592.53 samples/sec#011loss=2.473355\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:53 INFO 139866244298560] Epoch[68] Batch[110] avg_epoch_loss=2.573137\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:53 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=110 train loss <loss>=2.37647519112\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:53 INFO 139866244298560] Epoch[68] Batch [110]#011Speed: 469.42 samples/sec#011loss=2.376475\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:54 INFO 139866244298560] Epoch[68] Batch[115] avg_epoch_loss=2.561016\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=115 train loss <loss>=2.29193630219\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:54 INFO 139866244298560] Epoch[68] Batch [115]#011Speed: 441.34 samples/sec#011loss=2.291936\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:54 INFO 139866244298560] Epoch[68] Batch[120] avg_epoch_loss=2.544785\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:54 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=120 train loss <loss>=2.16821162701\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:54 INFO 139866244298560] Epoch[68] Batch [120]#011Speed: 572.41 samples/sec#011loss=2.168212\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:55 INFO 139866244298560] Epoch[68] Batch[125] avg_epoch_loss=2.540922\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:55 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=125 train loss <loss>=2.44744973183\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:55 INFO 139866244298560] Epoch[68] Batch [125]#011Speed: 475.31 samples/sec#011loss=2.447450\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:56 INFO 139866244298560] Epoch[68] Batch[130] avg_epoch_loss=2.537219\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=130 train loss <loss>=2.44390044212\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:56 INFO 139866244298560] Epoch[68] Batch [130]#011Speed: 585.20 samples/sec#011loss=2.443900\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:56 INFO 139866244298560] Epoch[68] Batch[135] avg_epoch_loss=2.540921\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:56 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=135 train loss <loss>=2.63790860176\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:56 INFO 139866244298560] Epoch[68] Batch [135]#011Speed: 472.39 samples/sec#011loss=2.637909\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:57 INFO 139866244298560] Epoch[68] Batch[140] avg_epoch_loss=2.552161\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=140 train loss <loss>=2.85790534019\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:57 INFO 139866244298560] Epoch[68] Batch [140]#011Speed: 562.63 samples/sec#011loss=2.857905\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:57 INFO 139866244298560] Epoch[68] Batch[145] avg_epoch_loss=2.566507\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:57 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=145 train loss <loss>=2.97105407715\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:57 INFO 139866244298560] Epoch[68] Batch [145]#011Speed: 443.72 samples/sec#011loss=2.971054\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:58 INFO 139866244298560] Epoch[68] Batch[150] avg_epoch_loss=2.574253\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:58 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=150 train loss <loss>=2.80043325424\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:58 INFO 139866244298560] Epoch[68] Batch [150]#011Speed: 589.01 samples/sec#011loss=2.800433\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:59 INFO 139866244298560] Epoch[68] Batch[155] avg_epoch_loss=2.571353\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=155 train loss <loss>=2.48376526833\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:59 INFO 139866244298560] Epoch[68] Batch [155]#011Speed: 479.44 samples/sec#011loss=2.483765\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:59 INFO 139866244298560] Epoch[68] Batch[160] avg_epoch_loss=2.575870\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:59 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=160 train loss <loss>=2.71680107117\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:03:59 INFO 139866244298560] Epoch[68] Batch [160]#011Speed: 591.00 samples/sec#011loss=2.716801\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:00 INFO 139866244298560] Epoch[68] Batch[165] avg_epoch_loss=2.567016\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=165 train loss <loss>=2.28193860054\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:00 INFO 139866244298560] Epoch[68] Batch [165]#011Speed: 473.82 samples/sec#011loss=2.281939\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:00 INFO 139866244298560] Epoch[68] Batch[170] avg_epoch_loss=2.563764\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:00 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=170 train loss <loss>=2.45577597618\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:00 INFO 139866244298560] Epoch[68] Batch [170]#011Speed: 586.05 samples/sec#011loss=2.455776\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:01 INFO 139866244298560] Epoch[68] Batch[175] avg_epoch_loss=2.560720\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:01 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=175 train loss <loss>=2.45662822723\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:01 INFO 139866244298560] Epoch[68] Batch [175]#011Speed: 455.66 samples/sec#011loss=2.456628\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:02 INFO 139866244298560] Epoch[68] Batch[180] avg_epoch_loss=2.565454\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=180 train loss <loss>=2.73210067749\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:02 INFO 139866244298560] Epoch[68] Batch [180]#011Speed: 588.01 samples/sec#011loss=2.732101\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:02 INFO 139866244298560] Epoch[68] Batch[185] avg_epoch_loss=2.566363\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:02 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=185 train loss <loss>=2.59923887253\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:02 INFO 139866244298560] Epoch[68] Batch [185]#011Speed: 425.69 samples/sec#011loss=2.599239\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:03 INFO 139866244298560] Epoch[68] Batch[190] avg_epoch_loss=2.561993\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:03 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=190 train loss <loss>=2.39943270683\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:03 INFO 139866244298560] Epoch[68] Batch [190]#011Speed: 588.66 samples/sec#011loss=2.399433\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:04 INFO 139866244298560] Epoch[68] Batch[195] avg_epoch_loss=2.576623\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=195 train loss <loss>=3.13551239967\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:04 INFO 139866244298560] Epoch[68] Batch [195]#011Speed: 478.42 samples/sec#011loss=3.135512\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:04 INFO 139866244298560] Epoch[68] Batch[200] avg_epoch_loss=2.594513\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:04 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=200 train loss <loss>=3.29580407143\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:04 INFO 139866244298560] Epoch[68] Batch [200]#011Speed: 590.43 samples/sec#011loss=3.295804\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:05 INFO 139866244298560] Epoch[68] Batch[205] avg_epoch_loss=2.618123\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:05 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=205 train loss <loss>=3.56721744537\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:05 INFO 139866244298560] Epoch[68] Batch [205]#011Speed: 479.99 samples/sec#011loss=3.567217\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:06 INFO 139866244298560] Epoch[68] Batch[210] avg_epoch_loss=2.633442\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=210 train loss <loss>=3.2645881176\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:06 INFO 139866244298560] Epoch[68] Batch [210]#011Speed: 476.07 samples/sec#011loss=3.264588\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:06 INFO 139866244298560] Epoch[68] Batch[215] avg_epoch_loss=2.635977\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:06 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=215 train loss <loss>=2.74295072556\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:06 INFO 139866244298560] Epoch[68] Batch [215]#011Speed: 592.11 samples/sec#011loss=2.742951\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:07 INFO 139866244298560] Epoch[68] Batch[220] avg_epoch_loss=2.637933\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=220 train loss <loss>=2.72244076729\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:07 INFO 139866244298560] Epoch[68] Batch [220]#011Speed: 475.49 samples/sec#011loss=2.722441\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:07 INFO 139866244298560] Epoch[68] Batch[225] avg_epoch_loss=2.630224\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:07 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=225 train loss <loss>=2.28947691917\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:07 INFO 139866244298560] Epoch[68] Batch [225]#011Speed: 501.93 samples/sec#011loss=2.289477\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:08 INFO 139866244298560] Epoch[68] Batch[230] avg_epoch_loss=2.627352\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:08 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=230 train loss <loss>=2.49754629135\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:08 INFO 139866244298560] Epoch[68] Batch [230]#011Speed: 468.22 samples/sec#011loss=2.497546\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:09 INFO 139866244298560] Epoch[68] Batch[235] avg_epoch_loss=2.625368\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=235 train loss <loss>=2.53370761871\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:09 INFO 139866244298560] Epoch[68] Batch [235]#011Speed: 576.61 samples/sec#011loss=2.533708\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:09 INFO 139866244298560] Epoch[68] Batch[240] avg_epoch_loss=2.624594\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:09 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=240 train loss <loss>=2.58805131912\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:09 INFO 139866244298560] Epoch[68] Batch [240]#011Speed: 480.31 samples/sec#011loss=2.588051\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:10 INFO 139866244298560] Epoch[68] Batch[245] avg_epoch_loss=2.628250\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:10 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=245 train loss <loss>=2.80449633598\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:10 INFO 139866244298560] Epoch[68] Batch [245]#011Speed: 591.09 samples/sec#011loss=2.804496\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:11 INFO 139866244298560] Epoch[68] Batch[250] avg_epoch_loss=2.635547\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=250 train loss <loss>=2.99455280304\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:11 INFO 139866244298560] Epoch[68] Batch [250]#011Speed: 471.29 samples/sec#011loss=2.994553\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:11 INFO 139866244298560] Epoch[68] Batch[255] avg_epoch_loss=2.650283\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:11 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=255 train loss <loss>=3.39001498222\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:11 INFO 139866244298560] Epoch[68] Batch [255]#011Speed: 593.73 samples/sec#011loss=3.390015\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:12 INFO 139866244298560] Epoch[68] Batch[260] avg_epoch_loss=2.657043\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=260 train loss <loss>=3.00314545631\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:12 INFO 139866244298560] Epoch[68] Batch [260]#011Speed: 493.69 samples/sec#011loss=3.003145\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:12 INFO 139866244298560] Epoch[68] Batch[265] avg_epoch_loss=2.662519\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:12 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, batch=265 train loss <loss>=2.94837055206\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:12 INFO 139866244298560] Epoch[68] Batch [265]#011Speed: 555.10 samples/sec#011loss=2.948371\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:13 INFO 139866244298560] processed a total of 17167 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 33414.15500640869, \"sum\": 33414.15500640869, \"min\": 33414.15500640869}}, \"EndTime\": 1599444253.123314, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599444219.708541}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:13 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=513.762501367 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:13 INFO 139866244298560] #progress_metric: host=algo-1, completed 86 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=68, train loss <loss>=2.65933715411\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:13 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:13 INFO 139866244298560] Epoch[69] Batch[0] avg_epoch_loss=2.121636\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=0 train loss <loss>=2.12163615227\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:13 INFO 139866244298560] Epoch[69] Batch[5] avg_epoch_loss=2.069715\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:13 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=5 train loss <loss>=2.06971548001\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:13 INFO 139866244298560] Epoch[69] Batch [5]#011Speed: 592.01 samples/sec#011loss=2.069715\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:14 INFO 139866244298560] Epoch[69] Batch[10] avg_epoch_loss=2.205180\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:14 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=10 train loss <loss>=2.36773638725\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:14 INFO 139866244298560] Epoch[69] Batch [10]#011Speed: 481.50 samples/sec#011loss=2.367736\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:15 INFO 139866244298560] Epoch[69] Batch[15] avg_epoch_loss=2.379544\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=15 train loss <loss>=2.76314454079\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:15 INFO 139866244298560] Epoch[69] Batch [15]#011Speed: 584.62 samples/sec#011loss=2.763145\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:15 INFO 139866244298560] Epoch[69] Batch[20] avg_epoch_loss=2.483470\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:15 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=20 train loss <loss>=2.81603288651\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:15 INFO 139866244298560] Epoch[69] Batch [20]#011Speed: 472.73 samples/sec#011loss=2.816033\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:16 INFO 139866244298560] Epoch[69] Batch[25] avg_epoch_loss=2.535863\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:16 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=25 train loss <loss>=2.75591311455\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:16 INFO 139866244298560] Epoch[69] Batch [25]#011Speed: 590.39 samples/sec#011loss=2.755913\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:17 INFO 139866244298560] Epoch[69] Batch[30] avg_epoch_loss=2.532624\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=30 train loss <loss>=2.51578409672\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:17 INFO 139866244298560] Epoch[69] Batch [30]#011Speed: 474.49 samples/sec#011loss=2.515784\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:17 INFO 139866244298560] Epoch[69] Batch[35] avg_epoch_loss=2.473366\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:17 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=35 train loss <loss>=2.10596556664\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:17 INFO 139866244298560] Epoch[69] Batch [35]#011Speed: 593.64 samples/sec#011loss=2.105966\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:18 INFO 139866244298560] Epoch[69] Batch[40] avg_epoch_loss=2.464310\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=40 train loss <loss>=2.39911074638\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:18 INFO 139866244298560] Epoch[69] Batch [40]#011Speed: 438.72 samples/sec#011loss=2.399111\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:18 INFO 139866244298560] Epoch[69] Batch[45] avg_epoch_loss=2.466844\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:18 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=45 train loss <loss>=2.48762135506\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:18 INFO 139866244298560] Epoch[69] Batch [45]#011Speed: 587.18 samples/sec#011loss=2.487621\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:19 INFO 139866244298560] Epoch[69] Batch[50] avg_epoch_loss=2.449556\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:19 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=50 train loss <loss>=2.29050226212\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:19 INFO 139866244298560] Epoch[69] Batch [50]#011Speed: 471.26 samples/sec#011loss=2.290502\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:20 INFO 139866244298560] Epoch[69] Batch[55] avg_epoch_loss=2.449178\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=55 train loss <loss>=2.44532833099\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:20 INFO 139866244298560] Epoch[69] Batch [55]#011Speed: 588.86 samples/sec#011loss=2.445328\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:20 INFO 139866244298560] Epoch[69] Batch[60] avg_epoch_loss=2.448108\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:20 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=60 train loss <loss>=2.43612513542\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:20 INFO 139866244298560] Epoch[69] Batch [60]#011Speed: 484.63 samples/sec#011loss=2.436125\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:21 INFO 139866244298560] Epoch[69] Batch[65] avg_epoch_loss=2.448881\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=65 train loss <loss>=2.45830674171\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:21 INFO 139866244298560] Epoch[69] Batch [65]#011Speed: 590.71 samples/sec#011loss=2.458307\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:21 INFO 139866244298560] Epoch[69] Batch[70] avg_epoch_loss=2.520222\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:21 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=70 train loss <loss>=3.46191663742\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:21 INFO 139866244298560] Epoch[69] Batch [70]#011Speed: 485.71 samples/sec#011loss=3.461917\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:22 INFO 139866244298560] Epoch[69] Batch[75] avg_epoch_loss=2.559103\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:22 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=75 train loss <loss>=3.11121373177\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:22 INFO 139866244298560] Epoch[69] Batch [75]#011Speed: 491.84 samples/sec#011loss=3.111214\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:23 INFO 139866244298560] Epoch[69] Batch[80] avg_epoch_loss=2.572498\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=80 train loss <loss>=2.7761095047\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:23 INFO 139866244298560] Epoch[69] Batch [80]#011Speed: 536.00 samples/sec#011loss=2.776110\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:23 INFO 139866244298560] Epoch[69] Batch[85] avg_epoch_loss=2.586851\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:23 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=85 train loss <loss>=2.81937437057\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:23 INFO 139866244298560] Epoch[69] Batch [85]#011Speed: 476.90 samples/sec#011loss=2.819374\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:24 INFO 139866244298560] Epoch[69] Batch[90] avg_epoch_loss=2.568976\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:24 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=90 train loss <loss>=2.2615134716\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:24 INFO 139866244298560] Epoch[69] Batch [90]#011Speed: 552.50 samples/sec#011loss=2.261513\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:25 INFO 139866244298560] Epoch[69] Batch[95] avg_epoch_loss=2.546709\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=95 train loss <loss>=2.1414618969\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:25 INFO 139866244298560] Epoch[69] Batch [95]#011Speed: 454.16 samples/sec#011loss=2.141462\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:25 INFO 139866244298560] Epoch[69] Batch[100] avg_epoch_loss=2.548087\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:25 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=100 train loss <loss>=2.57454295158\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:25 INFO 139866244298560] Epoch[69] Batch [100]#011Speed: 592.03 samples/sec#011loss=2.574543\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:26 INFO 139866244298560] Epoch[69] Batch[105] avg_epoch_loss=2.546658\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=105 train loss <loss>=2.51779046059\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:26 INFO 139866244298560] Epoch[69] Batch [105]#011Speed: 479.84 samples/sec#011loss=2.517790\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:26 INFO 139866244298560] Epoch[69] Batch[110] avg_epoch_loss=2.536478\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:26 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=110 train loss <loss>=2.32064988613\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:26 INFO 139866244298560] Epoch[69] Batch [110]#011Speed: 594.36 samples/sec#011loss=2.320650\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:27 INFO 139866244298560] Epoch[69] Batch[115] avg_epoch_loss=2.543616\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:27 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=115 train loss <loss>=2.70208454132\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:27 INFO 139866244298560] Epoch[69] Batch [115]#011Speed: 483.13 samples/sec#011loss=2.702085\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:28 INFO 139866244298560] Epoch[69] Batch[120] avg_epoch_loss=2.558490\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=120 train loss <loss>=2.90356669426\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:28 INFO 139866244298560] Epoch[69] Batch [120]#011Speed: 555.87 samples/sec#011loss=2.903567\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:28 INFO 139866244298560] Epoch[69] Batch[125] avg_epoch_loss=2.578458\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:28 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=125 train loss <loss>=3.06169996262\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:28 INFO 139866244298560] Epoch[69] Batch [125]#011Speed: 485.73 samples/sec#011loss=3.061700\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:29 INFO 139866244298560] Epoch[69] Batch[130] avg_epoch_loss=2.587902\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:29 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=130 train loss <loss>=2.82586731911\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:29 INFO 139866244298560] Epoch[69] Batch [130]#011Speed: 466.70 samples/sec#011loss=2.825867\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:30 INFO 139866244298560] Epoch[69] Batch[135] avg_epoch_loss=2.582002\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=135 train loss <loss>=2.42743535042\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:30 INFO 139866244298560] Epoch[69] Batch [135]#011Speed: 579.23 samples/sec#011loss=2.427435\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:30 INFO 139866244298560] Epoch[69] Batch[140] avg_epoch_loss=2.565836\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:30 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=140 train loss <loss>=2.12611262798\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:30 INFO 139866244298560] Epoch[69] Batch [140]#011Speed: 468.67 samples/sec#011loss=2.126113\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:31 INFO 139866244298560] Epoch[69] Batch[145] avg_epoch_loss=2.554272\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=145 train loss <loss>=2.228175354\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:31 INFO 139866244298560] Epoch[69] Batch [145]#011Speed: 589.70 samples/sec#011loss=2.228175\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:31 INFO 139866244298560] Epoch[69] Batch[150] avg_epoch_loss=2.543574\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:31 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=150 train loss <loss>=2.23117966652\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:31 INFO 139866244298560] Epoch[69] Batch [150]#011Speed: 481.61 samples/sec#011loss=2.231180\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:32 INFO 139866244298560] Epoch[69] Batch[155] avg_epoch_loss=2.542102\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:32 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=155 train loss <loss>=2.49766054153\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:32 INFO 139866244298560] Epoch[69] Batch [155]#011Speed: 596.50 samples/sec#011loss=2.497661\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:33 INFO 139866244298560] Epoch[69] Batch[160] avg_epoch_loss=2.540229\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=160 train loss <loss>=2.48179292679\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:33 INFO 139866244298560] Epoch[69] Batch [160]#011Speed: 435.91 samples/sec#011loss=2.481793\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:33 INFO 139866244298560] Epoch[69] Batch[165] avg_epoch_loss=2.537528\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:33 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=165 train loss <loss>=2.45054101944\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:33 INFO 139866244298560] Epoch[69] Batch [165]#011Speed: 572.59 samples/sec#011loss=2.450541\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:34 INFO 139866244298560] Epoch[69] Batch[170] avg_epoch_loss=2.543457\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=170 train loss <loss>=2.74031796455\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:34 INFO 139866244298560] Epoch[69] Batch [170]#011Speed: 476.85 samples/sec#011loss=2.740318\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:34 INFO 139866244298560] Epoch[69] Batch[175] avg_epoch_loss=2.563947\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:34 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=175 train loss <loss>=3.26470155716\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:34 INFO 139866244298560] Epoch[69] Batch [175]#011Speed: 586.57 samples/sec#011loss=3.264702\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:35 INFO 139866244298560] Epoch[69] Batch[180] avg_epoch_loss=2.583030\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:35 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=180 train loss <loss>=3.25476193428\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:35 INFO 139866244298560] Epoch[69] Batch [180]#011Speed: 475.00 samples/sec#011loss=3.254762\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:36 INFO 139866244298560] Epoch[69] Batch[185] avg_epoch_loss=2.605371\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=185 train loss <loss>=3.41411819458\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:36 INFO 139866244298560] Epoch[69] Batch [185]#011Speed: 591.48 samples/sec#011loss=3.414118\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:36 INFO 139866244298560] Epoch[69] Batch[190] avg_epoch_loss=2.611921\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:36 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=190 train loss <loss>=2.85557160378\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:36 INFO 139866244298560] Epoch[69] Batch [190]#011Speed: 479.25 samples/sec#011loss=2.855572\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:37 INFO 139866244298560] Epoch[69] Batch[195] avg_epoch_loss=2.610541\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:37 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=195 train loss <loss>=2.55779795647\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:37 INFO 139866244298560] Epoch[69] Batch [195]#011Speed: 594.15 samples/sec#011loss=2.557798\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:38 INFO 139866244298560] Epoch[69] Batch[200] avg_epoch_loss=2.612806\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=200 train loss <loss>=2.70162768364\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:38 INFO 139866244298560] Epoch[69] Batch [200]#011Speed: 479.28 samples/sec#011loss=2.701628\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:38 INFO 139866244298560] Epoch[69] Batch[205] avg_epoch_loss=2.612235\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:38 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=205 train loss <loss>=2.58924820423\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:38 INFO 139866244298560] Epoch[69] Batch [205]#011Speed: 538.78 samples/sec#011loss=2.589248\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:39 INFO 139866244298560] Epoch[69] Batch[210] avg_epoch_loss=2.604753\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=210 train loss <loss>=2.2965321064\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:39 INFO 139866244298560] Epoch[69] Batch [210]#011Speed: 469.78 samples/sec#011loss=2.296532\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:39 INFO 139866244298560] Epoch[69] Batch[215] avg_epoch_loss=2.598528\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:39 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=215 train loss <loss>=2.33580851555\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:39 INFO 139866244298560] Epoch[69] Batch [215]#011Speed: 588.40 samples/sec#011loss=2.335809\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:40 INFO 139866244298560] Epoch[69] Batch[220] avg_epoch_loss=2.602223\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:40 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=220 train loss <loss>=2.76184544563\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:40 INFO 139866244298560] Epoch[69] Batch [220]#011Speed: 464.91 samples/sec#011loss=2.761845\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:41 INFO 139866244298560] Epoch[69] Batch[225] avg_epoch_loss=2.602762\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=225 train loss <loss>=2.62660136223\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:41 INFO 139866244298560] Epoch[69] Batch [225]#011Speed: 583.48 samples/sec#011loss=2.626601\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:41 INFO 139866244298560] Epoch[69] Batch[230] avg_epoch_loss=2.612035\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:41 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=230 train loss <loss>=3.0311747551\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:41 INFO 139866244298560] Epoch[69] Batch [230]#011Speed: 478.73 samples/sec#011loss=3.031175\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:42 INFO 139866244298560] Epoch[69] Batch[235] avg_epoch_loss=2.623846\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=235 train loss <loss>=3.16951403618\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:42 INFO 139866244298560] Epoch[69] Batch [235]#011Speed: 598.96 samples/sec#011loss=3.169514\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:42 INFO 139866244298560] Epoch[69] Batch[240] avg_epoch_loss=2.640022\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:42 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=240 train loss <loss>=3.40353980064\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:42 INFO 139866244298560] Epoch[69] Batch [240]#011Speed: 484.26 samples/sec#011loss=3.403540\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:43 INFO 139866244298560] Epoch[69] Batch[245] avg_epoch_loss=2.657085\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:43 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=245 train loss <loss>=3.47949285507\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:43 INFO 139866244298560] Epoch[69] Batch [245]#011Speed: 530.63 samples/sec#011loss=3.479493\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:44 INFO 139866244298560] Epoch[69] Batch[250] avg_epoch_loss=2.662390\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=250 train loss <loss>=2.92340393066\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:44 INFO 139866244298560] Epoch[69] Batch [250]#011Speed: 475.40 samples/sec#011loss=2.923404\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:44 INFO 139866244298560] Epoch[69] Batch[255] avg_epoch_loss=2.664853\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:44 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=255 train loss <loss>=2.78850536346\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:44 INFO 139866244298560] Epoch[69] Batch [255]#011Speed: 479.97 samples/sec#011loss=2.788505\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:45 INFO 139866244298560] Epoch[69] Batch[260] avg_epoch_loss=2.661527\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:45 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=260 train loss <loss>=2.49125027657\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:45 INFO 139866244298560] Epoch[69] Batch [260]#011Speed: 579.46 samples/sec#011loss=2.491250\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] Epoch[69] Batch[265] avg_epoch_loss=2.666940\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, batch=265 train loss <loss>=2.9495010376\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] Epoch[69] Batch [265]#011Speed: 570.53 samples/sec#011loss=2.949501\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] processed a total of 17027 examples\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"update.time\": {\"count\": 1, \"max\": 32994.328022003174, \"sum\": 32994.328022003174, \"min\": 32994.328022003174}}, \"EndTime\": 1599444286.118391, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599444253.123393}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] #throughput_metric: host=algo-1, train throughput=516.056505489 records/second\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] #progress_metric: host=algo-1, completed 87 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] #quality_metric: host=algo-1, epoch=69, train loss <loss>=2.66733317473\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] loss did not improve\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] Loading parameters from best epoch (59)\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"state.deserialize.time\": {\"count\": 1, \"max\": 7.9498291015625, \"sum\": 7.9498291015625, \"min\": 7.9498291015625}}, \"EndTime\": 1599444286.127253, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599444286.118473}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] stopping training now\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] #progress_metric: host=algo-1, completed 100 % of epochs\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] Final loss: 2.64734417353 (occurred at epoch 59)\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] #quality_metric: host=algo-1, train final_loss <loss>=2.64734417353\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] Worker algo-1 finished training.\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 WARNING 139866244298560] wait_for_all_workers will not sync workers since the kv store is not running distributed\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] All workers finished. Serializing model for prediction.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"get_graph.time\": {\"count\": 1, \"max\": 125.01406669616699, \"sum\": 125.01406669616699, \"min\": 125.01406669616699}}, \"EndTime\": 1599444286.253208, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599444286.127303}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] Number of GPUs being used: 0\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"finalize.time\": {\"count\": 1, \"max\": 185.70590019226074, \"sum\": 185.70590019226074, \"min\": 185.70590019226074}}, \"EndTime\": 1599444286.31385, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599444286.253269}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] Serializing to /opt/ml/model/model_algo-1\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] Saved checkpoint to \"/opt/ml/model/model_algo-1-0000.params\"\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"model.serialize.time\": {\"count\": 1, \"max\": 10.381937026977539, \"sum\": 10.381937026977539, \"min\": 10.381937026977539}}, \"EndTime\": 1599444286.324335, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599444286.31391}\n",
      "\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] Successfully serialized the model for prediction.\u001b[0m\n",
      "\u001b[34m[09/07/2020 02:04:46 INFO 139866244298560] No test data passed, skipping evaluation.\u001b[0m\n",
      "\u001b[34m#metrics {\"Metrics\": {\"totaltime\": {\"count\": 1, \"max\": 2333865.8130168915, \"sum\": 2333865.8130168915, \"min\": 2333865.8130168915}, \"setuptime\": {\"count\": 1, \"max\": 9.898900985717773, \"sum\": 9.898900985717773, \"min\": 9.898900985717773}}, \"EndTime\": 1599444286.339471, \"Dimensions\": {\"Host\": \"algo-1\", \"Operation\": \"training\", \"Algorithm\": \"AWS/DeepAR\"}, \"StartTime\": 1599444286.324385}\n",
      "\u001b[0m\n",
      "\n",
      "2020-09-07 02:04:55 Uploading - Uploading generated training model\n",
      "2020-09-07 02:04:55 Completed - Training job completed\n",
      "Training seconds: 2388\n",
      "Billable seconds: 2388\n"
     ]
    }
   ],
   "source": [
    "data_channels = {\"train\": \"s3://\"+ s3_bucket + \"/\" + prefix + \"/train/train.json\"}\n",
    "\n",
    "estimator.fit(inputs=data_channels, wait=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------!"
     ]
    }
   ],
   "source": [
    "#deepAr-forecast-2020-09-07-01-20-27-189 is the name\n",
    "endpoint_name = sagemaker_session.endpoint_from_job(\n",
    "    job_name=\"deepAr-forecast-2020-09-07-01-20-27-189\",\n",
    "    initial_instance_count=1,\n",
    "    instance_type='ml.m4.xlarge',\n",
    "    deployment_image=image_name,\n",
    "    role=role)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto3.client('sagemaker').delete_endpoint(EndpointName = endpoint_name)\n",
    "#also delete the model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
