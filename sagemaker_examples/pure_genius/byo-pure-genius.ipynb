{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Heart failure is a common event caused by Cardiovascular Disease. The 12 variables can be used to predict mortality.\n",
    "### This is an example for bringing your own algorithm\n",
    "This notebook shows how to deploy your own container, this will show sklearn example, however do not deploy this way a sklearn model, use instead already containerized framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sagemaker as sage\n",
    "import boto3\n",
    "import os\n",
    "\n",
    "sess = sage.Session()\n",
    "role = sage.get_execution_role()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>anaemia</th>\n",
       "      <th>creatinine_phosphokinase</th>\n",
       "      <th>diabetes</th>\n",
       "      <th>ejection_fraction</th>\n",
       "      <th>high_blood_pressure</th>\n",
       "      <th>platelets</th>\n",
       "      <th>serum_creatinine</th>\n",
       "      <th>serum_sodium</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoking</th>\n",
       "      <th>time</th>\n",
       "      <th>DEATH_EVENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "      <td>582</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>265000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>7861</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>0</td>\n",
       "      <td>263358.03</td>\n",
       "      <td>1.1</td>\n",
       "      <td>136</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "      <td>146</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>162000.00</td>\n",
       "      <td>1.3</td>\n",
       "      <td>129</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50.0</td>\n",
       "      <td>1</td>\n",
       "      <td>111</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>210000.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>137</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>65.0</td>\n",
       "      <td>1</td>\n",
       "      <td>160</td>\n",
       "      <td>1</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>327000.00</td>\n",
       "      <td>2.7</td>\n",
       "      <td>116</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    age  anaemia  creatinine_phosphokinase  diabetes  ejection_fraction  \\\n",
       "0  75.0        0                       582         0                 20   \n",
       "1  55.0        0                      7861         0                 38   \n",
       "2  65.0        0                       146         0                 20   \n",
       "3  50.0        1                       111         0                 20   \n",
       "4  65.0        1                       160         1                 20   \n",
       "\n",
       "   high_blood_pressure  platelets  serum_creatinine  serum_sodium  sex  \\\n",
       "0                    1  265000.00               1.9           130    1   \n",
       "1                    0  263358.03               1.1           136    1   \n",
       "2                    0  162000.00               1.3           129    1   \n",
       "3                    0  210000.00               1.9           137    1   \n",
       "4                    0  327000.00               2.7           116    0   \n",
       "\n",
       "   smoking  time  DEATH_EVENT  \n",
       "0        0     4            1  \n",
       "1        0     6            1  \n",
       "2        1     7            1  \n",
       "3        0     7            1  \n",
       "4        0     8            1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"heart_failure.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "age                         0\n",
       "anaemia                     0\n",
       "creatinine_phosphokinase    0\n",
       "diabetes                    0\n",
       "ejection_fraction           0\n",
       "high_blood_pressure         0\n",
       "platelets                   0\n",
       "serum_creatinine            0\n",
       "serum_sodium                0\n",
       "sex                         0\n",
       "smoking                     0\n",
       "time                        0\n",
       "DEATH_EVENT                 0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DEATH_EVENT\n",
       "0    203\n",
       "1     96\n",
       "Name: age, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(\"DEATH_EVENT\")[\"age\"].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Since I made no changes I do not have to export the dataframe to a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use default bucket\n",
    "bucket = sess.default_bucket()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload data to input/data/training\n",
    "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join('tryouts/input/data/training', 'train.csv')).upload_file('heart_failure.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Containers\n",
    "\"It is like a virtual machine but lighter!\"<br>\n",
    "Software that packages up code and all its dependencies so the application runs quickly and reliably from one computing environment to another. Available for both Linux and Windows-based applications, containerized software will always run the same, regardless of the infraestructure. Is basically, packaging software into standarized units for development, shipment and deployment.<br>\n",
    "Containers are an abstraction at the app layer that packages code and dependencies together. Multiple containers can run on the same machine and share the OS kernel with other containers, each running as isolated processes in user space. Containers take up less space than VMs (container images are typically tens of MBs in size), can handle more applications and require fewer VMs and Operating systems:\n",
    "https://www.docker.com/resources/what-container.\n",
    "<br>\n",
    "Is more powerful than a virtual enviroment since it is completely independent from language.<br>\n",
    "Common **Docker commands** are:\n",
    "* docker pull\n",
    "* docker build\n",
    "* docker images\n",
    "* docker ps\n",
    "* docker rmi/rm\n",
    "* docker run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you open dockerfile you will see installation of flask, that is a web framework that handles requests. Gunicorn that is a HTTP server for Unix and Nginx that handles HTTP requests that manage the input/output of the container efficently."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### To test locally:\n",
    "#### I name the image pure-genius, feel free to name it as you want, just make sure to remember it.\n",
    "On the folder where dockerfile is run the following command:\n",
    "**docker build -t pure-genius .**<br>\n",
    "Once done, go to local_test folder, inside test_dir, go to **input/data/training** and store training dataset. After that run **train_local.sh** and **serve_local.sh**. Place your test file where your predict.sh for easy and run bash predict.sh name_of_file.csv text/csv. In my case I called payload.csv my file. Then **./predict.sh payload.csv text/csv**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use build_push.sh to build and push image to ECR\n",
    "ECR stands for Elastic Container Registry, is basically for storing docker containers. It aims to make easier for developers to store, manage and implement docker images.**ECR** is fully integrated with **ECS**. Run either ./build_push.sh or bash build_push.sh, both followed by the name you want to give to the image, this case I will call it **pure-genius**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inside Jupyter Labs you will find the **terminal service**, go inside your folder where storing all the info. Type command: **cd SageMaker** (remember you can take a look at all files inside your current directory with ls). And go inside the folder containing the Dockerfile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-09-09 01:57:55 Starting - Starting the training job...\n",
      "2020-09-09 01:57:57 Starting - Launching requested ML instances.........\n",
      "2020-09-09 01:59:33 Starting - Preparing the instances for training...\n",
      "2020-09-09 02:00:22 Downloading - Downloading input data\n",
      "2020-09-09 02:00:22 Training - Downloading the training image.....\n",
      "2020-09-09 02:01:16 Uploading - Uploading generated training model\n",
      "2020-09-09 02:01:16 Completed - Training job completed\n",
      "Training seconds: 68\n",
      "Billable seconds: 68\n"
     ]
    }
   ],
   "source": [
    "account = sess.boto_session.client('sts').get_caller_identity()['Account']\n",
    "region = sess.boto_session.region_name\n",
    "image = '{}.dkr.ecr.{}.amazonaws.com/pure-genius:latest'.format(account, region)\n",
    "\n",
    "#https://aws.amazon.com/sagemaker/pricing/\n",
    "#I will use default bucket to store input, model, output\n",
    "svm = sage.estimator.Estimator(image,\n",
    "                       role, 1, 'ml.m5.large',\n",
    "                       output_path=\"s3://{}/tryouts/model\".format(sess.default_bucket()),\n",
    "                       sagemaker_session=sess)\n",
    "\n",
    "svm.fit(\"s3://\" + bucket + \"/tryouts/input/data/training/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Will do a batch transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "output_folder = \"tryouts/output\"\n",
    "output_path=\"s3://{}/{}\".format(sess.default_bucket(), output_folder)\n",
    "\n",
    "transformer = svm.transformer(instance_count=1,\n",
    "                               instance_type='ml.m5.large',\n",
    "                               output_path=output_path,\n",
    "                               assemble_with='Line',\n",
    "                               accept='text/csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I will manually upload the test data from the test folder found here, call payload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s3://sagemaker-us-east-1-563718358426/tryouts/input/data/payload.csv'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = \"s3://{}/{}\".format(sess.default_bucket(), \"tryouts/input/data/payload.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "........................\n",
      "\u001b[32m2020-09-09T02:19:59.975:[sagemaker logs]: MaxConcurrentTransforms=1, MaxPayloadInMB=6, BatchStrategy=MULTI_RECORD\u001b[0m\n",
      "\u001b[34mStarting the inference server with 2 workers.\u001b[0m\n",
      "\u001b[34m2020/09/09 02:19:58 [crit] 10#10: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Sep/2020:02:19:58 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-09-09 02:19:59 +0000] [9] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[34m2020/09/09 02:19:59 [error] 10#10: *3 connect() to unix:/tmp/gunicorn.sock failed (111: Connection refused) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Sep/2020:02:19:59 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m[2020-09-09 02:19:59 +0000] [9] [INFO] Listening at: unix:/tmp/gunicorn.sock (9)\u001b[0m\n",
      "\u001b[34m[2020-09-09 02:19:59 +0000] [9] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[34m[2020-09-09 02:19:59 +0000] [14] [INFO] Booting worker with pid: 14\u001b[0m\n",
      "\u001b[34m[2020-09-09 02:19:59 +0000] [15] [INFO] Booting worker with pid: 15\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Sep/2020:02:19:59 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Sep/2020:02:19:59 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[34mInvoked with 299 records\u001b[0m\n",
      "\u001b[34m169.254.255.130 - - [09/Sep/2020:02:20:00 +0000] \"POST /invocations HTTP/1.1\" 200 598 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mStarting the inference server with 2 workers.\u001b[0m\n",
      "\u001b[35m2020/09/09 02:19:58 [crit] 10#10: *1 connect() to unix:/tmp/gunicorn.sock failed (2: No such file or directory) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Sep/2020:02:19:58 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2020-09-09 02:19:59 +0000] [9] [INFO] Starting gunicorn 19.10.0\u001b[0m\n",
      "\u001b[35m2020/09/09 02:19:59 [error] 10#10: *3 connect() to unix:/tmp/gunicorn.sock failed (111: Connection refused) while connecting to upstream, client: 169.254.255.130, server: , request: \"GET /ping HTTP/1.1\", upstream: \"http://unix:/tmp/gunicorn.sock:/ping\", host: \"169.254.255.131:8080\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Sep/2020:02:19:59 +0000] \"GET /ping HTTP/1.1\" 502 182 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m[2020-09-09 02:19:59 +0000] [9] [INFO] Listening at: unix:/tmp/gunicorn.sock (9)\u001b[0m\n",
      "\u001b[35m[2020-09-09 02:19:59 +0000] [9] [INFO] Using worker: gevent\u001b[0m\n",
      "\u001b[35m[2020-09-09 02:19:59 +0000] [14] [INFO] Booting worker with pid: 14\u001b[0m\n",
      "\u001b[35m[2020-09-09 02:19:59 +0000] [15] [INFO] Booting worker with pid: 15\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Sep/2020:02:19:59 +0000] \"GET /ping HTTP/1.1\" 200 1 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Sep/2020:02:19:59 +0000] \"GET /execution-parameters HTTP/1.1\" 404 2 \"-\" \"Go-http-client/1.1\"\u001b[0m\n",
      "\u001b[35mInvoked with 299 records\u001b[0m\n",
      "\u001b[35m169.254.255.130 - - [09/Sep/2020:02:20:00 +0000] \"POST /invocations HTTP/1.1\" 200 598 \"-\" \"Go-http-client/1.1\"\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "transformer.transform(data_test, content_type='text/csv', split_type='Line')\n",
    "transformer.wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
