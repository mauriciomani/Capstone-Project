{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import boto3\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.amazon.amazon_estimator import get_image_uri\n",
    "from sagemaker.session import s3_input, Session\n",
    "from sagemaker.predictor import csv_serializer, json_deserializer\n",
    "#Use instead of image uri\n",
    "#from sagemaker.xgboost.estimator import XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You will get the current AWS role you are working on\n",
    "role = get_execution_role()\n",
    "#The region you are working on\n",
    "region = boto3.Session().region_name\n",
    "bucket = \"sagemaker-us-east-1\"\n",
    "prefix = \"tryouts\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"train.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check capstone ipynb for more information on EDA and cleaning.\n",
    "In a nutshell below how to transform it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_title(string):\n",
    "    start = string.find(\",\")\n",
    "    end = string.find(\".\")\n",
    "    return(string[start +2:end].strip())\n",
    "df['title'] = df.Name.apply(find_title)\n",
    "df.title.replace({\n",
    "    \"Capt\": \"Crew\",\n",
    "    \"Col\": \"Crew\",\n",
    "    \"Major\": \"Crew\",\n",
    "    \"Jonkheer\": \"Royal\",\n",
    "    \"Don\": \"Royal\",\n",
    "    \"Sir\" : \"Royal\",\n",
    "    \"Dr\": \"Crew\",\n",
    "    \"Rev\": \"Crew\",\n",
    "    \"the Countess\":\"Royal\",\n",
    "    \"Mme\": \"Mrs\",\n",
    "    \"Mlle\": \"Miss\",\n",
    "    \"Ms\": \"Mrs\",\n",
    "    \"Mr\" : \"Mr\",\n",
    "    \"Mrs\" : \"Mrs\",\n",
    "    \"Miss\" : \"Miss\",\n",
    "    \"Master\" : \"Master\",\n",
    "    \"Lady\" : \"Royal\"}, inplace = True)\n",
    "\n",
    "df['Cabin'] = df.Cabin.str[0]\n",
    "df['young'] = (df.Age<=15).astype(int)\n",
    "df[\"family\"] = df.SibSp + df.Parch\n",
    "#Make sure target variable is your first column\n",
    "df = df[[\"Survived\", \"Pclass\", \"Sex\", \"Age\", \"family\", \"young\", \"Embarked\", \"title\"]]\n",
    "#our filling shall be done ater train-val split, however, for simplicty we will perform before\n",
    "df.fillna(value={\"Embarked\": df.Embarked.mode(), \"Cabin\": \"other\", \"Age\": df.Age.median()}, inplace = True)\n",
    "df = pd.get_dummies(df, columns=[\"Sex\", \"Embarked\", \"Pclass\", \"title\"], drop_first=True)\n",
    "train = df.sample(frac = 0.8, random_state = 12)\n",
    "test = df[~df.index.isin(train.index)]\n",
    "\n",
    "train.to_csv(\"train_transformation.csv\", index = False, header = False)\n",
    "test.to_csv(\"validation_transformation.csv\", index = False, header = False)\n",
    "\n",
    "#you do not have to create the buckets prior performing this\n",
    "train_loc = boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train', 'train.csv')).upload_file('train_transformation.csv')\n",
    "test_loc = boto3.Session().resource(\"s3\").Bucket(bucket).Object(os.path.join(prefix, \"validation\", \"test.csv\")).upload_file('validation_transformation.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n",
      "'s3_input' class will be renamed to 'TrainingInput' in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "#The above functions does not provide string location, so you have to do it manually.\n",
    "#Remember to create the bucket before the above and below operations\n",
    "train_loc = s3_input('s3://{}/{}/{}/'.format(bucket, prefix, 'train'), content_type=\"csv\")\n",
    "test_loc = s3_input(\"s3://{}/{}/{}/\".format(bucket, prefix, \"validation\"), content_type=\"csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Survived', 'Age', 'family', 'young', 'Sex_male', 'Embarked_Q',\n",
       "       'Embarked_S', 'Pclass_2', 'Pclass_3', 'title_Master', 'title_Miss',\n",
       "       'title_Mr', 'title_Mrs', 'title_Royal'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'get_image_uri' method will be deprecated in favor of 'ImageURIProvider' class in SageMaker Python SDK v2.\n",
      "Parameter image_name will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    }
   ],
   "source": [
    "output_path = 's3://{}/{}/model'.format(bucket, prefix)\n",
    "container = get_image_uri(region, 'xgboost', repo_version='1.0-1')\n",
    "\n",
    "#https://docs.aws.amazon.com/sagemaker/latest/dg/xgboost_hyperparameters.html\n",
    "hyperparameters = {\"max_depth\":\"5\", \n",
    "                   \"eta\":\"0.2\",\n",
    "                   \"gamma\":\"4\", \n",
    "                   \"min_child_weight\":\"6\", \n",
    "                   \"subsample\":\"0.7\", \n",
    "                   \"eval_metric\": \"error\",\n",
    "                   \"objective\":\"reg:logistic\", \n",
    "                   \"num_round\":\"50\"}\n",
    "\n",
    "#https://aws.amazon.com/sagemaker/pricing/instance-types/\n",
    "estimator = sagemaker.estimator.Estimator(image_name=container, \n",
    "                                          hyperparameters=hyperparameters,\n",
    "                                          role=role,\n",
    "                                          train_instance_count=1, \n",
    "                                          train_instance_type='ml.m5.large', \n",
    "                                          output_path=output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-08-22 18:09:23 Starting - Starting the training job...\n",
      "2020-08-22 18:09:25 Starting - Launching requested ML instances......\n",
      "2020-08-22 18:10:38 Starting - Preparing the instances for training......\n",
      "2020-08-22 18:11:28 Downloading - Downloading input data...\n",
      "2020-08-22 18:12:24 Training - Training image download completed. Training in progress.\n",
      "2020-08-22 18:12:24 Uploading - Uploading generated training model.\u001b[34mINFO:sagemaker-containers:Imported framework sagemaker_xgboost_container.training\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter eval_metric value error to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:Failed to parse hyperparameter objective value reg:logistic to Json.\u001b[0m\n",
      "\u001b[34mReturning the value itself\u001b[0m\n",
      "\u001b[34mINFO:sagemaker-containers:No GPUs detected (normal if no gpus installed)\u001b[0m\n",
      "\u001b[34mINFO:sagemaker_xgboost_container.training:Running XGBoost Sagemaker in algorithm mode\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[18:12:20] 713x13 matrix with 9269 entries loaded from /opt/ml/input/data/train?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Determined delimiter of CSV input is ','\u001b[0m\n",
      "\u001b[34m[18:12:20] 178x13 matrix with 2314 entries loaded from /opt/ml/input/data/validation?format=csv&label_column=0&delimiter=,\u001b[0m\n",
      "\u001b[34mINFO:root:Single node training.\u001b[0m\n",
      "\u001b[34mINFO:root:Train matrix has 713 rows\u001b[0m\n",
      "\u001b[34mINFO:root:Validation matrix has 178 rows\u001b[0m\n",
      "\u001b[34m[0]#011train-error:0.18513#011validation-error:0.14045\u001b[0m\n",
      "\u001b[34m[1]#011train-error:0.18513#011validation-error:0.14045\u001b[0m\n",
      "\u001b[34m[2]#011train-error:0.18513#011validation-error:0.14045\u001b[0m\n",
      "\u001b[34m[3]#011train-error:0.18654#011validation-error:0.15730\u001b[0m\n",
      "\u001b[34m[4]#011train-error:0.18654#011validation-error:0.15730\u001b[0m\n",
      "\u001b[34m[5]#011train-error:0.18373#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[6]#011train-error:0.18934#011validation-error:0.15730\u001b[0m\n",
      "\u001b[34m[7]#011train-error:0.18934#011validation-error:0.15730\u001b[0m\n",
      "\u001b[34m[8]#011train-error:0.17952#011validation-error:0.15168\u001b[0m\n",
      "\u001b[34m[9]#011train-error:0.16970#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[10]#011train-error:0.16970#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[11]#011train-error:0.17532#011validation-error:0.15730\u001b[0m\n",
      "\u001b[34m[12]#011train-error:0.17111#011validation-error:0.16292\u001b[0m\n",
      "\u001b[34m[13]#011train-error:0.17111#011validation-error:0.16292\u001b[0m\n",
      "\u001b[34m[14]#011train-error:0.16830#011validation-error:0.15168\u001b[0m\n",
      "\u001b[34m[15]#011train-error:0.16830#011validation-error:0.15168\u001b[0m\n",
      "\u001b[34m[16]#011train-error:0.16550#011validation-error:0.15168\u001b[0m\n",
      "\u001b[34m[17]#011train-error:0.16970#011validation-error:0.15168\u001b[0m\n",
      "\u001b[34m[18]#011train-error:0.16690#011validation-error:0.15168\u001b[0m\n",
      "\u001b[34m[19]#011train-error:0.16830#011validation-error:0.15168\u001b[0m\n",
      "\u001b[34m[20]#011train-error:0.16129#011validation-error:0.15168\u001b[0m\n",
      "\u001b[34m[21]#011train-error:0.15989#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[22]#011train-error:0.15989#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[23]#011train-error:0.15989#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[24]#011train-error:0.15989#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[25]#011train-error:0.15989#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[26]#011train-error:0.16129#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[27]#011train-error:0.16129#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[28]#011train-error:0.16129#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[29]#011train-error:0.16129#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[30]#011train-error:0.16409#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[31]#011train-error:0.16409#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[32]#011train-error:0.16409#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[33]#011train-error:0.16409#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[34]#011train-error:0.16409#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[35]#011train-error:0.16409#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[36]#011train-error:0.16409#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[37]#011train-error:0.15848#011validation-error:0.15168\u001b[0m\n",
      "\u001b[34m[38]#011train-error:0.15848#011validation-error:0.15730\u001b[0m\n",
      "\u001b[34m[39]#011train-error:0.15848#011validation-error:0.15730\u001b[0m\n",
      "\u001b[34m[40]#011train-error:0.15989#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[41]#011train-error:0.16129#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[42]#011train-error:0.16129#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[43]#011train-error:0.15989#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[44]#011train-error:0.16129#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[45]#011train-error:0.16129#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[46]#011train-error:0.16129#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[47]#011train-error:0.16409#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[48]#011train-error:0.16409#011validation-error:0.14607\u001b[0m\n",
      "\u001b[34m[49]#011train-error:0.16409#011validation-error:0.14607\u001b[0m\n",
      "\n",
      "2020-08-22 18:12:31 Completed - Training job completed\n",
      "Training seconds: 63\n",
      "Billable seconds: 63\n"
     ]
    }
   ],
   "source": [
    "estimator.fit({\"train\":train_loc, \"validation\":test_loc})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Parameter image will be renamed to image_uri in SageMaker Python SDK v2.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------!"
     ]
    }
   ],
   "source": [
    "predictor = estimator.deploy(initial_instance_count=1, instance_type=\"ml.m5.xlarge\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_kaggle = pd.read_csv(\"test.csv\")\n",
    "passenger = test_kaggle.PassengerId\n",
    "test_kaggle['title'] = test_kaggle.Name.apply(find_title)\n",
    "test_kaggle.title.replace({\n",
    "    \"Capt\": \"Crew\",\n",
    "    \"Col\": \"Crew\",\n",
    "    \"Major\": \"Crew\",\n",
    "    \"Jonkheer\": \"Royal\",\n",
    "    \"Don\": \"Royal\",\n",
    "    \"Sir\" : \"Royal\",\n",
    "    \"Dr\": \"Crew\",\n",
    "    \"Rev\": \"Crew\",\n",
    "    \"the Countess\":\"Royal\",\n",
    "    \"Mme\": \"Mrs\",\n",
    "    \"Mlle\": \"Miss\",\n",
    "    \"Ms\": \"Mrs\",\n",
    "    \"Mr\" : \"Mr\",\n",
    "    \"Mrs\" : \"Mrs\",\n",
    "    \"Miss\" : \"Miss\",\n",
    "    \"Master\" : \"Master\",\n",
    "    \"Lady\" : \"Royal\"}, inplace = True)\n",
    "test_kaggle['Cabin'] = test_kaggle.Cabin.str[0]\n",
    "test_kaggle['young'] = (test_kaggle.Age<=15).astype(int)\n",
    "test_kaggle[\"family\"] = test_kaggle.SibSp + test_kaggle.Parch\n",
    "#Make sure target variable is your first column\n",
    "test_kaggle = test_kaggle[[\"Pclass\", \"Sex\", \"Age\", \"family\", \"young\", \"Embarked\", \"title\"]]\n",
    "#our filling shall be done ater train-val split, however, for simplicty we will perform before\n",
    "test_kaggle.fillna(value={\"Embarked\": test_kaggle.Embarked.mode(), \"Cabin\": \"other\", \"Age\": test_kaggle.Age.median()}, inplace = True)\n",
    "test_kaggle = pd.get_dummies(test_kaggle, columns=[\"Sex\", \"Embarked\", \"Pclass\", \"title\"], drop_first=True)\n",
    "test_kaggle[\"title_Royal\"] = test_kaggle.title_Dona\n",
    "test_kaggle = test_kaggle.drop(\"title_Dona\", axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we are in observation number: 0\n",
      "we are in observation number: 100\n",
      "we are in observation number: 200\n",
      "we are in observation number: 300\n",
      "we are in observation number: 400\n"
     ]
    }
   ],
   "source": [
    "predictor.content_type = \"text/csv\"\n",
    "predictor.serializer = csv_serializer\n",
    "predictor.deserializer = None\n",
    "\n",
    "scores = []\n",
    "for obs in range(test_kaggle.shape[0]):\n",
    "    if obs % 100 == 0:\n",
    "        print(\"we are in observation number: {}\".format(obs))\n",
    "    else:\n",
    "        pass\n",
    "    prediction = predictor.predict([list(test_kaggle.iloc[obs])])\n",
    "    scores.append(float(prediction))\n",
    "scores = [1 if score > 0.5 else 0 for score in scores]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_output = passenger.to_frame()\n",
    "final_output[\"Survived\"] = scores\n",
    "final_output.to_csv(\"submission1.csv\", index = False, header = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "estimator.delete_endpoint() will be deprecated in SageMaker Python SDK v2. Please use the delete_endpoint() function on your predictor instead.\n"
     ]
    }
   ],
   "source": [
    "estimator.delete_endpoint()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
